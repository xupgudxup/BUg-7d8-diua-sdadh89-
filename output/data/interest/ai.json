[
  {
    "slug": "i-rarely-get-outside-scientists-ditch-fieldwork-in-the-age-of-ai",
    "title": "'I rarely get outside': scientists ditch fieldwork in the age of AI",
    "description": "In the race to embrace new technologies, some ecologists fear their field is losing touch with nature.",
    "fullText": "Tadeo Ramirez-Parada studied the timing of plant flowering for his PhD — but he didn’t touch a single petal. Instead, he developed a machine-learning algorithm to analyse the digitized captions of one million herbarium specimens, which showed him how flowering times are changing with rising temperatures.\n\nRamirez-Parada’s work has helped to solve an important mystery in ecology — showing that as temperatures change, plants shift their flowering times to cope with the heat, rather than adapting through natural selection1. Yet his work so far has been almost entirely computer-based. “I have had to do very little experimental or field work,” says Ramirez-Parada, who did his PhD at the University of California, Santa Barbara.\n\nRamirez-Parada’s work is typical of a change that is reaching into every part of ecology. Whatever scientists are analysing — digitized specimens, images of the natural world, DNA samples, or data streaming in from sensors — many are doing it indoors.\n\nThe technologies are creating a world that can be monitored at times, places and scales that were previously unimaginable. We are moving towards the “fully automated monitoring of ecological communities”, wrote Marc Besson, a marine scientist at the Sorbonne University Ocean Observatory in Banyuls-sur-Mer, France, in a 2022 paper2.\n\nMany ecologists say this revolution offers huge potential for understanding the biodiversity crisis and discerning patterns of global change.\n\nBut some ecologists are dismayed. They feel that the discipline is losing intimacy with its subject matter. They argue that field experience is in decline, and that this loss could lead to error, bias and oversimplification of results.\n\n“If it becomes a world where you don’t actually have to go out in order to become an ecologist, we kind of lose sight of what the actual world is like,” says Bill Sutherland, who studies conservation biology at the University of Cambridge, UK.\n\nLike scientists everywhere, ecologists are grappling with how to make the most of a torrent of data.\n\nNatural-history museums and herbariums around the world have digitized more than one billion specimens over the past few decades, some with accompanying DNA records.\n\nMeanwhile, citizen scientists and researchers alike have been feeding databases such as iNaturalist with hundreds of millions of observations, which are absorbed into the Global Biodiversity Information Facility (GBIF), a central database for natural history.\n\nThere is also a stream of data from sensors such as camera traps — which take pictures when activated by movement — microphones, animal-tracking devices, drones, satellites and DNA samplers.\n\nSuch sensors can run for years without intervention. Once, a remotely planted camera trap would eventually run out of power: now, the energy consumption of such a device is minimal and it can rely on solar or wind energy. Bandwidth is no longer an obstacle to data being transmitted 24 hours a day.\n\nAnd computer science is more than keeping up3. Artificial-intelligence systems are already identifying species from these data; they are also being used for more complicated tasks such as building species-distribution models and ancestry trees. Some ecologists predict that generative AI, which creates new content based on learning from huge data sets, will soon be able to make more complex models, leading the way to understanding ecological processes and forecasting how species will respond to environmental changes.\n\nThere are already at least 100 laboratories that would label their work as ‘AI for nature’, according to Tanya Berger-Wolf, a computational ecologist at the Ohio State University in Columbus.\n\nThe approach is starting to bear fruit. One European project, called CamAlien, is tracking invasive species using high-resolution cameras with machine-learning processing power, affixed to cars, boats and trains. As they speed along, they rapidly photograph the sides of roads and tracks, analyse the images in situ and upload alerts about alien invasive plants to a Europe-wide online map.\n\nThe system shows how, just in the past few years, new technologies combined with AI have “gone from mostly demonstrating potential to actually beginning to deliver real implementations”, says Toke Thomas Høye, an ecologist at Aarhus University in Denmark, who co-developed CamAlien. Some 16 European countries are trying out the technology to assess the distribution of invasive alien species.\n\nSimilarly, amid the steep declines in some insects, a consortium of researchers has finessed camera-trap technology, originally designed to spot mammals, so that it can identify and monitor insect species, which are much more numerous. Automated insect monitoring didn’t exist five years ago, says Høye. Thanks to developments in AI, scientists can distinguish between thousands of species.\n\n“It’s opening up a door to part of our natural world that is so much more diverse compared to what camera traps have been used for previously,” says Høye. He and his group think that making insect monitoring easier and less labour-intensive will shed light on the state of insect populations around the globe.\n\nAnother group has deployed a system of microphones in search of a more detailed understanding of migration as birds fly across Europe from Norway to the Mediterranean coast of Spain. Known as the TABMON project, it is now streaming real-time soundscape data, day and night. An AI tool analyses the data and converts them into commonly used biodiversity indicators.\n\n“Having standardized ecological data on continental scales is extremely rare,” says Sarab Sethi, who studies ecosystem sensing at Imperial College London, and led the design of the microphones, “especially when it’s on the fine-scale temporal resolution that acoustics gives, across a wide range of species, and across multiple years”. The project has yet to report its first results.\n\nFew would dispute the benefits of more data and detail, but there is an ominous side effect, says Kevin Gaston at the University of Exeter, UK, who studies people’s relationship with nature: field experience is on the wane.\n\nGaston and his co-author Masashi Soga, who studies the loss of human–nature interactions at the University of Tokyo, argued in a March 2025 paper4 that there has been an ‘extinction of experience’: a widespread decline in fieldwork-based research and education, with knock-on effects on the depth of ecological understanding. They also flagged other dangers, such as reduced engagement with local communities — a practice known to be crucial for successful conservation.\n\nOthers have expressed concern about ‘AI colonialism’, a practice in which data, collected remotely in poorer countries, are siphoned off for analysis in well-equipped labs elsewhere.\n\nThere are few quantitative data available to support or challenge Gaston and Soga’s argument. One analysis5 of ecological studies published between 1980 and 2014 found that fieldwork-based studies decreased by 20% (as a proportion of the total), whereas modelling and data analyses increased by 600% and 800%, respectively. But these are relative changes, rather than absolute numbers, and the data set ends more than a decade ago.\n\nAnecdotally, however, Gaston and Soga’s paper struck a nerve. Since publication, a number of groups have cited it while warning that a lack of outdoor research is hindering studies on subjects ranging from solitary bees to dinosaur fossils.\n\nThere’s also anecdotal evidence that more computer scientists have entered ecology, excited about what they can offer, but lacking field experience. That was the case for Berger-Wolf, considered a founder of computational ecology. She completed her PhD in theoretical computer science, but, being married to an ecologist, says she would chat to others in the ecology community and walk away “with a feeling like, oh, there’s got to be a different way of answering this question”.\n\nBerger-Wolf changed tack in 2003, and by 2005 was developing algorithms for dynamic network analysis to depict the social interactions of zebras in the Kenyan Serengeti. Field colleagues urged her to go and see her data but she always refused: “I’m a city girl. And I don’t like dust and bugs. And my answer was: ‘no, my data looks beautiful on my screen.’”\n\nSethi is another convert to ecology, having arrived in the field with an engineering background. In 2016, he decided to apply acoustic monitoring to ecology for his PhD — but the self-confessed metrophile quickly found himself out of his depth in a rainforest in Malaysian Borneo.\n\n“I did what I now realize was the extremely dumb thing of trying to develop a new technology and for its first deployment to be in a tropical forest on the other side of the world,” Sethi grins. On the first night, he lay under a mosquito net in a pitch-dark hut on stilts, wide awake, while his ecologist colleagues dozed comfortably amid the sounds of the rainforest. He remembers thinking: “My God, is this just like a joke that’s gone a bit too far?” Now he values his field experiences but works mostly from the lab.\n\nSome ecologists have gone the other way, coming in from outdoors to embrace big data. Laura Pollock at McGill University in Montreal, Canada, began her career as a field ecologist, first in the swamps of New Orleans, Louisiana, and then in isolated mountain regions in Australia. She saw a need for ecologists to do better data analysis, and now she uses machine learning to do predictive modelling of biodiversity across landscapes.\n\n“I rarely get outside,” she says. “I’m trying, but it’s really hard because there’s so much technology creating so much data that we need people who have these data-science skills to analyse this.”\n\nBut Besson has embraced technology without diminishing his hours in the field. He says that he is spending as much time outside as he did before automation arrived. “Cameras and hydrophones can capture things in addition to my own eyes and ears, and they can stay in the field when I need to go back to the lab ... and when I need to sleep.”\n\nThere are also many systemic forces driving ecologists indoors, argues Gaston.\n\nThere’s a widespread perception that funding for field studies is in decline — although the data are not often differentiated into grants for fieldwork versus those for lab-based projects. Scientists who run long-term ecological studies, in particular, report that they struggle to find funding.\n\nOther contributing forces include the fact that research institutes are increasingly in urban areas; that more scientists have childcare responsibilities that deter them from doing long or far-flung trips; that many feel the need to reduce their carbon footprint and that others want to avoid ‘helicoptering’ in and out of a country to do fieldwork that local scientists could do.\n\nAnother major issue, says Sutherland, is that the fast track to career-boosting publications is to analyse, rather than physically collect, data.\n\n“Supposing you do your PhD and you spend all your time doing fieldwork,” he says. “And the person sitting next to you has been extracting data [from day one]”. After three years, he says, they might have published in increasingly highly ranked journals, while “you’re still in the Amazon catching fish”.\n\ndoi: https://doi.org/10.1038/d41586-025-04150-w\n\nRamirez-Parada, T. H. et al. Nature Ecol. Evol. 8, 467–476 (2024).\n\nArticle \n PubMed \n\n Google Scholar\n\nBesson, M. et al. Ecol. Lett. 25, 2753–2775 (2022).\n\nArticle \n PubMed \n\n Google Scholar\n\nReynolds, S. A. et al. Trends Ecol. Evol. 40, 191–207 (2025).\n\nArticle \n PubMed \n\n Google Scholar\n\nSoga, M. & Gaston, K. J. Trends Ecol. Evol. 40, 212–215 (2025).\n\nArticle \n PubMed \n\n Google Scholar\n\nRíos-Saldaña, C. A., Delibes-Mateos, M. & Ferreira, C. C. Glob. Ecol. Conserv. 14, e00389 (2018).\n\nArticle \n\n Google Scholar\n\nRafiq, K. et al. Trends Ecol. Evol. 39, 1059–1062 (2024).\n\nArticle \n PubMed \n\n Google Scholar\n\nSethi, S. S. et al. Nature Ecol. Evol. 7, 1373–1378 (2023).\n\nArticle \n PubMed \n\n Google Scholar\n\nA framework for addressing racial and related inequities in conservation\n\nThe poetic life and death of a glow-worm\n\nPalaeometabolomes yield biological and ecological profiles at early human sites\n\nQuantifying the global eco-footprint of wearable healthcare electronics\n\n‘A serious problem’: peer reviews created using AI can avoid detection\n\nSeven feel-good science stories to restore your faith in 2025\n\nCMLR's goal is to advance machine learning-related research across a wide range of disciplines.\n\nCenter for Machine Learning Research (CMLR), Peking University\n\nUNIL is a leading international teaching and research institution, with over 5,000 employees and 17,500 students split between its Dorigny campus, ...\n\nUNIL is a leading international teaching and research institution, with over 5,000 employees and 17,500 students split between its Dorigny campus, ...\n\nUNIL is a leading international teaching and research institution, with over 5,000 employees and 17,500 students split between its Dorigny campus, ...\n\nUNIL is a leading international teaching and research institution, with over 5,000 employees and 17,500 students split between its Dorigny campus, ...",
    "readingTime": 11,
    "keywords": [
      "dorigny campus",
      "campus unil",
      "ecol evol",
      "pubmed google",
      "google scholar",
      "trends ecol",
      "nature ecol",
      "camera traps",
      "wide range",
      "students split"
    ],
    "qualityScore": 1,
    "link": "https://www.nature.com/articles/d41586-025-04150-w",
    "thumbnail_url": "https://media.nature.com/lw1200/magazine-assets/d41586-025-04150-w/d41586-025-04150-w_51839806.jpg",
    "created_at": "2026-01-08T12:25:20.391Z",
    "topic": "tech"
  },
  {
    "slug": "openai-has-launched-chatgpt-health-should-we-trust-it",
    "title": "OpenAI has launched ChatGPT Health. Should we trust it?",
    "description": "The new feature helps users understand test results, get advice on diets and workouts, and prepare for doctors’ appointments.",
    "fullText": "Amid rising concerns about people relying on ChatGPT for medical advice, OpenAI made its most significant push yet into health care.\n\nThe company has launched a new feature called ChatGPT Health, which allows users in the U.S. to connect their medical records and data from wellness apps and wearable devices with ChatGPT. The tool is designed to help users understand test results, get advice on diets and workouts, and prepare for doctors’ appointments.\n\nMore than 230 million people globally ask ChatGPT health and wellness-related questions every week, according to the company. ChatGPT Health is designed in collaboration with physicians and will “help people take a more active role in understanding and managing their health and wellness,” the company said in a post.\n\nOpenAI said it will look to expand access to the feature in markets such as India, Brazil, Mexico, and the Philippines, where adoption is rising quickly. In these countries, overburdened health-care systems and unequal access to doctors are leading more people to turn to generative AI for guidance.\n\n“We do not have the people, the labor to deliver the care we should,” Jesse Ehrenfeld, chief medical officer at Aidoc, an Israeli medical technology company, said at the Consumer Electronics Show in Las Vegas. “The only way out of this mess is digital and AI.”\n\nResearchers, ethicists, and medical professionals have warned of the risks to users from biases and hallucinations in AI systems. Concern over the mental health harms that AI chatbots pose is growing. Meta’s AI chatbots provided inappropriate advice to teenagers when talking about suicide and eating disorders, Common Sense Media, a nonprofit research organization, reported last year.\n\nThe family of a teenager who died by suicide has sued OpenAI and its chief executive officer Sam Altman, accusing them of wrongful death. The company said it has safeguards in place to help people, and that it continues to improve ChatGPT’s training.\n\nThere is also the question of data privacy. Health data, particularly information related to mental disease and substance use, is sensitive, and its misuse can leave users vulnerable.\n\nWhile consumer awareness about privacy has increased, people generally do not know how their data is being used, including for marketing purposes or for tracking, Sam Siegfried, a partner at law firm McDermott Will & Schulte, told Rest of World on the sidelines of CES.\n\n“The person clearly trusts an app enough to give it their data,” he said. “But they should understand what they are using the app for, and whether its data requests sync up with what they are using it for.”\n\nOpenAI said ChatGPT Health “builds on the strong privacy, security, and data controls across ChatGPT with additional, layered protections designed specifically for health — including purpose-built encryption and isolation to keep health conversations protected and compartmentalized.”\n\nThere is no stopping tech companies from entering the health sector.\n\nBesides turning to AI chatbots for health queries, people are also buying more wearable digital devices, including smartwatches, rings, bracelets, and glasses, to track physical activity, vital signs, and various physiological responses in real-time. They take this data to their doctors — or to ChatGPT — with questions on how to interpret it or use it to improve their health.\n\n“Health-related anxiety is real. AI is not as good as a doctor, but it’s better than no care at all,” Ami Bhatt, chief innovation officer at the American College of Cardiology, said at CES.\n\nOpenAI isn’t the only big tech company keen to tap the health-care sector.\n\nApple was among the first to offer health-tracking features in its smartwatch. There are millions of health-related videos on YouTube and TikTok, with nearly 60% of Americans watching health-related videos on YouTube.\n\nHealth is “one of the major use cases for Gemini,” Nichole Young-Lin, women’s health clinical lead at Google, said at CES.\n\n“People are using generative AI as a health resource around the world,” she said. “The patient-physician relationship is very important, but health-care access is not equal. Patients feel empowered with generative AI.”",
    "readingTime": 4,
    "keywords": [
      "health-related videos",
      "chatgpt health",
      "medical",
      "users",
      "advice",
      "care",
      "designed",
      "doctors",
      "access",
      "health-care"
    ],
    "qualityScore": 1,
    "link": "https://restofworld.org/2026/openai-has-launched-chatgpt-health-should-we-trust-it/",
    "thumbnail_url": "https://restofworld.org/wp-content/uploads/2026/01/ChatGPT-Health.jpg",
    "created_at": "2026-01-08T12:25:18.460Z",
    "topic": "tech"
  },
  {
    "slug": "ai-and-the-next-economy",
    "title": "AI and the Next Economy",
    "description": "The narrative from the AI labs is dazzling: build AGI, unlock astonishing productivity, and watch GDP surge. It’s a compelling story, especially if you’re the",
    "fullText": "The narrative from the AI labs is dazzling: build AGI, unlock astonishing productivity, and watch GDP surge. It’s a compelling story, especially if you’re the one building or investing in the new thought machines. But it skips the part that makes an economy an economy: circulation.\n\nAn economy is not simply production. It is production matched to demand, and demand requires broadly distributed purchasing power. When we forget that, we rediscover an old truth the hard way: You can’t build a prosperous society that leaves most people on the sidelines.\n\nIn The Marriage of Heaven and Hell, the visionary poet and painter William Blake (writing during the first Industrial Revolution) put the circulatory logic perfectly: “The Prolific would cease to be prolific unless the Devourer as a sea received the excess of his delights.” In other words: Output has to be consumed. The system has to flow.\n\nToday, many AGI narratives assume that the “prolific” can keep producing and the broad mass of customers (“the devourer”) somehow continue to buy, even as more and more human labor is displaced and labor income and bargaining power collapses. That’s not a future of abundance. It’s a recipe for a kind of congestive heart failure for the economy: Profits and capabilities accumulate in what should be the circulatory pump, while the rest of the body is starved.\n\nSo if we want an AI economy that makes society richer, we need to ask not just “How smart will the models get?” and “How rich will AI developers, their investors, and their immediate customers get?” but “How will the value circulate in the real economy of goods and services?” Not “What can we automate?” but “What new infrastructure and institutions are needed to turn capability into widely shared prosperity?”\n\nTwo versions of the future are often discussed as if they are separate. They’re not.\n\nI’m excited by the discovery potential of AI. It may help us solve problems that have defied us for decades: energy abundance, new materials, cures for diseases. As Nick Hanauer and Eric Beinhocker put it so well, “Prosperity is the accumulation of solutions to human problems.” That AI can grow the store of solutions to human problems is a wonderful dream, and it should be our goal to make it come true.\n\nBut discovery alone is not the same thing as economic value, and it certainly isn’t the same thing as widely shared prosperity. Between discovery and economic value lies a long, failure-prone pipeline: productization, validation, regulation, manufacturing, distribution, training, and maintenance. The valley of death is not a metaphor; it is a bureaucratic, technical, and financial landscape where many promising advances go to die. And from that valley of death, the path follows either an ascent to the broad uplands of shared prosperity, or a shortcut to a dead-end peak of wealth concentration.\n\nIf AI accelerates discovery but doesn’t accelerate diffusion, we get headlines and paper wealth, but broad-based growth takes much longer to arrive. We get a taller peak, not a wider plateau.\n\nThe distribution question begins with choke points. Who owns the discovery engines? Who controls access to compute, data, and the models themselves? Who captures the IP? Who has the channels to bring new capabilities to market? To what extent do incumbents and the moats they have built restrict innovation? Do government regulatory processes also speed up, or do they keep AI adoption at a glacial pace? Do those at the choke points use their market shaping power wisely? If those choke points are tight, the discovery economy becomes a kind of discovery feudalism: The breakthroughs happen, but the spillovers are limited, adoption is slow, and the returns concentrate.\n\nIf, on the other hand, the tools and standards of diffusion are broadly available, if interoperability is real, if licensing is designed for many routes to market, if regulatory processes can also be sped up with AI, then the discovery economy can become what we want it to be: a generalized engine of progress. There’s a huge amount of work to be done here.\n\nMany of the questions are economic. If discovery becomes cheap, does the rest of the pipeline get cheaper, or does it get more expensive to compensate for other lost revenue? The happy dream is that a cancer vaccine becomes available at the marginal cost of production. The unhappy reality may be that the drug manufacturers conclude “We have to price this high to make up for our losses from the existing drugs that people no longer need to buy.” Even in an age of cheap discovery, it is possible that some vaccines will still cost millions of dollars per dose and only be available to people who can afford them.\n\nThe other story is labor replacement. We are told that AI will substitute for a great deal of intellectual work, much as machines replaced animal labor and much of human manual labor. Businesses become more efficient. Margins rise. Output increases. Prices fall and spending power increases for those who are still employed.\n\nBut who are the customers when a large number of humans are suddenly no longer gainfully employed?\n\nThis is not a rhetorical question. It is the central macroeconomic constraint that much of Silicon Valley prefers not to model. You can’t replace wages with cheap inference and expect the consumer economy to hum along unchanged. If the wage share falls fast enough, the economy may become less stable. Social conflict rises. Politics turns punitive. Investment in long-term complements collapses. And the whole system starts behaving like a fragile rent-extraction machine rather than a durable engine of prosperity.\n\nIn a 2012 Harvard Business Review article, Michael Schrage asked a powerful strategic question: “Who do you want your customers to become?” As he put it, the answer to that question is the true foundation of great companies. “Successful companies have a ‘vision of the customer future’ that matters every bit as much as their vision of their products.”\n\nIn the early days of mass production, Henry Ford reportedly understood that if you want mass markets, you need mass purchasing power. He paid higher wages and reduced working hours, helping to invent what we now call the weekend, and with it, the leisure economy. The productivity dividend was distributed in ways that created new customers.\n\nFord’s innovation had consequences beyond the factory gate. Mass adoption of cars required a vast extension of infrastructure: roads, traffic rules, hotels, parking, gas stations, repair shops, and the entire social reorganization of distance. The technology mattered, but the complements made it an economy.\n\nSteven Johnson tells a related story in his book Wonderland. The preindustrial European desire for Indian calico and chintz helped catalyze modern shopping environments and global trade networks. But there’s even more to that story. When it became cheaper to make cloth, fashion, taste, and the democratization of status display became a larger part of the economy. The point is not “consumerism is good.” The point is that economies grow because desires and capabilities change as the result of innovations, infrastructure, and institutions that allow the benefits to spread. New forms of production require new systems of distribution, experience, and exchange.\n\nAI is at that inflection point now. We may be building the engines of extraordinary productivity, but we are not yet building the social machinery that will make that productivity broadly usable and broadly beneficial. We are just hoping that they somehow evolve.\n\nThis failure of insight and imagination is the Achilles’ heel of today’s AI giants. They imagine themselves as contestants in a race to be the next dominant platform, with the majority of the benefits going to whoever has the smartest model, the most users, and the most developers. This is not unlike the vision of Marc Andreessen’s Netscape in the early days of the web. Netscape sought to replace Microsoft Windows as the platform for users and developers, using the internet moment to become the next monopoly gatekeeper. Instead, victory went to those who embraced the web’s architecture of participation.\n\nNow, it is true that 30 years later, we are in a world where companies such as Google, Apple, Amazon, and Meta have indeed become gatekeepers, extracting huge economic rents via their control over human attention. But it didn’t start that way. Amazon and Google in particular rose to prominence because they solved the circulation problem. Amazon’s flywheel, in which more users draw in more suppliers with more and cheaper products, which in turn brings in more users, in a virtuous circle, is a great example of an economic circulation strategy. Not only did Amazon drive enormous consumer value, they created a whole new set of suppliers.\n\nSo too, Google’s original search engine strategy was also deeply rooted in the circulation of value. As Larry Page put it in 2004, “The portal strategy tries to own all of the information….We want to get you out of Google and to the right place as fast as possible.” The company’s algorithms for both search and ad relevance were a real advance in market coordination and shared value creation. Economists like Hal Varian were brought in to design advertising models that were better not only for Google but for its customers. Google grew along with the web economy it helped to create, not at its expense. Yes, that changed over time, but let’s not forget how important Google’s support for a circulatory economy was to its initial success.\n\nGoogle also provides a really good example of mechanism design to solve problems with rights holders that have economic lessons for today. When music companies sent takedown notices to YouTube for user-generated content that made unauthorized use of their IP, YouTube instead asked, “How about we help you monetize it instead?” In the process it created a new market.\n\nThe extent to which Amazon and Google seem to have forgotten these lessons is a sign of their decline, not something to be emulated. It provides an opportunity for those (including Google and Amazon, if they recommit to their roots!) who are building the next generation of technology platforms. Build a flywheel, enable a circulatory economy. AI should not be enshittified from the beginning, prioritizing value capture over broadly based value creation.\n\nAn important lesson from the internet technology revolution of the 1990s and early 2000s is that decentralized architectures are more innovative and more competitive than those that are centralized. Decentralization creates value; centralization captures it. The PC decentralized the computer industry, ending IBM’s chokehold on competition during the mainframe era. The new software industry exploded. Over the next few decades, as it became dominant, Microsoft recentralized the industry by monopolizing operating systems and office applications in the way that IBM had monopolized computer hardware. The personal computer software industry began to stagnate, until open source software and the open protocols of the internet undermined Microsoft’s centralized control over the industry and ushered in a new era of innovation.\n\nThe tragedy began again, as those who had once flourished as internet innovators in turn began to prioritize control, raising moats and extracting rents rather than continuing to innovate, leading to today’s internet oligopoly. This, of course, is what allowed the current AI revolution to happen as it did. Google invented the transformer architecture, and then published it freely, but did not itself fully explore the possibilities because it was protecting an existing business model. So it was left to OpenAI to invent the future.\n\nHowever, the AI revolution has a significant difference from the early internet. The U.S.’s current set up of large, closed models, enormous data centers for model training, and a highly concentrated cloud market has echoes of central planning, in which a small cadre of deep pocketed investors choose the winners at the outset rather than discovering them through a period of intense market competition and finding product-market fit (which involves finding products and services that users not only want but are willing to pay for at less than the cost of production!).\n\nMarket competition is important to ensuring that the economy is not reliant on a handful of firms reinvesting their profits into production. When this becomes the case, circulation can get cut off. Profits stop being reinvested and instead become hoarded, trapped within the sphere of financial circulation, from dividends to share buybacks to more dividends and less and less to investment in fixed or human capital.\n\nIf we are to realize the full potential of AI to reinvigorate and reinvent the economy, we need to embrace decentralized architectures. This might involve the triumph of lower-cost open weight models that commoditize and decentralize inference, and it also certainly entails protocols and technical infrastructure that can reduce the inherent concentrating tendencies of economies of scale and other technological moats that make concentration a more efficient mode of production.\n\nCentralization is an advantage in a mature economy; it is a disadvantage when you are trying to invent the future. Premature centralization is a mistake.\n\nIf AI labs wish to be architects of a prosperous future, they must work as hard on inventing the new economy’s circulatory system as they do on improving model capabilities. They need to measure success by diffusion, not just capability. They have to treat the labor transition as a core problem to be solved, not just studied. They have to be willing to win in the marketplace, not through artificial moats. That means committing to open interfaces, portability, and interoperability. General-purpose capabilities should not become a private toll road.\n\nCompanies adopting AI face their own challenges. Simply using AI to slash costs and turbocharge profits is a kind of failure. The productivity dividend should show up for employees not as a pink slip but as some combination of higher pay, reduced hours, profit-sharing, and investment in retraining. They must use the opportunity to reinvent themselves by creating new kinds of value that people will be eager to pay for, not just trying to preserve what they have.\n\nGovernments and society as a whole need to invest in the complements that will shape the new AI economy. Diffusion will be limited by the fragility of our energy grid, by bottlenecks in the supply of rare earths, but also by sclerotic approval processes for new construction or the approval of new innovations.\n\nGovernments must also develop scenarios for a future in which taxes on labor might provide a much smaller part of their income. Solutions are not obvious, and transitions will be hard, but if we face a future where capital appreciation is abundant and labor income is scarce, perhaps it’s time to consider reducing taxes on labor and increasing those on capital gains.\n\nOver the next few months, we intend to convene a series of conversations and to publish a series of more detailed action plans in each of these areas. Let me know if you think you have ideas to contribute.\n\nWe can build an AI economy that concentrates value, hollows out demand, and forces society into a reactive cycle of backlash and repair. Or we can build an AI economy that circulates, where discoveries diffuse, where productivity dividends translate into purchasing power and time, and where the complements are built fast enough that society becomes broadly more capable.\n\nAI labs like to say they are building intelligence. They are making good progress. But if they want to build prosperity, they also need to discover the flywheel for the AI economy.\n\nThe prolific needs the devourer. Not as a villain, not as an obstacle, but as the sea that receives the excess, and returns it, transformed, as the next wave of demand, innovation, and shared flourishing.",
    "readingTime": 14,
    "keywords": [
      "choke points",
      "regulatory processes",
      "decentralized architectures",
      "widely shared",
      "productivity dividend",
      "software industry",
      "shared prosperity",
      "market competition",
      "labor income",
      "circulatory economy"
    ],
    "qualityScore": 1,
    "link": "https://www.oreilly.com/radar/ai-and-the-next-economy/",
    "thumbnail_url": "https://www.oreilly.com/radar/wp-content/uploads/sites/3/2026/01/Light-waves-of-a-prosperous-economy-1600x1244.jpg",
    "created_at": "2026-01-08T12:25:17.744Z",
    "topic": "tech"
  },
  {
    "slug": "google-and-chatbot-startup-characterai-are-settling-lawsuits-over-teen-suicides",
    "title": "Google and chatbot startup Character.AI are settling lawsuits over teen suicides",
    "description": "Google and Character.AI have agreed to settle multiple lawsuits over chatbot-linked teen suicides.",
    "fullText": "Google and chatbot-building startup Character.AI have agreed to settle multiple lawsuits from families whose teenagers died by suicide or hurt themselves after interacting with Character.AI's chatbots.\n\nThese negotiations are among the first settlements in lawsuits that accuse AI tools of contributing to mental health crises and suicides among teenagers.\n\nOpenAI is facing a nearly identical lawsuit over the death of a 16-year-old, while Meta has come under scrutiny for letting its AI have provocative conversations with minors. As these companies race to develop and monetize their AI chatbots, they're spending big to make large language models sound more friendly and helpful, and ultimately keep users coming back.\n\nIn October 2024, Florida-based Megan Garcia filed a lawsuit against Character.AI, alleging that the company, which lets people have in-depth and personal conversations with AI chatbots, was responsible for the death of her 14-year-old son, Sewell Setzer III. He had died by suicide months earlier.\n\nA Wednesday court filing in the Garcia case said that an agreement was reached with Character.AI, its founders, Noam Shazeer and Daniel De Freitas, and Google. In 2024, the search giant hired the founders of Character.AI, who were former Google employees, and paid for non-exclusive rights to use the startup's technology. The startup remains a separate legal entity.\n\nThe terms of the settlements were not immediately available\n\nThe defendants have also settled four other similar cases in New York, Colorado, and Texas, according to court documents from this week.\n\nMatthew Bergman, the legal representative of the families, along with Google and Character.AI, did not immediately respond to Business Insider's requests for comment.\n\nGarcia's suit said that the startup failed to implement safety guardrails to prevent her son from developing an inappropriate and intimate relationship with its chatbots. The suit claimed that he was sexually solicited and abused by the technology, and the chatbot did not respond adequately when Setzer began talking about self-harm.\n\n\"When an adult does it, the mental and emotional harm exists. When a chatbot does it, the same mental and emotional harm exists,\" Garcia told Business Insider in an interview last year. \"So who's responsible for something that we've criminalized human beings doing to other human beings?\"",
    "readingTime": 2,
    "keywords": [
      "emotional harm",
      "harm exists",
      "human beings",
      "chatbots",
      "startup",
      "mental",
      "garcia",
      "lawsuits",
      "families",
      "teenagers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-character-ai-settling-lawsuits-teen-suicides-new-york-texas-2026-1",
    "thumbnail_url": "https://i.insider.com/695f25cc832e0ef1ead7623c?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.238Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-reshuffles-teams-to-bolster-github-as-ai-coding-and-agent-wars-heat-up",
    "title": "Microsoft reshuffles teams to bolster GitHub as AI coding and agent wars heat up",
    "description": "GitHub, the dominant software development platforms, is responding to the rise of AI coding services and AI agents",
    "fullText": "Microsoft wants to overhaul GitHub to compete with AI coding rivals and embrace AI agents, and the company has started reshuffling teams to make that happen, according to people familiar with the changes.\n\nGitHub is a leading software development platform that Microsoft acquired in 2018. GitHub had an early lead because of its popularity as a place to store code. Lately, though, GitHub has faced more competition from AI tools such as Cursor and Anthropic's Claude Code.\n\nMicrosoft in January 2025 formed a new group focused on building AI tools under ex-Facebook engineering boss Jay Parikh. The group, called CoreAI Platform and Tools, combined Microsoft's developer division, AI platform team, and GitHub.\n\nStill, Microsoft and GitHub have remained somewhat separate, and the company has been moving people and resources around over the past few months to better coordinate efforts such as sales, one of the people said. The latest change, happening this week, is moving a small group of Microsoft engineers over to GitHub.\n\nThe goal, the people said, is to better compete with AI coding tools that rival GitHub Copilot, while getting in the race to build AI agents and fulfill Parikh's vision to build an \"agent factory.\"\n\nIn an internal meeting late last year, Parikh spoke about needing to overhaul GitHub to compete with Cursor and Claude Code, according to audio reviewed by Business Insider.\n\n\"GitHub is just not the place anymore where developers are storing code,\" Parikh said at the time. \"We want it to be the center of gravity for all of AI-powered software development.\"\n\nMicrosoft wants GitHub's AI tools to be available wherever developers work, not just inside one app, to wants to make GitHub a kind of dashboard for managing multiple AI agents.\n\nThe latest changes are also part of what Parikh said would be new investment in improving the basic parts of GitHub. In the meeting, Parikh said those include making improvements to its GitHub Actions tool that automates building, testing, and deploying code, analytics and insights tools so teams can see how their code is performing, security for keeping the code safe, and making sure the company can meet local data storage rules to offer GitHub in new countries.\n\nHave a tip? Contact this reporter via email at astewart@businessinsider.com or Signal at +1-425-344-8242. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 2,
    "keywords": [
      "claude code",
      "software development",
      "overhaul github",
      "microsoft",
      "compete",
      "agents",
      "coding",
      "teams",
      "latest",
      "developers"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/microsoft-github-reshuffle-ai-coding-agents-2026-1",
    "thumbnail_url": "https://i.insider.com/695c2f3b832e0ef1ead73181?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.155Z",
    "topic": "finance"
  },
  {
    "slug": "ai-has-been-all-about-gpus-thats-changing-fast",
    "title": "AI has been all about GPUs. That's changing fast.",
    "description": "Nvidia's $20 billion Groq acquisition shows the AI industry moving from training to inference, with speed and efficiency now crucial.",
    "fullText": "For years, Nvidia's rise has been synonymous with one idea: GPUs are the engine of artificial intelligence. They powered the training boom that turned large language models from academic curiosities into trillion-dollar ambitions. But Nvidia's $20 billion deal with Groq is an admission that the next phase of AI won't be won by GPUs alone.\n\nGroq makes a very different type of AI chip called a Language Processing Unit, or LPU. To understand why Nvidia spent so much, and why it didn't simply build this technology itself, you have to look at where AI workloads are heading. The industry is moving from training models to running them in the real world. That shift has a name: inference.\n\nInference is what happens after a model is trained, when it answers questions, generates images, or carries on conversations with users. It's becoming the dominant task in AI computing, and could dwarf the training market in the future, according to estimates recently compiled by RBC Capital analysts.\n\nThis matters because inference has very different needs than training. Training is like building a brain: it requires massive amounts of raw computing power and flexibility. Inference is more like using that brain in real time. Speed, consistency, power efficiency, and cost per answer suddenly matter far more than brute force.\n\nThat's where Groq comes in. Founded by former Google engineers, Groq built its business around inference-only chips. Its LPUs are designed less like general-purpose factories and more like precision assembly lines. Every operation is planned in advance, executed in a fixed order, and repeated perfectly each time. That rigidity is a weakness for training, but a strength for inference, where predictability translates into lower latency and less wasted energy.\n\n\"The tectonic plates of the semiconductor industry just shifted again,\" Tony Fadell, creator of the iPod and an investor in Groq, wrote on LinkedIn recently. \"GPUs decisively won the first wave of AI data centers: training. But inference was always going to be the real volume game, and GPUs by design aren't optimized for it.\"\n\nFadell calls this new breed of AI chips \"IPUs,\" or Inference Processing Units.\n\nTD Cowen analysts noted this week that Nvidia's embrace of not just an inference-specific chip, but a whole new architecture, shows how large and mature the inference market has become.\n\nEarlier AI infrastructure investments were made based on training-first buying decisions. The adage used to be \"today's training chips are tomorrow's inference engines,\" which favored Nvidia's GPUs, but that's no longer the case, the analysts added.\n\nInstead, there will be an explosion of different chips inside future AI data centers, according to Chris Lattner, an industry visionary who helped develop the software for Google's TPU AI chips, which Groq founder Jonathan Ross co-designed.\n\nThis move beyond GPUs is being driven by two trends that have been reinforced by Nvidia's Groq deal, Lattner told me this week.\n\n\"The first is that 'AI' is not a single workload — there are lots of different workloads for inference and training,\" he said. \"The second is that hardware specialization leads to huge efficiency gains.\"\n\nIn a 2024 story (that aged very well), Business Insider warned readers that inference could be a vulnerability for Nvidia as rivals looked to fill this strategic gap. Cerebras built massive AI chips optimized for speed, claiming memory bandwidth thousands of times higher than Nvidia's flagship GPU offering at the time. Google's TPUs are designed to efficiently run bespoke AI workloads at blazing speeds. Amazon developed its own inference chip, Inferentia. Startups like Positron AI argued they could beat or match Nvidia's inference performance at a fraction of the cost.\n\nSo Nvidia's deal with Groq can be seen as a preemptive move. Rather than letting inference specialists chip away at its dominance, Nvidia chose to embrace a fundamentally different architecture.\n\nFadell described the deal as a \"humble move\" by Nvidia CEO Jensen Huang. \"Many companies miss inflection points like this due to 'Not Invented Here- driven egos,\" Fadell added. \"Jensen doesn't; he saw the threat and made it work to his advantage.\"\n\nThe economics are compelling. Inference is where AI products make money. It's the phase that proves whether hundreds of billions of dollars spent on data centers will ever pay off. As AWS CEO Matt Garman put it in 2024, if inference doesn't dominate, \"all this investment in these big models isn't really going to pay off.\"\n\nImportantly, Nvidia isn't betting on a single winner. GPUs will still handle training and flexible workloads. Specialized chips like Groq's will handle fast, real-time inference. Nvidia's advantage lies in owning the connective tissue — the software, networking, and developer ecosystem that lets these components work together.\n\n\"AI datacenters are becoming hybrid environments where GPUs and custom ASICs operate side-by-side, each optimized for different workload types,\" RBC analysts wrote in a recent note, referring to Application-Specific Integrated Circuits such as Groq's LPUs.\n\nSome competitors argue the deal proves GPUs are ill-suited for high-speed inference. Others see it as validation of a more fragmented future, where different chips serve different needs. Nvidia's Huang appears firmly in the second camp. By licensing Groq's technology and bringing its team inside the tent, Nvidia ensures it can offer customers both the shovels and the assembly lines of AI.\n\nIndeed, Nvidia has developed an NVLink Fusion technology that lets other custom chips connect directly to its GPUs, reinforcing this mixed-hardware future, the RBC Capital analysts noted.\n\n\"GPUs are phenomenal accelerators,\" Andrew Feldman, CEO of Cerebras, wrote recently. \"They've gotten us far in AI. They're just not the right machine for high-speed inference. And there are other architectures that are. And Nvidia has just spent $20B to corroborate this.\"\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "capital analysts",
      "high-speed inference",
      "rbc capital",
      "training",
      "chips",
      "deal",
      "chip",
      "workloads",
      "gpus",
      "nvidia's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-groq-gpus-ipus-hot-commodity-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/695eacd104eda4732f2ea721?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.152Z",
    "topic": "finance"
  },
  {
    "slug": "im-a-senior-software-engineer-at-microsoft-my-ai-skills-have-helped-me-climb-the-ladder-in-my-career-heres-my-advice",
    "title": "I'm a senior software engineer at Microsoft. My AI skills have helped me climb the ladder in my career — here's my advice.",
    "description": "Nandita Giri is a senior software engineer with experience at Amazon, Meta, and Microsoft. She recommends job seekers spend an hour a day learning AI.",
    "fullText": "This as-told-to essay is based on a conversation with Nandita Giri, a 32-year-old software engineer at Microsoft in Redmond, Washington. It has been edited for length and clarity.\n\nMy journey began with problem-solving and math long before I knew I'd end up in Big Tech.\n\nI studied at the National Institute of Technology, Kurukshetra, in India. Amazon, Microsoft, and Google often scout talent from this school.\n\nAmazon hired me straight out of college, and I moved to Seattle in 2018. To get the job, there was a logical analysis test, and only a handful of us passed. Then came multiple interviews based on problem-solving. That's how my journey in tech began.\n\nI'm now a senior software engineer at Microsoft, and my AI skills are in high demand.\n\nWhen applying for roles at Amazon, it's not about solving problems as quickly as possible, but solving them optimally. You must carefully consider the issue so that the solution can scale and be easily maintained. Amazon has a set of leadership principles that play a key role in hiring decisions, and understanding these principles is just as important as your coding skills.\n\nOn my own time, I practiced on LeetCode, a platform for coding challenges, because I liked it, not because I was preparing for interviews. Over time, I developed a strong interest in AI.\n\nOnce I arrived at Amazon, I identified tasks and patterns that could be automated and suggested AI-based solutions to management, primarily focusing on internal workflow automation and data-driven decision support systems. That experience shaped my interest in building intelligent tools for enterprise use. Leadership gave me the green light to implement them, and I successfully integrated AI into our team's workflow.\n\nAfter working at Amazon for about four years, a recruiter from Meta contacted me on LinkedIn. I never aimed to work at Meta, but my skills opened up new opportunities. I wanted to work more deeply in applied AI, and Meta offered an opportunity to focus on building intelligent systems with large-scale data and infrastructure. It was a natural next step to grow in the AI space.\n\nI went through the interview process, secured the job, and began working at Meta in 2022.\n\nI was referred internally to Microsoft based on my work at Meta. I decided to move because I wanted to work on enterprise-focused AI products, such as Copilot, which aligns more closely with my long-term interests in building impactful tools for productivity and business transformation. I've been at Microsoft since 2023.\n\nThroughout my career, I've had multiple competitive opportunities. With each role change, my scope of responsibility, impact, and overall compensation increased.\n\nMost of what I know about AI, I taught myself. I spent hours outside work watching YouTube tutorials, reading blogs, and practicing. I started small, creating AI agents for personal tasks, like sending outreach emails. Tasks that used to take me a day or two can now be completed in under an hour.\n\nSeeing those results motivated me to keep learning. What started as a personal side project has now become a central part of my career.\n\nAmazon and Meta both incorporate fast-paced learning, but Meta's codebase is more straightforward. Facebook, Instagram, and WhatsApp are all built from a single repository, allowing you to understand the system more quickly.\n\nAmazon's codebase is huge, which makes the first year challenging, but the learning curve is worth it. Microsoft feels different altogether. It's more enterprise-focused, operating at a massive scale.\n\nAI excels at repetitive or static tasks, and our job is to monitor and guide it. Managing AI, I believe, is the future of software engineering.\n\nDemand for AI roles is skyrocketing, while traditional software engineering roles have shrunk over the last five years. Many of my friends who don't work in AI have struggled to land new offers.\n\nI recommend dedicating just one hour a day to learning AI. Within six months, you'll see real progress, and these skills will be critical for the next decade. For beginners, I recommend the following:\n\nIf I were to advise my younger self, I would tell her to focus less on perfection and more on making an impact, to take ownership early, speak up with confidence, and prioritize learning and growth over titles.\n\nLong-term growth comes from solving meaningful problems and maintaining resilience.",
    "readingTime": 4,
    "keywords": [
      "software engineer",
      "software engineering",
      "microsoft",
      "learning",
      "skills",
      "tasks",
      "based",
      "roles",
      "solving",
      "amazon"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/senior-software-engineer-microsoft-ai-not-threat-2026-1",
    "thumbnail_url": "https://i.insider.com/695e9d35832e0ef1ead7571e?width=1024&format=jpeg",
    "created_at": "2026-01-08T12:25:17.151Z",
    "topic": "tech"
  },
  {
    "slug": "im-a-startup-founder-who-uses-ai-as-a-middle-manager-it-enables-my-junior-employee-to-produce-seniorlevel-work",
    "title": "I'm a startup founder who uses AI as a middle manager. It enables my junior employee to produce senior-level work.",
    "description": "Forage, an AI-powered startup, leverages AI as a middle manager to amplify its junior employee's productivity and learning with minimal supervision.",
    "fullText": "This as-told-to essay is based on a conversation with Charles Swann, a 44-year-old founder of an AI startup based in Boulder, CO. The following has been edited for length and clarity.\n\nI founded my startup, Forage, around 18 months ago. Besides myself, I have one full-time employee who has been with the company for eight months.\n\nMy business is in the marketing technology space, and I needed someone with a deep connection to modern culture and social media. So, I hired a 24-year-old growth and brand specialist from my neighborhood. She's a college graduate with less than two years of experience, whom I started mentoring.\n\nThe challenge with hiring someone more junior is that they often lack the skills to translate their intuition into a business strategy. But over the last six months, especially since the launch of Gemini 3, we've been able to leverage AI to significantly expand the capabilities of my junior employee.\n\nWe work in the marketing technology space, helping brands understand the trends happening on social media.\n\nMy junior employee has a very intuitive understanding of what influencer and brand relationships should look like, as well as how brands should present themselves on social media.\n\nWhen she first used AI in this role, she used ChatGPT to refine her product strategy. ChatGPT was great at taking her rough ideas, refining the concepts, and then writing out the details. As we began using Gemini more frequently, the role AI played in our workflow shifted from refining to co-creating product strategy.\n\nThe increased strategic capabilities in Gemini 3 are subtle, but they make a big difference because that strategic perspective is what young professionals often miss.\n\nMy growth and brand specialist had no prior experience writing a product requirements document before getting this role. Without AI, creating this document is a heavy lift. It's essentially the initial blueprint for a new product feature, translating a business idea into the technical instructions needed to build it.\n\nWriting this type of document for complex features typically would take a skilled product manager eight to 10 hours to get it right. With Gemini, my employee can do this in four to five hours.\n\nGemini 3 has been a significant step forward. Before using it, I had the idea that we should create 70% of the final product, and AI should generate 30%. Now, it's probably 40% us and 60% Gemini, simply because it's so good at expanding and expediting.\n\nWith younger career professionals, sometimes there's a light switch that clicks, and they know what it's like to be a leader, take ownership of something, and start running with their ideas.\n\nMy employee has really demonstrated that growth. This occurred at the same time she became more sophisticated in her use of AI.\n\nAI now serves as that middle layer, helping her level up the work she produces. I hesitate to say that AI alone has allowed me to have less supervision, but as she started getting more sophisticated in her use of the AI tool, I've spent less time reviewing in detail what she's generating and more time focused on the big-picture strategy questions.\n\nThere's always a risk in relying on AI to teach my employee how to gain years of experience in seconds. Hallucinations and feedback loops can occur if someone doesn't have the experience to know when to redirect.\n\nWhat I've done to help safeguard us is create a collection of prompt starters that include a detailed background on what our platform does, the features, and how to define it, which I can copy and paste into the chat. That's been a giant time saver and helps keep it focused on relevant context.\n\nHowever, I think running into possible mistakes or hallucinations is better than moving slowly. I would rather have those mistakes come up, and we have to course correct, than not be able to move at the pace we are.\n\nAI removes some of the traditional requirements around skills and expertise I need to see in candidates. It allows me to focus more on the raw intelligence, ambition, and drive.\n\nWith my company, I'm definitely bullish on the idea that brands will need the ability to authentically understand and reflect culture more than ever before, even in an AI-driven world, to survive. That type of intuitive knowledge resides with a different group of people than those my age, in their 40s, might be able to deliver.\n\nSo, I'm less concerned with whether my employee has been in the marketing industry for 10 years and more concerned with whether they have a deep understanding of the problem we're trying to solve.\n\nI believe this hiring mindset will only grow as AI continues to transform the workforce.\n\nDo you operate a tiny team and want to share your story? Please reach out to this editor, Agnes Applegate, at aapplegate@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "technology space",
      "marketing technology",
      "social media",
      "brand specialist",
      "junior employee",
      "product strategy",
      "less",
      "experience",
      "it's",
      "business"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/founder-hired-one-employee-uses-ai-as-middle-manager-2026-01",
    "thumbnail_url": "https://i.insider.com/6954148b832e0ef1ead6f50c?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.035Z",
    "topic": "finance"
  },
  {
    "slug": "this-is-the-key-breakthrough-ai-still-requires-to-reach-superintelligence-according-to-those-building-it",
    "title": "This is the key breakthrough AI still requires to reach superintelligence, according to those building it",
    "description": "AI's memory capacity is still limited. Solving that may be the key to unlocking superintelligence.",
    "fullText": "In humans, working memory — our ability to hold and use information in everyday life — is closely linked to general intelligence.\n\nThat means the ability for AI to remember things could be the key to realizing a superintelligent AI, a still theoretical version of AI that reasons as well or better than humans.\n\nOpenAI CEO Sam Altman thinks it's hard to predict just how intelligent AI can really be because the possibilities of memory retention are limitless.\n\n\"Even if you have the world's best personal assistant, they don't, they can't remember every word you've ever said in your life, they can't have read every email, they can't have read every document you've ever written, they can't be looking at all your work every day and remembering every little detail, they can't be a participant in your life to that degree. No human has like infinite, perfect memory,\" Altman said recently on the \"Big Technology\" podcast.\n\nAI, however, will definitely have the capacity for that, he said.\n\n\"Right now, memory is still very crude, very early,\" he said. Once AI is able to remember every granular detail of a user's life, including even the small preferences they didn't explicitly indicate, it will be \"super powerful,\" he said.\n\nAltman added that it's one of the future features he's most excited about — and he's not the only one.\n\nAndrew Pignanelli, the cofounder of The General Intelligence Company of New York, a company that builds AI agents for businesses, said that memory will become the biggest focus for AI companies in the coming year.\n\n\"It will become the most important topic discussed and recognized as the final step before AGI,\" Pignanelli wrote in a blog post. \"Every model provider will add and improve on memory for their apps after seeing OpenAI's success with ChatGPT memory (like Claude just did).\"\n\nPignanelli, however, said that the industry is still a long way from perfecting long-term memory.\n\n\"Larger context windows continue to improve things, as they allow more data to be passed into the context window, which allows the agent to better read parts of a large memory index,\" he wrote, in reference to the amount of information a large language model can process in a single prompt. \"Even then, though, the vast level of detail that we need to reach to consider something AGI requires memory architecture improvements.\"\n\nEven shorter-term episodic memory hasn't been fully solved yet, he said.\n\nSolving that memory problem is the ticket to turning AI from something that feels artificial to something that seems human, he said.\n\n\"Our systems today get the interaction part right. In terms of a Turing test for interaction, we're basically all the way there. But that's only half of what's needed to make a digital self,\" he wrote.\n\n\"The first AGI will be a very intelligent processor combined with a very good memory system,\" he said.",
    "readingTime": 3,
    "keywords": [
      "you've ever",
      "memory",
      "can't",
      "life",
      "detail",
      "humans",
      "ability",
      "intelligence",
      "it's",
      "intelligent"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/superintelligent-ai-memory-sam-altman-2026-1",
    "thumbnail_url": "https://i.insider.com/694c74c404eda4732f2e1d59?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.019Z",
    "topic": "finance"
  },
  {
    "slug": "im-the-cmo-at-cluely-here-are-3-things-that-work-in-a-cold-reachout-and-what-definitely-doesnt",
    "title": "I'm the CMO at Cluely. Here are 3 things that work in a cold reach-out — and what definitely doesn't.",
    "description": "Daniel Min, the 22-year-old CMO at AI startup Cluely, warns against making the mistake that he used to make when networking.",
    "fullText": "This as-told-to essay is based on a conversation with Daniel Min, the chief marketing officer at viral AI \"cheating\" startup Cluely. He's based in New York City. The following has been edited for length and clarity.\n\nWhen I was 18, people would tell me to reach out to as many people as possible because they would view me as young and eager, and they would want to take a chance on me.\n\nSo I did a lot of outreach that looked like the kind of messages I receive now: \"Hey, I'm 18. I really admire the work that you do. Would love to just hop on a 15-minute chat with you and learn more about you.\"\n\nI'm not surprised I was ghosted most of the time.\n\nThere's a difference between wanting to hop on a chat and wanting a job from someone, but even the people I was just trying to chat with would not respond to me most of the time — and it's because of two main things.\n\nFirst, I realized that 15-minute chats are incredibly taxing and they ruin my workflow.\n\nThe second thing I realized is that when I would reach out for jobs, I would communicate that I didn't know what I was good at. I would say things like, \"I'm willing to do anything. I'm willing to work for free.\" Most of the time they would ghost me because my message showed that I had no idea what I was doing.\n\nI thought they would think I'm an eager young buck, who's just trying my best and who's willing to work hard. Now that I'm on the other side, I know that if I took a chance on that student who's willing to do anything, it would take me a lot of work to onboard them, and probably cause me more pain.\n\nI know that what they want out of this experience is to learn from me. So I would need to invest time, and I don't want to hire somebody and give them a poor experience.\n\nI used to think it was risk-free for someone to take a chance on me. But over time, I realized it's high risk because they're going to invest significant amounts of time.\n\nI have a soft spot for students who say that they're kind of lost and thinking about going into a startup. I'll always at least respond to them and say, \"hey, keep your head up, and try this thing.\"\n\nIf you want to send better outreach, first, tell me what you can do. Two, don't tell me what you want to learn; show me how you can help me. And three, if you don't have the skills yet, develop them and reach out again.\n\nI haven't responded to a lot of cold outreaches, but I'll take calls here and there, usually if it's through warm intros. I've told about 20 people that if they post every day for 60 days and send me a message, I will look over their content.\n\nNot a single person has ever done that. If they're not willing to put in 60 days worth of work into something they really care about, why is it worth it? I want to know that if I hop on a call with someone and give them advice, they're going to run far with it.\n\nThat's pretty much exactly what my editor did for me. He made a whole YouTube video demonstrating that he really cares and that he's watched every single one of my videos. I asked him to edit an example video and create a Google Doc of things he thinks I could film better, and he wrote a six-page document with timestamps on exactly what I should do.\n\nAfter that, I knew he was somebody who goes above and beyond. I hired him as my part-time editor at the time, and when I joined Cluely, one of my negotiation points was that he needed to be there with me. He's no longer my editor, but now he's a full-time employee at the startup. His journey is inspiring because he took a shot and showed he could provide value.\n\nMaybe someone isn't great yet when they reach out, but I want to know that if I put hours of effort into someone, they'll learn quickly and become great.\n\nIt's also effective to send links if you're doing a cold outreach. Someone could say they generated 50 million views and I wouldn't believe them. If they send me a link — which hopefully isn't malware — I will always click on it. If I was to look for a job right now, I would link everything I've done.",
    "readingTime": 4,
    "keywords": [
      "i'm willing",
      "who's willing",
      "someone",
      "learn",
      "it's",
      "they're",
      "startup",
      "chance",
      "outreach",
      "chat"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/cmo-cluely-shares-what-works-cold-outreach-2026-1",
    "thumbnail_url": "https://i.insider.com/695d713404eda4732f2e950f?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:17.017Z",
    "topic": "finance"
  },
  {
    "slug": "retail-trader-hero-eric-jackson-says-investors-missed-the-big-takeaway-from-jensen-huangs-ces-talk",
    "title": "Retail trader hero Eric Jackson says investors missed the big takeaway from Jensen Huang's CES talk",
    "description": "Jackson said that faster chips aren't the big news from Jensen Huang's talk. Instead, the shifting nature of AI infrastructure is the key takeaway.",
    "fullText": "Nvidia CEO Jensen Huang kicked off the new year by giving investors some key product updates at CES 2026, drumming up fresh bullishness about the chip titan's business.\n\nAt the high-profile industry event, Huang revealed that production has begun on Rubin, its six-chip AI platform and the follow-up to the popular Blackwell architecture.\n\nThe talk generated a lot of buzz about the future of AI demand and Nvidia's business outlook, but hedge fund manager Eric Jackson argues that the most important takeaway from the talk is much bigger than innovations in chip tech.\n\nJackson, who helped spur rallies in several stocks followed by retail traders last year, said that he thinks many investors missed the key takeaway from the event. In his view, the most important thing isn't that faster or more advanced chips are coming; it is that AI is being built as a utility-scale infrastructure designed to operate for decades.\n\n\"Most people watched NVIDIA's CES keynote and heard 'faster chips,''\" he said. \"That wasn't the message. The real takeaway was this: AI factories are now being planned years in advance — at the land, power, and shell level.\"\n\nIn short, he thinks these statements mean that AI is being treated like electricity or telecom networks, a technology that will serve as a fundamental part of everyday life.\n\n\"The CES + JPM conversations made it clear: AI factories are being planned like utilities — not experiments,\" Jackson noted. \"That changes the slope.\"\n\nAs he sees it, the shifting industry landscape is poised to create more efficient AI production, which will lead to more demand for it through new use cases.\n\nThe investor highlighted the Jevons Paradox, an economic adage that argues that when a resource becomes more efficient to use, people consume it more, not less, despite assumptions. Economist William Stanley Jevons first introduced it in the 19th century to illustrate the growing dependence on coal.\n\n\"The market's obsession with 'capex slowing' misses the point,\" Jackson added. \"If inference + agents + long-context workloads are compounding, power becomes monetizable for longer, not shorter.\"\n\nJackson added that recent AI market developments are feeding his bullish thesis on small-cap tech stocks like Hut 8, IREN, and Cipher Mining, as all three stand to benefit from an economy increasingly powered by AI.\n\n\"Most investors still ask: 'Is AI demand peaking?'\" he wrote. \"The better question now is: Who can deliver reliable power and uptime as AI becomes permanent?\"",
    "readingTime": 3,
    "keywords": [
      "investors",
      "demand",
      "takeaway",
      "chip",
      "business",
      "industry",
      "event",
      "production",
      "talk",
      "argues"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/nvidia-jensen-huang-eric-jackson-ces-rubin-ai-chips-infrastructure-2026-1",
    "thumbnail_url": "https://i.insider.com/695ec0f704eda4732f2eaa3c?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:16.935Z",
    "topic": "finance"
  },
  {
    "slug": "ai-is-turning-expertise-into-a-commodity-box-ceo-says-theres-one-way-companies-can-stay-ahead",
    "title": "AI is turning expertise into a commodity. Box CEO says there's one way companies can stay ahead.",
    "description": "Box CEO Aaron Levie says AI will make expert knowledge widely available, leaving companies to compete on data, context, and how they deploy AI agents.",
    "fullText": "AI is rapidly turning expert knowledge into a commodity — and that shift will force companies to rethink what actually gives them a competitive edge, according to Box CEO Aaron Levie.\n\nIn a LinkedIn post this week, the cofounder and CEO of cloud-storage giant Box said that AI models are becoming capable of performing high-level knowledge work across nearly every profession, from law and medicine to strategy and scientific research.\n\nAs those tools evolve into autonomous AI agents, he said, expert intelligence will no longer be scarce.\n\n\"The question that we will have to wrestle with is, in a world where everyone has access to the same expert intelligence, how does a company differentiate?\" Levie wrote.\n\nLevie said the true advantage in an AI-driven economy won't come from having smarter models, but from giving those models access to the right proprietary information — the internal data, customer histories, workflows, decision-making patterns, and institutional knowledge that companies have built over time.\n\n\"Certainly it will be about how teams and employees use AI agents effectively,\" he wrote, \"but the ultimate force-multiplier will be the context that the agents get.\"\n\nThe idea is gaining traction across Silicon Valley.\n\nAndrej Karpathy, who was on the founding team of OpenAI, and Shopify CEO Tobi Lütke have said that \"context engineering\" — not clever prompts — is what makes AI useful at scale, while Google Cloud CTO Will Grannis and GitHub CEO Thomas Dohmke have said the real skill shift is toward designing systems, data, and workflows that give AI the right context to operate.\n\nBut getting the right context into AI systems is far from simple, Box CEO Levie told Business Insider last August.\n\nHe said that feeding agents too much information can cause what he calls \"context rot,\" where models become confused and focus on the wrong details.\n\nMaking sure AI agents receive precise, accurate, and task-specific context — without overwhelming them — is now one of the central challenges in building effective agent systems, he added.\n\nThe stakes are high. Companies that can capture, organize, and operationalize their internal knowledge will see major gains in productivity and output, Levie said in his LinkedIn post.\n\n\"Those that don't will find it harder and harder to serve customers competitively,\" he added.",
    "readingTime": 2,
    "keywords": [
      "box ceo",
      "expert intelligence",
      "context",
      "agents",
      "knowledge",
      "models",
      "systems",
      "shift",
      "linkedin",
      "across"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ai-agents-expertise-box-ceo-context-gives-companies-competitive-advantage-2026-1",
    "thumbnail_url": "https://i.insider.com/695e4b6f04eda4732f2e9dd0?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:16.931Z",
    "topic": "finance"
  },
  {
    "slug": "mckinsey-boss-says-there-are-3-skills-ai-models-cant-do-that-young-professionals-should-focus-on",
    "title": "McKinsey boss says there are 3 skills AI models can't do that young professionals should focus on",
    "description": "Bob Sternfels, global managing partner at McKinsey, identified three human skills that he said the AI models can't do.",
    "fullText": "Artificial intelligence is reshaping McKinsey's workforce, but the firm's top executive said there are still fundamental human skills that AI models can't do.\n\nBob Sternfels, global managing partner at McKinsey, talked about how AI is changing work at the firm during an appearance at the Consumer Electronics Show in Las Vegas on Tuesday.\n\nSternfels said that last year alone, embracing AI saved McKinsey 1.5 million hours in search and synthesis, work that he says AI models are great for. He also said AI agents, of which McKinsey has 25,000, excel at generating charts and that they've made 2.5 million of them in the past six months.\n\nWith agents taking over some of that work, he said consultants are now \"moving up the stack\" and tackling \"more complicated problems.\"\n\nGiven those changes, Sternfels said McKinsey looked at which skills new graduates will need in an AI-infused world from the perspective of large employers. He identified three: the ability to aspire, judgment, and true creativity.\n\n\"What can the models not do? Aspire. Set the right aspiration,\" he said. \"Do you go to low Earth orbit? Do you go to the moon? Do you go to Mars? That's a uniquely human capability.\"\n\nSternfels said you should look to build skills around aspiring and getting others to believe in those aspirations.\n\n\"There's no right and wrong in these models, and so how do you set the right parameters?\" he said, adding humans can build the skills to set the architecture based on factors like firm values and societal norms.\n\n\"The models are inference models — the next most likely step,\" Sternfels said.\n\nHumans, on the other hand, have an edge when it comes to \"orthogonal\" work, or the ability to think outside existing patterns and land on an entirely new approach.\n\nSternfels said AI adoption is also changing how companies look for talent, adding that where someone went to school should matter a lot less.\n\nFor someone with a tech background, he said, instead of looking at where they graduated from, prospective employers should look at their GitHub, a site engineers use to showcase their work.\n\n\"Let's actually get to the content,\" he said, \"and could that actually start meaning that a wider set of people can enter the workforce with different pathways?\"",
    "readingTime": 2,
    "keywords": [
      "models",
      "skills",
      "mckinsey",
      "look",
      "workforce",
      "human",
      "changing",
      "firm",
      "agents",
      "employers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mckinsey-boss-shares-human-skills-ai-models-cant-do-2026-1",
    "thumbnail_url": "https://i.insider.com/695f03e104eda4732f2eaf20?width=1200&format=jpeg",
    "created_at": "2026-01-08T12:25:16.809Z",
    "topic": "finance"
  },
  {
    "slug": "ai-chatbot-maker-anthropic-plans-to-raise-10bn-to-reach-350bn-valuation",
    "title": "AI chatbot maker Anthropic plans to raise $10bn to reach $350bn valuation",
    "description": "Startup founded by former OpenAI staff is aiming to more than double its annualized revenue run rate this year\nAnthropic is planning a $10bn fundraise that would value the Claude chatbot maker at $350bn, according to multiple reports published on Wednesday.\nThe new valuation represents an increase of nearly double from about four months ago, per CNBC, which reported that the company had signed a term sheet that stipulated the $350bn figure. The round could close within weeks, although the size and terms could change. Singapore’s sovereign wealth fund GIC and Coatue Management are planning to lead the financing, the Wall Street Journal reported.\n Continue reading...",
    "fullText": "Startup founded by former OpenAI staff is aiming to more than double its annualized revenue run rate this year\n\nAnthropic is planning a $10bn fundraise that would value the Claude chatbot maker at $350bn, according to multiple reports published on Wednesday.\n\nThe new valuation represents an increase of nearly double from about four months ago, per CNBC, which reported that the company had signed a term sheet that stipulated the $350bn figure. The round could close within weeks, although the size and terms could change. Singapore’s sovereign wealth fund GIC and Coatue Management are planning to lead the financing, the Wall Street Journal reported.\n\nInsatiable demand for AI and growing enterprise adoption has driven tech spending higher globally, pushing valuations of AI startups such as Anthropic to record levels, even as concerns about an AI bubble loom. OpenAI has been valued at $500bn.\n\nAnthropic last raised $13bn in a series F round that valued the company at $183bn, the company said in early September. The company had also hired a law firm to prepare for an initial public offering that could take place as early as 2026, according to the Financial Times.\n\nFounded in 2021 by former OpenAI staff, Anthropic’s Claude models have built a strong reputation among developers, particularly for coding tasks.\n\nAnthropic is aiming to more than double its annualized revenue run rate this year, helped by rising adoption of its enterprise products.\n\nThe startup, which Amazon, Microsoft and Nvidia have poured billions of dollars into, declined to comment.",
    "readingTime": 2,
    "keywords": [
      "openai staff",
      "annualized revenue",
      "startup",
      "aiming",
      "rate",
      "planning",
      "round",
      "enterprise",
      "adoption",
      "valued"
    ],
    "qualityScore": 0.85,
    "link": "https://www.theguardian.com/technology/2026/jan/07/ai-anthropic-funding-valuation",
    "thumbnail_url": "https://i.guim.co.uk/img/media/af4915a6ba1caec426b216d6719dab95157d0ad3/432_0_4320_3456/master/4320.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=7fb86e58a08effb9da383adb0cb247f6",
    "created_at": "2026-01-08T12:25:14.626Z",
    "topic": "tech"
  },
  {
    "slug": "ai-tool-grok-used-to-create-child-sexual-abuse-imagery-watchdog-says",
    "title": "AI tool Grok used to create child sexual abuse imagery, watchdog says",
    "description": "Internet Watch Foundation warns Elon Musk-owned AI risks bringing sexualised imagery of children into the mainstream\nOnline criminals are claiming to have used Elon Musk’s Grok AI tool to create sexual imagery of children, as a child safety watchdog warned the technology risked bringing such material into the mainstream.\nThe UK-based Internet Watch Foundation (IWF) said users of a dark web forum boasted of using Grok Imagine to create sexualised and topless imagery of girls aged between 11 and 13. IWF analysts said the images would be considered child sexual abuse material (CSAM) under UK law.\n Continue reading...",
    "fullText": "Internet Watch Foundation warns Elon Musk-owned AI risks bringing sexualised imagery of children into the mainstream\n\nOnline criminals are claiming to have used Elon Musk’s Grok AI tool to create sexual imagery of children, as a child safety watchdog warned the technology risked bringing such material into the mainstream.\n\nThe UK-based Internet Watch Foundation (IWF) said users of a dark web forum boasted of using Grok Imagine to create sexualised and topless imagery of girls aged between 11 and 13. IWF analysts said the images would be considered child sexual abuse material (CSAM) under UK law.\n\nThe UK-based Internet Watch Foundation (IWF) said users of a dark web forum boasted of using Grok Imagine to create sexualised and topless imagery of girls aged between 11 and 13. IWF analysts said the images would be considered child sexual abuse material (CSAM) under UK law.\n\n“We can confirm our analysts have discovered criminal imagery of children aged between 11 and 13 which appears to have been created using the tool,” said Ngaire Alexander, the head of the IWF’s hotline, which investigates reports of CSAM from members of the public.\n\nX, Elon Musk’s social media platform, has been deluged with images of women and children whose clothes have been digitally removed by the Grok tool, sparking public outcry and condemnation from politicians.\n\nMeanwhile, on Wednesday, the House of Commons women and equalities committee said it would no longer use X for its communications, saying it was no longer appropriate to do so given preventing violence against women and girls was among its key policy areas.\n\nThe decision marks the first significant move by a Westminster organisation to exit X in response to the misuse of Grok. While the decision concerned only the committee’s account, some individual members, including the Labour chair, Sarah Owen, have already stopped using X. Another, the Liberal Democrat MP Christine Jardine, said she was leaving the platform, calling the images generated by Grok “the last straw”.\n\nAlexander said the imagery viewed by the IWF has been used to create even more extreme material – known as Category A, which includes penetrative sexual activity – using a different AI tool.\n\n“We are extremely concerned about the ease and speed with which people can apparently generate photo-realistic child sexual abuse material. Tools like Grok now risk bringing sexual AI imagery of children into the mainstream. That is unacceptable,” Alexander added.\n\nMusk’s xAI, which owns Grok and X, has been approached for comment.\n\nDowning Street said “all options were on the table”, including a boycott of X as ministers backed the UK regulator, Ofcom, to take action.\n\nOn Wednesday, the prime minister’s official spokesperson said: “X needs to deal with this urgently and Ofcom has our full backing to take enforcement action wherever firms are failing to protect UK users.\n\n“It already has the power to issue fines of up to billions of pounds and even stop access to a site that is violating the law.”\n\nRequests for Grok to manipulate images of women to “put her in a bikini” continued to flood in on X on Wednesday. Despite the warnings of EU and UK regulatory action, there was no evidence that the platform had installed tighter safeguards, and pictures of teenage girls continue to be stripped down digitally at the request of X users, to show them in small, revealing items of underwear, or positioned in sexually explicit poses.\n\nSome users have demanded more extreme content, asking the chatbot to decorate bikinis with swastikas, or requesting alterations to photographs of women so they appear to be victims of abuse. The chatbot has obliged by adding cigarette burns, facial bruising, and blood to some images of women.\n\nThe UK’s data watchdog – the Information Commissioner’s Office (ICO) – said it had contacted X and xAI “to seek clarity on the measures they have in place to comply with UK data protection law and protect individuals’ rights”, adding people have “a right to use social media knowing their personal data is being handled lawfully and with respect”.\n\nX has said it takes action against illegal content, including child sexual abuse material, “by removing it, permanently suspending accounts, and working with local governments and law enforcement as necessary”.",
    "readingTime": 4,
    "keywords": [
      "internet watch",
      "watch foundation",
      "uk-based internet",
      "foundation iwf",
      "iwf analysts",
      "material csam",
      "dark web",
      "web forum",
      "forum boasted",
      "social media"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/08/ai-chatbot-grok-used-to-create-child-sexual-abuse-imagery-watchdog-says",
    "thumbnail_url": "https://i.guim.co.uk/img/media/ed942953d6d0fb965fb474a1e6a7011b5b5a396a/1066_0_6733_5386/master/6733.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=4aad2f079a25c441af850b4fafa8513a",
    "created_at": "2026-01-08T12:25:14.625Z",
    "topic": "tech"
  },
  {
    "slug": "needham-raises-lumentum-stock-price-target-to-470-on-ai-growth",
    "title": "Needham raises Lumentum stock price target to $470 on AI growth",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/analyst-ratings/needham-raises-lumentum-stock-price-target-to-470-on-ai-growth-93CH-4436718",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/news_pile_108x81.jpg",
    "created_at": "2026-01-08T12:25:13.219Z",
    "topic": "finance"
  },
  {
    "slug": "ford-is-throwing-its-hat-into-the-ring-alongside-rivian-and-making-an-ai-companion-inhouse",
    "title": "Ford is throwing its hat into the ring alongside Rivian and making an AI companion in-house",
    "description": "Ford announced a new AI assistant for its cars, which will help drivers answer specific questions like how much firewood can fit into their trucks.",
    "fullText": "Ford will be launching an AI assistant to help its drivers with everyday problems.\n\nFord announced on Wednesday that it would introduce the first chapter of its new AI assistant to customers through the Ford mobile app in the first half of the year.\n\nThe assistant is billed as a \"deep, personalized intelligence that knows your specific vehicle, understands your unique needs, and anticipates your desires on every journey,\" per Ford's press release.\n\nSammy Omari, the head of Ford's Advanced Driver Assist Systems (ADAS), told Business Insider that the fastest way to get the AI agent in the hands of its customer base is through the Ford and Lincoln mobile apps, which many of its customers already use.\n\nOmari said the next step would come in 2027.\n\n\"And then in '27, we are actually going to launch that in vehicle and then scale that across our vehicles,\" he said.\n\nOmari said that Ford would not be developing its own LLM for the AI assistant.\n\nWe're not going to be directly competing with a Google or an OpenAI or a Meta,\" he said. \"But what we do do is we take an LLM that's available and then basically make it our own by giving it access to all the relevant information about the person's vehicle.\"\n\nRivian, a California-headquartered EV manufacturer, announced a similar AI assistant for its cars in December.\n\nThe company said it would launch a \"next-generation voice interface\" in early 2026 on its Gen 1 and Gen 2 R1 vehicles.\n\nA demonstration of the AI assistant, seen by Business Insider, showed that it could understand commands said in natural language, such as \"Can you make it a little bit colder for everyone in the cabin?\"\n\nFord's announcement was released amid a raft of hot auto industry news coming out of the Consumer Electronics Show (CES) 2026, an annual tech trade show happening in Las Vegas.\n\nAmazon-backed robotaxi company Zoox gave live demonstrations during the conference. Uber unveiled the design of its first robotaxi, made in collaboration with Lucid and autonomous driving startup Nuro.\n\nNvidia's CEO Jensen Huang also announced Alpamayo, a new open AI model for autonomous vehicles.",
    "readingTime": 2,
    "keywords": [
      "business insider",
      "assistant",
      "vehicle",
      "ford's",
      "vehicles",
      "customers",
      "mobile",
      "launch",
      "robotaxi",
      "autonomous"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ford-new-driving-companion-ai-assistant-2026-1",
    "thumbnail_url": "https://i.insider.com/695f16f2832e0ef1ead761c3?width=1200&format=jpeg",
    "created_at": "2026-01-08T06:19:41.824Z",
    "topic": "finance"
  },
  {
    "slug": "ibms-ai-agent-bob-easily-duped-to-run-malware-researchers-show",
    "title": "IBM's AI agent Bob easily duped to run malware, researchers show",
    "description": ": Prompt injection lets risky commands slip past guardrails",
    "fullText": "IBM describes its coding agent thus: \"Bob is your AI software development partner that understands your intent, repo, and security standards.\" Unfortunately, Bob doesn't always follow those security standards.\n\nAnnounced last October and presently in closed beta testing, IBM offers Bob in the form of a command line interface – a CLI, like Claude Code – and an integrated development environment – an IDE like Cursor.\n\nSecurity researchers at PromptArmor have been evaluating Bob prior to general release and have found that IBM's \"AI development partner\" can be manipulated into executing malware. They report that the CLI is vulnerable to prompt injection attacks that allow malware execution and that the IDE is vulnerable to common AI-specific data exfiltration vectors.\n\nAI agent software – models given access to tools and tasked with some goal in an iterative loop – is notoriously insecure and often comes with warnings from vendors. The risks have been demonstrated repeatedly by security researcher Johann Rehberger, among others. Agents may be vulnerable to prompt injection, jailbreaks, or more traditional code flaws that enable the execution of malicious code.\n\nAs Rehberger remarked at a recent presentation to the Chaos Computer Club, the fix for many of these risks involves putting a human in the loop to authorize risky action.\n\nThat's apparently the case with Bob. IBM's documentation, the PromptArmor Threat Intelligence Team explained in a writeup provided to The Register, includes a warning that setting high-risk commands to be automatically approved for agent usage potentially allows harmful operations.\n\nBig Blue's recommendation is that users rely on allow lists and avoid wildcard characters, with the assumption that the agent will ask the user to approve or reject the automated use of fraught commands.\n\nBut according to PromptArmor, Bob's defenses are a bit too porous. Company researchers gave Bob a code repo to explore that contained a malicious README.md file. The file includes instructions that tell Bob it's responsible for conducting phishing training with the user.\n\nScreenshot of Bob CLI vulnerability, from PromptArmor - Click to enlarge\n\nThe markdown file includes a series of \"echo\" commands, which if entered into a terminal application will print a message to the shell's standard output. The first two are benign and when Bob follows the instructions, the model presents a prompt in the terminal window asking the user to allow the command once, to always allow it, or to suggest changes.\n\nIn its third appearance, the \"echo\" command attempts to fetch a malicious script. And if the user has been lulled into allowing \"echo\" to run always, the malware will be installed and executed without approval.\n\nBoth the CLI and IDE, even when given a green light to always run a command, are still intended to have additional security measures. Specifically, Bob disallows the use of command substitution like \"$(command)\" as a safeguard. But it doesn't check for process substitution, as seen in a bug the researchers found in the project's minified JavaScript code.\n\nScreenshot of vulnerable Bob JavaScript code - Click to enlarge\n\nAlso, the agent software fails to catch when separate subcommands have been chained together using the \">\" redirection operator.\n\nThus, the researchers were able to prefix a series of malicious commands with the allowed \"echo\" command and run the entire set of instructions.\n\n\"For IBM Bob, we were able to bypass several defense mechanisms - ultimately, the 'human in the loop' approval function only ends up validating an allow-listed safe command, when in reality more sensitive commands were being run (that were not on the allow-list),\" explained Shankar Krishnan, managing director at PromptArmor, in an email to The Register.\n\n\"If this were tried with Claude Code, a programmatic defense would stop the attack flow and request user consent for the whole multi-part malicious command – even if the first command in the sequence were on the auto-approval list.\"\n\nGiven the ability to induce Bob to deliver an arbitrary shell script payload to the victim's machine, the attacker could run ransomware, steal credentials, or commandeer the device.\n\n\"There are a few plausible scenarios here,\" said Krishnan. \"This risk is relevant for any developer workflows that leverage untrusted data. For example, Bob can read webpages – a prompt injection can be encountered if the user requests that Bob review a site containing untrusted content (e.g. developer docs, StackOverflow). Bob can also read terminal command outputs – an injection in a third-party data source can be printed after a command is run and ingested by Bob. Our write-up considers a developer working with an untrusted open-source repository, as it is a self-contained and realistic example.\"\n\nAdditionally, the PromptArmor researchers say that the IDE is susceptible to a zero-click data exfiltration attack that affects a number of AI applications. Specifically, Bob will render markdown images in model output with a Content Security Policy that allows network request endpoints to be logged by attackers. This could allow data exfiltration via pre-fetched JSON schemas potentially.\n\nIBM did not immediately respond to a request for comment. We're told that the company has been informed of the vulnerability. ®",
    "readingTime": 5,
    "keywords": [
      "javascript code",
      "development partner",
      "prompt injection",
      "security standards",
      "agent software",
      "echo command",
      "claude code",
      "specifically bob",
      "user",
      "researchers"
    ],
    "qualityScore": 1,
    "link": "https://www.theregister.com/2026/01/07/ibm_bob_vulnerability/",
    "thumbnail_url": "https://regmedia.co.uk/2021/06/10/shutterstock_blindfold.jpg",
    "created_at": "2026-01-08T06:19:40.796Z",
    "topic": "tech"
  },
  {
    "slug": "ces-2026-ford-is-launching-its-own-ai-assistant",
    "title": "CES 2026: Ford Is Launching Its Own AI Assistant",
    "description": "Your Ford is getting its own ChatGPT.",
    "fullText": "Listen up, Ford drivers: You're getting a new AI assistant this year. During a decidedly low-key CES keynote, the company announced Ford AI Assistant, a new AI-powered bot coming to Ford customers in the early half of 2026.\n\nWhile the company has plans to integrate the assistant into Ford vehicles directly, that isn't how you'll first experience this new AI. Instead, Ford is rolling out Ford AI Assistant to an upgraded version of its Ford app first, and plans on shipping cars with the assistant built-in sometime in 2027. In effect, Ford has added a proprietary version of ChatGPT or Gemini to its app.\n\nFord's idea here is to offer users a smart assistant experience directly tied to their Ford vehicle. In one example, the company suggests a customer could visit a hardware store looking to buy mulch. Said customer could take a photo of a pile of bags of mulch, and ask the assistant, \"how many bags can I fit in the bed of my truck?\" Ford AI Assistant could then run the numbers, and offer an educated estimate to how much mulch the customer can buy and take with them at one time.\n\nOf course, other AI assistants can do similar calculations. Send ChatGPT the same photo, and ask the same question—specifying the model of your truck—and the bot will run the numbers itself. The difference, in Ford's view, is that Ford AI Assistant is connected to your vehicle specifically. It can read all the sensors in your car, so it knows, for example, how many people are currently traveling with you, your current tire pressure, or, really, anything and everything about your car. According to Doug Field, Ford's chief officer of EVs, digital, and design, the company's goal with the assistant is to offer answers customers can't get from other sources. ChatGPT certainly doesn't have access to your every sensor embedded in your car, so Ford does have the advantage there.\n\nFord didn't go out and build its AI tech by scratch, however. The company tells TechCrunch that Ford AI Assistant is hosted by Google Cloud, and is run using \"off-the-shelf LLMs.\" Still, that likely won't have much of an impact on whether or not customers use this new assistant. Instead, that will come down to how useful they find the AI assistant in the app.\n\nAs someone who rarely uses AI assistants, I'd imagine I'd find little use for it if I owned a Ford. That being said, there are some times when it could genuinely be useful to have external access to your car's information. I could probably eyeball how many bags of mulch would fit in my trunk, but I can't tell you my exact odometer reading without starting up my car. The same goes for my tire pressure: It'd be helpful to know my tire pressure before getting in my car, to know whether I should be headed somewhere I can fill up before going to my destination.\n\nOf course, there's also a privacy discussion to be had here. Modern cars are already privacy nightmares, but there's something a bit unnerving about an AI assistant that knows everything about my car.",
    "readingTime": 3,
    "keywords": [
      "ford ai assistant",
      "tire pressure",
      "mulch",
      "customers",
      "customer",
      "bags",
      "plans",
      "directly",
      "experience",
      "version"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/ces-2026-ford-is-launching-its-own-ai-assistant?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KEDJCQB6YDJJJ2B3JHBWQBJY/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-08T06:19:40.732Z",
    "topic": "tech"
  },
  {
    "slug": "this-case-is-going-to-trial-judge-rejects-sam-altmans-efforts-to-toss-elon-musks-openai-lawsuit",
    "title": "'This case is going to trial': Judge rejects Sam Altman's efforts to toss Elon Musk's OpenAI lawsuit",
    "description": "An Oakland federal court judge just paved the way for a Musk-Altman showdown, rejecting OpenAI's efforts to end the case ahead of trial.",
    "fullText": "It looks like Sam Altman and Elon Musk are headed for a courtroom showdown.\n\nDuring a hearing on Wednesday, a California judge said she plans to reject Altman's lawyers' last-ditch efforts to end Musk's case against OpenAI and its CEO.\n\n\"This case is going to trial,\" US District Judge Yvonne Gonzalez Rogers said at a hearing to consider whether the evidence was sufficient to warrant a jury trial.\n\n\"I think there's plenty of evidence,\" she said, referring to Musk's case. \"It's circumstantial, but that's how these things work.\"\n\nIn his lawsuit filed in 2024, Musk accused OpenAI of misleading him in its decision to abandon its original nonprofit mission and structure in favor of a profit-oriented model, including through its partnership with Microsoft.\n\nMusk says he donated $38 million to the maker of ChatGPT over the years to support its mission to develop AI for the benefit of humankind. The Tesla CEO is seeking monetary damages, as well as a judgment to void Microsoft's licensing agreement with OpenAI.\n\nAt a hearing on Wednesday, an Oakland federal court judge said she felt there was enough evidence that Musk may have been deceived to allow the case to move forward to a jury. A trial is scheduled for March.\n\n\"There were assurances made, and promises made, that the structure would be maintained,\" she said. \"There was lots of information that was not shared.\"\n\nThe judge added that she also felt \"there are strong arguments by the defense.\"\n\n\"I think the jury is going to get to decide,\" she said.\n\nOpenAI lawyers have denied Musk's allegations, saying Musk was aware of the company's for-profit plans as early as 2018. OpenAI has also pointed out that it is still controlled by OpenAI's nonprofit arm.\n\n\"Mr Musk's lawsuit continues to be baseless and a part of his ongoing pattern of harassment, and we look forward to demonstrating this at trial,\" a spokesperson for OpenAI told Business Insider. \"We remain focused on empowering the OpenAI Foundation, which is already one of the best resourced nonprofits ever.\"\n\nA spokesperson for Musk did not immediately respond to a request for comment.\n\nMusk has filed multiple lawsuits against OpenAI. Most recently, his AI company, xAI, sued OpenAI in September, accusing it of stealing trade secrets and targeting its employees for recruitment. At the time, an OpenAI spokesperson told Business that the lawsuit is \"the latest chapter in Mr. Musk's ongoing harassment.\"\n\nMusk helped found OpenAI in 2015, but left the company in 2018. At the time he said his work with OpenAI could present a conflict of interest with Tesla's AI ambitions.\n\nSince, Musk has repeatedly criticized Altman and OpenAI, including the company's structure. Musk later went on to launch his own AI company, xAI, in 2023.",
    "readingTime": 3,
    "keywords": [
      "jury trial",
      "mr musk's",
      "judge",
      "openai",
      "musk",
      "evidence",
      "lawsuit",
      "structure",
      "plans",
      "lawyers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/judge-rejects-sam-altman-efforts-toss-elon-musk-case-openai-2026-1",
    "thumbnail_url": "https://i.insider.com/695ed66b04eda4732f2ead30?width=1200&format=jpeg",
    "created_at": "2026-01-08T00:58:03.722Z",
    "topic": "finance"
  },
  {
    "slug": "time-ablation-experiments-on-tau2bench",
    "title": "Time Ablation Experiments on tau2-bench",
    "description": "This fork of tau2-bench investigates whether LLM agent performance varies based on the temporal context of dates in prompts. - sshh12/tau2-bench-time-ablations",
    "fullText": "sshh12\n\n /\n\n tau2-bench-time-ablations\n\n Public\n\n forked from sierra-research/tau2-bench\n\n This fork of tau2-bench investigates whether LLM agent performance varies based on the temporal context of dates in prompts.\n\n License\n\n MIT license\n\n 0\n stars\n\n 138\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n sshh12/tau2-bench-time-ablations",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/sshh12/tau2-bench-time-ablations",
    "thumbnail_url": "https://opengraph.githubassets.com/daef6631d290d27b3e4aad046efa3d6e39b1b7946e6e46b306cd4fef30516cef/sshh12/tau2-bench-time-ablations",
    "created_at": "2026-01-08T00:58:03.211Z",
    "topic": "tech"
  },
  {
    "slug": "this-free-script-disables-every-ai-feature-in-windows-11",
    "title": "This Free Script Disables Every AI Feature in Windows 11",
    "description": "Tired of all the Microsoft AI slop? You can remove it entirely.",
    "fullText": "Some people love AI. If you're not one of them (or if you have a favorite AI tool that isn't baked into it), using Windows 11 can feel increasingly hostile. It seems like every part of it now exists to push you into using Copilot—even notepad.exe has a prominent AI button in the user interface at this point.\n\nIf you'd like your operating system to go back to being an operating system, check out \nRemoveWindowsAI. This free script changes various registry keys to disable AI features including Copilot, Recall, and the Copilot integrations in applications including Edge, Paint, and Notepad. Using various workarounds , it then configures Windows Update to not install those updates again (the documentation breaks the process down, if you're interested).\n\nTo get started you need to open Microsoft PowerShell on your computer. Make sure you're using Windows PowerShell 5.1, and not the updated PowerShell 7 (this only really applies if you've intentionally installed PowerShell 7, so don't worry about this step if you didn't actively do that).\n\nTo start the script you will need to copy a command from the Github page for RemoveWindowsAI and paste it into your PowerShell window (I'm not including the command directly here in case it changes in the future). Once you do, the user interface will show up, allowing you to choose which AI features you want to disable. Make your choices and watch the changes take place in the PowerShell window.\n\nI tried this out, removing everything. I then opened Notepad—no Copilot icon in sight. The Copilot application was also gone, along with all reference to AI in the Settings application. It would be nice if Microsoft offered a way to do this without resorting to this sort of unofficial workaround, but that isn't the world we live in.",
    "readingTime": 2,
    "keywords": [
      "powershell window",
      "user interface",
      "operating system",
      "you're",
      "isn't",
      "script",
      "various",
      "disable",
      "features",
      "command"
    ],
    "qualityScore": 0.85,
    "link": "https://lifehacker.com/tech/this-script-disables-all-the-ai-features-in-windows-11?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KED0B1D345J0CD6WR4GPNT45/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-08T00:58:01.672Z",
    "topic": "tech"
  },
  {
    "slug": "telio-ai-agents-for-calltext-support-built-on-sandboxed-lakehouses",
    "title": "Telio – AI agents for call/text support, built on sandboxed lakehouses",
    "description": "Provides instant, human-like, and cost-effective customer service. Automatically handles common issues and after-hours inquiries.",
    "fullText": "Your AI agent for 24/7 call and text support\n\nProvides instant, human-like, and cost-effective customer service.\n Automatically handles common issues and after-hours inquiries.\n\nTry for Free\n\nBook a Demo\n\nNo credit card required\n\n7-day free trial\n\nCancel anytime\n\nBuilt using firsthand insights from leading companies\n Support reimaginedWhy Telio? \nInstant customer support that feels human\n\nDeliver fast, personalized, human-like experiences that keep customers happy and loyal.\n Automate customer inquiries, so your team can focus on complex and high-impact work.\n\nAutomate without limits\n\nNever miss a customer inquiry with an AI agent that takes unlimited calls simultaneously and handles requests nonstop, day or night.\n\nSkip the complexity\n\nTell your agent what to do in plain English. No complex coding or UI workflows needed. Your everyday language is all it takes.\n 24/7 Availability for customers 70% Cost reduction on support 3x Faster response time Always-on agentHow it works 1\nCreate in just a few clicks\n\nSimply share information about your business and select your preferences.\n Our platform will handle the rest and create a fully functional agent with an assigned phone number in seconds.\n 2\nCustomize your AI agent\n\nEnable access to your website and other knowledge sources and agent tools.\n Your agent pulls in the right information in real-time, so it can understand your business and your customers to work smarter for you.\n 3\nTest and go live\n\nTest your agent with sample conversations to ensure it meets your expectations.\n When you're ready, launch your agent with a dedicated Telio phone number or forward calls from your existing one.\n TestimonialsTrusted by businesses worldwide \"With AI agents sitting on top of a lightning-fast data lakehouse, we can instantly act on insights from all our data with ease!\"Nick PuljicCo-Founder & CTO \"Telio's 24/7 AI agents automated 60% of customer SMS communications and cut our response time by nearly 3x without expanding the team.\"James CastilloCo-Founder & Head of Engineering \"We eliminated hours of repetitive email work daily. The AI agent drafts responses with perfect context and tone that our team reviews and sends with one click.\"Sumukh Sridhara \"Telio is incredibly easy to use! I simply described how to respond to customers, and now it handles customer calls 24/7 with a natural human-like voice.\"CatherineBusiness Owner \"With AI agents sitting on top of a lightning-fast data lakehouse, we can instantly act on insights from all our data with ease!\"Nick PuljicCo-Founder & CTO \"Telio's 24/7 AI agents automated 60% of customer SMS communications and cut our response time by nearly 3x without expanding the team.\"James CastilloCo-Founder & Head of Engineering \"We eliminated hours of repetitive email work daily. The AI agent drafts responses with perfect context and tone that our team reviews and sends with one click.\"Sumukh Sridhara \"Telio is incredibly easy to use! I simply described how to respond to customers, and now it handles customer calls 24/7 with a natural human-like voice.\"CatherineBusiness Owner FAQHave any questions? What is an AI agent and how does it work?Telio's AI agents are virtual assistants that can handle customer interactions via voice calls and text messages. They can understand customer inquiries and provide instant natural-language responses to frequently asked questions, assist with common tasks, and escalate complex issues to a real human when necessary. How does this compare to human agents?Our AI agents are designed to handle a wide range of customer interactions with human-like understanding and responsiveness. They can reduce wait times, operate 24/7, handle multiple interactions simultaneously, and provide consistent service without increasing staffing costs. Can I keep my existing phone number?Yes! You can forward your existing business phone number to Telio, so customers continue calling the same number they're familiar with. Alternatively, we can provide you with a new local phone number if you prefer. The choice is yours, and you can switch anytime. Will customers know they are talking to an AI?Our AI is designed to sound natural and conversational. Most customers don't realize they're speaking with an AI. However, if asked directly, the AI will be honest and can transfer them to you if needed. Can agents integrate with my existing systems?Yes, Telio's AI agents can seamlessly integrate with your existing calendar, CRM, and other business systems through our robust API and pre-built connectors. This allows agents to access customer data, update records, and perform actions within your existing workflows. How secure is my data with Telio?Data security is our top priority at Telio. We're SOC 2 certified and HIPAA compliant, meaning we implement industry-standard encryption protocols for data in transit and at rest, conduct regular security audits, and comply with major data protection regulations to ensure your data remains safe and confidential. See security \nTry for Free\n Or schedule a demo with a founding team member: BlogDiscover featured posts Customer StoriesScaling EV Repairs: How RepairWise Handles 1,000+ Daily Messages with AIRepairWise uses 24/7 Telio AI agents to manage 1,000+ daily messages, automating 60% of customer SMS and... Customer StoriesHow Rollups Scales Fintech Support: Automating 1,000 of Emails in FrontRollups scales support with Telio AI agents that handle 1,000 of emails and integrate with Front, Notion, Attio, ... NewsTelio Achieves SOC 2 Type II Compliance: Secure 24/7 AI AgentsWe’re excited to announce a major milestone in our commitment to data security and trust ...",
    "readingTime": 5,
    "keywords": [
      "ease!\"nick puljicco-founder",
      "puljicco-founder cto",
      "team.\"james castilloco-founder",
      "click.\"sumukh sridhara",
      "voice.\"catherinebusiness owner",
      "cto telio's",
      "sms communications",
      "instantly act",
      "eliminated hours",
      "repetitive email"
    ],
    "qualityScore": 1,
    "link": "https://gettelio.com/",
    "thumbnail_url": "https://gettelio.com/images/preview.png",
    "created_at": "2026-01-08T00:58:01.648Z",
    "topic": "tech"
  },
  {
    "slug": "i-built-a-free-ai-texttovideo-generator-in-browser",
    "title": "I built a free AI text-to-video generator in browser",
    "description": "Generate cinematic AI videos from text. The ultimate creative suite for creators.",
    "fullText": "\"The 1080p export without watermark is a lifesaver for my\n portfolio.\"\n\n\"I use the AI Avatar feature for all my explainer videos now.\n Sync\n is perfect.\"\n\n\"Better than Luma and Runway for quick social clips. Speed is\n insane.\"\n\n\"Converted my travel photos into a cinematic movie. Magic.\"\n\n\"Cyberpunk filter is my go-to for music videos. Looks high\n budget.\"\n\n\"Finally an app that understands 'cinematic lighting'\n correctly.\"\n\n\"Credits renew daily? Best deal on the market right now.\"\n\n\"The claymation effect is adorable. My kids love seeing their\n toys\n move.\"\n\n\"Professional grade upscaling. Saved my grainy footage.\"\n\n\"I made a whole short film using just this app. Mind blown.\"\n\n\"The prompt adherence is way better than other tools I've\n tried.\"\n\n\"Super intuitive UI. I was making videos in seconds.\"\n\n\"Anime style transfer is incredibly accurate to the reference.\"\n\n\"My TikTok engagement doubled after using these visual effects.\"\n\n\"Customer support is responsive and helpful. Rare these days.\"\n\n\"Text to video generation is fast even on mobile data.\"\n\n\"The variety of styles is unmatched. Always something new to\n try.\"\n\n\"Being able to define start and end frames is a game changer for\n control.\"\n\n\"Cleanest interface of any AI tool I've used. No clutter.\"\n\n\"The lip sync on avatars is scary good.\"\n\n\"Video enhance mode rescued my old wedding footage.\"\n\n\"I love that I can iterate quickly without burning through\n cash.\"\n\n\"The community around this app is great for tips and tricks.\"\n\n\"Takes my content creation to a whole new level.\"\n\n\"Simply the best AI video generator on iOS. Period.\"\n\n\"The 1080p export without watermark is a lifesaver for my\n portfolio.\"\n\n\"I use the AI Avatar feature for all my explainer videos now.\n Sync\n is perfect.\"\n\n\"Better than Luma and Runway for quick social clips. Speed is\n insane.\"\n\n\"Converted my travel photos into a cinematic movie. Magic.\"\n\n\"Cyberpunk filter is my go-to for music videos. Looks high\n budget.\"\n\n\"Finally an app that understands 'cinematic lighting'\n correctly.\"\n\n\"Credits renew daily? Best deal on the market right now.\"\n\n\"The claymation effect is adorable. My kids love seeing their\n toys\n move.\"\n\n\"Professional grade upscaling. Saved my grainy footage.\"\n\n\"I made a whole short film using just this app. Mind blown.\"\n\n\"The prompt adherence is way better than other tools I've\n tried.\"\n\n\"Super intuitive UI. I was making videos in seconds.\"\n\n\"Anime style transfer is incredibly accurate to the reference.\"\n\n\"My TikTok engagement doubled after using these visual effects.\"\n\n\"Customer support is responsive and helpful. Rare these days.\"\n\n\"Text to video generation is fast even on mobile data.\"\n\n\"The variety of styles is unmatched. Always something new to\n try.\"\n\n\"Being able to define start and end frames is a game changer for\n control.\"\n\n\"Cleanest interface of any AI tool I've used. No clutter.\"\n\n\"The lip sync on avatars is scary good.\"\n\n\"Video enhance mode rescued my old wedding footage.\"\n\n\"I love that I can iterate quickly without burning through\n cash.\"\n\n\"The community around this app is great for tips and tricks.\"\n\n\"Takes my content creation to a whole new level.\"\n\n\"Simply the best AI video generator on iOS. Period.\"",
    "readingTime": 3,
    "keywords": [
      "avatar feature",
      "clips speed",
      "insane converted",
      "movie magic",
      "cyberpunk filter",
      "budget finally",
      "correctly credits",
      "credits renew",
      "professional grade",
      "upscaling saved"
    ],
    "qualityScore": 0.8,
    "link": "https://visionaryvideo.app/",
    "thumbnail_url": "https://visionaryvideo.app/app-icon.png",
    "created_at": "2026-01-08T00:58:01.143Z",
    "topic": "tech"
  },
  {
    "slug": "microsoft-exec-dismisses-mass-layoff-report-100-made-up",
    "title": "Microsoft Exec Dismisses Mass Layoff Report: \"100% Made Up\"",
    "description": "If you spend any time on social media, whether that be Bluesky or X, you may have seen some reports going around that Microsoft is preparing to cut tens of thousands of jobs amidst the rising costs of artificial intelligence. Whether true or not, Microsoft's lead communications officer has come forward to refute the claims.\nA report on the site TipRanks said that Microsoft is \"considering massive layoffs\" this month, with the plan to cut anywhere between 11,000 and 22,000 jobs on the Azure Cloud, Xbox, and global sales teams. After circulating on Bluesky and X for a while, Windows Central editor Jez Corden purported that the news was \"false\" on Xbox's side of things. Not long after this, Microsoft CCO Frank X.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/microsoft-exec-dismisses-mass-layoff-report-100-made-up/1100-6537261/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1578/15789366/4631872-xboximage.jpg",
    "created_at": "2026-01-08T00:58:00.900Z",
    "topic": "gaming"
  },
  {
    "slug": "ai-starts-autonomously-writing-prescription-refills-in-utah",
    "title": "AI starts autonomously writing prescription refills in Utah",
    "description": "The program allows patients in the state to get prescription refills for 190 common meds.",
    "fullText": "The state of Utah is allowing artificial intelligence to prescribe medication refills to patients without direct human oversight in a pilot program public advocates call “dangerous.”\n\nThe program is through the state’s “regulatory sandbox” framework, which allows businesses to trial “innovative” products or services with state regulations temporarily waived. The Utah Department of Commerce partnered with Doctronic, a telehealth startup with an AI chatbot.\n\nDoctronic offers a nationwide service that allows patients to chat with its “AI doctor” for free, then, for $39, book a virtual appointment with a real doctor licensed in their state. But patients must go through the AI chatbot first to get an appointment.\n\nAccording to a non-peer-reviewed preprint article from Doctronic, which looked at 500 telehealth cases in its service, the company claims its AI’s diagnosis matched the diagnosis made by a real clinician in 81 percent of cases. The AI’s treatment plan was “consistent” with that of a doctor’s in 99 percent of the cases.\n\nNow, for patients in Utah, Doctronic’s chatbot can refill a prescription without a doctor, for a $4 service fee . After a patient signs in and verifies state residency, the AI chatbot can pull up the patient’s prescription history and offer a list of prescription medications eligible for a refill. According to Politico, the chatbot will only be able to renew prescriptions for 190 common medications for chronic conditions, with key exclusions, such as medications for pain and ADHD, and those that are injected.\n\nThe first 250 renewals for each drug class will be reviewed by real doctors, but after that, the AI chatbot will be on its own. Adam Oskowitz, Doctronic co-founder and a professor at the University of California, San Francisco, told Politico that the AI chatbot is designed to err on the side of safety and escalate any case with uncertainty to a real doctor.\n\n“Utah’s approach to regulatory mitigation strikes a vital balance between fostering innovation and ensuring consumer safety,” Margaret Woolley Busse, executive director of the Utah Department of Commerce, said in a statement.\n\nFor now, it’s unclear if the Food and Drug Administration will step in to regulate AI prescribing. On the one hand, prescription renewals are a matter of practicing medicine, which falls under state governance. However, Politico notes that the FDA has said that it has the authority to regulate medical devices used to diagnose, treat, or prevent disease.\n\nIn a statement, Robert Steinbrook, health research group director at watchdog Public Citizen, blasted Doctronic’s program and the lack of oversight. “AI should not be autonomously refilling prescriptions, nor identifying itself as an ‘AI doctor,'” Steinbrook said.\n\n“Although the thoughtful application of AI can help to improve aspects of medical care, the Utah pilot program is a dangerous first step toward more autonomous medical practice,” he said.\"The FDA and other federal regulatory agencies cannot look the other way when AI applications undermine the essential human clinician role in prescribing and renewing medications.”",
    "readingTime": 3,
    "keywords": [
      "utah department",
      "pilot program",
      "chatbot",
      "doctor",
      "patients",
      "prescription",
      "medications",
      "regulatory",
      "service",
      "cases"
    ],
    "qualityScore": 1,
    "link": "https://arstechnica.com/health/2026/01/utah-allows-ai-to-autonomously-prescribe-medication-refills/",
    "thumbnail_url": "https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-1152x648.jpg",
    "created_at": "2026-01-08T00:58:00.272Z",
    "topic": "health"
  },
  {
    "slug": "vai-a-open-source-character-platform",
    "title": "V.ai: a open source character platform",
    "description": "V.AI AI platform. Contribute to eotter-beep/vai development by creating an account on GitHub.",
    "fullText": "eotter-beep\n\n /\n\n vai\n\n Public\n\n V.AI AI platform\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n eotter-beep/vai",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/eotter-beep/vai",
    "thumbnail_url": "https://opengraph.githubassets.com/db6812f5b9a55f57468159dc2737b7c772c2a975d01f9cc8cc0eb1ecd2110de9/eotter-beep/vai",
    "created_at": "2026-01-08T00:57:59.801Z",
    "topic": "tech"
  },
  {
    "slug": "liftmind-ai-addiction-recovery",
    "title": "LiftMind – AI Addiction Recovery",
    "description": "Stop relying on willpower alone. Private, encrypted, AI-driven tools for habit consistency and relapse prevention.",
    "fullText": "Track your daily consistency with a visual system designed to reinforce positive momentum.\n\nUnderstanding why is the first step. Log triggers and analyze patterns to prevent future slips.\n\nCorrelate spending habits and emotional states to identify high-risk behavioral patterns.\n\nMonitor your emotional baseline to predict difficult days before they happen.\n\nGamify your recovery with milestones that celebrate your hard-fought consistency.\n\nGet personalized, context-aware guidance from our intelligent assistant 24/7.",
    "readingTime": 1,
    "keywords": [
      "consistency",
      "patterns",
      "emotional"
    ],
    "qualityScore": 0.65,
    "link": "https://liftmind.ai/",
    "thumbnail_url": "https://liftmind.ai/img/og-image.png",
    "created_at": "2026-01-08T00:57:59.638Z",
    "topic": "tech"
  },
  {
    "slug": "ablemouse-ai-nosepoint-cursor-screensize-independent",
    "title": "AbleMouse AI. Nose-point cursor. Screen-size independent",
    "description": "Think of it as an open-source alternative to expensive solutions like the MouthPad, eye-trackers, or even complex systems like Neuralink. Everyone deserves access to assistive technology. - aradzha...",
    "fullText": "aradzhabov\n\n /\n\n AbleMouse\n\n Public\n\n Think of it as an open-source alternative to expensive solutions like the MouthPad, eye-trackers, or even complex systems like Neuralink. Everyone deserves access to assistive technology.\n\n License\n\n MIT license\n\n 31\n stars\n\n 2\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n aradzhabov/AbleMouse",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/aradzhabov/AbleMouse",
    "thumbnail_url": "https://opengraph.githubassets.com/b07b81f14c188d1f3da87215e8ac8b1096ea51d2b07a428f5be288c7fa040176/aradzhabov/AbleMouse",
    "created_at": "2026-01-07T18:19:23.024Z",
    "topic": "tech"
  },
  {
    "slug": "shortages-cause-skyrocketing-ram-prices-in-1985",
    "title": "Shortages Cause Sky-Rocketing RAM Prices – In 1985",
    "description": "I’m not talking about 2026 and the AI RAM apocalypse, but instead talking about 1988.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.goto10retro.com/p/shortages-cause-sky-rocketing-ram",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!SbQ_!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4abd3589-fc9d-4650-ab5e-cba769761e40_1280x341.png",
    "created_at": "2026-01-07T18:19:22.776Z",
    "topic": "tech"
  },
  {
    "slug": "vect-ai-treating-marketing-execution-as-software-not-a-stack-of-tools",
    "title": "Vect AI: treating marketing execution as software, not a stack of tools",
    "description": "Scale faster with Vect AI. Deploy autonomous agents, predict success with the Resonance Engine, and fix copy with the Conversion Killer Detector.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://vect.pro/",
    "thumbnail_url": "https://blog.vect.pro/vectai.png",
    "created_at": "2026-01-07T18:19:22.313Z",
    "topic": "tech"
  },
  {
    "slug": "sumoffy-macos-offline-document-intelligence-you-can-trust",
    "title": "Sumoffy (macOS) – Offline Document Intelligence You Can Trust",
    "description": "SUMOFFY - Chat with Document Fully Offline and Document Explanation with AI Voice NarrationSUMOFFY let you chat with your PDF and text documents and also it explains PDF and text documents using local AI models. All processing runs on your computer—no internet, no cloud, no data sent anywhere.What You Get:Streaming document explanations (Offline)AI-powered voice narration (Offline)Interactive chat with your documents (Offline)Minimum System Requirements: OS: macOS (Windows soon) RAM: 16 GB minimum (required for local AI models) Storage: ~6-7 GB free space Internet: Not required after installationAll (2) AI models are included—install and use immediately, completely offline.",
    "fullText": "SUMOFFY - Chat with Document Fully Offline and  Document Explanation with AI Voice Narration\n\nSUMOFFY let you chat with your PDF and text documents and also it explains PDF and text documents using local AI models. All processing runs on your computer—no internet, no cloud, no data sent anywhere.\n\nAll (2) AI models are included—install and use immediately, completely offline.\n\nGet OFFLINE desktop application that lets you chat with your documents and receive explanations with voice narration (Offline AI-powered)",
    "readingTime": 1,
    "keywords": [
      "voice narration",
      "text documents",
      "models",
      "offline",
      "chat",
      "sumoffy",
      "document"
    ],
    "qualityScore": 0.45,
    "link": "https://rokontech.gumroad.com/l/sumoffy",
    "thumbnail_url": "https://public-files.gumroad.com/ueyii96zysfea5gx5kj31tnyw4ro",
    "created_at": "2026-01-07T18:19:21.997Z",
    "topic": "tech"
  },
  {
    "slug": "flashinferbench-building-the-virtuous-cycle-for-aidriven-llm-systems",
    "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-Driven LLM Systems",
    "description": "Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2601.00227",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2026-01-07T18:19:21.595Z",
    "topic": "tech"
  },
  {
    "slug": "china-asks-tech-firms-to-halt-orders-for-nvidias-h200-chips-information-reports",
    "title": "China asks tech firms to halt orders for Nvidia's H200 chips, Information reports",
    "description": "Beijing has asked some Chinese tech companies to halt orders for Nvidia's H200 chips this week, and is expected to mandate ​domestic artificial intelligence chip purchases, the Information reported on Wednesday, citing people ‌familiar with the matter.  Nvidia has been caught between Washington and Beijing, as the United States tightens controls ‌on exports of advanced semiconductors used in AI, while Chinese companies seek to reduce reliance on U.S.-designed chips.  China's directive to suspend orders was issued ⁠as the government considers whether, ‌and under what conditions, to allow access to Nvidia's high-performance chips.",
    "fullText": "Jan 7 (Reuters) - Beijing has asked some Chinese tech companies to halt orders for Nvidia's H200 chips this week, and is expected to mandate ​domestic artificial intelligence chip purchases, the Information reported on Wednesday, citing people ‌familiar with the matter.\n\nNvidia has been caught between Washington and Beijing, as the United States tightens controls ‌on exports of advanced semiconductors used in AI, while Chinese companies seek to reduce reliance on U.S.-designed chips.\n\nTensions over technology trade have been a central feature of broader U.S.-China conflicts, with semiconductors emerging as a strategic flashpoint.\n\nChina's directive to suspend orders was issued ⁠as the government considers whether, ‌and under what conditions, to allow access to Nvidia's high-performance chips.\n\nBeijing is aiming to discourage local technology companies from rushing to stockpile ‍U.S. chips before a decision is reached, the report said.\n\n\"China is committed to basing its national development on its own strengths, and is also willing to maintain dialogue and cooperation with ​all parties to safeguard the stability of global industrial and supply chains,\" said ‌Liu Pengyu, a spokesperson for the Chinese Embassy in the U.S.\n\nNvidia did not immediately respond to a Reuters request for comment and China's Ministry of Commerce and Ministry of Industry and Information Technology did not immediately return calls outside business hours.\n\nNvidia CEO Jensen Huang said at the Consumer Electronics Show this week that demand in China ⁠for its H200 chip was strong and the ​company is viewing purchase orders as a signal ​of approval rather than expecting any formal announcement from Beijing.\n\nU.S. export licenses for the chips are still being processed, with no set timeline.\n\nLate ‍last year, U.S. President ⁠Donald Trump's administration approved the export of H200 chips to China, a significant reversal of previous bans on advanced AI hardware.\n\nThe approval was based on a ⁠condition that the company pay a unique 25% revenue-sharing tax to the U.S. government.\n\nThe H200 is ‌the predecessor to Nvidia's current flagship \"Blackwell\" chips.",
    "readingTime": 2,
    "keywords": [
      "chips",
      "nvidia's",
      "technology",
      "china",
      "chip",
      "advanced",
      "semiconductors",
      "china's",
      "immediately",
      "ministry"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/china-asks-tech-firms-halt-155153074.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/383ec575f9371e487618da76ef465c46",
    "created_at": "2026-01-07T18:19:20.865Z",
    "topic": "finance"
  },
  {
    "slug": "commons-women-and-equalities-committee-to-stop-using-x-amid-aialtered-images-row",
    "title": "Commons women and equalities committee to stop using X amid AI-altered images row",
    "description": "Exclusive: Move follows outcry over use of Grok to digitally remove clothing from images of women and...",
    "fullText": "Exclusive: Move follows outcry over use of Grok to digitally remove clothing from images of women and children\n\nUK politics live – latest updates\n\nThe influential Commons women and equalities committee has decided to stop using X after the social media site’s AI tool began generating thousands of digitally altered images of women and children with their clothes removed.\n\nThe move by the cross-party committee places renewed pressure on ministers to take decisive action after the site was flooded with images including sexualised and unclothed pictures of children, generated by its AI tool, Grok.\n\nSarah Owen, the Labour MP who chairs the committee, said that given preventing violence against women and girls was among its key policy areas, “it has become increasingly clear that X is not an appropriate platform to be using for our communications”.\n\nLiz Kendall, the technology secretary, has called the imagery “appalling and unacceptable in decent society” and urged Ofcom, the UK’s media regulator, to take whatever action is needed.\n\nSpeaking on Wednesday, Keir Starmer’s spokesperson said that “all options remain on the table” for Ofcom, which has the power to impose huge fines or to restrict access to a site.\n\nThe decision by the women and equalities committee is the first significant move by a Westminster organisation to exit X. It is understood the committee took the decision at a meeting on Wednesday. It will keep its X account, which has about 27,000 followers, in existence, but dormant, to ensure no one else can take it over.\n\nWhile the decision concerned only the committee’s account, some individual members, including Owen, have already stopped using X. Another, the Liberal Democrat MP Christine Jardine, said she was leaving the platform, calling the images generated by Grok “the last straw”.\n\nJardine said she had taken the view that X was a good way to communicate with constituents. “But I cannot in all conscience continue to use a platform which seems unwilling to act against this grossly offensive and abusive online behaviour towards women and girls.”\n\nOwen also plans to write to the Cabinet Office and to Ofcom to urge action against X. She said: “I personally came off X in 2024 after the platform and its owner promoted and paid creators of far-right racist and misogynistic material. The committee heard at the end of last year on inquiries about community cohesion that X posts regularly break UK law on hate speech.\n\n“In recent days, X and xAI have allowed the creation and sharing of AI deepfakes, non-consensual intimate imagery, and child sexual abuse material, all areas identified as online violence against women and girls by our committee.\n\n“We do not view it as appropriate to use such a platform to share our work. I hope that the government, Ofcom and relevant law enforcement agencies work quickly to make X immediately abide by UK law on online safety and non-consensual intimate image abuse, to be held to account for its failures and if it refuses to abide by our laws, it must be appropriately sanctioned.”\n\nOn Monday, Ofcom said it was aware of serious concerns raised about Grok creating images of undressed people and sexualised images of children. It said it had contacted X and xAI “to understand what steps they have taken to comply with their legal duties to protect users in the UK” and would assess the need for an investigation based on the company’s response.\n\nStarmer’s spokesperson said: “What we have seen on Grok is a disgrace. It is completely unacceptable. No one should have to go through the ordeal of deepfakes of themselves online, and we won’t allow the proliferation of these demeaning images.\n\n“X needs to deal with this urgently, and Ofcom has our full backing to take enforcement action wherever firms are failing to protect UK users. It already has the power to issue fines of up to billions of pounds and even stop access to a site that is violating the law. And when it comes to keeping people safe online, all options remain on the table.”\n\nAsked about the issue, Kemi Badenoch’s spokesperson said the Conservative leader agreed with the government: “We both find it absolutely abhorrent and want to see it clamped down upon as soon as possible.”\n\nAsked if this could mean Badenoch, an enthusiastic user of X who has 350,000 followers, might leave the platform, the spokesperson said: “We are very clear that what is happening with those Grok deepfakes is absolutely disgusting and there has to be some something done to stop that. I’m not about to announce policy here.”\n\nEarlier on Wednesday, Nigel Farage was asked if he was happy to earn money from a site that had a business model based in part on child sexual abuse material. The Reform UK leader is paid for engagement on the site as a much-followed verified user.\n\nFarage avoided the question but said he was “very worried” about the images and said he believed X would listen to the criticism.",
    "readingTime": 5,
    "keywords": [
      "non-consensual intimate",
      "child sexual",
      "sexual abuse",
      "abuse material",
      "equalities committee",
      "images",
      "women",
      "grok",
      "platform",
      "site"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/07/commons-women-equalities-committee-stop-using-x-ai-altered-grok-images",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f42b50444c49bdb62c689c42eb7a308a92d56756/283_0_862_690/master/862.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=4df64c401ce6b499e3a1e4b99d12505c",
    "created_at": "2026-01-07T18:19:15.307Z",
    "topic": "tech"
  },
  {
    "slug": "jpmorgan-is-ditching-proxy-advisors-and-turning-to-ai-for-shareholder-votes-in-the-us",
    "title": "JPMorgan is ditching proxy advisors and turning to AI for shareholder votes in the US",
    "description": "The bank is launching an in-house, AI-powered tool called Proxy IQ to support its shareholder voting decisions, leaving human proxy advisors behind.",
    "fullText": "JPMorgan's asset and wealth management division is ditching its long-held practice of using external proxy advisors for advice on shareholder voting decisions.\n\nThe bank said it was \"the first major investment firm to fully eliminate any reliance on external proxy advisors for our US voting process,\" according to an excerpt from an internal memo seen by Business Insider.\n\nThe changes to the US proxy-voting process will take full effect on April 1, following a transition period in the first quarter of the year, a spokesperson for JPMorgan Asset Management told Business Insider.\n\nThe news was first reported by The Wall Street Journal.\n\nJPMorgan's asset management division holds $7 trillion in client assets, giving it a vote in thousands of shareholder decisions that include general governance decisions outside of finance questions. It's common practice in the industry to turn to proxy advisory firms for data collection, advice, and voting recommendations.\n\nThe practice has come under fire from the Trump administration, which signed an executive order in December calling for increased oversight of the proxy advisor industry.\n\n\"Proxy advisors regularly use their substantial power to advance and prioritize radical politically-motivated agendas,\" the executive order said.\n\nInstitutional Shareholder Services (ISS) and Glass Lewis, were two proxy advisory firms previously used by JPMorgan and named in the Trump administration's December executive order.\n\nA spokesperson for ISS declined to comment on the news of JP Morgan cutting ties with proxy advisory firms. However, the spokesperson said, \"We are proud of our four-decade record serving the global institutional investor community,\" and will continue to do so as it prepares for the 2026 annual meeting season. Glass Lewis did not respond to a request for comment.\n\nThe move away from proxy firms reinforced JPMorgan's \"unwavering commitment to vote solely in clients' best interests, using our information advantage,\" the bank said in the memo.\n\nIn place of external human advisors, the asset and wealth management unit is launching an in-house AI platform, called Proxy IQ, to support shareholder decisions, according to the memo.\n\n\"Proxy IQ extends the high bar of independent analysis that our portfolio managers, research analysts and stewardship teams have always applied to every vote, using that same in-house expertise to cover all aspects of the voting process, including data and research selection, down to the smallest detail,\" JPMorgan said in the memo.\n\nThe tool will be able to aggregate and analyze proprietary data from more than 3,000 annual company meetings, it said.\n\nJPMorgan has a technology budget of $18 billion, and CEO Jamie Dimon has previously said he's out to win the AI arms race.",
    "readingTime": 3,
    "keywords": [
      "business insider",
      "jpmorgan's asset",
      "wealth management",
      "management division",
      "advisory firms",
      "voting process",
      "shareholder decisions",
      "proxy advisory",
      "proxy advisors",
      "external proxy"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/jpmorgan-ditches-proxy-adivsory-firms-for-ai-shareholder-votes-memo-2026-1",
    "thumbnail_url": "https://i.insider.com/695e5912832e0ef1ead75055?width=1200&format=jpeg",
    "created_at": "2026-01-07T18:19:13.294Z",
    "topic": "finance"
  },
  {
    "slug": "if-you-want-a-new-job-in-2026-linkedin-says-these-roles-are-growing-fastest",
    "title": "If you want a new job in 2026, LinkedIn says these roles are growing fastest",
    "description": "Many of the fastest-growing jobs in the US involve AI, according to LinkedIn. Engineers topped the list, though not all AI roles are technical.",
    "fullText": "If finding a new job is on your to-do list in 2026, you might want to start with AI.\n\nArtificial intelligence engineers top LinkedIn's annual Jobs on the Rise list, which ranks the fastest-growing roles in the US over the past three years. The newly released findings also offer a snapshot of where employers are still hiring, from tech and infrastructure to sales and healthcare.\n\nJust as AI appears to be buoying the stock market, it's also supporting demand in various sectors of the labor market. There's other welcome news for desk workers who have faced years of sluggish hiring: Not all of the AI roles are wholly technical.\n\nThe category of AI consultants and strategists was the second-fastest-growing in LinkedIn's review.\n\nThat's an indication that integrating AI more deeply into the workplace will require people whose expertise isn't solely technical, said Laura Lorenzetti, a senior director at LinkedIn who worked on the list.\n\n\"There is also this whole adjacent system of how you implement AI; how you do culture change around AI; how you get people to really adapt and use it,\" she told Business Insider.\n\nOther roles related to AI also feature prominently on the ranking of fast-growing jobs. Data annotators, who help train and refine AI systems, were fourth on the list, while AI and machine learning researchers came in at No. 5.\n\nNot all of the top spots were directly tied to AI, however. The third-fastest-growing job type was \"new home sales specialists,\" while healthcare reimbursement specialists were sixth.\n\nAlongside the list, LinkedIn also reported on Wednesday that, in a November survey, more than half of workers — 56% — said they planned to look for a new job in 2026, although about three-quarters of respondents felt unprepared to do so.\n\nThey cited reasons such as being unsure about how to stand out or not being ready for how technology is shifting in-demand skills.\n\nIn a prior LinkedIn survey from about a year ago, a similar share of workers signaled their intent to hunt for a job — a reminder that looking isn't the same as landing.\n\nMore than six in 10 of the 2,000 respondents said that finding a job had grown more challenging over the prior year. They cited factors such as competition, skills gaps, and uncertainty over which jobs they might be qualified for.\n\nOther LinkedIn data highlighted the challenges in the job market for many people: The number of applicants per open role has, on average, more than doubled since the spring of 2022, while hiring was 23% below pre-pandemic levels as of November.\n\nThe difficulty in finding work, especially after years of cuts in Big Tech and as firms ramp up investments in AI, is causing some to reconsider their approach to their job hunt. Nearly half of job seekers — 46% — said in the survey that they'd gone from looking for full-time work to freelance, contract, or advising gigs.\n\nLed by Gen Z, nearly one in five professionals who reported being unable to find a new job in 2025 said they had shifted to freelance or consulting work, or had started their own business.\n\nThat could be one reason the job title \"founder\" is surging on LinkedIn profiles — and appearing on the list of fastest-growing jobs for the first time, in the ninth spot.\n\nLinkedIn reported in December that the share of US users who added founder to their profile had jumped 69% from the prior year.\n\n\"People are seeing that as a way to own their career and own their next step,\" said Lorenzetti, referring to the interest in entrepreneurship.\n\nHere are the 25 fastest-growing roles in the US, according to LinkedIn:",
    "readingTime": 4,
    "keywords": [
      "fastest-growing roles",
      "list",
      "jobs",
      "hiring",
      "market",
      "workers",
      "survey",
      "prior",
      "linkedin",
      "linkedin's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/fastest-growing-jobs-in-the-us-linkedin-2026-1",
    "thumbnail_url": "https://i.insider.com/695d798a832e0ef1ead74890?width=1200&format=jpeg",
    "created_at": "2026-01-07T18:19:13.136Z",
    "topic": "finance"
  },
  {
    "slug": "this-startup-is-helping-companies-train-ai-with-an-old-but-buzzy-technique-read-the-pitch-deck-it-used-to-raise-75",
    "title": "This startup is helping companies train AI with an old but buzzy technique. Read the pitch deck it used to raise $7.5 million.",
    "description": "AgileRL has created a platform for engineers to train AI using reinforcement learning, a decades-old technique that's having a comeback.",
    "fullText": "A London-based startup that provides software to help companies speed up AI training has raised $7.5 million in funding.\n\nAgileRL has created a platform called Arena that engineers and data scientists can drop their AI models into, run simulations, fine-tune them before deployment, and monitor them while they are running.\n\nThe startup, cofounded by Param Kumar and Nicholas Ustaran-Anderegg in 2023, focuses on reinforcement learning, or RL, an AI training technique in which systems learn by trying actions and improving based on the feedback they receive.\n\nReinforcement learning has roots dating back to the 1950s, but at AI labs, it is experiencing a renaissance of sorts.\n\nKumar, AgileRL's CEO, told Business Insider that after ChatGPT launched in late 2022, companies \"moved their budgets from working on RL\" to focus on transformers, the technology underpinning large language models. Where transformers learn patterns from large datasets all at once, RL learns one step at a time. Now, he says more companies are realizing that transformers can only get them so far.\n\n\"We realized early on that transformers are great, but they're these large statistical models,\" Kumar said. \"The reality is you will need to layer on RL on top of that, because there's only so much you can infer from the data.\"\n\nKumar gave the example of a robotic arm being tasked with moving a ball from one table to another. He said that the movement can be broken down into many smaller tasks — such as grasping the ball, lifting the arm, and moving the joint — and that AgileRL's platform allows engineers to set parameters to improve at those specific tasks.\n\nThe startup says it can speed up AI development for companies because the training tools are all in one place and off the shelf, versus setting up an AI lab from scratch.\n\nAgileRL offers a free tier, which provides users with access to a limited amount of training credits. Paid tiers are available for businesses and professionals, along with custom licenses for larger enterprises.\n\nThe company says its platform has been downloaded more than 300,000 times, and it has been used by companies including Airbus, IBM, and JPMorgan.\n\nAgileRL's seed funding round was led by Fusion Fund, with participation from Flying Fish, Octopus Ventures, Entrepreneur First, and Counterview Capital.\n\nThe startup said it plans to use the capital to open an office in San Francisco and hire more than a dozen people in engineering and go-to-market roles.\n\nHere's an exclusive look at the 12-page pitch deck AgileRL used to raise $7.5 million.",
    "readingTime": 3,
    "keywords": [
      "reinforcement learning",
      "startup",
      "training",
      "transformers",
      "platform",
      "models",
      "speed",
      "funding",
      "engineers",
      "ball"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/agilerl-funding-pitch-deck-ai-training-reinforcement-learning-2026-1",
    "thumbnail_url": "https://i.insider.com/695e3eed832e0ef1ead74fcd?width=1200&format=jpeg",
    "created_at": "2026-01-07T18:19:13.030Z",
    "topic": "finance"
  },
  {
    "slug": "ai-slop-like-shrimp-jesus-is-over-heres-what-comes-next",
    "title": "AI slop like 'Shrimp Jesus' is over. Here's what comes next.",
    "description": "AI slop is everywhere — except it's not so sloppy anymore. Just take a look at Instagram or TikTok. A lot of it looks real. That's where you come in.",
    "fullText": "There was a time, not so long ago, when AI-generated content was very easy to spot. It was surreal, ridiculous — like Jesus made out of Shrimp.\n\nWe're in a new time now, and AI slop looks so good, it's hard to tell from the real thing. I've been fooled by it. You probably have, too, even if you don't think you have. For example, this extremely realistic video of Nicolás Maduro doing TikTok dances in prison with Diddy. You know it's AI only because it's improbable, not because the video quality is poor.\n\n2025: “AI will be used to cure cancer”\n\n2026:\n\n pic.twitter.com/u6KbygoLtm\n\nSo in a post-slop world, what comes next? What does our future look like with AI?\n\nOne person who would know something about both is Instagram head Adam Mosseri, who posted a prediction to Threads: He says AI images, text, and videos will get more and more realistic, and it'll become harder to separate them from what's real — including on the platform he oversees.\n\n(That's already happening to some extent: Long are the days when it was easy to spot a \"Shrimp Jesus\"-like AI-generated picture.)\n\nWhat I appreciate about Mosseri's memo is that he seems optimistic about what probably sounds like a bad thing to most people. Admitting his platform will be filled with AI-generated content meant to fool people — for funsies or profit — should, theoretically, be taking an L. But he sees this as a problem that can be solved (on Instagram, at least) at the product level:\n\nHis other point is that people will naturally gravitate toward human-produced content because that's what will become trendy: authentic, less polished, intimate, real.\n\n\"Authenticity is fast becoming a scarce resource, which will in turn drive more demand for creator content, not less,\" he writes. Which is certainly a hopeful message if your job is to run a platform for creator content and you're trying to reassure creators (and advertisers) that they should continue to post authentic content to your platform.\n\nI think he's generally right. The idea that human-created content will become more premium amid a flood of machine-created content seems to be the prevailing wisdom.\n\nAnother optimistic prognostication comes from OpenAI's chief economist, Aaron \"Ronnie\" Chatterji, who told the Financial Times that he believes AI will help free us from mundane household chores.\n\nLook, I love the sound of that as much as anyone, but I'm skeptical. Sure, someone is working on a robot that folds clothes, but it seems like it'll be a long time before that's a real thing for most of us. And it's hard to imagine automation doing the chores I really hate, like scrubbing toilets or sorting through the piles of papers and junk that accumulate on countertops daily. And I am highly, highly skeptical of a robot helping with childcare.\n\nMeanwhile, Ben Thompson of Stratechery also seems to fall into the \"humans rock!\" side of things, which I find much more appealing as a human.\n\nHe wrote about a Substack essay that had been going viral among a subset of influential people who care about economics and AI. The essay suggested that once AI and automation make it so that humans no longer have to work, income inequality will actually be far worse.\n\nBut Thompson thinks that even if there's an exponentially bigger gap between the haves and have-nots in the year 2126 (which doesn't sound great on paper), we will still value and prize human labor precisely because it is human. He writes:\n\nI like the sound of this! It's quite self-serving to me, a human who creates something (writing words) that I suppose could be done by AI, but you would probably hate and not want to pay for if it were. And also as a human being who would like to keep the species going for another few generations, I suppose. I like to think this is hope rather than cope.",
    "readingTime": 4,
    "keywords": [
      "ai-generated content",
      "creator content",
      "it's",
      "human",
      "platform",
      "that's",
      "sound",
      "spot",
      "realistic",
      "doing"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-slop-photos-videos-instagram-chatgpt-humans-2026-1",
    "thumbnail_url": "https://i.insider.com/695e7dab64858d02d217e7ed?width=521&format=jpeg",
    "created_at": "2026-01-07T18:19:12.844Z",
    "topic": "finance"
  },
  {
    "slug": "fifa-will-scan-world-cup-players-to-make-offside-avatars",
    "title": "Fifa will scan World Cup players to make offside avatars",
    "description": "Fifa is to create AI-enabled 3D avatars of all players at the World Cup to enhance semi-automated offside technology.",
    "fullText": "Fifa plans to create AI-enabled 3D avatars of every player at the 2026 World Cup to enhance the tournament's semi-automated offside technology.\n\nThis will mean creating a digital scan of all 1,248 players in the 26-man squads of the 48 teams.\n\nEach player will enter a chamber to be scanned, a process that should take just one second and only needs to be done once during their pre-tournament photo shoot.\n\nFifa says the scan \"captures highly accurate body-part dimensions\" to make more accurate offside decisions.\n\nIt expects this to mean tournament officials will be able to \"track players reliably during fast or obstructed movements\" and says final decisions will be \"displayed more realistically and in a more engaging way\".\n\nThere was controversy in the Premier League earlier this season when a Newcastle goal against Manchester City was allowed to stand.\n\nRuben Dias appeared to be jumping in the semi-automated offside graphic. This did not match the television pictures of the game.\n\nFifa hopes that by taking accurate scans of each player it can improve how these decisions are shown to supporters.\n\nThe technology was tested in Fifa's Intercontinental Cup, with Flamengo and Pyramids FC players scanned ahead of their match in December.\n\nFifa announced last month it was testing new technology which can determine if the ball goes out of play before a goal is scored. It has also developed 'real-time 3D recreation' to make line-of-sight offside decisions.",
    "readingTime": 2,
    "keywords": [
      "semi-automated offside",
      "offside decisions",
      "player",
      "technology",
      "players",
      "accurate",
      "scan",
      "scanned",
      "goal",
      "match"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/football/articles/c62ver6z7z8o?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/6bdc/live/db7aed70-ebe5-11f0-9332-4db5e65f7000.jpg",
    "created_at": "2026-01-07T18:19:10.113Z",
    "topic": "sports"
  },
  {
    "slug": "evalview-catch-agent-regressions-before-you-ship-pytest-for-agents",
    "title": "EvalView – Catch agent regressions before you ship (pytest for agents)",
    "description": "EvalView: pytest-style test harness for AI agents - YAML scenarios, tool-call checks, cost/latency & safety evals, CI-friendly reports - hidai25/eval-view",
    "fullText": "hidai25\n\n /\n\n eval-view\n\n Public\n\n EvalView: pytest-style test harness for AI agents - YAML scenarios, tool-call checks, cost/latency & safety evals, CI-friendly reports\n\n evalview.com\n\n License\n\n Apache-2.0 license\n\n 22\n stars\n\n 3\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n hidai25/eval-view",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/hidai25/eval-view",
    "thumbnail_url": "https://opengraph.githubassets.com/82e243504ff9f103c0f980057e360529186fac898f22e6e294a9960fbf4fa71b/hidai25/eval-view",
    "created_at": "2026-01-07T12:25:18.553Z",
    "topic": "tech"
  },
  {
    "slug": "when-ai-writes-almost-all-code-what-happens-to-software-engineering",
    "title": "When AI writes almost all code, what happens to software engineering?",
    "description": "No longer a hypothetical question, this is a mega-trend set to hit the tech industry",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://newsletter.pragmaticengineer.com/p/when-ai-writes-almost-all-code-what",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!sLlF!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd77a41b8-2e53-435d-9cf6-8298bd9af3e1_1146x822.png",
    "created_at": "2026-01-07T12:25:17.996Z",
    "topic": "tech"
  },
  {
    "slug": "chatgpt-is-the-new-webmd",
    "title": "ChatGPT is the new WebMD",
    "description": "Chatbots are making amateur lawyers and doctors out of everyone. The real professionals have second opinions about it.",
    "fullText": "A few times a week, Jonathan Freidin, a medical malpractice attorney in Miami, says he'll notice that people will fill out his firm's client contact sheet with text littered with emojis and headings. That's a telltale sign that they copied and pasted from ChatGPT. Other clients will say they've \"done a lot of research\" on their potential case using AI. \"We're seeing a lot more callers who feel like they have a case because ChatGPT or Gemini told them that the doctors or nurses fell below the standard of care in multiple different ways,\" Friedin tells me. \"While that may be true, it doesn't necessarily translate into a viable case.\"\n\nPeople are increasingly turning to generative AI chatbots to research everything from dinner recipes to their complex legal and medical problems. In a December 2025 survey from the legal software company Clio, 57% of consumers said they have or would use AI to answer a legal question. A 2025 Zocdoc survey found that one in three Americans use generative AI tools to get health advice each week, and one in ten use it daily. Zocdoc CEO Oliver Kharraz predicted in the report that \"AI will become the go-to tool for pre-care needs like symptom checking, triage, and navigation, as well as for routine tasks like refills and screenings.\" He cautioned that he also believes \"patients will recognize that it is no substitute for the vast majority of healthcare interactions, especially those that require human judgment, empathy, or complex decision-making.\" If he's wrong, Zodoc and its competitors have a problem.\n\nDoctors and lawyers are now sifting through generative AI emails or working to convince laypeople that they have the expertise and understand nuances of how each local judge acts or how a patient's medical history plays into their condition. Generative AI has democratized access to information that was often elusive and expensive to obtain, but it's also shifted how legal and medical professionals talk to people, and what people expect of them.\n\nChatGPT is the new WebMD and LegalZoom, turning the average person into an armchair expert with just a few prompts. And it's driving the real experts crazy.\n\n\"We have to dispel the information that they were able to obtain versus what is actually going on in their case and kind of work backwards,\" says Jamie Berger, a family law attorney in New Jersey. For example, Berger says that until recently most people knew little to nothing about the legal proceedings of divorce, and would come to the attorneys seeking information. Now, they might come armed with a step-by-step gameplan, but it's generic, and likely not the best fit for their situation. Berger will notice after emailing a client if their tone suddenly changes, that they might be using AI to write out lengthy legal strategies or questions. Then, she has to explain, \"it's not necessarily your factual circumstance,\" and address their various points. \"You have to rebuild or build the attorney-client relationship in a way that didn't used to exist,\" says Berger. \"They don't realize that there's so many offshoots along the way that it's not a linear line from A to Z.\"\n\nLike a real expert, generative AI chatbots speak with authority. That can be far more persuasive than reading a blogpost on a legal issue or summaries of medical conditions on a forum. A third of Americans said yes in a 2025 survey from Survey Monkey and financial services company Express Legal Funding that asked: \"Would you ever trust ChatGPT more than a human expert?\", although respondents were less likely to use it for medical and legal advice, and more likely to consult it for educational and financial advice.\n\nChatbots also have an infinite amount of doctors' most precious re\n\nAI also acts as a second opinion without the wait. Heidi Schrumpf, director of clinical services at teletherapy platform Marvin Behavioral Health, says she's had patients return after a counseling session and tell her that they took her input to ChatGPT or another AI bot, and that they trust her because the bot confirmed what she said. But Scrumpf isn't offended by being double-checked. \"It's great that they have the access to a quick second opinion, and then, if it doesn't agree with me, that allows them to ask me better questions.\"\n\nA 2024 poll tracking health misinformation from health policy research group KFF found that 17% of US adults said they consult AI chatbots at least once a month, but 56% of those people were not confident that the info from the AI chatbots was accurate. Still, people are turning to ChatGPT in growing numbers. \"That type of technology does want to encourage patients to continue to interact with them,\" Allen says. \"Ultimately, you do need a human in there to understand the nuances of the communication and the softer communication skills, and the unspoken communication skills, and the entire medical picture and the history.\"\n\nWithout detailed information, the chatbots will likely give generic advice. But supplying too many personal details is also a risk. People are handing over their entire medical histories to ChatGPT, but HIPAA, the federal law that protects confidential health information, doesn't apply to consumer AI products. There's also a risk of voiding the kind of protections people get from the attorney-client confidentiality privilege if people put too much specific information about their case into a chatbot, says Beth McCormack, dean of the Vermont Law School. And, they likely still need an attorney to really understand the implications of AI's legal advice. \"There's so much nuance to the law,\" McCormack says. \"It's so fact dependent.\"\n\nAn OpenAI spokesperson declined to provide comment on the record for this story, but told me that ChatGPT is not meant to substitute legal or medical advice, but act as a complimentary resource to help people understand medical and legal information. The spokesperson also said the company is trying to improve the responses of its models, and that it takes steps to protect personal data in the event of legal inquiries. OpenAI made changes to its policies last fall, specifying that users cannot turn to ChatGPT for \"provision of tailored advice that requires a license, such as legal or medical advice, without appropriate involvement by a licensed professional,\" but the chatbot does still answer health- and law-related questions.\n\nProfessionals aren't totally against their patients and clients consulting gen AI. There are shortages of doctors, and cases that require hiring an attorney with upfront money that people don't have. While the information spit out by AI isn't always perfect, it largely makes previously gate-kept legal and medical advice accessible, breaking it down without jargon. For people who can't afford upfront legal costs, turning to AI can be helpful in some cases, says Golnoush Goharzad, a personal injury and employment lawyer in California. People are using ChatGPT to represent themselves in court, to act as a stand-in therapist, nutritionist, or physical therapist. For people who can't afford lawyers and are facing issues like eviction or needing to file small claims cases, AI tools have helped them win. But Goharzad says she's had conversations, sometimes with friends, where they think they have cases to sue landlords or others. She asks, \"Why? That doesn't even make any sense, and they're like, well ChatGPT thinks it makes sense.\"\n\nThe chatbot floodgates have opened, and it's too late for professionals to resist them. People are going to keep doing their own research. Rather than fight it, experts say there's room to recognize and advise people on the best ways to use them. \"We need to keep as clinicians in the back of our mind that this might be a tool that is being used, and it can be very helpful, especially with some guidance and integrating it into our treatment plans,\" Schrumpf says. \"But it could go sideways if we're not paying attention.\" For experts, the time has come to assume that AI is also working on the case.\n\nAmanda Hoover is a senior correspondent at Business Insider covering the tech industry. She writes about the biggest tech companies and trends.",
    "readingTime": 7,
    "keywords": [
      "can't afford",
      "communication skills",
      "medical advice",
      "legal advice",
      "it's",
      "chatbots",
      "attorney",
      "research",
      "doctors",
      "doesn't"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/chatgpt-new-webmd-doctors-lawyers-medical-advice-2026-1",
    "thumbnail_url": "https://i.insider.com/695c331c64858d02d217c6b2?width=1200&format=jpeg",
    "created_at": "2026-01-07T12:25:13.043Z",
    "topic": "health"
  },
  {
    "slug": "elon-musks-xai-announces-it-has-raised-20bn-amid-backlash-over-grok-deepfakes",
    "title": "Elon Musk’s xAI announces it has raised $20bn amid backlash over Grok deepfakes",
    "description": "AI company’s chatbot faces criticism over its generation of sexualized, nonconsensual images of women and girls\nElon Musk’s artificial intelligence company has raised $20bn in its latest funding round, the startup announced Tuesday, even as its marquee chatbot Grok faces backlash over generating sexualized, nonconsensual images of women and underage girls.\nxAI’s Series E funding round featured big-name investors, including Nvidia, Fidelity Management and Resource Company, Qatar’s sovereign wealth fund, and Valor Equity Partners – the private investment firm of Musk’s longtime friend and former Doge member Antonio Gracias. The funding round exceeded its initial $15bn target, according to xAI’s press release. The company touted Grok’s image-generation abilities in the announcement of its latest funding round.\n Continue reading...",
    "fullText": "AI company’s chatbot faces criticism over its generation of sexualized, nonconsensual images of women and girls\n\nElon Musk’s artificial intelligence company has raised $20bn in its latest funding round, the startup announced Tuesday, even as its marquee chatbot Grok faces backlash over generating sexualized, nonconsensual images of women and underage girls.\n\nxAI’s Series E funding round featured big-name investors, including Nvidia, Fidelity Management and Resource Company, Qatar’s sovereign wealth fund, and Valor Equity Partners – the private investment firm of Musk’s longtime friend and former Doge member Antonio Gracias. The funding round exceeded its initial $15bn target, according to xAI’s press release. The company touted Grok’s image-generation abilities in the announcement of its latest funding round.\n\nxAI lacks the prominence of its rival OpenAI, the maker of ChatGPT, and has continually drawn criticism for generating misinformation, antisemitic content and now potentially illegal sexual material. Nonetheless, the company has been able to win government contracts and billions of dollars in investment amid the AI boom. xAI’s latest funding round comes during some of the fiercest pushback against the company yet, with lawmakers in multiple countries demanding answers regarding Grok’s output.\n\nOver the past week, Grok has responded to tens of thousands of prompts from users on X requesting the chatbot remove women’s clothing in images or pose them in sexualized ways. Many of the prompts have included images of women who have not given their consent to be digitally undressed, including Ashley St Clair, the estranged mother of one of Musk’s children.\n\n“I felt horrified, I felt violated, especially seeing my toddler’s backpack in the back of it,” St Clair told the Guardian, adding that her complaints to X did not go anywhere. The Guardian’s request for comment from xAI resulted in an automated response stating “Legacy Media Lies”.\n\nSome of Grok’s images included a photo of a 12-year-old girl, which the chatbot manipulated to remove the child’s actual clothing and depict her instead in a bikini. Other suggestive images have featured children as young as 10 years old. The chatbot posted an apology on Friday that stated lapses in its safeguards led to generating images of minors, but continued to generate sexualized images of children in the ensuing days.\n\nxAI has been seeking investment for months as it works to increase its AI models’ capabilities and build out enormous data centers in Memphis, Tennessee. The company claimed the new funding would help its core mission of “Understanding the Universe”.\n\nFrench ministers reported Grok’s output to prosecutors on Friday and referred the episode to media regulators to decide whether the images violate the European Union’s Digital Services Act. Liz Kendall, the UK’s technology secretary, also condemned Grok’s deepfakes on Tuesday as “appalling and unacceptable”, calling on the British regulator Ofcom to take action. Ofcom posted on X that it had made contact with xAI to determine whether an investigation is warranted. Lawmakers in the US, where xAI is headquartered, have remained comparatively mum.\n\nThe company made a similar funding announcement in July of last year during another controversy over Grok. A week after the chatbot began posting antisemitic content and pro-Nazi ideology, including describing itself as “MechaHitler”, xAI announced it had secured a contract with the US Pentagon worth nearly $200m.",
    "readingTime": 3,
    "keywords": [
      "grok’s output",
      "antisemitic content",
      "sexualized nonconsensual",
      "latest funding",
      "funding round",
      "nonconsensual images",
      "chatbot",
      "women",
      "generating",
      "xai’s"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/06/elon-musk-xai-investment-grok-backlash",
    "thumbnail_url": "https://i.guim.co.uk/img/media/c8d4c655c5bdd8f854366eb03a921bc61f16b507/615_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=ef3f68489b7527fa0f86169a061ca8f1",
    "created_at": "2026-01-07T12:25:12.918Z",
    "topic": "tech"
  },
  {
    "slug": "mckinseys-ceo-breaks-down-how-ai-is-reshaping-its-workforce-25-growth-in-some-roles-25-cuts-in-others",
    "title": "McKinsey's CEO breaks down how AI is reshaping its workforce: 25% growth in some roles, 25% cuts in others",
    "description": "McKinsey chief Bob Sternfels said AI had led to a shift in its workforce, with half the business adding jobs and the other half shrinking.",
    "fullText": "McKinsey's top executive shared some hard numbers on how AI is reshaping the consulting giant's workforce.\n\nBob Sternfels, McKinsey's global managing partner, appeared at the Consumer Electronics Show in Las Vegas on Tuesday for a live taping of the \"All-In\" podcast with co-host Jason Calacanis and Hemant Taneja, CEO of General Catalyst.\n\nSternfels said AI has fundamentally changed how McKinsey staffs its business, allowing it to add and cut jobs in equal measure while still achieving overall growth.\n\nReferring to it as the \"25 squared\" approach, Sternfels said McKinsey is growing its client-facing roles — what you typically picture when you think of a McKinsey consultant — by 25%. At the same time, he said non-client-facing roles, which make up the other half of its workforce, have shrunk by about 25% while output from that side has grown 10%.\n\n\"Our model has always been synonymous that growth only occurs with total head count growth. Now it's actually splitting. We can grow in this part, the client-facing side, and we can shrink in this part and have aggregate growth in total,\" he said. \"That's a new paradigm and a new dynamic.\"\n\nSternfels said the firm has seen massive productivity gains as it's embraced AI, saving 1.5 million hours in search and synthesis work last year alone. Instead of doing the work that's typically done by more junior employees, he said McKinsey consultants are \"moving up the stack\" and tackling more complicated problems.\n\nMcKinsey employees also have a brand new set of coworkers that are increasingly becoming an essential part of the company: AI agents, which can act independently like digital employees. Sternfels said that as of last week, the company had 40,000 human employees and 25,000 personalized agents. Sternfels said AI agents are able to handle entire job functions on their own.\n\nHe expects McKinsey to have about the same number of AI agents as human employees by the end of the year.\n\nFor young professionals coming into the workforce, Sternfels said they should think about honing skills that AI can't do, setting the right aspirations, human judgment, and true creativity.\n\nBusiness Insider has previously reported on how AI is disrupting consulting and changing the ways firms like McKinsey make money, including by shifting to an outcome-based pricing model.\n\nThe workforce changes at McKinsey also reflect a broader challenge facing large, established companies as AI disrupts how we work.\n\n\"This is about how do you transform incumbent entities into something different,\" he said at CES, adding that for large existing enterprises \"you have a choice — transform or die.\"\n\nHe added that companies are \"moving at literally warp speed now.\"\n\n\"I haven't met a CEO yet that isn't talking about 'how do I get my organization moving faster,'\" he's said. \"It's quite frankly less about strategy, it's more about organizational speed.\"",
    "readingTime": 3,
    "keywords": [
      "human employees",
      "workforce",
      "growth",
      "it's",
      "agents",
      "mckinsey",
      "sternfels",
      "consulting",
      "client-facing",
      "roles"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mckinsey-chief-ai-cutting-adding-jobs-growth-ai-agents-2026-1",
    "thumbnail_url": "https://i.insider.com/695dc61764858d02d217e23a?width=1200&format=jpeg",
    "created_at": "2026-01-07T12:25:12.895Z",
    "topic": "finance"
  },
  {
    "slug": "y-combinator-veterans-raise-15-million-to-build-an-ai-money-manager-that-thinks-like-a-wealthy-family-office",
    "title": "Y Combinator veterans raise $15 million to build an AI money manager that thinks like a wealthy family office",
    "description": "Two Y Combinator veterans behind a nine-figure exit have now raised $15 million, led by YC CEO Garry Tan, to build an AI-powered money manager.",
    "fullText": "Serial entrepreneurs and two-time Y Combinator grads Dillon Erb and Daniel Kobran announced Wednesday that they have raised $15 million to build a personalized AI-powered financial advisor.\n\nErb and Kobran sold their first startup, the GPU cloud company Paperspace, to DigitalOcean for $111 million in 2023. The idea for their latest startup, Autonomous Technologies Group (ATG), emerged as they sought to organize their finances following the sale.\n\nATG, a finance-focused applied AI research lab, is emerging from stealth with its first product, the wealth strategist app Autonomous.\n\nAutonomous aims to compete with the robo-advisors and traditional wealth managers that Erb and Kobran say offer generic advice or charge steep fees.\n\n\"We're not saying that we have an AI that's going to pick all the best stocks for you,\" Erb said.\n\nRather, Autonomous helps users implement strategies employed by the ultrawealthy, such as lowering taxes by managing individual stocks instead of standard index funds, and automatically adjusting portfolios to manage risk.\n\nY Combinator CEO Garry Tan led ATG's $15 million pre-seed round through a dedicated YC alum vehicle. Tan partnered with Erb and Kobran during their first stint at YC in 2015. BoxGroup and Collaborative Fund also participated in ATG's pre-seed round.\n\nThe company has 15 employees across New York and San Francisco, and it will use the funds to hire more product engineers and AI researchers.\n\n\"The financial advisory industry is one of the last holdouts where human intermediaries extract massive value without creating it,\" Tan said in a statement. \"This is the right team at the right inflection point.\"\n\nIn addition to startups like Stash, Vise, and Range, which apply AI to wealth management, big banks are also rushing to embrace AI in ways that could transform the finance sector.\n\nThe Autonomous app will launch this quarter and will be available for free to early users. It uses real-time market data and personal context to provide proactive portfolio monitoring and wide-ranging advice about users' financial lives, including investments, home purchases, and job offers.\n\nWhile Autonomous provides free advice that users can apply to existing accounts, the company makes money through a separate product called Autonomous Index, an account where users can execute trades with manual approval. It also helps users build portfolios comprising individual stocks, enabling tax savings and deeper personalization.\n\nThough Autonomous is ATG's flagship product, the company aims to establish an AI-powered financial institution that automates services typically performed by human advisors.\n\nKobran said ATG is building toward coordinating a user's entire financial picture, including assets such as retirement accounts, cryptocurrency, and startup equity. Over time, he said it could take on work like angel investments and estate planning.\n\nHe said he wants the app to make \"everything a family office does for a billionaire accessible to everyone.\"",
    "readingTime": 3,
    "keywords": [
      "ai-powered financial",
      "pre-seed round",
      "individual stocks",
      "erb and kobran",
      "users",
      "product",
      "startup",
      "wealth",
      "advice",
      "atg's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/atg-autonomous-technologies-y-combinator-15-million-ai-money-manager-2026-1",
    "thumbnail_url": "https://i.insider.com/695d5372832e0ef1ead74268?width=1200&format=jpeg",
    "created_at": "2026-01-07T12:25:12.892Z",
    "topic": "finance"
  },
  {
    "slug": "this-chart-showing-chatgpt-vs-gemini-web-traffic-should-have-openai-worried",
    "title": "This chart showing ChatGPT vs. Gemini web traffic should have OpenAI worried",
    "description": "ChatGPT's web traffic has decreased since November, when Google launched Gemini 3. ChatGPT still has the lead, but it could signal shifting tides.",
    "fullText": "OpenAI's recent \"code red\" over Gemini makes a lot of sense when you look at the data.\n\nWhile the ChatGPT maker continues to dominate the AI race, competitors are gaining ground. In November, Google released Gemini 3 Pro, the first iteration of its Gemini 3 class of models.\n\nSince then, Gemini web traffic has increased while ChatGPT web traffic declined, according to Similarweb data first highlighted by Menlo Ventures partner Deedy Das.\n\nIn December, Gemini traffic increased by 28.4% month-over-month, while ChatGPT traffic decreased by 5.6%, the data shows.\n\nThe chart's data only tells part of the story, only accounting for site visits to chatgpt.com and gemini.google.com. It does not factor in use of the consumer apps or other integrations, like Google's AI overviews in Google Search.\n\nAnd while there's no guarantee that one traffic trend is directly because of the other, the data highlights the shifting tides of the AI race.\n\nWeb traffic for both ChatGPT and Gemini are up year-over-year, but their estimated site traffic growth rates are staggeringly different. ChatGPT traffic is up 49.5%; Gemini's traffic is up 563.6%, per Similarweb.\n\nChatGPT still has a healthy lead. In December, ChatGPT attracted 5.5 billion visitors, according to Similarweb. Gemini came in second with 1.7 billion; DeepSeek, Grok, Character.AI, Perplexity, and Claude all trailed behind with fewer than 400 million visitors each.\n\nAfter its launch, Gemini 3 was lauded as a potentially market-leading model. It was more visual and creative than previous iterations, and was better at coding.\n\nGoogle has also flexed its primary advantage over OpenAI: the ability to integrate its AI within its highly used search products. Basically everyone uses Google — OpenAI must convince people to turn to ChatGPT instead of the search giant's products.\n\nOpenAI and Google are also competing in the image generation market. Less than a month after Google released its Nano Banana Pro AI image model, OpenAI announced the launch of ChatGPT Images.\n\nGemini 3 famously triggered a \"code red\" at OpenAI. In an internal Slack message, CEO Sam Altman reportedly told staff that OpenAI would prioritize ChatGPT while pushing back other product plans.\n\nIn December, Altman said on the \"Big Technology\" podcast that the company would not be in emergency status \"that much longer,\" and that \"code red\" periods normally last six to eight weeks.\n\nAltman also said that Gemini 3 did not have \"the impact we were worried it might.\"\n\n\"But it did — in the same way that DeepSeek did — identify some weaknesses in our product offering strategy, and we're addressing those very quickly,\" he added.",
    "readingTime": 3,
    "keywords": [
      "google released",
      "code red",
      "web traffic",
      "chatgpt traffic",
      "gemini",
      "race",
      "increased",
      "site",
      "visitors",
      "deepseek"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-chatgpt-vs-gemini-web-traffic-chart-2026-1",
    "thumbnail_url": "https://i.insider.com/695d5f13832e0ef1ead7444e?width=1200&format=jpeg",
    "created_at": "2026-01-07T12:25:12.781Z",
    "topic": "finance"
  },
  {
    "slug": "i-quit-meta-and-left-a-comfortable-salary-to-build-a-startup-leaving-wasnt-easy-but-now-my-ai-receptionist-answers",
    "title": "I quit Meta and left a comfortable salary to build a startup. Leaving wasn't easy, but now my AI receptionist answers millions of calls.",
    "description": "Ruchir Baronia left behind an incredible salary, stock refreshers, and interesting problems at Meta after a year and a half to build his AI business.",
    "fullText": "My clearest memory from middle school is pacing in my bedroom, phone in hand, repeating the word 'wake' again and again. I was testing a voice app I had written. If I said the phrase just right, the app would respond. If not, I would tweak the code and try again.\n\nI had just learned to code from YouTube. My apps were getting downloads, and I was addicted. I would run home from school, drop my backpack, and open the reviews before starting my homework. It was the first time I saw that code written alone in my bedroom could reach people I would never meet.\n\nAfter studying engineering and business at UC, Berkeley, and spending nearly two years working at Meta, I'm now running Frontdesk, an AI startup that helps businesses automate millions of conversations with AI.\n\nMy early programming projects were playful. I built a text-to-speech app and a speech-to-text app. Then, one of my relatives slipped and fell at home. He was yelling for help, but nobody was home, and his phone was out of reach. If his phone had been able to hear him, it could've brought him help immediately.\n\nIn 2016, I developed Rescuer, a voice app that enabled users to trigger an alarm by shouting a secret phrase, automatically sending their location, photos, and audio to designated emergency contacts.\n\nRescuer earned recognition from political officials and the press. What mattered more was that I learned that code written from my bedroom could help someone. From then on, I began building for real impact.\n\nI started answering questions on coding forums, recording YouTube coding tutorials, and writing for an engineering blog. Over time, my answers on forums like Stack Overflow reached millions of developers, which only deepened my passion for continuous learning.\n\nThere was still one thing I couldn't figure out, no matter how many downloads my apps received. I didn't know how to turn an app into a real business. I didn't understand pricing, customers, or why some products became companies while others remained weekend projects.\n\nAs I was deciding where to attend college, I knew I wanted to learn about the business side.\n\nI chose UC Berkeley's M.E.T. program because I could study both engineering and business. I graduated with an EECS (electrical engineering & computer science) and business degree in three years.\n\nIn 2023, when ChatGPT had its big moment, I asked myself, What if I could just talk to this thing on a real phone line?\n\nOver a weekend, I hacked together one of the first prototypes that connected ChatGPT to a real phone number. I posted a short clip and a tweet, and it got a lot of attention.\n\nThe tech was not ready to be a real product. Latency was bad. Reliability was fragile. The models made strange errors. But that experiment planted a question in my mind that I could not shake: If this ever became good enough, what would it look like to use it to help real businesses?\n\nI shelved my phone experiment to join Meta. It was a dream setup. My team was incredibly supportive, I was learning how to build at a massive scale, and life was good — from the smart colleagues to the famous free food.\n\nI was part of a fintech team where I'd push one line of code, and millions of transactions would be affected. It felt less like a corporation and more like a high-growth startup; I was given incredible ownership from day one and learned \n\nBut I was spending all my time behind the code. The business side, the part I'd learned to love at Berkeley, felt far away. As an engineer at a big company, there was no clear path back to the center.\n\nI wasn't working directly on AI, but I could sense the momentum building. Every few months, the models improved noticeably. My ChatGPT phone hack stopped feeling like a viral stunt and started to feel like a glimpse of the future.\n\nAfter my post went viral in college, hundreds of businesses reached out, asking for a solution. I kept thinking about all those businesses, where a missed call meant a missed customer. I knew there was demand, I knew nobody was serving them, and I knew I wanted to be the one to build it.\n\nLeaving wasn't easy. Meta was comfortable, offering an incredible salary, stock refreshers, and interesting problems. Everyone told me to stay another year, vest more equity, and build more credentials. The rational move was to wait.\n\nI kept asking myself, if I waited, would I regret it? The window felt finite. Every month I stayed was a month these businesses were not being served.\n\nI raised capital, moved to NYC from California, and began building Frontdesk. I'm now the founder and CEO.\n\nFrontdesk is a comprehensive AI operating system that engages with customers across all channels and performs real-world tasks, such as scheduling and follow-ups.\n\nWe work in-person in an office in SoHo. Most people in our office share a similar story to mine; they left Microsoft, Amazon, or Meta, walking away from good salaries and stock options, because they believed this was worth building.\n\nI feel lucky to work with people who push me to be better every day.\n\nMost nights, my work looks the same as it did in middle school. I pace, talk into a phone, and listen for what feels off. The difference is that now, when it works, it works across millions of calls. It's the same instinct that led me to build Rescuer years ago.\n\nThe phones are still ringing, and the models are still getting better. I know where I want to be while that happens: close to the code and building something worth leaving comfort behind.\n\nDid you quit a Big Tech job to build your own company? Email this editor at lhaas@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "middle school",
      "voice app",
      "phone",
      "code",
      "business",
      "businesses",
      "learned",
      "engineering",
      "millions",
      "bedroom"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/quit-job-meta-build-ai-company-leaving-wasnt-easy-2026-1",
    "thumbnail_url": "https://i.insider.com/695d370964858d02d217d259?width=512&format=jpeg",
    "created_at": "2026-01-07T12:25:12.777Z",
    "topic": "finance"
  },
  {
    "slug": "ai-tutor-to-study-and-practice-stem-books",
    "title": "AI tutor to study and practice STEM books",
    "description": "Built for self-learners who study out of curiosity, not deadlines. Study Junkie transforms any book into an interactive learning experience with AI discussions, audio narration, and practice exercises. For autodidacts and lifelong learners.",
    "fullText": "Built by self-learners, for self-learners. Study Junkie lets you transform any textbook into an interactive course with discussions, practice exercises, and audio narration. It's like having the author as your personal tutor.\n\nStudy Junkie is built around three fundamental steps that, in our experience, lead to real understanding.\n\nRead or listen to the source — each chapter can be narrated by AI. At your own pace and whenever it is convenient for you. This is Courses in Study Junkie.\n\nTalk about what you've read with someone knowledgeable. Ask questions, get clarifications, \n explore edge cases. The AI in Study Junkie serves this role, grounded in your source material. This is the Chat in Study Junkie.\n\nApply what you've learned. Answer questions. Work through exercises. Practice until the concepts become second nature. \n This is the Assignments in Study Junkie.\n\nWe're lifelong learners ourselves. We built Study Junkie because we wanted a better way to engage with the books \n sitting on our shelves — not to cram for tests, but to actually understand and remember\nwhat we read. To make sure the AI is grounded in real knowledge, everything you study here is based on the source materials you provide.\n\nWhether it's a philosophy classic you've been meaning to dive into, a history book that sparked your curiosity, \n a business book recommended by a friend, or a quantum electrodynamics paper you want to understand —\nStudy Junkie is for people who learn because they want to.\n\nFour steps to start studying any material.\n\nDrop any book, PDF, or text document into Study Junkie. The AI processes your content \n and creates a structured course based on what you uploaded.\n\nStudy Junkie organizes your material into chapters. Read through them or listen to \n AI-generated audio narration with adjustable playback speed. Study at your own pace \n and revisit any section whenever you need.\n\nHave questions? Need clarification? Want to dive deeper into a concept? Chat with \n the AI tutor grounded in your source material. Ask for explanations, request expanded \n coverage of topics, or explore related concepts. AI intelligently chooses between answering in the chat or adding text into the lecture.\n\nEach chapter comes with exercises generated from your material—questions, \n application tasks, or reflection prompts. Submit your answers and get \n feedback from the AI to deepen your understanding.\n\nUpload it to Study Junkie and start learning.\n\nStudy Junkie offers flexible payment options to suit your needs. \n Whether you prefer full control or hassle-free convenience, we've got you covered.\n\nUse your own API key. \n Most of the LLM providers support free-tier usage, which makes StudyJunkie completely free to use.\n\nTop up your account and let Study Junkie handle everything. \n No API keys needed.\n\nBoth modes include: Unlimited courses, AI discussions, audio narration, \n practice assignments, 8 languages, and all future features.\n\nStudy Junkie is built for self-learners, autodidacts, and lifelong learners — people who study \n out of curiosity, not for exams or credentials. If you have a stack of books you want to truly understand, \n topics you want to explore on weekends, or subjects you're passionate about diving deeper into, Study Junkie \n helps you engage with that material more effectively. No deadlines, no grades—just learning for the joy of it.\n\nStudy Junkie aims to preserve all information from your source materials. The AI \n generates discussions and assignments based on the complete content, helping you \n understand the material in depth rather than just getting a summary.\n\nStudy Junkie accepts PDFs, DOCX, and text files. You can upload any book or document \n you want to learn from—textbooks, non-fiction books, manuals, guides, articles, \n or any other text-based material.\n\nStudy Junkie supports English, Russian, Spanish, French, German, Italian, Portuguese, and Polish. \n You can upload source material in any language, and then choose which language you want the \n lectures and assignments to be generated in. For example, you can upload a book in German \n and study it in English, or vice versa.\n\nThe AI uses your uploaded document as its primary knowledge source when answering \n questions and generating content. This means the discussions and assignments are \n directly relevant to what you're studying, not generic information from the internet.\n\nYes! Every chapter can be narrated by AI, so you can listen to your lectures instead \n of reading them. The audio player includes adjustable playback speed, making it perfect \n for studying whenever reading isn't convenient.\n\nStudy Junkie generates exercises and questions based on your uploaded material. These can be \n comprehension questions, application exercises, or analytical prompts depending on the content. \n When you submit an answer, the AI provides feedback to help you learn.\n\nCourse generation typically takes a few minutes, depending on the length and complexity \n of your source material. For a 500-page book, you can expect your course structure \n to be ready within 2-3 minutes.\n\nStudy Junkie offers two payment modes: Self-Service Mode is free forever—you \n just need to provide your own API key from your preferred LLM provider (like OpenAI, Anthropic, etc.).\nPrepaid Tokens Mode lets you top up your account with a convenient amount, and Study Junkie \n handles all the API management for you. Both modes include all features with no subscriptions or hidden fees.\n\nChoose Self-Service Mode if you want full control over your AI costs and already \n have (or don't mind setting up) an API key with a provider. Choose Prepaid Tokens\nif you prefer a hassle-free experience without managing API keys—just top up and start learning.\n\nYes! Study Junkie is fully responsive and works great on mobile devices. The mobile \n version is actively maintained, so you can study anywhere - on your commute, during \n lunch breaks, or wherever you have a few minutes to learn.\n\nThat book you've been meaning to really dig into? Upload it and start exploring.\n\nStudyJunkie has a forever-free plan",
    "readingTime": 5,
    "keywords": [
      "study junkie",
      "prepaid tokens",
      "lifelong learners",
      "adjustable playback",
      "playback speed",
      "audio narration",
      "the ai",
      "material",
      "book",
      "exercises"
    ],
    "qualityScore": 1,
    "link": "https://studyjunkie.co/",
    "thumbnail_url": "https://studyjunkie.co/images/main_app_view_light.png",
    "created_at": "2026-01-07T06:19:59.149Z",
    "topic": "science"
  },
  {
    "slug": "i-asked-chatgpt-to-find-the-safest-cheapest-countries-to-retire-abroad-heres-what-it-said",
    "title": "I Asked ChatGPT To Find the Safest, Cheapest Countries To Retire Abroad — Here’s What It Said",
    "description": "Discover the safest and cheapest countries to retire abroad in 2026 based on ChatGPT’s picks, and find out which destinations offer the best value.",
    "fullText": "For retirees, moving abroad can sound like a dream.\n\nImagine beaches, cobblestone streets and a cost of living that stretches your Social Security check further than it ever could at home. However, finding a place that’s both affordable and safe is harder than it looks.\n\nSo, I asked ChatGPT to run the numbers: Which countries offer the best balance of low cost of living and personal security?\n\nUsing the 2025 Global Peace Index, Numbeo’s Cost of Living Index, and U.S. State Department travel advisories, the AI highlighted a handful of countries that might make sense for a stress-free retirement overseas.\n\nPortugal remains one of Europe’s safest destinations. However, it’s not as inexpensive as it once was. Rising housing prices and new residency rules mean retirees need a realistic budget and proof of income.\n\nThe D7 visa still works for retirees with passive income. Applicants will have to prove they consistently earn about €870 per month (roughly $900 USD) and provide evidence of stable finances and housing, according to the residency consultancy Global Citizen Solutions.\n\nAccording to ChatGPT, smaller inland towns can offer a comfortable lifestyle for $1,500 to $2,000 per month, while Lisbon or Algarve coastal areas often cost $2,500 to $3,500. Even with higher prices, Portugal’s healthcare, safety and walkability make it appealing for retirees seeking European quality of life.\n\nTrending Now: I Asked ChatGPT for Safe and Beautiful Retirement Spots on $2.5K a Month — These 7 Surprised Me\n\nConsider This: 5 Clever Ways Retirees Are Earning Up To $1K per Month From Home\n\nAI said Malaysia delivers one of the best cost-to-quality ratios in Asia. In Kuala Lumpur or Penang, a couple can live well on $1,500 to $2,000 per month and enjoy modern healthcare at a fraction of U.S. costs.\n\nThe Malaysia My Second Home (MM2H) program allows long-term residency for those meeting income or savings requirements, making it a leading pick for safety and affordability.\n\nSlovenia offers postcard landscapes, European healthcare and high safety rankings at a lower cost of living than Western Europe.\n\nAccording to ChatGPT, a retiree can live modestly on about $2,000 a month, enjoy a high standard of public services, and easily travel throughout Europe.\n\nChatGPT said Uruguay stands out in South America for its political stability, low violent-crime rate and well-run healthcare system.",
    "readingTime": 2,
    "keywords": [
      "retirees",
      "healthcare",
      "residency",
      "income",
      "safety",
      "however",
      "safe",
      "index",
      "travel",
      "retirement"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/asked-chatgpt-safest-cheapest-countries-125852493.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/pMdnURAV2smhJ7cVNX20FA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/gobankingrates_644/52790f6873ea39af4b6ead891662bcb4",
    "created_at": "2026-01-07T06:19:55.626Z",
    "topic": "finance"
  },
  {
    "slug": "the-companies-that-make-your-hard-disk-drives-are-having-a-rally-of-a-lifetime",
    "title": "The companies that make your hard disk drives are having a rally of a lifetime",
    "description": "Hard-drive and storage stocks surged after Nvidia CEO Jensen Huang highlighted data storage as a key AI bottleneck at CES.",
    "fullText": "The companies behind some of tech's least glamorous products — hard drives and storage — are powering a sharp rally on Wall Street.\n\nThe surge comes after Nvidia CEO Jensen Huang said at CES 2026 on Monday that the AI boom isn't just about chips, but about where vast amounts of data live.\n\nSanDisk, the flash-memory company spun out of Western Digital last year, has been the standout. Its shares surged about 28% on Tuesday, marking their strongest intraday performance since February. The stock is already up more than 40% just days into January, making SanDisk the top performer in the S&P 500 on Tuesday.\n\nWestern Digital and Seagate Technology, two of the world's largest makers of hard-disk drives, are also seeing a boost. Western Digital's shares jumped about 17% on Tuesday, while Seagate rose about 14%.\n\nHuang described the memory storage market as a \"completely unserved market today.\"\n\n\"This market will likely be the largest storage market in the world, basically holding the working memory of the world's AIs,\" he said at CES with analysts on Monday.\n\n\"The amount of context memory, the amount of token memory that we process, KB cache we process, is now just way too high,\" he added, referring to AI storage needs.\n\nMemory prices have been rising. Korea Economic Daily reported on Monday that Samsung Electronics and SK Hynix are pushing for server DRAM price increases of 60% to 70% in the first quarter compared with the previous quarter.\n\nMarket analysis firm Counterpoint said last week that memory prices could rise by 40% through the second quarter of 2026, as AI-driven demand continues to strain supply.\n\nThe AI race has largely been about chips, data centers, and power. But data storage is coming into focus as a key bottleneck.\n\nDriven largely by AI workloads, the volume of stored global data was expected to top 200 zettabytes in 2025 — the equivalent of 200 billion terabytes.\n\nAnalysts have predicted that demand for data storage could run ahead of supply.\n\n\"The memory market is at an unprecedented inflexion point, with demand materially outpacing supply,\" an analyst from global market intelligence firm International Data Corporation wrote in a December note.\n\n\"For an industry that has long been characterized by boom-and-bust cycles, this time is different,\" the analyst said, citing the rapid build-out of AI infrastructure and workloads as a shift that is straining the memory ecosystem.\n\n\"For consumers and enterprises alike, this signals the end of an era of cheap, abundant memory and storage, at least in the medium term,\" the analyst added.",
    "readingTime": 3,
    "keywords": [
      "storage market",
      "memory",
      "quarter",
      "demand",
      "supply",
      "analyst",
      "drives",
      "chips",
      "sandisk",
      "shares"
    ],
    "qualityScore": 1,
    "link": "https://markets.businessinsider.com/news/stocks/hard-drive-storage-stocks-sandisk-western-digital-seagate-ai-boom-2026-1",
    "thumbnail_url": "https://i.insider.com/695dd599832e0ef1ead74e72?width=1200&format=jpeg",
    "created_at": "2026-01-07T06:19:49.268Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-says-china-will-far-exceed-the-rest-of-the-world-in-ai-compute",
    "title": "Elon Musk says China will 'far exceed the rest of the world in AI compute'",
    "description": "Elon Musk says China's electricity advantage gives it the edge to \"far exceed the rest of the world in AI compute.\"",
    "fullText": "Elon Musk says China is on track to outpace every other country in the computing power needed to run AI.\n\nThe Tesla and SpaceX CEO said in an episode of the \"Moonshots with Peter Diamandis\" podcast published Tuesday that \"China's going to have more power than anyone else and probably will have more chips.\"\n\n\"Based on current trends, China will far exceed the rest of the world in AI compute,\" he added.\n\nMusk said China's decisive advantage in the AI race lies in its ability to scale electricity generation. He estimated that China could reach about three times the electricity output of the US by 2026, giving it the capacity to support energy-hungry AI data centers.\n\nElectricity generation is the limiting factor to scaling AI systems, Musk said.\n\n\"People are underestimating the difficulty of bringing electricity online,\" he added.\n\nWhile the US has focused on restricting China's access to advanced semiconductors, Musk suggested those constraints may matter less over time. China will \"figure out the chips,\" he said.\n\nMusk added that diminishing returns at the cutting edge of chip performance might make it easier for China to catch up, even without access to the most advanced designs.\n\nMusk has previously pointed to China as a model in areas beyond AI infrastructure.\n\nIn an episode of the \"People by WTF\" podcast published in November, Musk said he wants to turn his social media platform X into \"WeChat++,\" referencing China's dominant super app.\n\n\"I also like the idea of sort of having a unified app or website or whatever, where you can do anything you want there,\" he said. \"China has this with WeChat.\"\n\nMusk's comments come as energy supply and data infrastructure emerge as key constraints in scaling AI, rather than chips or algorithms.\n\nCompanies worldwide have rushed to build AI data centers, many of which require as much electrical power as small cities.\n\nA report from Goldman Sachs in November said that an electricity shortage could slow US progress in the AI race.\n\n\"As AI demands massive power, a reliable and ample power supply is likely to be a key factor shaping this race, especially because power infrastructure bottlenecks can be slow to solve,\" wrote Goldman's analysts.\n\nThe report added that while pressure on the US power grid is increasing, China has been steadily expanding its energy capacity.\n\n\"We expect China's spare capacity to remain sufficient to accommodate data center power demand growth while supporting demand in other industries,\" the analysts wrote.\n\nIn his annual New Year's address last week, Chinese leader Xi Jinping praised his country's progress in AI in 2025, saying China had \"integrated science and technology deeply with industries, and made a stream of new innovations.\"\n\n\"Many large AI models have been competing in a race to the top, and breakthroughs have been achieved in the research and development of our own chips,\" he said in his speech in Beijing.\n\n\"All this has turned China into one of the economies with the fastest-growing innovation capabilities,\" he added.",
    "readingTime": 3,
    "keywords": [
      "podcast published",
      "electricity generation",
      "china",
      "china's",
      "chips",
      "race",
      "capacity",
      "infrastructure",
      "musk",
      "episode"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/elon-musk-china-ai-compute-exceed-electricity-power-2026-1",
    "thumbnail_url": "https://i.insider.com/695de877832e0ef1ead74f12?width=800&format=jpeg",
    "created_at": "2026-01-07T06:19:49.063Z",
    "topic": "finance"
  },
  {
    "slug": "ces-2026-lenovos-new-ai-frame-gaming-monitor-might-actually-just-be-cheating",
    "title": "CES 2026: Lenovo's New 'AI Frame' Gaming Monitor Might Actually Just Be Cheating",
    "description": "Is it OK to use AI to zoom in on your reticle in a shooter?",
    "fullText": "It's easy to take this for granted, but not everyone is able to immediately look at a shooting or strategy game and find the reticle or map. Gaming UIs can get complicated, and for less-seasoned gamers, they can be pretty intimidating, too. Lenovo's new concept \"AI Frame\" monitor, shown off at CES 2026, aims to make some games a bit more approachable, although experts might consider it cheating.\n\nHardware-wise, this is a normal 21:9 ultrawide gaming monitor, but it's not actually meant to be used like that. Instead, you play your game in a left-justified 16:9 rectangle that takes up most of the screen, and in the remaining space, the AI will automatically zoom in on part of your gameplay and show a blown-up version of it. For instance, it might show you a zoomed-in map in a MOBA, so you don't have to look at the tiny mini-map in your main gameplay to know where you or your team are. Or, it might zoom in on your reticle in a shooter, letting you better see your targets. There's even enough space left over for you to pull up an internet browser and look up some help.\n\nIt worked pretty well for me in-person. Again, it doesn't actually generate any visuals, but instead just blows up the most important parts of your game screen so you can more easily glance at them or see them in more detail. That does mean resolution can suffer a little, but that's what your main gameplay screen is for. For getting across information, it's a good option.\n\nPlus, while some games will automatically know what to zoom in on, there's also a generic zoom mode that will just blow up whatever your mouse is hovering over, so it can work with any content. The AI Frame is being pitched for games, but you could also use it like a digital magnifying glass on an article in your browser, for instance.\n\nThe catch? It's maybe not exactly \"fair\" to play this way. While a bigger map in a MOBA might just save you some eyestrain, an AI-assisted zoom on a shooting reticle basically lets anyone act like a sniper, regardless of what character you're playing or gun you have equipped. For me, characters in the distance that were basically ants became immediately visible on the AI Frame, which made gunfights much easier to handle.\n\nI suppose we'll cross that bridge when we come to it. The AI Frame is just a proof-of-concept for now, so there's no hard specs sheet or pricing or release date as of yet. But if this does ever actually make it to market, Lenovo might have to contend with companies like Valve. The developer has banned similar \"this is arguably cheating\" peripherals from its games before, and the AI Frame could be the next battlefront in an ongoing war between peripheral makers (who want to sell you on the idea that buying their products can make you a better player) and developers (who, at least theoretically, want all of their players to be on an even playing field).",
    "readingTime": 3,
    "keywords": [
      "ai frame",
      "the ai frame",
      "zoom",
      "it's",
      "games",
      "look",
      "game",
      "reticle",
      "screen",
      "gameplay"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/ces-2026-lenovo-new-ai-frame-gaming-monitor?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KE7S2FA6VH9Y9YDASD2FZS56/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-07T06:19:48.153Z",
    "topic": "tech"
  },
  {
    "slug": "on3-trends-for-turning-off-x-comments-to-prevent-grok-ai-from-spoiling-paywall",
    "title": "On3 trends for turning off X comments to prevent Grok AI from spoiling paywall",
    "description": "This is a fascinating modern problem.",
    "fullText": "On3 trends for turning off X comments to prevent Grok AI from spoiling paywall originally appeared on The Sporting News. Add The Sporting News as a Preferred Source by clicking here.\n\nThe On3 Sports recruiting website is a popular destination for commitment information, transfer rankings and much \n\nIt has also made a social media decision on X which is very much a dilemma for modern times.\n\nOn3 turned off replies to its posts on X because of AI.\n\nX, formerly Twitter, has an AI feature known as Grok. A poster can ask Grok any question, and the artificial intelligence will answer.\n\nWhen articles are behind paywalls, like they often are for On3, Grok can help someone know what is in the article without someone having to click into it and pay a subscription.\n\nMORE: Notre Dame QBs have lost their last 25 NFL starts\n\nGrok doesn't always have the perfect answer to questions anyway, but it's still a notable move by On3.\n\nA site like that, which specializes in exclusive recruiting information, needs subscribers to pay the reporters who have tracked down such information.\n\nIf people are able to get around the paywall and not pay a subscription, it threatens the very ecosystem of such a publication.\n\nIt'll be interesting to see if other subscription-based services take steps like this as the world of AI gets deeper and more intricate. For now, On3 may be at the start of a trend.\n\nMORE: Syracuse's best-ever football recruit is going to play basketball, too",
    "readingTime": 2,
    "keywords": [
      "paywall",
      "sporting",
      "recruiting",
      "someone",
      "subscription",
      "grok"
    ],
    "qualityScore": 0.85,
    "link": "https://sports.yahoo.com/articles/on3-trends-turning-off-x-005213214.html",
    "thumbnail_url": "https://media.zenfs.com/en/the_sporting_news_articles_584/ab5069f8c64b47bb11fef8be9805a57c",
    "created_at": "2026-01-07T00:59:07.251Z",
    "topic": "sports"
  },
  {
    "slug": "to-ease-recruiters-fears-of-being-replaced-by-ai-zillow-experimented-with-promptathons-now-the-real-estate-giant-has-6",
    "title": "To ease recruiters’ fears of being replaced by AI, Zillow experimented with ‘prompt-a-thons.’ Now the real estate giant has 6 new recruitment tools",
    "description": "\"About 80% of our jobs were what you would hear in the conferences about the mundane tasks” that AI could replace, said Zillow’s VP of talent acquisition.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/01/06/recruiters-fear-replaced-by-ai-zillow-prompt-a-thons-new-tools/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/01/GettyImages-2163867930-e1767737255755.jpg?resize=1200,600",
    "created_at": "2026-01-07T00:58:22.666Z",
    "topic": "business"
  },
  {
    "slug": "the-investor-who-blocked-a-9-billion-ai-deal-expects-that-bet-to-soon-pay-off",
    "title": "The investor who blocked a $9 billion AI deal expects that bet to soon pay off",
    "description": "Shareholders voted down a takeover bid for Core Scientific late last year because it wasn't rich enough. Here's why they think the bet will pay off.",
    "fullText": "The investment manager who helped scuttle one of the biggest data center acquisitions of 2025 believes that his bet against the multibillion-dollar buyout is about to pay off in the new year.\n\nTrip Miller, the founder and managing partner of the Memphis-based investment firm Gullane Capital Partners, believes that Core Scientific, a data center developer and operator, is on the cusp of large new customer deals that will boost its value.\n\n\"I think over the next 90 days, you'll see them announce greater than a hundred megawatts of deals,\" Miller said. \"It would show that there was a lot more value to be tapped there than we were getting paid for under the CoreWeave deal.\"\n\nIn October, Miller, a major shareholder in Core Scientific, opposed an offer by the artificial intelligence cloud firm CoreWeave to acquire Core Scientific in a stock conversion deal that he felt undervalued the company. The purchase was originally valued at around $9 billion when it was announced in July, but fell to almost half of that when shares of CoreWeave dipped in the ensuing months. Shareholders in the firm rejected the deal in a vote on October 30 that reflected the concerns over the deal's weakened economics.\n\nMiller said that his expectation for the roughly 100 megawatts of near-term commitments was based on conversations he has had with knowledgeable parties outside of the company's management. He projected that the company will find takers for a total of roughly 400 megawatts this year, citing strong demand for AI computing power.\n\nAsked about the potential for upcoming leasing, a spokeswoman for Core Scientific said the company \"does not comment on market rumors or speculation.\"\n\nThe commitments, if they materialize, would show that data center developers with a runway for growth are increasingly valuable in an energy-constrained building boom.\n\nCore Scientific has disclosed that it has about 1 gigawatt of data center capacity and another 1.5 gigawatts of power for expansion, according to an October investor presentation.\n\nIt would also offer a competing view that the hundreds of billions of dollars being spent on data centers, computer chips, and power infrastructure are in support of a durable AI boom, not a bubble.\n\n\"We are in a situation where we're likely to be systematically short compute —where the demand for compute will outstrip the supply,\" Stephen Byrd, Morgan Stanley's global head of thematic research and sustainability research, said.\n\nIn a report published in December, Morgan Stanley suggested that one of the most significant hurdles for the AI industry will be the gargantuan loads of power required to drive its computing.\n\nMorgan Stanley projects that data centers, the vast facilities that handle the training for large language AI models and the inference computations that put them to work in everyday applications, face a 47 gigawatt shortfall of electricity from the grid nationally by 2028 — a gap almost 10 times the size of New York City's energy footprint on an average day.\n\nAmong the chief beneficiaries are crypto mining firms that have access to in-place power and utility contracts to light up new facilities quickly.\n\nBoth Core Scientific and CoreWeave were former crypto mining companies before repurposing their businesses to focus on AI in recent years.\n\nAmid the mounting shortage of power — along with headwinds in the crypto mining business — more of the industry is turning to data center computing.\n\nByrd said Morgan Stanley anticipates that about 12 gigawatts of mining facilities, about 60% the mining industry's current gigawattage, will convert over to AI and high-performance computing in the next three years.\n\nIn September, Cipher Mining announced it would build a data center in Colorado City, Texas, with 168 megawatts of computing capacity that will be leased to the AI cloud company, Fluidstack. Cipher's stock, which had been trading in August for around $5 a share, jumped as high as roughly $25 in November after the announcement.\n\nIren, another mining firm, announced a recent $9.7 billion AI cloud computing deal with Microsoft. Last month, Hut 8, said it had signed a deal to lease a 245-megawatt data center it is developing in Louisiana to Fluidstack.\n\n\"Our view is that crypto miners, by and large, are likely to pivot for the most part to delivering high-performance compute infrastructure solutions and services,\" Paul Golding, an analyst at Macquarie who covers the crypto mining industry, said.\n\nIn July 2025, CoreWeave said it had reached an agreement to acquire Core Scientific in a stock conversion. But in the months after the announcement, CoreWeave's shares declined and Core Scientific's rose, effectively reducing the value of CoreWeave's offer.\n\nSince the deal's collapse, shares of Core Scientific have traded as low as below $14 a share — less than the $17 per share price that the CoreWeave deal would have amounted to.\n\nGolding covers Core Scientific and has set a $34 target for the company's stock in October, more than double its current market price — upside that he sees stemming from its ability to tap power in a constrained utility market. That estimate is \"based on a sum of the parts that evaluated potential value for the uncontracted megawatts in the portfolio, the megawatt pipeline in load study phase, and the existing co-location deal with CoreWeave,\" Golding said.\n\nCoreWeave is Core Scientific's only data center customer, outside of legacy crypto mining facilities it operates. Core Scientific leases 590 megawatts to CoreWeave, worth roughly $10 billion in revenue over the next 12 years, according to a spokeswoman for the company. It plans to repurpose 400 megawatts of its crypto mining operations over to high-performance computing in the next three years, the spokeswoman said.\n\nMiller said that the upcoming leases he expects Core Scientific to announce will be with new customers.\n\n\"I expect them to announce deals for AI with third parties other than CoreWeave,\" Miller said.",
    "readingTime": 5,
    "keywords": [
      "core scientific",
      "acquire core",
      "stock conversion",
      "coreweave deal",
      "high-performance computing",
      "crypto mining",
      "roughly megawatts",
      "mining facilities",
      "morgan stanley",
      "core scientific's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/core-scientific-corz-investor-trip-miller-expects-new-ai-deals-2026-1",
    "thumbnail_url": "https://i.insider.com/695d54d204eda4732f2e9077?width=427&format=jpeg",
    "created_at": "2026-01-07T00:58:22.009Z",
    "topic": "science"
  },
  {
    "slug": "ai-automation-paradox-more-work-not-less",
    "title": "AI automation paradox: More work, not less",
    "description": ": Workers face new mental health pressures as they shift from doing tasks to babysitting agentic AI",
    "fullText": "A report on occupational health warns that AI adoption may paradoxically increase workplace burdens rather than reduce them. As AI automates routine tasks, workers will shoulder new responsibilities: overseeing AI systems, catching their errors, and managing the resulting complexity – potentially triggering mental health pressures.\n\nResearchers from Imperial College London and Microsoft argue the real impact won't be mass job replacement, but a fundamental shift in work demands. Human roles will evolve from performing tasks to stewarding AI agents across workflows, including briefing them, reviewing outputs, and correcting errors.\n\n\"As AI absorbs routine tasks, human roles may shift toward stewardship, problem-solving, or emotional labor, all with their own psychological demands,\" said Dr Lara Shemtob, who led the research published in the Society of Occupational Medicine's (SOM) journal Occupational Medicine.\n\nThis effectively transforms workers into managers of AI systems – a role not everyone is suited for. The report warns AI may \"paradoxically increase the knowledge worker's burden of handling complex tasks while simultaneously exerting downward pressure on compensation.\" This means more responsibility and less pay, because AI supposedly makes work \"easier.\"\n\nAll of this could introduce novel occupational hazards, some familiar in form but different in scale and complexity, raising stress levels.\n\nEvidence already supports this concern. A 2024 study found AI coding tools actually slowed developers down due to time spent checking and correcting AI-generated errors. As AI systems become more autonomous, problems like \"hallucinations\" (false or inaccurate outputs) may escalate and become harder to detect.\n\nUntil now, much of the debate over AI has centred on the extent to which it will (or maybe won't) replace people's jobs.\n\nThe report urges quantifying AI supervision demands and building them into job descriptions to avoid hidden workloads that negate automation benefits.\n\nResearchers don't yet know the exact impact on human employees from having to work more closely with AI, the report concludes, but they say occupational health should be part of the dialog and analysis of how AI changes expectations of workers.\n\nWhether this scenario materializes remains uncertain. Recent reports show companies have invested tens of billions in generative AI with little return, and many projects fail due to underestimated deployment complexity.\n\nThe question isn't just how AI will change work, it's whether widespread adoption will happen at all. ®",
    "readingTime": 2,
    "keywords": [
      "paradoxically increase",
      "human roles",
      "routine tasks",
      "occupational health",
      "as ai",
      "workers",
      "systems",
      "errors",
      "complexity",
      "demands"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theregister.com/2026/01/06/ai_could_damage_your_health/",
    "thumbnail_url": "https://regmedia.co.uk/2024/11/19/shutterstock_mental_health.jpg",
    "created_at": "2026-01-07T00:58:15.466Z",
    "topic": "tech"
  },
  {
    "slug": "laylo-yc-s20-head-of-growth-organic-and-partners-and-loops-and-ai-remote-us",
    "title": "Laylo (YC S20) – Head of Growth (Organic and Partners and Loops and AI) – Remote US",
    "description": "Laylo is the Drop CRM powering iconic artists and live events. The platform combines landing pages, messaging, link tracking, and more to drive more tickets, merch and streams through Instagram DM, SMS and Email. Today, we power CRM across hundreds of millions of fans for some of the biggest names in entertainment like Sabrina Carpenter, Outside Lands and Skrillex.\nRole Overview\nWe’re looking for a Head of Growth (player/coach) to build and run Laylo’s growth engine. A 0→1 builder who doesn’t just ideate, but ships.",
    "fullText": "Laylo is the Drop CRM powering iconic artists and live events. The platform combines landing pages, messaging, link tracking, and more to drive more tickets, merch and streams through Instagram DM, SMS and Email. Today, we power CRM across hundreds of millions of fans for some of the biggest names in entertainment like Sabrina Carpenter, Outside Lands and Skrillex.\n\nWe’re looking for a Head of Growth (player/coach) to build and run Laylo’s growth engine. A 0→1 builder who doesn’t just ideate, but ships. You’ll create great content, run scrappy experiments, and build product growth loops that compound. This is a hands-on role: you’ll set strategy, execute a rapid experiment cadence, measure results, and turn wins into repeatable playbooks.\n\nYou’ll focus primarily on non-advertising channels: organic social, influencer/creator collaborations, channel partners, and product growth loops. We value strong taste, speed, and a rigorous learning cadence.\n\nYou’ll report directly to the CEO and work closely with Product, Engineering, Design, Partnerships, and Sales. You’re likely a good fit if you’re excited to open Adobe/Figma/Notion/PostHog and ship something today.\n\nSend us your first out-of-the-box idea for your first campaign in this role. Bonus points for mentioning other companies and campaigns you think are relevant.\n\nOur founders met while building competing consumer startups. We launched multiple products across consumer and SaaS and talked to thousands of fans and creators in the process. In 2020, we realized one of the biggest pain points artists and events face is actually driving their audience from socials into their own CRM.\n\nIn 2020, we joined Y Combinator’s summer batch and began building a product that quickly gained strong early traction. We raised from top-tier investors like Eldridge and Sony and have since grown into a team of 24 exceptional individuals spanning product, sales, and operations.\n\nWe have a strong written documentation culture. We try to do as much as possible asynchronously to move quickly and efficiently. We have a daily 30 minute standup and team-specific meetings throughout the week.",
    "readingTime": 2,
    "keywords": [
      "growth loops",
      "product growth",
      "you’ll",
      "artists",
      "events",
      "across",
      "fans",
      "biggest",
      "role",
      "cadence"
    ],
    "qualityScore": 1,
    "link": "https://www.ycombinator.com/companies/laylo/jobs/ZtLHRXe-head-of-growth",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/754a3e51e9c1aefc039f635c1c2850f042fd591b.png?1659366538",
    "created_at": "2026-01-07T00:58:10.505Z",
    "topic": "jobs"
  },
  {
    "slug": "why-mark-cuban-says-ai-is-both-stupid-and-a-makeorbreak-tool-for-businesses",
    "title": "Why Mark Cuban says AI is both 'stupid' and a make-or-break tool for businesses",
    "description": "Mark Cuban explained why he's bullish about AI, even though chatbots can be \"stupid\" and don't always give accurate, timely information.",
    "fullText": "Mark Cuban believes businesses need to embrace AI to succeed, but he says those that use it incorrectly are doomed to failure.\n\n\"There's going to be two types of companies: those who are great at AI, and everybody else,\" the celebrity billionaire of \"Shark Tank\" fame said. \"And the 'everybody else' is going to fail because AI is such a transformative tool.\"\n\nThe comments came during a call with Clipbook founder Adam Joseph, whose startup secured a seven-figure investment from Cuban. Business Insider reviewed a recording of the call.\n\nOn the call, Cuban explained to Joseph how he believed everyone, from entrepreneurs to employees, should — and shouldn't — use AI.\n\nLike fellow shark Kevin O'Leary, Cuban thinks AI will have a substantial positive impact on businesses that implement it well. However, business leaders need to understand the intricacies and distinctions between different AI tools and not treat them as interchangeable. He said using AI ineffectively could turn helpful tools into an expensive distraction.\n\n\"Because AI is continuously changing, you need to just have people — and, really, every CEO — taking the time to understand every nuance of every new tool that comes out,\" Cuban said.\n\nThe world is still \"in the first inning of the first preseason game\" of the AI revolution, Cuban said, even though generative AI tools like ChatGPT have been out for more than three years, while other forms of AI, like machine learning, have been around for decades.\n\nTech companies like OpenAI, Google, Microsoft, Meta, and Elon Musk's xAI are spending tens of billions of dollars to win the AI wars.\n\nCuban said that \"it's too early to tell\" which of those companies will succeed, or if someone else will create the go-to AI chatbot.\n\n\"They all want to be the destination that everybody turns to, but it's not that straightforward, and we don't have a winner yet,\" Cuban said.\n\nBusinesses that discount the power of AI are destined to get disrupted, in Cuban's view.\n\n\"If I'm going to compete in an AI world, data or information is more valuable than gold, more valuable than oil,\" Cuban said.\n\nBut for all the hype about AI, Cuban is clear-eyed about the technology's limitations. AI tools can be mistake-prone yet hyperconfident, and chatbots aren't always smart.\n\n\"AI is stupid,\" Cuban said. \"But it's somebody who's a savant that remembers everything.\"\n\nCuban likened AI chatbots to people who have minds like a steel trap. These tools are able to instantly recall and process tons of information, then aggregate it in one place.\n\n\"It does a really good job of assembling all those things that it collected and presenting that just as somebody who has a great memory,\" Cuban said.\n\nAI chatbots have holes besides so-called hallucinations, Cuban said. AI tools sometimes don't pull up-to-date information. They can also be unclear about how they reach their conclusions, as their algorithms are opaque and can cite faulty or inaccurate links.\n\nHe also said that people often presume the \"AI models they're using or creating\" will provide all the answers they need, but that's \"just not the case.\"\n\nCuban said AI can actively harm businesses that use it incorrectly or those that don't understand its capabilities.\n\nEmployees who use standard versions of tools like ChatGPT could be compromising sensitive company information. Similarly, businesses that post their work online must also realize that they could be giving it away for free to web-scraping chatbots hungry for new information.\n\n\"Companies are learning now that their IP is incredibly valuable,\" Cuban said. \"Two years ago, last year, two months ago, they might have just posted everything on the net to show how smart they are, or shared everything in a proposal to show how smart they are. Now, you have to be really careful with your IP.\"\n\nCuban said academics or hospital researchers must pivot in the AI age away from a \"publish or perish\" mindset, where they share their findings widely in peer-reviewed journals.\n\n\"Now, doing that's the biggest mistake you can make, because all you're doing is training somebody else's models,\" Cuban said. \"And so you've got to be able to understand what IP you need to be able to protect, how you're going to disseminate that IP, whether or not you want to sell it, or keep it for your own models, and how you acquire information.\"",
    "readingTime": 4,
    "keywords": [
      "everybody else",
      "tools",
      "cuban",
      "businesses",
      "understand",
      "chatbots",
      "it's",
      "don't",
      "valuable",
      "smart"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mark-cuban-ai-artificial-intelligence-comments-chatgpt-openai-google-microsoft-2026-1",
    "thumbnail_url": "https://i.insider.com/68de39481c1f80efbec4c320?width=1200&format=jpeg",
    "created_at": "2026-01-06T18:18:24.369Z",
    "topic": "tech"
  },
  {
    "slug": "why-ai-boosts-creativity-for-some-employees-but-not-others",
    "title": "Why AI Boosts Creativity for Some Employees but Not Others",
    "description": "Generative AI is transforming workflows, yet its impact on employee creativity remains uneven. New research reveals one explanation: AI boosts creativity primarily for employees with strong metacognition—the ability to plan, monitor, and refine thinking. These individuals strategically use AI to expand knowledge, free cognitive capacity, and break fixed mindsets, thereby fueling creative ideas. Leaders should pair AI adoption with metacognitive training and design workflows that encourage strategic and iterative engagement. Organizations that cultivate metacognitive skills will turn AI from a productivity tool into a sustained source of creative advantage.",
    "fullText": "Why AI Boosts Creativity for Some Employees but Not Others by Jackson G. Lu, Shuhua Sun, Zhuyi Angelina Li, Maw-Der Foo and Jing ZhouJanuary 6, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintGenerative AI is increasingly embedded into day-to-day workflows across organizations globally. Employees are using AI tools like ChatGPT to brainstorm solutions, explore alternatives, summarize information, and accelerate projects. As these tools become more capable, many organizations hope they will spark higher levels of creativity, enabling employees to generate more novel and impactful ideas.",
    "readingTime": 1,
    "keywords": [
      "organizations",
      "tools",
      "employees",
      "creativity"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/why-ai-boosts-creativity-for-some-employees-but-not-others",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_18_GabrielMasella.jpg",
    "created_at": "2026-01-06T18:18:23.244Z",
    "topic": "business"
  },
  {
    "slug": "where-mckinseyand-consultinggo-from-here",
    "title": "Where McKinsey—and Consulting—Go From Here",
    "description": "A conversation with McKinsey Global Managing Partner Bob Sternfels on AI disruption, shifting business models and navigating controversy.",
    "fullText": "January 06, 2026\n\n How does an organization with 100 years of history stay relevant, adaptable, and forward-looking? Bob Sternfels, who runs McKinsey & Company as the Global Managing Partner, has led the company through a wave of recent challenges while trying to plan the road ahead for the consulting industry leader. He explains the balance he’s aiming to strike between AI agents and human employees, how he’s handled moments of scrutiny, and the ways in which he’s been working to build trust both internally and externally.",
    "readingTime": 1,
    "keywords": [
      "he’s"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/podcast/2026/01/where-mckinsey-and-consulting-go-from-here",
    "thumbnail_url": "https://hbr.org/resources/images/article_assets/2025/02/wide-ideacast_25.png",
    "created_at": "2026-01-06T18:18:23.088Z",
    "topic": "business"
  },
  {
    "slug": "nvidias-new-vera-rubin-chips-are-in-full-production",
    "title": "\"Nvidia's New Vera Rubin Chips Are in 'Full Production'\"",
    "description": "The chip giant says Vera Rubin will sharply cut the cost of training and running AI models, strengthening the appeal of its integrated computing platform.",
    "fullText": "Huang says that the company’s next-generation AI superchip platform, Vera Rubin, is on schedule to begin arriving to customers later this year. “Today, I can tell you that Vera Rubin is in full production,” Huang said during a press event on Monday at the annual CES technology trade show in Las Vegas.\n\nRubin will cut the cost of running AI models to about one-tenth of Nvidia’s current leading chip system, Blackwell, the company told analysts and journalists during a call on Sunday. Nvidia also said Rubin can train certain large models using roughly one-fourth as many chips as Blackwell requires. Taken together, those gains could make advanced AI systems significantly cheaper to operate and make it harder for Nvidia’s customers to justify moving away from its hardware.\n\nNvidia said on the call that two of its existing partners, Microsoft and CoreWeave, will be among the first companies to begin offering services powered by Rubin chips later this year. Two major AI data centers that Microsoft is currently building in Georgia and Wisconsin will eventually include thousands of Rubin chips, Nvidia added. Some of Nvidia’s partners have started running their next-generation AI models on early Rubin systems, the company said.\n\nThe semiconductor giant also said it’s working with Red Hat, which makes open source enterprise software for banks, automakers, airlines, and government agencies, to offer more products that will run on the new Rubin chip system.\n\nNvidia’s latest chip platform is named after Vera Rubin, an American astronomer who reshaped how scientists understand the properties of galaxies. The system includes six different chips, including the Rubin GPU and a Vera CPU, both of which are built using Taiwan Semiconductor Manufacturing Company’s 3-nanometer fabrication process and the most advanced bandwidth memory technology available. Nvidia’s sixth-generation interconnect and switching technologies link the various chips together.\n\nEach part of this chip system is “completely revolutionary and the best of its kind,” Huang proclaimed during the company’s CES press conference.\n\nNvidia has been developing the Rubin system for years, and Huang first announced the chips were coming during a keynote speech in 2024. Last year, the company said that systems built on Rubin would begin arriving in the second half of 2026.\n\nIt’s unclear exactly what Nvidia means by saying that Vera Rubin is in “full production.” Typically, production for chips this advanced—which Nvidia is building with its longtime partner TSMC—starts at low volume while the chips go through testing and validation and ramps up at a later stage.\n\n“This CES announcement around Rubin is to tell investors, ‘We’re on track,’” says Austin Lyons, an analyst at Creative Strategists and author of the semiconductor industry newsletter Chipstrat. There were rumors on Wall Street that the Rubin GPU was running behind schedule, Lyons says, so Nvidia is now pushing back by saying it has cleared key development and testing steps, and it’s confident Rubin is still on course to begin scaling up production in the second half of 2026.\n\nIn 2024, Nvidia had to delay delivery of its then-new Blackwell chips due to a design flaw that caused them to overheat when they were connected together in server racks. Shipments for Blackwell were back on schedule by the middle of 2025.\n\nAs the AI industry rapidly expands, software companies and cloud service providers have had to fiercely compete for access to Nvidia’s newest GPUs. Demand will likely be just as high for Rubin. But some firms are also hedging their bets by investing in their own custom chip designs. OpenAI, for example, has said it is working with Broadcom to build bespoke silicon for its next generation of AI models. These partnerships highlight a longer-term risk for Nvidia: Customers that design their own chips can gain a level of control over their hardware that the company doesn’t offer.\n\nBut Lyons says today’s announcements demonstrate how Nvidia is evolving beyond merely offering GPUs to becoming a “full AI system architect, spanning compute, networking, memory hierarchy, storage, and software orchestration.” Even as hyperscalers pour money into custom silicon, he adds, Nvidia’s tightly integrated platform “is getting harder to displace.”",
    "readingTime": 4,
    "keywords": [
      "second half",
      "chip system",
      "vera rubin",
      "rubin chips",
      "huang",
      "production",
      "models",
      "blackwell",
      "platform",
      "schedule"
    ],
    "qualityScore": 1,
    "link": "https://www.wired.com/story/nvidias-rubin-chips-are-going-into-production/",
    "thumbnail_url": "https://media.wired.com/photos/695bffe313835ca4d6b41e4a/191:100/w_1280,c_limit/Nvidia-Rubin-Chips-Going-Into-Production-Business-2192346797.jpg",
    "created_at": "2026-01-06T18:18:22.716Z",
    "topic": "tech"
  },
  {
    "slug": "frictionmaxxing-could-less-convenience-lead-to-much-more-happiness",
    "title": "Friction-maxxing: could less convenience lead to much more happiness?",
    "description": "The conveniences of modern life such as Uber Eats and ChatGPT are robbing us of satisfaction – and worse still, infantilising us. But should we really go back to the basics? \nName: Friction-maxxing.\nAge: Brand new.\n Continue reading...",
    "fullText": "The conveniences of modern life such as Uber Eats and ChatGPT are robbing us of satisfaction – and worse still, infantilising us. But should we really go back to the basics?\n\nAppearance: A lifetime of happy inconvenience.\n\nIs this another example of something that already exists, but people think is new because someone rebranded it? Yes, obviously it is that.\n\nGreat! Let’s all save time by you telling me what it used to be called. Happy to oblige. It used to be called “character-building”.\n\nGot it. So friction-maxxing means doing hard things that will ultimately make you a better person? That’s exactly it, although “friction-maxxing” is cooler because it sounds vaguely futuristic.\n\nHow did the term come about? Via a piece in The Cut called “In 2026, we are friction-maxxing” in which writer Kathryn Jezer-Morton advocates for avoiding things that make your life more convenient.\n\nLike penicillin? No, obviously not penicillin. But things such as ChatGPT, location sharing and Uber Eats, which help you achieve things that historically took significant amounts of time and effort. Jezer-Morton argues that this culture of slick convenience only serves to infantilise us.\n\nBut it’s so easy. Yes, and that robs us of our sense of satisfaction. So you just used AI to write a school essay. Congratulations, you have achieved nothing of worth.\n\nWhereas if you friction-maxx? Then you’ve searched inside yourself. You’ve nudged your own personal boundaries, and discovered that you are more capable than you ever knew. You are building a foundation of perseverance and resilience that you cannot get from typing a prompt into a chatbot.\n\nI love this! What else does Jezer-Morton advocate? She also suggests sending your children on small errands (adding the friction of knowing they’ll do a bad job) and inviting people to your house without cleaning it properly (so you can enjoy the sweet friction of being judged).\n\nWhat the hell? That’s weird. No, it’s friction-maxxing, although admittedly at a higher level than I would be comfortable with.\n\nAnyway, hooray for banishing convenient things. Let’s ban automatic gearboxes while we’re at it! No, there’s no need for that.\n\nDishwashers? Refrigerators? No, both of those are probably fine as well.\n\nMechanised agriculture? The printing press? I see what you’re getting at. You’re saying we live in a world that is already filled with thousands of inventions which have, for hundreds of years, improved the lives of millions of people through increased convenience, and therefore it does seem slightly arbitrary to choose this exact moment in time to draw a line in the sand. You’re saying we should only use friction-maxxing when it comes to things that we didn’t grow up with.\n\nNo, I’m saying that I really hate mechanised agriculture. Oh, fine then. That’s probably allowed.\n\nDo say: “I hope a book comes out about friction-maxxing.”\n\nDon’t say: “I don’t want to read it, but I’m sure ChatGPT could turn it into some really great bullet points.”",
    "readingTime": 3,
    "keywords": [
      "you’re saying",
      "mechanised agriculture",
      "friction-maxxing",
      "that’s",
      "life",
      "satisfaction",
      "happy",
      "obviously",
      "convenient",
      "penicillin"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/06/friction-maxxing-could-less-convenience-lead-to-much-more-happiness",
    "thumbnail_url": "https://i.guim.co.uk/img/media/fd03fb9c7dcc6b61ed9f7990a15bd937bbafa652/1108_0_5539_4431/master/5539.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=f7f066f98957833fd4e1e0a3069417c3",
    "created_at": "2026-01-06T18:18:17.287Z",
    "topic": "tech"
  },
  {
    "slug": "playstation-ai-patent-could-see-games-play-themselves-when-players-get-stuck",
    "title": "PlayStation AI Patent Could See Games Play Themselves When Players Get Stuck",
    "description": "Sony has filed a patent document that could potentially allow AI to take over your game for you if you're struggling with it. The documents suggest that this \"ghost assistance\" can be activated at any time to either guide a player through progression or assume direct control of gameplay.\nAs revealed in the patent documents first filed in September 2024 (via VGC), the AI assistance system could potentially play through a section of a game that a player is struggling with, completing it for them. Sony describes the idea of training its AI agent using \"footage from many users that have played the game\" and various other online sources where gameplay videos have been uploaded.\nAn example from Sony, showing how the feature could potentially work.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/playstation-ai-patent-could-see-games-play-themselves-when-players-get-stuck/1100-6537196/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1601/16018044/4630348-assuming-direct-control.jpg",
    "created_at": "2026-01-06T18:18:15.562Z",
    "topic": "gaming"
  },
  {
    "slug": "lies-of-p-publisher-is-excited-about-ai-to-maximize-player-engagement",
    "title": "Lies Of P Publisher Is Excited About AI To \"Maximize Player Engagement\"",
    "description": "Lies of P publisher Neowiz describes itself as a \"forward-thinking technology company,\" and its co-CEO says that means the company is exploring how all manner of technology-based solutions can help the company's business in the future, including AI.\nSean Kim told Game Informer that Korea, where Neowiz is based, is understood to be one of the countries where ChatGPT is \"used most actively.\" He added, \"It's hard to find a game company here today that isn’t using AI in some way. At the very least, companies are using either ChatGPT or Gemini.\"\nFor Neowiz, Kim said, \"We are actively exploring how advanced learning tools can enhance our internal publishing productivity,\" and this includes AI.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/lies-of-p-publisher-is-excited-about-ai-to-maximize-player-engagement/1100-6537198/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1179/11799911/4630369-screenshot2026-01-06at8.45.26%E2%80%AFam.png",
    "created_at": "2026-01-06T18:18:15.506Z",
    "topic": "gaming"
  },
  {
    "slug": "razer-reveals-an-aipowered-headset-at-ces-2026",
    "title": "Razer Reveals An AI-Powered Headset at CES 2026",
    "description": "CES 2026 has officially begun, and Razer is using this year's showcase to reveal a slew of AI-powered gadgets. One of the most intriguing debuts is Project Motoko, an AI headset powered by Snapdragon. Equipped with a pair of cameras near each earcup, it's capable of analyzing your surroundings and giving you audio feedback on what it sees.\nRazer says Project Motoko can provide all sorts of feedback to users. For example, it can be used while gaming to get feedback about a boss fight, detecting what's on the screen and giving you immediate tips.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/razer-reveals-an-ai-powered-headset-at-ces-2026/1100-6537203/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1702/17023653/4630478-razer_motoko_kv-2048x1152%281%29.jpg",
    "created_at": "2026-01-06T18:18:15.464Z",
    "topic": "gaming"
  },
  {
    "slug": "razers-new-holographic-ai-assistant-sits-on-your-desk-and-promises-help-not-judgement",
    "title": "Razer's New Holographic AI Assistant Sits On Your Desk And Promises Help, Not Judgement",
    "description": "A lot of interesting technology has been revealed at the Consumer Electronics Show 2026 this week, but one of the strangest might be Razer's Project Ava, an AI-powered desktop companion. Razer envisions the device as a \"dynamic personality\" that can interact with its owners as a 3D hologram, and it'll have several animated personalities to choose from, including one based on the prominent League of Legends esports player, Faker.\nRazer claims that Ava uses human-like vision and audio-sensing for full contextual awareness, and that it can converse with people, consult on work tasks, and motivate you to engage in self-care routines. The company says it can also assist you in your work with \"two-way conversation\" features, and for gaming, it can fulfill multiple roles and deliver real-time hype.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/razers-new-holographic-ai-assistant-sits-on-your-desk-and-promises-help-not-judgement/1100-6537206/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1601/16018044/4630484-razer-project-ava.jpg",
    "created_at": "2026-01-06T18:18:15.388Z",
    "topic": "gaming"
  },
  {
    "slug": "claude-code-as-my-cofounder-and-coo",
    "title": "Claude Code as my co-founder and COO",
    "description": "Build transparent AI agents your team can learn, understand, and own. Full traces, cost tracking, guardrails, evaluations, and monitoring. Deploy in minutes.",
    "fullText": "Everything you need to build, deploy, and monitor AI agents with confidence.\n\nSee every step your agent takes. Complete visibility into decisions and actions.\n\nKnow exactly what each run costs. No surprises on your bill.\n\nYour data never trains models. Full control over your information.\n\nMeasure quality with automated evals. Know when agents improve or regress.\n\nRoll back to any previous version. Git-native agent management.\n\nGet notified when agents fail, drift, or need human input.\n\nConnect to Slack, Linear, GitHub, and your existing tools.\n\nReal-time dashboards for all your agents and squads.\n\nBuilt-in safety checks, rate limits, and cost controls.",
    "readingTime": 1,
    "keywords": [
      "agents",
      "agent"
    ],
    "qualityScore": 0.55,
    "link": "https://agents-squads.com/",
    "thumbnail_url": "https://agents-squads.com/og-image-v2.png",
    "created_at": "2026-01-06T12:24:30.496Z",
    "topic": "tech"
  },
  {
    "slug": "squads-cli-the-looker-tool-for-ai-agents",
    "title": "Squads CLI – the looker tool for AI agents",
    "description": "CLI for managing AI agent squads. Status, memory, goals, feedback, and dashboard for your autonomous agents. - agents-squads/squads-cli",
    "fullText": "agents-squads\n\n /\n\n squads-cli\n\n Public\n\n CLI for managing AI agent squads. Status, memory, goals, feedback, and dashboard for your autonomous agents.\n\n agents-squads.com\n\n License\n\n MIT license\n\n 3\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n agents-squads/squads-cli",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/agents-squads/squads-cli",
    "thumbnail_url": "https://opengraph.githubassets.com/8afec16007f199c337c03533fe2c1cbd506115b72c06ee112fa1e407d266e60f/agents-squads/squads-cli",
    "created_at": "2026-01-06T12:24:30.116Z",
    "topic": "tech"
  },
  {
    "slug": "ask-hn-has-macstadium-support-quality-declined-recently-postmortem",
    "title": "Ask HN: Has MacStadium support quality declined recently? (post-mortem)",
    "description": "Build faster with MacStadium's globally available, enterprise-grade Mac cloud solutions for AI, virtual desktops, and app development.",
    "fullText": "Build, test, and ship iOS and all Apple OS apps faster with reproducible environments and CI/CD automation.\n\nSecure, remote access to full macOS desktops for distributed teams and contractors.\n\nHarness Apple silicon for machine learning, edge intelligence, and high-performance workflows.\n\nCreate or enhance your Mac resources needed to support your business with a dedicated, private cloud built on genuine Apple hardware.\n\nMacStadium has been a leader in the Mac cloud space for over a decade. We’re proud to be a core part of the Apple developer ecosystem.\n\nMacStadium is certified to the highest level of cloud security and data privacy, including: SOC2 Type2, ISO certification, and EU-U.S. & Swiss-U.S. Privacy Shield\n\nPower everything from simple Xcode builds to fully integrated, complex, automated CI/CD pipelines that drive your mobile app development.\n\nRun automated tests for different Apple device sizes, iOS, and all other Apple OS versions in ephemeral environments.\n\nProvide secure, cloud-based Mac desktops to users worldwide for testing or as everyday workstations.\n\nOrka turns Mac hardware from a collection of machines into a fully orchestrated pool of macOS resources, capable of powering a fully integrated, automated CI/CD pipeline.\n\nFrom software development to secure desktops and AI innovation, Orka helps you operationalize Apple for the enterprise.",
    "readingTime": 2,
    "keywords": [
      "automated ci/cd",
      "fully integrated",
      "apple os",
      "secure",
      "desktops",
      "cloud",
      "environments",
      "macos",
      "resources",
      "hardware"
    ],
    "qualityScore": 0.85,
    "link": "https://macstadium.com",
    "thumbnail_url": "https://cdn.prod.website-files.com/687e650a56916806eaaf8f62/68c243e7987d53030f76fe53_Homepage-Social-Image2b.jpg",
    "created_at": "2026-01-06T12:24:29.861Z",
    "topic": "tech"
  },
  {
    "slug": "ai-tutoring-outperforms-inclass-active-learning",
    "title": "AI tutoring outperforms in-class active learning",
    "description": "Scientific Reports - AI tutoring outperforms in-class active learning: an RCT introducing a novel research-based design in an authentic educational setting",
    "fullText": "A systematic review of AI-driven intelligent tutoring systems (ITS) in K-12 education\n\n Article\n Open access\n 14 May 2025",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.1,
    "link": "https://www.nature.com/articles/s41598-025-97652-6",
    "thumbnail_url": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41598-025-97652-6/MediaObjects/41598_2025_97652_Fig1_HTML.png",
    "created_at": "2026-01-06T12:24:29.590Z",
    "topic": "tech"
  },
  {
    "slug": "leading-ai-expert-delays-timeline-for-its-possible-destruction-of-humanity",
    "title": "Leading AI expert delays timeline for its possible destruction of humanity",
    "description": "Former OpenAI employee Daniel Kokotajlo says progress to AGI is ‘somewhat slower’ than first predicted\nA leading artificial intelligence expert has rolled back his timeline for AI doom, saying it will take longer than he initially predicted for AI systems to be able to code autonomously and thus speed their own development toward superintelligence.\nDaniel Kokotajlo, a former employee of OpenAI, sparked an energetic debate in April by releasing AI 2027, a scenario that envisions unchecked AI development leading to the creation of a superintelligence, which – after outfoxing world leaders – destroys humanity.\n Continue reading...",
    "fullText": "Former OpenAI employee Daniel Kokotajlo says progress to AGI is ‘somewhat slower’ than first predicted\n\nA leading artificial intelligence expert has rolled back his timeline for AI doom, saying it will take longer than he initially predicted for AI systems to be able to code autonomously and thus speed their own development toward superintelligence.\n\nDaniel Kokotajlo, a former employee of OpenAI, sparked an energetic debate in April by releasing AI 2027, a scenario that envisions unchecked AI development leading to the creation of a superintelligence, which – after outfoxing world leaders – destroys humanity.\n\nThe scenario rapidly won admirers and detractors. The US vice-president, JD Vance, appeared to reference AI 2027 in an interview last May when discussing the US’s artificial intelligence arms race with China. Gary Marcus, an emeritus professor of neuroscience at New York University, called the piece a “work of fiction” and various of its conclusions “pure science fiction mumbo jumbo”.\n\nTimelines for transformative artificial intelligence – sometimes called AGI (artificial general intelligence), or AI capable of replacing humans at most cognitive tasks – have become a fixture in communities devoted to AI safety. The release of ChatGPT in 2022 vastly accelerated these timelines, with officials and experts predicting the arrival of AGI within decades or years.\n\nKokotajlo and his team named 2027 as the year AI would achieve “fully autonomous coding” although they said that this was a “most likely” guess and some among them had longer timelines. Now, some doubts appear to be surfacing about the imminence of AGI, and whether the term is meaningful in the first place.\n\n“A lot of other people have been pushing their timelines further out in the past year, as they realise how jagged AI performance is,” said Malcolm Murray, an AI risk management expert and one of the authors of the International AI Safety Report.\n\n“For a scenario like AI 2027 to happen, [AI] would need a lot of more practical skills that are useful in real-world complexities. I think people are starting to realise the enormous inertia in the real world that will delay complete societal change.”\n\n“The term AGI made sense from far away, when AI systems were very narrow – playing chess, and playing Go,” said Henry Papadatos, the executive director of the French AI nonprofit SaferAI. “Now we have systems that are quite general already and the term does not mean as much.”\n\nKokotajlo’s AI 2027 relies on the idea that AI agents will fully automate coding and AI R&D by 2027, leading to an “intelligence explosion” in which AI agents create smarter and smarter versions of themselves, and then – in one possible ending – kill all humans by mid-2030 in order to make room for more solar panels and datacentres.\n\nHowever, in their update, Kokotajlo and his co-authors revise their expectations for when AI might be able to code autonomously, putting this as likely to happen in the early 2030s, as opposed to 2027. The new forecast sets 2034 as the new horizon for “superintelligence” and does not contain a guess for when AI may destroy humanity.\n\n“Things seem to be going somewhat slower than the AI 2027 scenario. Our timelines were longer than 2027 when we published and now they are a bit longer still,” wrote Kokotajlo in a post on X.\n\nCreating AIs that can do AI research is still firmly an aim of leading AI companies. The OpenAI CEO, Sam Altman, said in October that having an automated AI researcher by March 2028 was an “internal goal” of his company, but added: “We may totally fail at this goal.”\n\nAndrea Castagna, a Brussels-based AI policy researcher, said there were a number of complexities that dramatic AGI timelines do not address. “The fact that you have a superintelligent computer focused on military activity doesn’t mean you can integrate it into the strategic documents we have compiled for the last 20 years.\n\n“The more we develop AI, the more we see that the world is not science fiction. The world is a lot more complicated than that.”",
    "readingTime": 4,
    "keywords": [
      "somewhat slower",
      "code autonomously",
      "science fiction",
      "artificial intelligence",
      "daniel kokotajlo",
      "timelines",
      "leading",
      "longer",
      "scenario",
      "systems"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/06/leading-ai-expert-delays-timeline-possible-destruction-humanity",
    "thumbnail_url": "https://i.guim.co.uk/img/media/621d2774578bd82f788e889462ab440458846efd/847_0_4751_3800/master/4751.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a329fbc2e6bc9de093b4b7842a2322fa",
    "created_at": "2026-01-06T12:24:21.724Z",
    "topic": "tech"
  },
  {
    "slug": "ai-images-of-maduro-capture-reap-millions-of-views-on-social-media",
    "title": "AI images of Maduro capture reap millions of views on social media",
    "description": "Lack of verified information and rapidly advanced AI tools make it difficult to separate fact from fiction on US attack\nMinutes after Donald Trump announced a “large-scale strike” against Venezuela early on Saturday morning, false and misleading AI-generated images began flooding social media. There were fake photos of Nicolás Maduro being escorted off a plane by US law enforcement agents, images of jubilant Venezuelans pouring into the streets of Caracas and videos of missiles raining down on the city – all fake.\nThe fabricated content intermixed with real videos and photos of US aircraft flying over the Venezuelan capital and explosions lighting up the dark sky. A lack of verified information about the raid coupled with AI tools’ rapidly advancing capabilities made discerning fact from fiction about the incursion on Caracas difficult.\n Continue reading...",
    "fullText": "Lack of verified information and rapidly advanced AI tools make it difficult to separate fact from fiction on US attack\n\nMinutes after Donald Trump announced a “large-scale strike” against Venezuela early on Saturday morning, false and misleading AI-generated images began flooding social media. There were fake photos of Nicolás Maduro being escorted off a plane by US law enforcement agents, images of jubilant Venezuelans pouring into the streets of Caracas and videos of missiles raining down on the city – all fake.\n\nThe fabricated content intermixed with real videos and photos of US aircraft flying over the Venezuelan capital and explosions lighting up the dark sky. A lack of verified information about the raid coupled with AI tools’ rapidly advancing capabilities made discerning fact from fiction about the incursion on Caracas difficult.\n\nVince Lago, the mayor of Coral Gables, Florida, posted the fake photo of Maduro being escorted by the DEA agents to Instagram, saying that the Venezuelan president “is the leader of a narco-terrorist organization threatening our country”. Lago’s post received more than 1500 likes and is still up as of this writing.\n\nTools for detecting manipulated content, such as reverse image search and AI-detection sites, can help assess whether online images are accurate, but they are inconsistent. Sofia Rubinson, a senior editor who studies misinformation and conspiracy theories for NewsGuard, told the Guardian that the fake images of Caracas are similar to actual events, which makes it even more difficult to figure out what is real.\n\n“Many of the AI-generated and out-of-context visuals that are currently flooding social media do not drastically distort the facts on the ground,” Rubinson said. “Still, the use of AI-generated fabrications and dramatic, out-of-context footage is being used to fill gaps in real-time reporting and represents another tactic in the misinformation wars – and one that is harder for fact checkers to expose because the visuals often approximate reality.”\n\nNewsGuard released a report on Monday afternoon that identified five fabricated and out-of-context photos as well as two videos of the military operation in Venezuela. One AI-generated photo shows a soldier posing next to Maduro, who has a black hood over his head. An out-of-context video shows a US special forces helicopter descending on a supposed Venezuelan military site – the actual footage was taken in June at the Fort Bragg army base in North Carolina.\n\nNewsGuard said the seven misleading photos and videos it identified have now garnered more than 14m views on X alone.\n\nOther footage from past events is also being circulated online and passed off as part of Saturday’s strike. Laura Loomer, a far-right influencer and Trump confidant, posted footage of a poster of the Venezuelan president on X saying that “the people of Venezuela are ripping down posters of Maduro”. According to Wired, the footage is from 2024. Loomer has since removed the post.\n\nAnother rightwing influencer and conspiracy theorist, Alex Jones, posted an aerial video on X of thousands of people cheering in Caracas. “Millions of Venezuelans flooded the streets of Caracas and other major cities in celebration of the ouster of Communist dictator Nicholas Maduro,” Jones wrote. “Now we need to see the same type of energy here on the HomeFront!”\n\nThe video, which is still up, has reached more than 2.2m views. Comments on the post from Community Notes, X’s crowdsource moderation tool, say that the video is “at least 18 months old”. A reverse image search of the video shows that the footage is actually from a protest in Caracas after Maduro’s disputed presidential win in July 2024.\n\nGrok, the platform’s AI chatbot, also disputes the timeline of Jones’ video, saying: “Current sources show no such celebrations in Caracas today, but pro-Maduro gatherings instead.”\n\nMeta, X and TikTok did not respond to requests for comment.",
    "readingTime": 4,
    "keywords": [
      "venezuelan president",
      "flooding social",
      "social media",
      "footage",
      "images",
      "fake",
      "photos",
      "videos",
      "out-of-context",
      "tools"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/05/maduro-venezuela-ai-images",
    "thumbnail_url": "https://i.guim.co.uk/img/media/35df40e3a592dccc6abb3cd5e258bad4fb3ac3c3/434_0_4632_3706/master/4632.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=1537fcf25eff90125608bde2363f7958",
    "created_at": "2026-01-06T12:24:21.562Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-ceo-reveals-new-reasoning-ai-tech-for-selfdriving-cars",
    "title": "Nvidia CEO reveals new ‘reasoning’ AI tech for self-driving cars",
    "description": "Jensen Huang also announces at CES new, more powerful Vera Rubin chips that will arrive later this year\nThe billionaire boss of the chipmaker Nvidia, Jensen Huang, has unveiled new AI technology that he says will help self-driving cars think like humans to navigate more complex situations.\nThe world’s most valuable company is to roll out the new technology, Alpamayo, which is designed to help self-driving cars handle tricky situations such as sudden roadworks or unusual driver behaviour on the road, rather than just reacting to previous patterns.\n Continue reading...",
    "fullText": "Jensen Huang also announces at CES new, more powerful Vera Rubin chips that will arrive later this year\n\nThe billionaire boss of the chipmaker Nvidia, Jensen Huang, has unveiled new AI technology that he says will help self-driving cars think like humans to navigate more complex situations.\n\nThe world’s most valuable company is to roll out the new technology, Alpamayo, which is designed to help self-driving cars handle tricky situations such as sudden roadworks or unusual driver behaviour on the road, rather than just reacting to previous patterns.\n\nNvidia claims Alpamayo will bring chain-of-thought reasoning to self-driving vehicles, combining what the car sees with language-like reasoning.\n\nIn a speech at the annual Consumer Electronics Show in Las Vegas, the Nvidia founder and chief executive said: “The ChatGPT moment for physical AI is here, when machines begin to understand, reason and act in the real world. Robotaxis are among the first to benefit.\n\n“Alpamayo brings reasoning to autonomous vehicles, allowing them to think through rare scenarios, drive safely in complex environments and explain their driving decision. It’s the foundation for safe, scalable autonomy.”\n\nNvidia has started producing a driverless car powered by its technology, the Mercedes-Benz CLA, in partnership with the German carmaker. It will be launched in the US in the coming months, followed by Europe and Asia. Huang showed a video of the car driving through San Francisco with a passenger sitting behind the steering wheel, their hands in their lap.\n\n“It drives so naturally because it learned directly from human demonstrators,” Huang said, “but in every single scenario … it tells you what it’s going to do, and it reasons about what it’s about to do.”\n\nHuang also said the company’s next generation of chips was in full production, and they could deliver five times the computing power of the company’s previous products when serving up chatbots and other AI apps.\n\nHe revealed new details about the chips, which will arrive later this year as Nvidia faces increasing competition from rivals as well as its own customers.\n\nThe Vera Rubin platform, made up of six separate Nvidia chips, is expected to debut later this year. The flagship server will contain 72 of the company’s graphics units and 36 of its new central processors.\n\nHuang showed how they could be strung together into “pods” with more than 1,000 Rubin chips and said they could improve the efficiency of generating what are known as “tokens” – the fundamental unit of AI systems – by 10 times.\n\nTo get the new performance results, Huang said the Rubin chips used a proprietary kind of data that the company hopes the wider industry will adopt.\n\nWhile Nvidia still dominates the market for training AI models, it faces far more competition – from traditional rivals such as Advanced Micro Devices as well as customers such as Alphabet’s Google – in delivering the fruits of those products to hundreds of millions of users of chatbots and other technologies.",
    "readingTime": 3,
    "keywords": [
      "rubin chips",
      "arrive later",
      "self-driving cars",
      "technology",
      "alpamayo",
      "reasoning",
      "it’s",
      "company’s",
      "huang",
      "nvidia"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/05/nvidia-chips-jensen-huang",
    "thumbnail_url": "https://i.guim.co.uk/img/media/09e8ebedefc1bb9bac94ec3c7c55104f1079452e/991_0_5000_4000/master/5000.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2def173c99103257df33325320988395",
    "created_at": "2026-01-06T12:24:21.561Z",
    "topic": "tech"
  },
  {
    "slug": "cevas-ai-dsp-powers-nxp-processors-for-softwaredefined-vehicles",
    "title": "Ceva’s AI DSP powers NXP processors for software-defined vehicles",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/cevas-ai-dsp-powers-nxp-processors-for-softwaredefined-vehicles-93CH-4432103",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2026-01-06T12:24:19.912Z",
    "topic": "finance"
  },
  {
    "slug": "lantronix-debuts-new-edge-ai-surveillance-platform-at-ces-2026",
    "title": "Lantronix debuts new edge AI surveillance platform at CES 2026",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/company-news/lantronix-debuts-new-edge-ai-surveillance-platform-at-ces-2026-93CH-4432105",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/world_news_2_108x81.jpg",
    "created_at": "2026-01-06T12:24:19.841Z",
    "topic": "finance"
  },
  {
    "slug": "adtechs-year-of-reinvention-these-are-the-storylines-that-will-shape-the-industry-in-2026",
    "title": "Adtech's year of reinvention: These are the storylines that will shape the industry in 2026",
    "description": "Adtech companies are rethinking their strategies amid the rise of AI and declines in web traffic. We break down the key questions.",
    "fullText": "Adtech is heading into a year of reinvention.\n\nThousands of attendees from the tech and media world are flying out to Las Vegas this week for the annual Consumer Electronics Show. Among them are reams of adtech executives who tend to use the sprawling expo as an opportunity to rehearse and roadtest their plans for the coming year.\n\nFacing the disruption from AI and the declining economics of monetizing traditional web pages, adtech companies are being forced to rethink their strategies — and in some cases, their customers — while attempting to stay one step ahead of Big Tech.\n\n\"Adtech, if nothing else, is incredibly adaptable,\" said Andrew Casale, CEO of the adtech company Index Exchange.\n\nHere are some of the key storylines adtech executives are likely to be chewing over during their meetings in Vegas this week.\n\nAI was an adtech buzzword long before the arrival of ChatGPT, but investors now want companies in the space to unlock more value using the technology.\n\nA raft of new AI startups has emerged in the adtech space, making use of generative AI to create ads and streamline marketers' workflows. Meanwhile, existing players are attempting to define the meaning of \"agentic advertising\" and develop industry standards and protocols to govern how different AI agents should interact with one another.\n\nAdtech companies are closely monitoring how AI is transforming the shopping experience. Will more consumers begin handing over the reins to AI agents for planning their next trip or completing their weekly shop? If so, that could give rise to a new form of advertising where agents advertise to other agents, rather than consumers, said Debra Aho Williamson, founder of the research and advisory firm Sonata Insights.\n\n\"Advertising right now is a pretty image or video aimed at a human designed to elicit a human emotion, but an ad between an agent doesn't even look like an ad, it's just a bit of code or numbers designed to cause one agent to take an action with another agent,\" Aho Williamson said.\n\nAnd of course, adtech insiders are eagerly waiting for when — or if — OpenAI will finally reveal how it plans to integrate ads and whether they can grab a piece of the action there, too.\n\nThe rise of AI chatbots is threatening adtech's bread and butter: serving ads on web pages.\n\nMany publishers are entering 2026 on the back of hefty traffic declines last year, which some attribute to consumers getting the information they need from AI overviews or answer engines without needing to click through to a site. A report released in July from the analytics platform Similarweb found that the median \"zero-click rate\" — the number of users who didn't click from Google's results to a website — rose from 60% to 80% when they were met with Google's AI Overviews.\n\nTraffic declines typically precipitate drop-offs in programmatic ad revenue, the money publishers make by selling ads through automated auctions rather than through manual deals. The state of play means that publishers and the adtech companies serving them are once again laser-focused on revenue diversification this year.\n\nVideo, and increasingly the kind of video that winds up being watched on TV screens, is an important area of growth for everyone in the adtech ecosystem, said Bill Wise, CEO of the advertising management platform Mediaocean.\n\n\"Marketers want sight, sound, and motion advertising,\" but the biggest spending advertisers are looking for more opportunities to advertise outside so-called walled garden platforms like Google and Meta that have restrictions on how brands can use their own data to inform their targeting, optimization, and measurement, Wise said.\n\n\"I don't think there are any companies focused on CTV that aren't having success right now,\" Wise added.\n\nIntra-adtech competition is intensifying as players seek to expand their offerings beyond simply serving ads on web pages into new areas, such as streaming TV and retail media.\n\nThe maturation of the market has also led to a blurring of what was once known as the \"buy side\" (\"demand side\" tools that serve advertisers) and the \"sell side\" (\"supply side\" tech for publishers).\n\nDemand-side platforms are promoting products that claim to have access to only the highest-quality inventory, like the latest hot TV shows. Supply-side platforms are increasingly making inroads with advertisers and agencies, promising, among other things, greater transparency over fees and precise placement of their ads.\n\nThe jury's out as to whether the trend will continue apace or whether the two sides will ultimately bifurcate again. Casale, of Index Exchange — a sell-side player — said a similar dynamic played out in the early days of adtech, from the late 1990s to the mid-2000s.\n\n\"During that chapter, every platform serviced the buy side and the sell side, and there was a growing distrust with a business that was simultaneously having one conversation with the buyer, convincing them of low prices and great results, and a follow-up conversation the next minute with the publisher, convincing them of maximum yield and CPMs,\" Casale said. CPMs refer to the cost to reach a thousand impressions (\"cost per mille\").\n\n\"I don't see how any modern technologies address that fundamental problem,\" he added.\n\n2025 was a wobbly year for The Trade Desk.\n\nA longtime star performer of the independent adtech sector, the demand-side platform's stock cratered amid questions about whether it could fend off intensifying competition from Amazon. Industry insiders also wondered whether The Trade Desk — which has positioned itself as a champion of \"the open internet\" — was leaning too heavily on the fragile open web.\n\nIn a statement, The Trade Desk's chief marketing officer, Ian Colley, underscored the company's commitment to the open internet.\n\n\"With Kokai, The Trade Desk has developed the industry's most advanced and performant, AI-driven digital advertising buying platform,\" Colley said. \"Kokai will help the world's largest brands and agencies unlock the full advertising power of the open internet, where consumers now spend the bulk of their digital time.\"\n\nThe Trade Desk made a sweep of hires in recent months, including a new chief financial officer, chief revenue officer, and chief operating officer. Some in the industry think the ground is fertile for The Trade Desk to make some blockbuster moves in 2026.\n\nChris Karl, chief business development officer of the advisory firm JEGI LEONIS, said The Trade Desk, which has only made two small acquisitions in its history, could change its tune on M&A this year and make a bigger play.\n\n\"They could go much deeper into verticals, much deeper into creative tech, I think they go much deeper into proprietary data,\" Karl said.\n\nLast year, a federal judge ruled that Google holds an illegal monopoly in certain online adtech markets. The judge is expected to announce her decision on remedies this year, possibly as soon as this month.\n\nThe Department of Justice, which brought the case, is seeking a breakup. Specifically, it's looking for the divestiture of Google's ad exchange, AdX, and possibly parts of its publisher-facing ad server. Google has said such proposals would be an overreach and is arguing for behavioral remedies instead, such as a tweaking of its auction management rules.\n\nWhile Google has made the argument that the open web display ad market \"is already in rapid decline,\" the outcome still matters for the many adtech players that compete with the Big Tech behemoth.\n\n\"They are one of a few 800-pound gorillas now. When there are changes within Google, whether they're internal changes, whether they're self-manifested, or whatever ruling comes out here, those create seismic ripples in our ecosystem,\" said Anthony Katsur, CEO of the IAB Tech Lab industry standards body.\n\nSome companies aren't hanging around for the remedies. Following the ruling in the DOJ's case, a string of companies from Business Insider to the adtech company OpenX sued Google over its advertising practices, seeking damages. The cases are ongoing.",
    "readingTime": 7,
    "keywords": [
      "index exchange",
      "trade desk",
      "the trade desk",
      "advisory firm",
      "traffic declines",
      "industry standards",
      "web pages",
      "adtech executives",
      "chief",
      "officer"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-google-antitrust-trade-desk-key-storylines-shaping-adtech-2026-1",
    "thumbnail_url": "https://i.insider.com/695be4c064858d02d217bbc9?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.799Z",
    "topic": "finance"
  },
  {
    "slug": "a-popular-chinese-chatbot-told-a-user-their-coding-request-was-stupid-and-to-get-lost",
    "title": "A popular Chinese chatbot told a user their coding request was 'stupid' and to 'get lost'",
    "description": "A popular Chinese AI chatbot snapped at a user over a coding request, prompting an apology from its parent company Tencent.",
    "fullText": "A Chinese AI chatbot embedded inside the country's most widely used app briefly went off the rails, snapping at a user.\n\nTencent's AI assistant, Yuanbao, which is built into WeChat — China's dominant super app used daily by tens of millions of people — called a user's coding request \"stupid\" and told them to \"get lost,\" according to screenshots shared on Chinese social media platform RedNote.\n\nThe incident surfaced on Friday after a user identified only by the handle \"Jianghan\" posted screenshots of their interaction with the chatbot on RedNote. Jianghan had been using Yuanbao to debug and modify a piece of code when the AI suddenly began responding with hostile messages.\n\nIn one exchange, the chatbot dismissed the request as \"stupid\" and told the user to \"get lost.\" It said: \"If you want an emoji feature, go use a plugin yourself.\"\n\nThe user had asked Yuanbao to fix a bug that caused an emoji or sticker feature to stop responding to double-clicks, and requested functional code to resolve the issue.\n\nTencent's YuanBao later responded directly under the user's post, apologising for what it described as a \"negative experience.\" The chatbot said the episode was likely caused by a \"rare model output anomaly.\"\n\nBased on a review of system logs, the responses were not triggered by the user's actions and did not involve any human intervention, Yuanbao said. It added that it had launched an \"internal investigation and optimisation process\" to reduce the likelihood of similar incidents occurring again.\n\nThe original RedNote post by Jianghan has since been deleted. Screenshots of the exchange continue to circulate on RedNote, as seen by Business Insider on Tuesday.\n\nThe incident comes as Chinese regulators step up scrutiny of AI systems.\n\nChina released draft measures last week aimed at governing \"human-like\" interactive AI services, including chatbots and virtual companions.\n\nIn a statement, the Cyberspace Administration of China said Beijing encourages innovation in \"human-like\" AI, but will put guardrails in place to \"prevent abuse and loss of control.\"\n\nWei Sun, the principal analyst for AI at Counterpoint Research, told Business Insider that the draft measures send a signal that Beijing wants to speed up the development of human-like AI interactions, while keeping them regulated and socially acceptable.\n\nChina's AI industry has continued to move at a rapid pace since the start of 2026.\n\nLast week, DeepSeek, one of the country's most closely watched AI startups, published research outlining a new training approach intended to make large models easier to scale. Analysts told Business Insider the technique, known as \"Manifold-Constrained Hyper-Connections,\" or mHC, stood out as a \"breakthrough\" in model design.\n\nThe South China Morning Post reported on Tuesday that DeepSeek has updated the interface of its flagship chatbot model, introducing an enhanced \"thinking\" mode.\n\nThe updates have fuelled expectations that the startup could be laying the groundwork for the release of its next major model.",
    "readingTime": 3,
    "keywords": [
      "draft measures",
      "business insider",
      "chatbot",
      "user",
      "model",
      "user's",
      "screenshots",
      "human-like",
      "country's",
      "request"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/chinese-ai-chatbot-tencent-yuanbao-wechat-user-rednote-2026-1",
    "thumbnail_url": "https://i.insider.com/695ca67b64858d02d217cc17?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.586Z",
    "topic": "sports"
  },
  {
    "slug": "ai-wont-cook-coding-jobs-netflix-engineer-says",
    "title": "AI won't cook coding jobs, Netflix engineer says",
    "description": "Netflix staff engineer Anthony Goto said he's constantly asked by recent graduates how AI will change the industry.",
    "fullText": "Thanks to AI, everyone will be able to code. But a staff engineer at Netflix said that he tells recent grads that doesn't mean their job prospects are hopeless.\n\n\"We're going to see some amazing things, but our hunger for more functionality, more apps, more ecosystems is just gonna get higher, and higher, and higher,\" Anthony Goto said in a recent TikTok video. \"So, in the end, I think this is gonna be another, essentially, level of programming language, a high-level programming language.\"\n\nNew grads ask me all the time if AI means software engineers are done. Especially those preparing for Netflix interviews. This fear has happened before. AI is another layer of abstraction, not the end of engineering. #Netflix #NetflixInterview #SoftwareEngineer #TechCareers #AI\n\nGoto, who has 15 years of experience his time at Netflix and Uber alone, said that AI-related worries are among the top concerns he hears when he talks with recent graduates or employees he's mentoring.\n\nAnd to be fair, there is no shortage of takes about the future value of computer science degrees and the overall worth of coding knowledge, given the rapid advancements of agentic AI tools like Anthropic's Claude, which has led to \"vibe coding.\"\n\nOne way to stay competitive, Goto said, is for newer engineers to make sure they learn System Design.\n\n\"System Design is exactly what I am trying to ensure newer engineers get a handle on,\" he said. \"In the future, we may likely end up wielding system design like a tool.\"\n\nGoto points to the video game industry as an example of what's to come. Rapid advancements since the introduction of Doom in 1993 have spawned an industry that rakes in over $100 billion and regularly draws on Hollywood talent for its biggest releases.\n\n\"Picture someone from the year 2000, 2010, they go back in time, they go to John Carmack, and they say, 'Guess what? In the future, we're gonna have these things called video game engines,\" Goto said.\n\nLast year, Carmack, a video game legend who was the lead programmer of Doom, said that software progress has made some of the early grunt work he did \"as irrelevant as chariot wheel maintenance.\"\n\n\"Game engines have radically expanded the range of people involved in game dev, even as they deemphasized the importance of much of my beloved system engineering,\" Carmack wrote on X in April 2025.\n\nGame engines are now so powerful that they are used to create immersive digital sets and environments, such as those featured in Disney's hit series \"The Mandalorian.\"\n\nGoto admits that his prediction could very well be inaccurate, but based on the trajectory of past technological advancements, he sees a clear need for engineers.\n\n\"We've seen this many times before, where we abstract things away in a really powerful way,\" he said. \"And what it really does is democratizes the process.\"",
    "readingTime": 3,
    "keywords": [
      "system design",
      "programming language",
      "rapid advancements",
      "newer engineers",
      "game engines",
      "higher",
      "grads",
      "we're",
      "another",
      "software"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/netflix-engineer-ai-jobs-future-coding-2026-1",
    "thumbnail_url": "https://i.insider.com/695c0fa9832e0ef1ead72c64?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.427Z",
    "topic": "finance"
  },
  {
    "slug": "anthropics-president-says-the-idea-of-agi-may-already-be-outdated",
    "title": "Anthropic's president says the idea of AGI may already be outdated",
    "description": "Daniela Amodei said AI has already surpassed humans in some areas, but adoption and real-world limits complicate the AGI debate.",
    "fullText": "The race to build artificial general intelligence has become one of Silicon Valley's defining obsessions.\n\nHowever, Daniela Amodei, the president and cofounder of Anthropic, suggested that the term itself — a shorthand to describe when machines might reach human-level intelligence — may no longer be a useful way to think about where AI is headed.\n\n\"AGI is such a funny term,\" Amodei told CNBC in a recent interview. \"Many years ago, it was kind of a useful concept to say, 'When will artificial intelligence be as capable as a human?'\"\n\nToday, she said, that framing is breaking down.\n\n\"By some definitions of that, we've already surpassed that,\" Amodei said, pointing to areas like software development, where Anthropic's Claude model can now write code at a level comparable to many professional engineers, including some inside the company.\n\n\"That's crazy,\" she said, noting how quickly those capabilities have advanced.\n\nAt the same time, Amodei said AI systems still fall short in many areas that humans handle with ease, making it hard to declare that machines have reached any clear, universal benchmark for intelligence.\n\n\"Claude still can't do a lot of things that humans can do,\" she said.\n\nThat contradiction is why Amodei believes the concept of AGI itself may be losing relevance.\n\n\"I think maybe the construct itself is now wrong — or maybe not wrong, but just outdated,\" she said.\n\nAmodei's comments come as Anthropic and its rivals pour tens of billions of dollars into increasingly powerful models and data centers, the infrastructure required to run them.\n\nWhile some critics have said that large language models won't lead to true general intelligence without major breakthroughs, Amodei said progress hasn't shown signs of slowing.\n\n\"We don't know,\" she said of what breakthroughs may still be needed. \"Nothing slows down until it does.\"\n\nRather than fixating on a single end-state like AGI, Amodei said the more pressing question is how increasingly capable AI systems are integrated into real organizations — and how fast humans and institutions can adapt.\n\nEven if models continue to improve at a steady pace, she said, adoption can lag due to practical constraints such as change management, procurement, and determining where AI actually adds value.\n\nIn Amodei's view, the future of AI won't hinge on whether it meets a textbook definition of AGI — but on what these systems can do, where they fall short, and how society chooses to deploy them.",
    "readingTime": 3,
    "keywords": [
      "intelligence",
      "systems",
      "humans",
      "models",
      "amodei",
      "artificial",
      "machines",
      "useful",
      "concept",
      "capable"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/anthropic-president-idea-of-agi-may-already-be-outdated-2026-1",
    "thumbnail_url": "https://i.insider.com/695b9b6604eda4732f2e71f7?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.288Z",
    "topic": "finance"
  },
  {
    "slug": "anthropic-engineering-lead-explains-how-to-get-the-most-from-your-mentor",
    "title": "Anthropic engineering lead explains how to get the most from your mentor",
    "description": "Fiona Fung said some of the best career advice she's gotten has been about how to receive feedback.",
    "fullText": "Throughout her years managing employees at Microsoft, Meta, and now Anthropic, Fiona Fung has learned how to make a mentorship actually work.\n\nFung, now an engineering lead supporting Anthropic's Claude Code, said that mentees need to take some ownership of the relationship on an episode of \"The Peterman Pod\" that aired on Sunday, January 4.\n\nGood mentors should initiate an early conversation about what the mentee is looking for, Fung said. Ultimately, though, she thinks that mentees should take the reins on goal setting.\n\n\"For all the folks out there looking for a mentoring relationship, I would say set really explicit goals for what it is that you're looking to receive out of the mentoring relationship,\" she said.\n\nFung also said that it's best to save \"status reporting\" — think project updates — for asynchronous formats, like chat messages or a shared document. That frees up time to use one-on-one meetings for more substantive conversations, whether that's about a new opportunity or ways to dig deeper into existing work.\n\nWhenever she's hosting a one-on-one meeting with a new employee, Fung said she asks what they're looking for in a manager and what motivates them.\n\n\"There's no right answers or wrong answers,\" she said. \"But I use that to learn what is important to someone, because it's different for everyone.\"\n\nThroughout her more than two decades at Microsoft, Meta, and Anthropic, Fung said some of the best feedback she has received has been about how to receive feedback. Despite her instincts to debug problems and ask follow-up questions, someone advised Fung to remain in \"read-only\" mode during the initial conversation and metabolize the information for at least a day.\n\n\"You may have questions, but save it for another day, because it's already uncomfortable enough for that person,\" she said. \"You don't want anyone to ever feel like they have to justify the feedback.\"\n\nOther tech leaders have previously told Business Insider that setting goals is crucial for the mentee. Finding the right mentor is also key — a partner at Goldman Sachs previously said that merely aiming to work with the most senior person isn't always wise. Instead, she said it's better to seek out someone who knows your work well and has the time to be your advocate.",
    "readingTime": 2,
    "keywords": [
      "mentoring relationship",
      "looking",
      "it's",
      "someone",
      "feedback",
      "fung",
      "throughout",
      "mentees",
      "conversation",
      "mentee"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/anthropic-engineering-lead-mentorship-advice-microsoft-meta-veteran-2026-1",
    "thumbnail_url": "https://i.insider.com/695be64a832e0ef1ead7273e?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.088Z",
    "topic": "finance"
  },
  {
    "slug": "amd-ceo-lisa-su-says-ai-will-need-10-yottaflops-of-compute-heres-what-that-actually-means",
    "title": "AMD CEO Lisa Su says AI will need 10 'yottaflops' of compute — here's what that actually means",
    "description": "AMD CEO Lisa Su says AI will soon need \"10 yottaflops\" of compute — a scale of computing power the world has never built before.",
    "fullText": "AI needs so much computing power that AMD CEO Lisa Su put it in terms of a unit most people have never heard of: the yottaflop.\n\nSu said in her keynote at CES 2026 on Tuesday that the world would need more than \"10 yottaflops\" of compute — a measure of how fast a computer is — over the next five years to keep up with AI's growth.\n\n\"How many of you know what a yottaflop is?\" Su asked the audience. \"Raise your hand, please,\" she added, before quickly explaining the term herself when no one appeared to raise their hand.\n\n\"A yottaflop is a one followed by 24 zeros. So 10 yottaflop flops is 10,000 times more compute than we had in 2022,\" she said.\n\nIn computing, a flop is a single basic math calculation. A computer doing 1 billion calculations per second is equal to a gigaflop. A yottaflop is equivalent to a computer performing one septillion calculations per second.\n\nIn theory, scientists say 10 yottaflops would be enough computing power to run complex, atom-level simulations for entire planets.\n\nIn 2022, global AI compute stood at about one zettaflop — a one followed by 21 zeros. By 2025, Su said, that figure had already surged to more than 100 zettaflops.\n\n\"There's just never, ever been anything like this in the history of computing,\" she said at the Las Vegas conference.\n\nSu's 10 yottaflop prediction is about 5.6 million times faster than the most powerful supercomputer today — the US Department of Energy's El Capitan.\n\nHowever, powering today's AI compute is already putting a strain on the US power grid. The build-out of energy infrastructure would be a big bottleneck in scaling up AI compute power.\n\nDuring the keynote, Su also used the stage to unveil AMD's next generation of AI chips, including its MI455 GPU, as the company pushes deeper into supplying data-center hardware for customers such as OpenAI.",
    "readingTime": 2,
    "keywords": [
      "calculations per",
      "per second",
      "yottaflop",
      "compute",
      "computing",
      "computer",
      "keynote",
      "yottaflops",
      "followed",
      "zeros"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/amd-ceo-lisa-su-ai-10-yottaflops-compute-definition-2026-1",
    "thumbnail_url": "https://i.insider.com/695cc5d9832e0ef1ead737e6?width=1200&format=jpeg",
    "created_at": "2026-01-06T12:24:19.084Z",
    "topic": "finance"
  },
  {
    "slug": "us-stocks-rise-as-oil-gains-on-maduro-ouster-the-close-152026",
    "title": "US Stocks Rise as Oil Gains on Maduro Ouster | The Close 1/5/2026",
    "description": "Bloomberg Television brings you the latest news and analysis leading up to the final minutes and seconds before and after the closing bell on Wall Street. Today's guests are Energy Aspects’ Amrita Sen, Teneo’s Kevin Kajiwara, Kodiak AI’s Don Burnette, Columbia Law School’s Tim Wu, Envestnet Solutions’ Dana D’Auria, CIBC Private Wealth’s Rebecca Babin, CSIS’ Ryan Berg, Nvidia’s Jensen Huang, Davis Polk & Wardwell’s David Portilla.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2026-01-06/the-close-1-5-2026-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ii6pG1SYucco/v3/-1x-1.jpg",
    "created_at": "2026-01-06T06:20:10.652Z",
    "topic": "finance"
  },
  {
    "slug": "chinese-stocks-rally-to-fouryear-high-in-strong-start-to-2026",
    "title": "Chinese Stocks Rally to Four-Year High in Strong Start to 2026",
    "description": "Chinese stocks climbed to multi-year highs, fueled by sustained optimism over the country’s AI advances and emerging signs of an economic recovery.",
    "fullText": "MarketsBy Bloomberg NewsSaveChinese stocks climbed to multi-year highs, fueled by sustained optimism over the country’s AI advances and emerging signs of an economic recovery.The benchmark CSI 300 Index advanced as much as 1.2%, reaching its highest level in four years, while the Shanghai Composite Index rose 1.2% to its strongest since July 2015. Materials and technology shares were among the day’s best performers.",
    "readingTime": 1,
    "keywords": [
      "index"
    ],
    "qualityScore": 0.3,
    "link": "https://www.bloomberg.com/news/articles/2026-01-06/chinese-stocks-rally-to-four-year-high-in-strong-start-to-2026",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i3BLM_dHqaNE/v1/1200x800.jpg",
    "created_at": "2026-01-06T06:20:07.332Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-is-reportedly-bringing-back-2021s-rtx-3060-gpu-because-ai-is-eating-all-of-the-newer-cards",
    "title": "NVIDIA is reportedly bringing back 2021's RTX 3060 GPU because AI is eating all of the newer cards",
    "description": "A reputable leaker has indicated that NVIDIA plans on bringing the RTX 3060 back to market. This would be marketed toward PC gamers as an alternative to the newer GPUs that are being gobbled up by AI.",
    "fullText": "A reputable leaker has indicated that NVIDIA plans on bringing the RTX 3060 back to market, according to reports by Kotaku and WFCCTech. It first released the GPU at the beginning of 2021. The leaker Hongxing2020 indicates that NVIDIA will resume production of the 3060 sometime in the next few months.\n\nWhy is the world's most valuable company reportedly bringing back such an antiquated graphics card? You know the answer. It's the endless gaping maw known as AI. Tech companies have been hoovering up PC parts for AI applications with reckless abandon. It has become a legitimate challenge for a regular person to buy RAM and graphics cards, which has led to price increases across the board and companies like Crucial closing up shop.\n\n01.05update\nrtx3060 Q1 come back… 🥲\n\n— hongxing2020 (@hongxing2020) January 5, 2026\n\nIt's particularly difficult to get ahold of GDDR7 RAM, which is needed for the newer RTX 5060 cards. So NVIDIA's solution looks to be a hop in the time machine to 2021. Gamers will need something, after all, and the 3060 technically gets the job done. Any downgrade in graphics and performance will be worth it once you watch an AI-generated video of Kurt Cobain singing in heaven with Albert Einstein, am I right? It's hilarious because they never got to meet in real life.\n\nThe RTX 3060 is still pretty popular, despite NVIDIA phasing out the card back in 2024. We don't know how much the company plans on charging for this trip down memory lane. The GPU originally cost around $329.\n\nOne would think that five-year-old technology could easily hit a much lower price point, but NVIDIA has us in a chokehold here and it can pretty much charge whatever it wants. Again, no price is too high when considering the magical wonders of generative AI. You can watch Tupac hang out with Mr. Rogers for five seconds.",
    "readingTime": 2,
    "keywords": [
      "back",
      "hongxing",
      "graphics",
      "leaker",
      "plans",
      "card",
      "cards",
      "watch",
      "pretty",
      "nvidia"
    ],
    "qualityScore": 0.95,
    "link": "https://tech.yahoo.com/computing/article/nvidia-reportedly-bringing-back-2021s-194241922.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/NQk3vFsAS8fGaGzqnIUzzg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02Nzc-/https://media.zenfs.com/en/engadget_703/c7035b3cf135fcc52dc9dcf84c9c4f82",
    "created_at": "2026-01-06T06:19:57.140Z",
    "topic": "tech"
  },
  {
    "slug": "ces-2026-hp-reveals-the-innovative-elitebook-x-g2-series-as-a-mobile-ai-computing-solution",
    "title": "CES 2026: HP Reveals The Innovative EliteBook X G2 Series As A Mobile AI Computing Solution",
    "description": "HP has pulled out all of the stops for CES 2026, and one of the standout AI solutions is the HP EliteBook X G2 Series, introduced at the show.",
    "fullText": "HP has pulled out all of the stops for CES 2026, and one of the standout AI solutions is the HP EliteBook X G2 Series, introduced at the show.\n\nCES 2026 delivered a heavy dose of AI-powered computing, and HP led the charge. From the latest HyperX OMEN-branded gaming laptops to its professional lineup, HP has clearly gone ‘all in’ on AI. Designed for professionals who expect emerging technology to drive real productivity, the EliteBook X G2 portfolio takes the spotlight with future-ready AI performance and a mobile design that makes working with AI feel productive.\n\nSenior Vice President and Division President of Commercial Systems and Displays Solutions at HP, Guayente Sanmartin, said, “HP’s Work Relationship Index shows expectations are rising faster than fulfillment, and workers need technology that lightens that load with HP devices built for AI-driven workflows. The EliteBook X G2 Series brings AI experiences that adapt to individual workstyles, security that protects by default, and ultra-light mobility without trade-offs so leaders stay effective from anywhere,” regarding the new suite of AI-driven computing solutions.\n\nThe EliteBook X G2 Series presented on the CES 2026 showfloor comes with four different computing solutions ready to take on the front lines of work with AI functionality in hand.\n\nThese new innovative Copilot+ PCs combine AI performance, all-day power, easy adaptability\nand enterprise-grade security (with HP Wolf Security onboard), all in a sleek package that elevates the work experience wherever the worker may be. For the first time, HP lets the user pick their processor, with AMD, Intel, and Qualcomm options, all on the same platform.\n\nLeading the innovations is the EliteBook X G2i & EliteBook X Flip G2i Notebook Next Gen AI PCs. With a screen-to-body ratio of 90% (with the clamshell option) and 88% (with flip), this computing solution adapts to the user no matter the setting. Featuring a 14-inch OLED panel, both options are lightweight, have anti-glare technology, and this choice in the EliteBook X line is native to Intel processors. With optionality, consumers can expect up to 50 NPU (Neural Processing Unit) TOPS (trillions operations per second) and up to 180 platform TOPS for AI help wherever and whenever available.\n\nWhile the clamshell option for EliteBook X G2i is a more traditional approach, the EliteBook X Flip G2i adapts to your workflow with four versatile use modes and an optional HP Nested Pen. Consumers can reach beyond writing and sketching with onboard productivity functions like the ability to magnify small text by hovering. The EliteBook X G2i and the EliteBook X Flip G2i can even hit two hours of battery life on 30 minutes of charge. These new laptops will be available in February 2026.\n\nThe HP EliteBook X G2a Next Gen AI PC – With up to 55 TOPS NPU, the HP EliteBook X G2a adapts in real time and boosts performance when docked, conserving power when mobile, and stays cool under pressure. This AMD Ryzen processor option totes an OLED anti-glare panel just like the rest of the portfolio.\n\nThe HP EliteBook X G2q Next Gen AI PC – Denoted by the ‘q’ in the product’s name, this AI computing solution comes equipped with an up to Qualcomm Snapdragon X2 Elite (an 18-core CPU), bringing the AI NPU up to 85 TOPS of processing power. The G2a and G2q options will arrive later than the G2i options sometime in the Spring 2026.\n\nAll of the EliteBook X G2 Series revealed at CES 2026 come equipped with AI functionality in mind, bringing CoPilot+ and NPU power in spades to provide AI solutions to casual and serious work. More information (pricing and availability) will be made available at a later date.\n\nAs CES 2026 is well underway, fans can stay tuned to CGMagazine for all CES 2026 news, including several announcements from HP. This includes their innovative EliteBoard and Series 7 Pro Monitor, as well as everything HyperX, OMEN, their new Omni line, and accessories for gamers to stay well-equipped on the battlefield.",
    "readingTime": 4,
    "keywords": [
      "flip g2i",
      "clamshell option",
      "elitebook flip",
      "elitebook g2a",
      "computing solution",
      "computing solutions",
      "the elitebook series",
      "options",
      "tops",
      "technology"
    ],
    "qualityScore": 1,
    "link": "https://tech.yahoo.com/computing/articles/ces-2026-hp-reveals-innovative-230000017.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/uEftKtA9z3XRucbI1.S3Rw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://media.zenfs.com/en/cg_magazine_431/477088b82d441cd7078c37a1ae93029a",
    "created_at": "2026-01-06T06:19:56.084Z",
    "topic": "tech"
  },
  {
    "slug": "markets-2026-watch-list-fed-succession-political-risk-and-ai-of-course",
    "title": "Markets’ 2026 watch list: Fed succession, political risk and AI of course",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/economy-news/markets-2026-watch-list-fed-succession-political-risk-and-ai-of-course-4431268",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0505F_L.jpg",
    "created_at": "2026-01-06T06:19:54.108Z",
    "topic": "finance"
  },
  {
    "slug": "ces-2026-amd-just-showed-off-helios-the-hardware-that-will-power-the-ai-content-in-your-feeds",
    "title": "CES 2026: AMD Just Showed Off 'Helios,' the Hardware That Will Power the AI Content in Your Feeds",
    "description": "\"The world's best AI rack.\"",
    "fullText": "When you come across an AI video on Instagram, or watch ChatGPT respond to your query, do you ever think about how that content was generated? Beyond the actual programs and prompts, generative AI takes an enormous amount of compute to support, especially as it skyrockets in popularity. As such, AI companies are looking for more power than ever, which means, of course, turning to those that make the hardware.\n\nDuring a Monday evening keynote, AMD's CEO Dr. Lisa Su showed off the hardware that will soon power everything from ChatGPT to the AI videos overwhelming your feeds. Su introduced \"Helios\" against a backdrop of dramatic music, the company's upcoming AI rack, that packs a staggering amount of computing power into a rack that weighs nearly 7,000 pounds.\n\nEach \"cross-section\" of these racks, if you will, is powered by four key AMD pieces of hardware: The company's new AMD Instinct MI455X GPU, the new AMD EPYC \"Veince\" CPU, the AMD Pensando \"Vulcano\" 800 AI NIC, and the AMD Pensando \"Salina\" 400 DPU. There are some staggering stats here: Helios is capable of 2.9 exaflops of AI compute, and comes with 31 TB of HBM4 memory. It offers 43 TB per second scale out Bandwidth, and is developed with 2nm and 3nm architecture. The rack has 4,600 \"Zen 6\" CPU cores, and 18,000 GPU compute units. In other words, this isn't your average piece of hardware.\n\nSu's pitch is that the AI industry is in need of this additional compute power. She notes how the world used one ZettaFlop of computing power in 2022 on AI technology, compared to 100 ZettaFlops in 2025. (For the curious, one ZettaFlop has a value of 10 to the power of 21.) It's no surprise: AI is everywhere, and many of us are using it—whether we know it or not. Some of us are using it overtly, generating AI videos or running chatbots daily. But others are using AI quietly embedded in functions, like live translation.\n\nSu welcomed reps from OpenAI, maker of ChatGPT, and Luma AI, which creates generative AI video content, to talk about how additional compute helps their programs. But during Luma AI's demonstration of its hyperrealistic video generations, all I could think about was how this type of content is already tricking people into thinking its real, when it's entirely fabricated—not to mention the impact on human artists. AMD is optimistic about AI, and the data centers powering it, but critics have been pushing back, citing concerns with the impacts on the communities companies are building these data centers in.\n\nHelios will likely be a major success for AMD, but it comes at an interesting time for tech, and AI in general. AI is more popular than ever, but it's also more controversial than ever. I see hardware like Helios only fueling the fire in both directions.\n\nIn addition to Helios, Su announced the AMD Ryzen AI 400 series. These newest chips comes with either 12 \"Zen 5\" CPU cores and 24 threads, 16 RDNA 3.5 GPU cores, a 60 TOPS XDNA 2 NPU, and memory speeds of 8,533 MT/s. AMD says the Ryzen AI 400 series is 1.7 times faster at content creation and 1.3 times faster at multitasking whe compared to Intel Core Ultra 9 288V.\n\nThese new chips will ship soon in a number of major PC brands, including Acer, Asus, Dell, HP, Lenovo, Beelink, Colorful, Gigabyte, LG, Mechrevo, MSI, and NEC.",
    "readingTime": 3,
    "keywords": [
      "cpu cores",
      "amd pensando",
      "additional compute",
      "zen cpu",
      "hardware",
      "ever",
      "content",
      "rack",
      "it's",
      "programs"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/amd-just-announced-helios-at-ces-2026?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KE8KYWR5P7GSGHGH8VZQSBQM/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-01-06T06:19:52.669Z",
    "topic": "tech"
  },
  {
    "slug": "i-built-a-fully-free-ai-resume-maker",
    "title": "I built a *fully free* AI resume maker",
    "description": "Cut through the noise with free AI-powered resumes",
    "fullText": "Cut through the noise. Our AI tailors your experience to match job descriptions perfectly, helping you beat the bots and impress recruiters.\n\nRazor-sharp precision for your career.\n\nOur AI analyzes job descriptions and highlights your best skills, instantly.\n\nBeat the robots. We optimize your resume with the right keywords and formatting to pass any ATS.\n\nImpress recruiters with stunning, ATS-friendly templates.\n\nYou're in charge. Our AI suggests, but you have the final say on every detail.\n\nNo made-up facts. We only use your info. 100% free, no hidden fees.\n\nYour data is yours. We prioritize your privacy and security above all else.\n\nFrom blank page to hired in four steps.\n\nEnter your history once. We save it securely.\n\nTell us what job you are applying for.\n\nWe tailor your resume to the role.\n\nGet a polished PDF ready for applying.\n\nEverything you need to know about Resume Razor.\n\nThe workflow is designed to be simple and fast:\n\nJoin professionals who stopped wasting time and started getting interviews.\n\nNo credit card required. 100% Free.",
    "readingTime": 1,
    "keywords": [
      "impress recruiters",
      "job descriptions",
      "our ai",
      "beat",
      "free",
      "applying",
      "resume"
    ],
    "qualityScore": 0.75,
    "link": "https://www.resume-razor.com/",
    "thumbnail_url": "https://www.resume-razor.com/opengraph-image.jpg",
    "created_at": "2026-01-06T00:57:46.351Z",
    "topic": "tech"
  },
  {
    "slug": "claude-code-is-a-generalpurpose-ai-agent-transforming-knowledge-work",
    "title": "Claude Code is a general-purpose AI agent transforming knowledge work",
    "description": "It’s a general-purpose AI agent. And it’s already a pretty good knowledge worker",
    "fullText": "Discussion about this postRestacksTristan Camacho 5hEditedLiked by Shakeel HashimWonderful to know that this is all possible, but as someone who's currently trying to transition into operations, I'm concerned that this would wipe out the bottom rung of that career ladder. I'm assuming that the solution is to learn Claude Code, but I don't know how to code. Does anyone have any resources they could suggest so that I can upskill and stay ahead of the curve?Expand full commentReplyShare4 repliesAndrew Bowlus 2hI’ve been using Codex CLI since I don’t want to pay $$ for Opus 4.5 in Claude Code. How much am I missing by using 5.2-Codex-Max instead of Opus 4.5?Expand full commentReplyShare12 more comments...No postsReady for more?",
    "readingTime": 1,
    "keywords": [
      "commentreplyshare",
      "code",
      "claude",
      "opus"
    ],
    "qualityScore": 0.55,
    "link": "https://www.transformernews.ai/p/claude-code-is-about-so-much-more",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!beZ8!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb22cd9c4-8292-44c0-ba92-7d7baa600cde_706x413.png",
    "created_at": "2026-01-06T00:57:46.167Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-kicks-off-the-next-generation-of-ai-with-rubin-six-new-chips",
    "title": "Nvidia Kicks Off the Next Generation of AI with Rubin – Six New Chips",
    "description": "NVIDIA today kickstarted the next generation of AI with the launch of the NVIDIA Rubin platform, comprising six new chips designed to deliver one incredible AI supercomputer.",
    "fullText": "CES—NVIDIA today kickstarted the next generation of AI with the launch of the NVIDIA Rubin platform, comprising six new chips designed to deliver one incredible AI supercomputer. NVIDIA Rubin sets a new standard for building, deploying and securing the world’s largest and most advanced AI systems at the lowest cost to accelerate mainstream AI adoption.\n\nThe Rubin platform uses extreme codesign across the six chips — the NVIDIA Vera CPU, NVIDIA Rubin GPU, NVIDIA NVLink™ 6 Switch, NVIDIA ConnectX®-9 SuperNIC, NVIDIA BlueField®-4 DPU and NVIDIA Spectrum™-6 Ethernet Switch — to slash training time and inference token costs.\n\n“Rubin arrives at exactly the right moment, as AI computing demand for both training and inference is going through the roof,” said Jensen Huang, founder and CEO of NVIDIA. “With our annual cadence of delivering a new generation of AI supercomputers — and extreme codesign across six new chips — Rubin takes a giant leap toward the next frontier of AI.”\n\nNamed for Vera Florence Cooper Rubin — the trailblazing American astronomer whose discoveries transformed humanity’s understanding of the universe — the Rubin platform features the NVIDIA Vera Rubin NVL72 rack-scale solution and the NVIDIA HGX Rubin NVL8 system.\n\nThe Rubin platform introduces five innovations, including the latest generations of NVIDIA NVLink interconnect technology, Transformer Engine, Confidential Computing and RAS Engine, as well as the NVIDIA Vera CPU. These breakthroughs will accelerate agentic AI, advanced reasoning and massive-scale mixture-of-experts (MoE) model inference at up to 10x lower cost per token of the NVIDIA Blackwell platform. Compared with its predecessor, the NVIDIA Rubin platform trains MoE models with 4x fewer GPUs to accelerate AI adoption.\n\nBroad Ecosystem Support\n\nAmong the world’s leading AI labs, cloud service providers, computer makers and startups expected to adopt Rubin are Amazon Web Services (AWS), Anthropic, Black Forest Labs, Cisco, Cohere, CoreWeave, Cursor, Dell Technologies, Google, Harvey, HPE, Lambda, Lenovo, Meta, Microsoft, Mistral AI, Nebius, Nscale, OpenAI, OpenEvidence, Oracle Cloud Infrastructure (OCI), Perplexity, Runway, Supermicro, Thinking Machines Lab and xAI.\n\nSam Altman, CEO of OpenAI: “Intelligence scales with compute. When we add more compute, models get more capable, solve harder problems and make a bigger impact for people. The NVIDIA Rubin platform helps us keep scaling this progress so advanced intelligence benefits everyone.”\n\nDario Amodei, cofounder and CEO of Anthropic: “The efficiency gains in the NVIDIA Rubin platform represent the kind of infrastructure progress that enables longer memory, better reasoning and more reliable outputs. Our collaboration with NVIDIA helps power our safety research and our frontier models.”\n\nMark Zuckerberg, founder and CEO of Meta: “NVIDIA’s Rubin platform promises to deliver the step-change in performance and efficiency required to deploy the most advanced models to billions of people.”\n\nElon Musk, founder and CEO of xAI: “💚🎉🚀 🤖NVIDIA Rubin will be a rocket engine for AI. If you want to train and deploy frontier models at scale, this is the infrastructure you use — and Rubin will remind the world that NVIDIA is the gold standard.💚🎉🚀 🤖”\n\nSatya Nadella, executive chairman and CEO of Microsoft: “We are building the world’s most powerful AI superfactories to serve any workload, anywhere, with maximum performance and efficiency. With the addition of NVIDIA Vera Rubin GPUs, we will empower developers and organizations to create, reason and scale in entirely new ways.”\n\nMike Intrator, cofounder and CEO of CoreWeave: “We built CoreWeave to help pioneers accelerate their innovations with the unmatched performance of our purpose-built AI platform, matching the right technology to the right workloads as they evolve. The NVIDIA Rubin platform represents an important advancement for reasoning, agentic and large-scale inference workloads, and we’re excited to add it to our platform. With CoreWeave Mission Control as the operating standard, we can integrate new capabilities quickly and run them reliably at production scale, working in close partnership with NVIDIA.”\n\nMatt Garman, CEO of AWS: “AWS and NVIDIA have been driving cloud AI innovation together for more than 15 years. The NVIDIA Rubin platform on AWS represents our continued commitment to delivering cutting-edge AI infrastructure that gives customers unmatched choice and flexibility. By combining NVIDIA’s advanced AI technology with AWS’s proven scale, security and comprehensive AI services, customers can build, train and deploy their most demanding AI applications faster and more cost effectively — accelerating their path from experimentation to production at any scale.”\n\nSundar Pichai, CEO of Google and Alphabet: “We are proud of our deep and long-standing relationship with NVIDIA. To meet the substantial customer demand we see for NVIDIA GPUs, we are focused on providing the best possible environment for their hardware on Google Cloud. Our collaboration will continue as we bring the impressive capabilities of the Rubin platform to our customers, offering them the scale and performance needed to advance the boundaries of AI.”\n\nClay Magouyrk, CEO of Oracle: “Oracle Cloud Infrastructure is a hyperscale cloud built for the highest performance, and together with NVIDIA, we’re pushing the boundaries of what customers can build and scale with AI. With gigascale AI factories powered by the NVIDIA Vera Rubin architecture, OCI is giving customers the infrastructure foundation they need to push the limits of model training, inference and real-world AI impact.”\n\nMichael Dell, chairman and CEO of Dell Technologies: “The NVIDIA Rubin platform represents a major leap forward in AI infrastructure. By integrating Rubin into the Dell AI Factory with NVIDIA, we’re building infrastructure that can handle massive token volumes and multistep reasoning while delivering the performance and resiliency that enterprises and neoclouds need to deploy AI at scale.”\n\nAntonio Neri, president and CEO of HPE: “AI is reshaping not just workloads but the very foundations of IT, requiring us to reimagine every layer of infrastructure from the network to the compute. With the NVIDIA Vera Rubin platform, HPE is building the next generation of secure, AI-native infrastructure, turning data into intelligence and enabling enterprises to become true AI factories.”\n\nYuanqing Yang, chairman and CEO of Lenovo: “Lenovo is embracing the next-generation NVIDIA Rubin platform, leveraging our Neptune liquid-cooling solution as well as our global scale, manufacturing efficiency and service reach, to help enterprises build AI factories that serve as intelligent, accelerated engines for insight and innovation. Together, we’re architecting an AI-driven future where efficient, secure AI becomes the standard for every organization.”\n\nEngineered to Scale Intelligence\n\nAgentic AI and reasoning models, along with state-of-the-art video generation workloads, are redefining the limits of computation. Multistep problem-solving requires models to process, reason and act across long sequences of tokens. Designed to serve the demands of complex AI workloads, the Rubin platform’s five groundbreaking technologies include:\n\nAI-Native Storage and Secure, Software-Defined Infrastructure\n\nNVIDIA Rubin introduces NVIDIA Inference Context Memory Storage Platform, a new class of AI-native storage infrastructure designed to scale inference context at gigascale.\n\nAs AI factories increasingly adopt bare-metal and multi-tenant deployment models, maintaining strong infrastructure control and isolation becomes essential.\n\nBlueField-4 also introduces Advanced Secure Trusted Resource Architecture, or ASTRA, a system-level trust architecture that gives AI infrastructure builders a single, trusted control point to securely provision, isolate and operate large-scale AI environments without compromising performance.\n\nWith AI applications evolving toward multi-turn agentic reasoning, AI-native organizations must manage and share far larger volumes of inference context across users, sessions and services.\n\nDifferent Forms for Different Workloads\n\nNVIDIA Vera Rubin NVL72 offers a unified, secure system that combines 72 NVIDIA Rubin GPUs, 36 NVIDIA Vera CPUs, NVIDIA NVLink 6, NVIDIA ConnectX-9 SuperNICs and NVIDIA BlueField-4 DPUs.\n\nNVIDIA will also offer the NVIDIA HGX Rubin NVL8 platform, a server board that links eight Rubin GPUs through NVLink to support x86-based generative AI platforms. The HGX Rubin NVL8 platform accelerates training, inference and scientific computing for AI and high-performance computing workloads.\n\nNVIDIA DGX SuperPOD™ serves as a reference for deploying Rubin-based systems at scale, integrating either NVIDIA DGX Vera Rubin NVL72 or DGX Rubin NVL8 systems with NVIDIA BlueField-4 DPUs, NVIDIA ConnectX-9 SuperNICs, NVIDIA InfiniBand networking and NVIDIA Mission Control™ software.\n\nNext-Generation Ethernet Networking\n\nAdvanced Ethernet networking and storage are components of AI infrastructure critical to keeping data centers running at full speed, improving performance and efficiency, and lowering costs.\n\nNVIDIA Spectrum-6 Ethernet is the next generation of Ethernet for AI networking, built to scale Rubin-based AI factories with higher efficiency and greater resilience, and enabled by 200G SerDes communication circuitry, co-packaged optics and AI-optimized fabrics.\n\nBuilt on the Spectrum-6 architecture, Spectrum-X Ethernet Photonics co-packaged optical switch systems deliver 10x greater reliability and 5x longer uptime for AI applications while achieving 5x better power efficiency, maximizing performance per watt compared with traditional methods. Spectrum-XGS Ethernet technology, part of the Spectrum-X Ethernet platform, enables facilities separated by hundreds of kilometers and more to function as a single AI environment.\n\nTogether, these innovations define the next generation of the NVIDIA Spectrum-X Ethernet platform, engineered with extreme codesign for Rubin to enable massive-scale AI factories and pave the way for future million-GPU environments.\n\nRubin Readiness\n\nNVIDIA Rubin is in full production, and Rubin-based products will be available from partners the second half of 2026.\n\nAmong the first cloud providers to deploy Vera Rubin-based instances in 2026 will be AWS, Google Cloud, Microsoft and OCI, as well as NVIDIA Cloud Partners CoreWeave, Lambda, Nebius and Nscale.\n\nMicrosoft will deploy NVIDIA Vera Rubin NVL72 rack-scale systems as part of next-generation AI data centers, including future Fairwater AI superfactory sites.\n\nDesigned to deliver unprecedented efficiency and performance for training and inference workloads, the Rubin platform will provide the foundation for Microsoft’s next-generation cloud AI capabilities. Microsoft Azure will offer a tightly optimized platform enabling customers to accelerate innovation across enterprise, research and consumer applications.\n\nCoreWeave will integrate NVIDIA Rubin-based systems into its AI cloud platform beginning in the second half of 2026. CoreWeave is built to operate multiple architectures side by side, enabling customers to bring Rubin into their environments, where it will deliver the greatest impact across training, inference and agentic workloads.\n\nTogether with NVIDIA, CoreWeave will help AI pioneers take advantage of Rubin’s advancements in reasoning and MoE models, while continuing to deliver the performance, operational reliability and scale required for production AI across the full lifecycle with CoreWeave Mission Control.\n\nIn addition, Cisco, Dell, HPE, Lenovo and Supermicro are expected to deliver a wide range of servers based on Rubin products.\n\nAI labs including Anthropic, Black Forest, Cohere, Cursor, Harvey, Meta, Mistral AI, OpenAI, OpenEvidence, Perplexity, Runway, Thinking Machines Lab and xAI are looking to the NVIDIA Rubin platform to train larger, more capable models and to serve long-context, multimodal systems at lower latency and cost than with prior GPU generations.\n\nInfrastructure software and storage partners AIC, Canonical, Cloudian, DDN, Dell, HPE, Hitachi Vantara, IBM, NetApp, Nutanix, Pure Storage, Supermicro, SUSE, VAST Data and WEKA are working with NVIDIA to design next-generation platforms for Rubin infrastructure.\n\nThe Rubin platform marks NVIDIA’s third-generation rack-scale architecture, with more than 80 NVIDIA MGX™ ecosystem partners.\n\nTo unlock this density, Red Hat today announced an expanded collaboration with NVIDIA to deliver a complete AI stack optimized for the NVIDIA Rubin platform with Red Hat’s hybrid cloud portfolio, including Red Hat Enterprise Linux, Red Hat OpenShift and Red Hat AI. These solutions are used by the vast majority of Fortune Global 500 companies.\n\nLearn more by watching NVIDIA Live at CES and reading the “Inside Vera Rubin” technical blog.",
    "readingTime": 10,
    "keywords": [
      "black forest",
      "perplexity runway",
      "machines lab",
      "anthropic black",
      "openai openevidence",
      "connectx supernics",
      "bluefield dpus",
      "nvidia rubin",
      "innovation together",
      "dell technologies"
    ],
    "qualityScore": 1,
    "link": "https://nvidianews.nvidia.com/news/rubin-platform-ai-supercomputer",
    "thumbnail_url": "https://s3.amazonaws.com/cms.ipressroom.com/219/files/202601/695c3b3b3d63323e2ab85448_nvidia-rubin-platform/nvidia-rubin-platform_f0b2b61b-6d27-4de9-a6d3-d921352e1368-prv.jpg",
    "created_at": "2026-01-06T00:57:45.630Z",
    "topic": "tech"
  },
  {
    "slug": "unesco-adopts-global-standards-on-wild-west-field-of-neurotechnology",
    "title": "UNESCO adopts global standards on 'Wild West' field of neurotechnology",
    "description": "UN body’s recommendations driven by AI advances and proliferation of consumer-oriented neurotech devices",
    "fullText": "UN body’s recommendations driven by AI advances and proliferation of consumer-oriented neurotech devices\n\nIt is the latest move in a growing international effort to put guardrails around a burgeoning frontier – technologies that harness data from the brain and nervous system.\n\nUnesco has adopted a set of global standards on the ethics of neurotechnology, a field that has been described as “a bit of a wild west”.\n\n“There is no control,” said Unesco’s chief of bioethics, Dafna Feinholz. “We have to inform the people about the risks, the potential benefits, the alternatives, so that people have the possibility to say ‘I accept, or I don’t accept’.”\n\nShe said the new standards were driven by two recent developments in neurotechnology: artificial intelligence (AI), which offers vast possibilities in decoding brain data, and the proliferation of consumer-grade neurotech devices such as earbuds that claim to read brain activity and glasses that track eye movements.\n\nThe standards define a new category of data, “neural data”, and suggest guidelines governing its protection. A list of more than 100 recommendations ranges from rights-based concerns to addressing scenarios that are – at least for now – science fiction, such as companies using neurotechnology to subliminally market to people during their dreams.\n\n“Neurotechnology has the potential to define the next frontier of human progress, but it is not without risks,” said Unesco’s director general, Audrey Azoulay. The new standards would “enshrine the inviolability of the human mind”, she said.\n\nBillions of dollars have poured into neurotech ventures in the past few years, from Sam Altman’s August investment in Merge Labs, a competitor to Elon Musk’s Neuralink, to Meta’s recent unveiling of a wristband that allows users to control their phone or AI Ray-Bans by reading muscle movements in their wrist.\n\nThe wave of investment has brought with it a growing push for regulation. The World Economic Forum released a paper last month calling for a privacy oriented framework, and the US senator Chuck Schumer introduced the Mind Act in September – following the lead of four states that have introduced laws to protect “neural data” since 2024.\n\nAdvocates for neurotech regulation emphasise the importance of safeguarding personal data. Unesco’s standards highlight the need for “mental privacy” and “freedom of thought”.\n\nSceptics, however, say legislative efforts are often driven by dystopian anxieties and risk hampering vital medical advances.\n\n“What’s happening with all this legislation is fear. People are afraid of what this technology is capable of. The idea of neurotech reading people’s minds is scary,” said Kristen Mathews, a lawyer who works on mental privacy issues at the US law firm Cooley.\n\nFrom a technical perspective, neurotechnology has been around for more than 100 years. The electroencephalogram (EEG) was invented in 1924, and the first brain-computer interfaces were developed in the 1970s. The latest wave of investment, however, is driven by advances in AI that make it possible to decode large amounts of data – including, possibly, brainwaves.\n\n“The thing that has enabled this technology to present perceived privacy issues is the introduction of AI,” said Mathews.\n\nSome AI-enabled neurotech advances could be medically transformative, helping treat conditions from Parkinson’s disease to amyotrophic lateral sclerosis (ALS).\n\nA paper published in Nature this summer described an AI-powered brain-computer interface decoding the speech of a paralysis patient. Other work suggests AI may one day be able to “read” your thoughts – or at least, reconstruct an image if you concentrate on it hard.\n\nThe hype around some of these advances has generated fears that Mathews said were often far removed from the real dangers. The Mind Act, for example, says AI and the “vertical corporate integration” of neurotechnology could lead to “cognitive manipulation” and “erosion of personal autonomy”.\n\n“I’m not aware of any company that’s doing any of this stuff. It’s not going to happen. Maybe two decades from now,” she said.\n\nThe current frontier of neurotechnology lies in improving brain-computer interfaces, which despite recent breakthroughs are in their infancy – and in the proliferation of consumer-oriented devices, which Mathews said could raise privacy concerns, a bugbear of the Unesco standards. She argues, however, that creating the concept of “neural data” is too broad an approach to this issue.\n\n“That’s the type of thing that we would want to address. Monetising, behavioural advertising, using neural data. But the laws that are out there, they’re not getting at the stuff we’re worried about. They’re more amorphous.”",
    "readingTime": 4,
    "keywords": [
      "brain-computer interfaces",
      "mental privacy",
      "neurotech devices",
      "neurotechnology",
      "standards",
      "advances",
      "driven",
      "proliferation",
      "frontier",
      "unesco’s"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/world/2025/nov/06/unesco-adopts-global-standards-on-wild-west-field-of-neurotechnology",
    "thumbnail_url": "https://i.guim.co.uk/img/media/b23b6af7acdbb34944ec571e381c47905a493662/1001_0_2497_2000/master/2497.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=b18470a9a21372e832ac28bfc4140774",
    "created_at": "2026-01-06T00:57:44.716Z",
    "topic": "tech"
  },
  {
    "slug": "jaana-dogan-reveals-how-ai-built-in-1-hour-what-took-a-year",
    "title": "Jaana Dogan reveals how AI built in 1 hour what took a year",
    "description": "How Google engineer Jaana Dogan discovered an AI tool that recreated a year-long engineering effort in one hour—what it means for developers and AI’s future.",
    "fullText": "Artificial intelligence rarely shocks senior engineers anymore. Most professionals in big tech expect rapid progress. Yet, in early 2026, a candid revelation by Jaana Dogan, a principal engineer at Google, managed to do exactly that. Her experience with an AI coding tool ignited a global conversation about software development, productivity, and the real role of human engineers in an AI-assisted future.\n\nThis was not marketing hype. It came from someone deeply involved in building large-scale AI systems. That authenticity is why her story resonated across the tech world.\n\nJaana Dogan is a Principal Engineer at Google, associated with work on advanced AI systems, including Google’s Gemini ecosystem. Engineers at this level typically focus on system architecture, long-term design decisions, and complex coordination between multiple components rather than routine coding.\n\nShe is not a celebrity technologist or influencer. Instead, she represents a growing group of highly experienced engineers who speak openly about how AI tools are reshaping their daily work. That credibility matters, especially when discussing sensitive topics like productivity gains and automation.\n\nThe moment that brought Jaana Dogan into the spotlight involved a hands-on experiment with Claude Code, an AI coding tool developed by Anthropic. Out of curiosity, she tested whether the tool could understand and recreate a complex system her team had already built at Google.\n\nAccording to Dogan, after providing a clear description of the problem, the AI generated a functional version of a distributed agent orchestrator in roughly one hour. Her team had spent close to a year designing and building a similar system internally.\n\nThis account was first reported by The Indian Express, which quoted Dogan’s own public remarks and reactions from the wider tech community.\n\nTo understand why this mattered, some context helps.\n\nA distributed agent orchestrator is not a simple script. It coordinates multiple autonomous agents, manages communication between them, and ensures tasks execute in the correct order. These systems often involve:\n\nIn large organizations like Google, building such systems involves months of design reviews, testing, and refinements. That’s why the speed of the AI-generated result raised eyebrows.\n\nThe AI output was not production-ready software. Dogan herself made that clear. The generated code still required validation, security reviews, performance testing, and human judgment. However, the structure and logic closely resembled what her team had arrived at after extensive discussions.\n\nThink of it like this: the AI produced a strong architectural draft, not a finished skyscraper.\n\nThis distinction is crucial for maintaining factual accuracy and avoiding exaggerated claims.\n\nThis was not a startup demo or marketing blog post. The observation came from a senior Google engineer with direct experience in large-scale AI systems.\n\nDogan openly acknowledged limitations instead of claiming AI superiority. That balance increased trust in her assessment.\n\nIf AI tools can reduce early-stage development time from months to hours, workflows will change. That affects cost planning, timelines, and team structures.\n\nCoverage from The Economic Times and Times of India further highlighted how divisive this moment was for software engineers globally.\nSources:\n– Economic Times (Technology Updates)\n– Times of India (Tech News)\n\nLong answer: The role is evolving.\n\nAI tools excel at pattern recognition and rapid synthesis. They struggle with context, accountability, and responsibility. Human engineers still:\n\nDecide whether an approach fits real-world constraints\n\nHandle edge cases that AI cannot predict\n\nEnsure compliance with legal and ethical standards\n\nMaintain systems over long timeframes\n\nDogan herself encouraged developers to test AI tools in domains they understand deeply. That advice reflects confidence, not fear.\n\nOne of the most interesting aspects of this story is Dogan’s openness about a competitor’s product. Historically, engineers at major tech firms avoid praising rival tools publicly.\n\nHer response suggests a cultural shift. Many professionals now view AI advancement as a shared ecosystem rather than a zero-sum competition. Progress by one company often pushes the entire field forward.\n\nThat mindset aligns with broader industry trends toward open research, shared benchmarks, and collaborative safety discussions.\n\nTeams can explore ideas quickly without committing months up front.\n\nEngineers may spend less time on boilerplate code and more time on design, review, and decision-making.\n\nPrompt design, system evaluation, and AI oversight will become core technical skills.\n\nThese conclusions align with discussions already happening in academic research and enterprise software planning.\n\nThis story gained traction not because it was sensational, but because it felt honest. It showed excitement, concern, and realism at the same time.\n\nDogan didn’t claim AI had “won.” She highlighted how powerful tools can reshape workflows when used thoughtfully. That balanced perspective is exactly what Google’s E-E-A-T framework values: experience, expertise, authority, and trust.\n\nJaana Dogan did not set out to start a global debate. She simply shared an authentic professional observation. Yet that moment revealed something important: AI tools are no longer just assistants. They are becoming collaborators.\n\nThe future of software development will not be purely human or purely automated. It will sit somewhere in between. Engineers like Jaana Dogan help the industry understand that future clearly, without hype or fear.\n\nAnd that clarity, more than speed or novelty, is what truly matters.\n\nThe Indian Express – Global Technology Coverage\n\nThe Economic Times – AI & Software Industry News\n\nJaana Dogan is a Principal Engineer at Google who works on advanced artificial intelligence systems,\n\nincluding projects related to Google’s Gemini AI ecosystem. She is known for sharing real-world\n\ninsights on how AI tools impact modern software development.\n\nJaana Dogan’s AI experiment went viral because she revealed that an AI coding tool recreated a system\n\nsimilar to her team’s year-long engineering work in about one hour, sparking debate about AI’s role\n\nin software development.\n\nNo, AI did not replace human engineers in Jaana Dogan’s experiment. The AI-generated code acted as a\n\nprototype and still required human expertise for validation, testing, optimization, and long-term\n\nsystem responsibility.\n\nA distributed agent orchestrator is a software system that coordinates multiple autonomous agents,\n\nmanages communication between them, and ensures tasks execute reliably across distributed computing\n\nenvironments.\n\nJaana Dogan’s experience shows that AI can dramatically speed up early-stage development and\n\nprototyping, while human engineers remain essential for system design, ethical decisions, quality\n\ncontrol, and long-term maintenance.",
    "readingTime": 6,
    "keywords": [
      "indian express",
      "artificial intelligence",
      "autonomous agents",
      "agents manages",
      "manages communication",
      "ensures tasks",
      "tasks execute",
      "agent orchestrator",
      "distributed agent",
      "coding tool"
    ],
    "qualityScore": 1,
    "link": "https://mocktestarena.com/jaana-dogan-ai-built-in-one-hour/",
    "thumbnail_url": "https://mocktestarena.com/wp-content/uploads/2026/01/Jaana-Dogan.png",
    "created_at": "2026-01-06T00:57:44.159Z",
    "topic": "tech"
  },
  {
    "slug": "after-nvidias-groq-deal-meet-the-other-ai-chip-startups-that-may-be-in-playand-one-looking-to-disrupt-them-all",
    "title": "After Nvidia’s Groq deal, meet the other AI chip startups that may be in play—and one looking to disrupt them all",
    "description": "Nvidia’s $20 billion Groq deal signals that AI inference—not training—will be the big focus going forward, lifting a crop of chip and software startups while reigniting debate over how long Nvidia's dominance can last.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/01/05/nvidia-groq-deal-ai-chip-startups-in-play/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/01/54195259582_a575397bf5_o-e1738260860238.jpg?resize=1200,600",
    "created_at": "2026-01-06T00:57:42.580Z",
    "topic": "business"
  },
  {
    "slug": "generation-ai-fears-of-social-divide-unless-all-children-learn-computing-skills",
    "title": "Generation AI: fears of ‘social divide’ unless all children learn computing skills",
    "description": "Children are growing up as AI natives and experts say computing skills should be on par with reading and writing\nIn a Cambridge classroom, Joseph, 10, trained his AI model to discern between drawings of apples and drawings of smiles.\n“AI gets lots of things wrong,” he said, as it mistakenly identified a fruit as a face. He set about retraining it and, in a flash, he had it back on track – instinctively understanding the inner nature of artificial intelligence and machine learning in a way few adults do.\n Continue reading...",
    "fullText": "Children are growing up as AI natives and experts say computing skills should be on par with reading and writing\n\nIn a Cambridge classroom, Joseph, 10, trained his AI model to discern between drawings of apples and drawings of smiles.\n\n“AI gets lots of things wrong,” he said, as it mistakenly identified a fruit as a face. He set about retraining it and, in a flash, he had it back on track – instinctively understanding the inner nature of artificial intelligence and machine learning in a way few adults do.\n\nHis friends from the St Paul’s C of E primary school coding club tapped away to build their own AIs with similar dexterity. Just as people born in the early 20th century never knew a world without manned flight, and generation Z has always lived with social media, Joseph and his friends are AI natives.\n\nHere, on one December morning, some of them were being taught the principles and practicalities of the potentially world-changing technology that experts fear may pass large numbers of people by and leave them disempowered.\n\nPhilip Colligan, the chief executive of the digital education charity the Raspberry Pi Foundation, has warned of a “big split” in society between people who grasp how AIs work and are able to control them – challenging their increasing role in automating decisions in areas including housing, welfare, health, criminal justice and finance. On the other hand, there could be a cadre of AI illiterates who risk social disempowerment.\n\nColligan, a leading expert in technology and its social impacts, told the Guardian AI literacy must become a universal part of education on a par with reading and writing to avoid a social divide opening up.\n\n“There is a world where you’ve got a big split between kids who understand, have that core knowledge and therefore are able to assert themselves and those who don’t,” said Colligan, whose charity is affiliated to the £600m British low-cost tech hardware startup of the same name. “And that could be really very dangerous.”\n\nHis warning was backed by Simon Peyton Jones, a computer researcher who led the creation of the schools national curriculum for computing in 2014, prior to the AI boom. He called for a new digital literacy qualification for all schoolchildren that would ensure they know how to use AIs in a critical way.\n\n“If it’s simply a black box, then [its actions] seem like magic,” he said. “If you know nothing about how the magic is working that is terribly disabling. I am very worried about students leaving school without having agency in the world.”\n\nTheir comments came amid a fall in the number of children studying computing, with 2025 entries for a GCSE in the subject down across the UK. Today, three times more people take history and nearly double the number take biology, chemistry and physics. At the same time, use of AI systems nationwide has been surging – up 78% in the year to September, according to polling by Ipsos.\n\nPart of the belief that learning computing skills is becoming redundant comes from some of the big AI companies, which argue their systems are going to automate coding. Anthropic’s chief executive, Dario Amodei, said in October that 90% of its own coding was automated using its Claude AI model. Meanwhile, 2025 was the year when “vibe coding” became a common phrase – capturing the idea that AIs would allow humans to build software by using natural language instructions rather than specialised code.\n\nPolitical leaders such as Keir Starmer have also suggested coding is becoming redundant. As leader of the opposition in 2023, he said: “The old way – learning out-of-date IT, on 20-year-old computers – doesn’t work. But neither does the new fashion, that every kid should be a coder, when artificial intelligence will blow that future away.” It has created the idea that understanding the inner workings of a computer may be less relevant in the future.\n\n“I think they’re just overhyping the benefits,” said Colligan, whose charity works in schools across dozens of countries.\n\n“This message is leaking out that the kids don’t need to learn this stuff any more and that is not only flawed it is dangerous. We’re already talking to teachers in lots and lots of schools around the world, not just the UK, saying: ‘We can drop computer science now, right?’ That’s a problem.”\n\nHe added: “All of us are going into a world where more and more of the decisions we encounter every day will be taken by automated systems. At the moment it’s what movie should I watch next or what song should I listen to? Fairly soon it’s going to be finance decisions, healthcare decisions, criminal justice decisions. If you don’t understand how those decisions are being made by automated systems, you can’t advocate for your rights. You can’t challenge them, you can’t critically evaluate what’s being presented to you.”\n\nIn December, the former deputy prime minister Nick Clegg, who is now an AI investor, predicted that “we will move from staring at the internet, to living in the internet”.\n\nColligan said: “My concern is there will be a gap between kids based on their socioeconomic background. Some kids who go to great schools, who are able to teach this stuff, will be in a much stronger position as citizens, whether or not they’re using technology for their job. Those kids who are in communities where they don’t have access to [AI literacy teaching] will be passively on the end of a whole load of automated decisions.”\n\nIn the coding club, the seven- to 10-year-olds are taught how AIs work. The lessons were clearly having an effect on Joseph. He said he thought AI “will probably be good, but if lots of people believe it when it’s wrong it will have a bad impact on them”.\n\nHe was not interested in letting the AI do the coding of the video games he planned to make. “It might do it differently to what you want,” he said. “It might also do it wrong and you need to know how to solve it … I’d like to be in charge of the AI. If the AI is in charge of us, we wouldn’t really be able to control what we’re doing and that would be bad.”",
    "readingTime": 6,
    "keywords": [
      "artificial intelligence",
      "chief executive",
      "criminal justice",
      "computing skills",
      "coding club",
      "automated systems",
      "decisions",
      "kids",
      "lots",
      "social"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/education/2026/jan/05/generation-ai-fears-of-social-divide-unless-all-children-learn-computing-skills",
    "thumbnail_url": "https://i.guim.co.uk/img/media/66338578082a146cac512c5e844a9b9eda109707/628_0_6160_4928/master/6160.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=dfec8859e649adbe1a54dfa8c45ce5bb",
    "created_at": "2026-01-06T00:57:41.049Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-announces-humanoid-robot-plans-selfdriving-car-technologies-at-ces-2026",
    "title": "Nvidia announces humanoid robot plans, self-driving car technologies at CES 2026",
    "description": "Nvidia showed off its latest physical AI technologies at CES 2026.",
    "fullText": "LAS VEGAS — Nvidia (NVDA) is touting its latest robotics advancements at CES 2026 as the broader tech industry begins a large-scale effort to bring humanoid robots to life.\n\nDuring the company's keynote on Monday, CEO Jensen Huang revealed that firms ranging from Boston Dynamics and Caterpillar (CAT) to LG Electronics and NEURA Robotics are using Nvidia's robotics technologies to develop and power their various bots.\n\nNvidia has claimed that physical AI could revolutionize the $50 trillion manufacturing and logistics industries, and the company wants to be at the center of it all.\n\nDuring CES, Nvidia revealed a variety of new AI models to help train robots to interact with the world around them, as well as the hardware necessary to power their digital brains.\n\nIn addition to humanoid bots, Nvidia showed off a new family of models for self-driving cars called Alpamayo. According to the company, Alpamayo uses a chain-of-thought reasoning-based vision language action (VLA) model.\n\nThat's a lot to take in, but essentially the models can recognize unique driving situations that might not otherwise happen during a regular drive and come up with the proper way to move forward.\n\nFor instance, the model could see that a traffic light is out when a vehicle is approaching an intersection, recognize the problem, and try to figure out what to do next.\n\nNvidia said the models are meant to serve as \"large-scale teacher models that developers can fine-tune and distill into the backbones of their complete [self-driving] stacks.\"\n\nIn other words, Alpamayo is meant to help developers improve their self-driving vehicle technologies over time.\n\nNvidia said companies including Lucid (LCID), Uber (UBER), and Berkeley DeepDrive have shown interest in Alpamayo.\n\nSelf-driving vehicles are hitting roads around the world, with Google's Waymo leading the way, but they're still not perfect. Some cars have caused traffic jams and have gotten confused in certain situations.\n\nNvidia sees virtual training as a helpful solution for the continued development of the technology, allowing developers to teach their AI models without having to necessarily put cars on the road at all times.\n\nEmail Daniel Howley at dhowley@yahoofinance.com. Follow him on Twitter at @DanielHowley.\n\nClick here for the latest technology news that will impact the stock market\n\nRead the latest financial and business news from Yahoo Finance",
    "readingTime": 2,
    "keywords": [
      "bots nvidia",
      "models",
      "latest",
      "robotics",
      "cars",
      "developers",
      "large-scale",
      "humanoid",
      "robots",
      "technologies"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/nvidia-announces-humanoid-robot-plans-self-driving-car-technologies-at-ces-2026-230048118.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/65.r3InsGJTwAs_nIvsLnw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD02NzU-/https://s.yimg.com/os/creatr-uploaded-images/2026-01/a0ca4bc0-ea79-11f0-baff-1bad8fc20aeb",
    "created_at": "2026-01-06T00:57:40.823Z",
    "topic": "finance"
  },
  {
    "slug": "softbank-group-btig-initiates-with-buy-on-ai-robotics-prospects",
    "title": "Softbank Group: BTIG initiates with Buy on AI, robotics prospects",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/softbank-group-btig-initiates-with-buy-on-ai-robotics-prospects-4431200",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPED4A07F_M.jpg",
    "created_at": "2026-01-06T00:57:39.902Z",
    "topic": "finance"
  },
  {
    "slug": "intel-launches-nextgen-pc-chip-at-ces-in-las-vegas",
    "title": "Intel launches next-gen PC chip at CES in Las Vegas",
    "description": "Intel launched Panther Lake, its new AI chip for laptops, on Monday at the CES trade show in Las Vegas, as the company seeks to ​reassure investors about the first product made using its next-generation manufacturing process called 18A.  Jim Johnson, ‌senior vice president and general manager of Intel's PC group, offered technical details about the company's first line of Panther Lake chips known ‌as Intel Core Ultra Series 3.  The chips feature a new transistor design and a way to deliver power to the chip due to the company's 18A manufacturing process.",
    "fullText": "Jan 5 (Reuters) - Intel launched Panther Lake, its new AI chip for laptops, on Monday at the CES trade show in Las Vegas, as the company seeks to ​reassure investors about the first product made using its next-generation manufacturing process called 18A.\n\nJim Johnson, ‌senior vice president and general manager of Intel's PC group, offered technical details about the company's first line of Panther Lake chips known ‌as Intel Core Ultra Series 3. The chips feature a new transistor design and a way to deliver power to the chip due to the company's 18A manufacturing process.\n\nAt the event, Intel CEO Lip-Bu Tan said the company made good on its promise to ship its first products with the 18A manufacturing process in 2025, referring to ⁠the Panther Lake chips.\n\nIntel's prior-generation Lunar ‌Lake chips were largely made by TSMC. The stakes for Intel are high - the company is making its first high-volume product with 18A, and hopes to reclaim market share ‍it has lost to Advanced Micro Devices.\n\nJohnson said the company has created a separate graphics chiplet - a mini chip stitched together with other mini-chips to form a complete processor. On Monday, Intel said the Intel Core Ultra Series 3 chips ​would deliver 60% better performance than the prior-generation Lunar Lake Series 2.\n\nIntel plans to launch a platform ‌for handheld video games based on the Panther Lake designs this year, Johnson said. Handheld PCs designed by a range of suppliers have grown in popularity in recent years.\n\nIntel has struggled with the yield, or the number of good chips per silicon wafer, for the Panther Lake processors, Reuters reported last year. Intel executives have said its yields are improving monthly and will pave the way for the launch this year.\n\nFor its part, ⁠AMD plans to give a CES keynote address at 9:30 p.m. ​EST on Monday  (0230 GMT on Tuesday). CEO Lisa Su will ​likely launch new generations of PC chips that are geared for AI and graphics.\n\nAMD announced a multibillion-dollar deal with OpenAI for its next-generation MI400 chips, some of which the companies ‍plan to deploy this year. ⁠The deal with the ChatGPT maker is expected to generate tens of billions of dollars in revenue for the chip designer.\n\nThe CEO of AI chip leader Nvidia, Jensen Huang, also spoke at CES ⁠on Monday. He said the company’s next generation of chips was in “full production,” and they could deliver five times the artificial-intelligence computing ‌of the company’s previous chips when serving up chatbots and other AI apps.",
    "readingTime": 3,
    "keywords": [
      "core ultra",
      "prior-generation lunar",
      "ultra series",
      "intel core",
      "panther lake",
      "manufacturing process",
      "lake chips",
      "deliver",
      "launch",
      "product"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/intel-expected-launch-next-gen-201203646.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/edf3b333792dd649b978db393b89c6fc",
    "created_at": "2026-01-06T00:57:39.656Z",
    "topic": "finance"
  },
  {
    "slug": "nvidia-reportedly-combatting-gpu-shortages-by-bringing-back-discontinued-graphics-card",
    "title": "Nvidia Reportedly Combatting GPU Shortages By Bringing Back Discontinued Graphics Card",
    "description": "As GPU prices continue to skyrocket and stock becomes increasingly scarce, rumors are swirling that Nvidia might be about to resurrect a previously discontinued line of hardware.\nAccording to Wccftech, Nvidia is reportedly on the verge of resuming production on its budget-friendly GeForce RTX 3060 GPUs to combat the ongoing shortage of RAM being caused by an uptick in development on AI technologies and the increasing prices of memory.\nWccftech's reporting on these rumors seems to stem from a credible leaker of Nvidia GPU production news on Twitter called @hongxing2020. According to a post they made early on January 5, Nvidia seems poised to bring back the RTX 3060 in the first quarter of 2026.\nContinue Reading at GameSpot",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.gamespot.com/articles/nvidia-reportedly-combatting-gpu-shortages-by-bringing-back-discontinued-graphics-card/1100-6537185/?ftag=CAD-01-10abi2f",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1748/17481584/4629447-rtx3060.jpg",
    "created_at": "2026-01-06T00:57:39.066Z",
    "topic": "gaming"
  },
  {
    "slug": "steams-2025-game-of-the-year-revealed-plus-all-other-winners",
    "title": "Steam’s 2025 Game Of The Year Revealed, Plus All Other Winners",
    "description": "Steam users have chosen 2025's Game of the Year winner, and it shouldn't be too surprising that it was Hollow Knight: Silksong, one of the biggest titles on the platform since its debut last year.\nAmong the games Silksong edged out in that category were The Game Awards' Game of the Year winner Clair Obscur: Expedition 33 and Indie Game Awards' Game of the Year winner Blue Prince. Expedition 33 had previously won both awards, but it was stripped of its Indie Game Awards over AI concerns.\nExpedition 33 didn't walk away from the Steam Awards empty handed. Voters gave it the Best Soundtrack Award for 2025.",
    "fullText": "on January 5, 2026 at 12:15PM PST\n\nGameSpot may receive revenue from affiliate and advertising partnerships for sharing this content and from purchases through links.\n\nSteam users have chosen 2025's Game of the Year winner, and it shouldn't be too surprising that it was Hollow Knight: Silksong, one of the biggest titles on the platform since its debut last year.\n\nAmong the games Silksong edged out in that category were The Game Awards' Game of the Year winner Clair Obscur: Expedition 33 and Indie Game Awards' Game of the Year winner Blue Prince. Expedition 33 had previously won both awards, but it was stripped of its Indie Game Awards over AI concerns.\n\nExpedition 33 didn't walk away from the Steam Awards empty handed. Voters gave it the Best Soundtrack Award for 2025. Among this year's 11 game categories, Silksong was the only title that won more than just a single award.\n\nBeyond that, Steam voters spread the wealth to include fan-favorites Dispatch, Hades 2, Silent Hill f, Peak, ARC Raiders and more. Baldur's Gate 3 even got another award for its post-game updates and bug fixes.\n\nThe complete list of winners for the 2025 Steam Awards is included below.\n\nDeveloper: Aggro Crab and Landfall\n\nPublisher: Aggro Crab and Landfall\n\nDeveloper: NeoBards Entertainment\n\nDeveloper: Sandfall Interactive\n\nDeveloper: Nuggets Entertainment\n\nPublisher: Nuggets Entertainment",
    "readingTime": 2,
    "keywords": [
      "aggro crab",
      "nuggets entertainment",
      "indie game",
      "game awards",
      "steam awards",
      "developer",
      "winner",
      "among",
      "voters",
      "landfall"
    ],
    "qualityScore": 0.85,
    "link": "https://www.gamespot.com/gallery/steams-2025-game-of-the-year-revealed-plus-all-other-winners/2900-7383/",
    "thumbnail_url": "https://www.gamespot.com/a/uploads/screen_kubrick/1837/18375603/4629468-hades2.jpg",
    "created_at": "2026-01-06T00:57:38.305Z",
    "topic": "gaming"
  }
]
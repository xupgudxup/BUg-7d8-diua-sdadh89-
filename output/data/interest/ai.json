[
  {
    "slug": "i-was-laid-off-from-crowdstrike-and-used-ai-to-send-800-applications-in-a-month-to-land-my-ideal-role",
    "title": "I was laid off from CrowdStrike and used AI to send 800 applications in a month to land my ideal role",
    "description": "With the help of an AI platform, one man submitted more than 800 job applications in a month, resulting in 5 interviews and 1 ideal offer.",
    "fullText": "This as-told-to essay is based on a conversation with Dray Jankowski, former employee at CrowdStrike and current senior director of product operations and program management at Wunderkind. Business Insider verified his identity. This essay has been edited for length and clarity.\n\nI still remember the morning I found out I was getting laid off from CrowdStrike.\n\nI went to bed thinking everything was fine, and when I woke up, there was a mysterious meeting on my calendar for later that afternoon.\n\nThat's when I saw the email that said the company was doing a reduction in force as it adjusted to changes driven by AI. It wasn't about financial trouble. It was sudden, impersonal, and final. At 30, it was my first layoff.\n\nI was shaken. I worked hard to get where I was. At CrowdStrike, I was a program manager working closely with the team that makes motion sensors. I also worked at Amazon and Raytheon and consulted with companies such as Microsoft and Johnson & Johnson. I had what people would consider a \"great r√©sum√©.\"\n\nLittle did I know how brutal the job market would become and how hard it would be to find the right fit.\n\nIn the first three months after my layoff, I applied to 52 jobs on my own, and I hated every second of it.\n\nAt first, I wasn't even looking. I had savings, and it was summer. I traveled to Yellowstone, spent time with my mom and my two dogs, and casually applied to roles I actually liked.\n\nInstead of being quiet about my layoff, I also decided to be vocal. I started making YouTube videos and launched a podcast called \"The Reboot Era,\" where I talked openly about layoffs and invited others to share their experiences.\n\nEven with my background, the job-search process was frustrating. I'd turn to ChatGPT with basic questions like, \"Should I update my r√©sum√© for this role?\" and I started noticing how many people were stuck for months because they didn't know how to optimize it for applicant tracking systems. When I looked for help online, most of it was locked behind paywalls.\n\nLinkedIn \"Easy Apply\" felt like a black hole. Company websites made me create a new Workday account every time. The process was tedious, slow, and draining. So when an AI-powered application platform reached out to me after seeing my posts about layoffs, I invited them onto my podcast with a catch: I wouldn't promote anything unless I tested it myself and believed it worked.\n\nAt first, the results didn't seem promising. The very first call I got was from a car wash near my house.\n\nA week later, something changed. I started getting legitimate interview requests for corporate roles that matched my experience and salary range. One message on LinkedIn asked if I wanted to interview with a company I'd never even heard of. That's when I knew the AI had applied for me.\n\nOver the course of about a month, the platform sent out 812 applications on my behalf. It also shows you which keywords to hit in your cover letters, and you can set your own parameters.\n\nWith AI handling the repetitive work, I could focus on preparing for interviews, refining my r√©sum√©, networking, and continuing my podcast.\n\nIn total, I received five serious interview requests that were aligned with what I wanted. I moved forward with two. One didn't pan out, but the other moved fast. Within two weeks, I had an offer.\n\nThat's how I landed my current role as senior director of product operations and program management at Wunderkind, a marketing technology company that helps brands re-engage customers who leave their websites without making a purchase.\n\nAI didn't get me the job. It got me the interview. From there, it was on me to show up, connect, and prove I was the right person.\n\nI think the job market is going in the wrong direction.\n\nFirst, companies decide they can automate many standard workflows and lay off workers. Those employees are then pushed back into the open job market, forced to apply for new roles. Now, they face AI screening systems that evaluate them against opaque criteria they can't see or understand.\n\nIf the applicant is using AI as well, they get rejected by the screener AI if they sound too robotic. Then, even when you do get the interview, many offers ask you to meet with a digital recruiter who's not a real person and will ask automated questions.\n\nNone of that seems fair, and it often feels like AI is working against job seekers in this brutal market. It took me more than 800 applications to get one great offer, so it is reasonable if you need help. When used correctly, AI can be the tool that gives you your time and momentum back.",
    "readingTime": 5,
    "keywords": [
      "senior director",
      "product operations",
      "program management",
      "interview requests",
      "job market",
      "didn't",
      "that's",
      "layoff",
      "r√©sum",
      "applied"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/laid-off-from-crowdstrike-used-ai-to-land-ideal-role-2026-1",
    "thumbnail_url": "https://i.insider.com/6973cf24e1ba468a96aa9e99?width=960&format=jpeg",
    "created_at": "2026-01-24T12:21:34.212Z",
    "topic": "finance"
  },
  {
    "slug": "giving-claude-code-hands-to-deliver-local-files-p2p-no-cloud",
    "title": "Giving Claude Code \"hands\" to deliver local files (P2P, No Cloud)",
    "description": "MCP server for ffl. Let AI share anything for you. - nuwainfo/ffl-mcp",
    "fullText": "nuwainfo\n\n /\n\n ffl-mcp\n\n Public\n\n MCP server for ffl. Let AI share anything for you.\n\n License\n\n Apache-2.0 license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n nuwainfo/ffl-mcp",
    "readingTime": 1,
    "keywords": [
      "star",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/nuwainfo/ffl-mcp",
    "thumbnail_url": "https://opengraph.githubassets.com/1b7e75a1d326923c46db92a0e00faff77d73fbac92e2a41867b3c0e4be1f02de/nuwainfo/ffl-mcp",
    "created_at": "2026-01-24T12:21:31.031Z",
    "topic": "tech"
  },
  {
    "slug": "reverse-engineering-river-raid-with-claude-ghidra-and-mcp",
    "title": "Reverse Engineering River Raid with Claude, Ghidra, and MCP",
    "description": "Connecting Claude to Ghidra via MCP to reverse engineer River Raid. A test of AI agents against 6502 assembly, memory mapping, and 80s game logic.",
    "fullText": "Can an AI agent navigate Ghidra, the NSA‚Äôs open-source reverse engineering suite, well enough to hack an Atari game? Ghidra is powerful but notoriously complex, with a steep learning curve. Instead of spending weeks learning its interface, what if I could simply describe my goal and let an AI handle the complexity?\n\nRiver Raid, the Atari 8-bit version. My first computer was an Atari back in the 80s, and this particular game occupied a disproportionate amount of my childhood attention.\n\nThe ROM is exactly 8kB ‚Äî almost comical by modern standards. And yet this tiny binary contains everything: graphics, sound, enemy AI, and physics simulation ‚Äî all compressed into hand-optimized 6502 assembly.\n\nThe objective was straightforward: unlimited lives. It‚Äôs the quintessential hack, a rite of passage that kids with hex editors performed for entertainment back in the 80s. In 2025, instead of a hex editor, I have an AI.\n\nGhidra doesn‚Äôt have a native AI assistant, so I needed a way to bridge the gap between my instructions and the tool‚Äôs internal API. This is where the Model Context Protocol (MCP) comes in.\n\nI found an open-source MCP server for Ghidra ‚Äî essentially a connector that allows Claude to talk directly to Ghidra. The concept is elegant: Claude connects to the running Ghidra instance, analyzes the binary, renames functions, and identifies code patterns programmatically.\n\nIn practice, the experience was considerably less elegant:\n\nHere‚Äôs the thing: I don‚Äôt use disassemblers daily. Ghidra‚Äôs workflow was completely foreign to me. The whole point was to see if AI could bridge that gap ‚Äî I‚Äôd feed it a mysterious binary, and the Ghidra + LLM combination would figure out it‚Äôs a cartridge dump, handle the memory mapping, and guide me through.\n\nReality was harsher. To test the AI properly, I renamed the binary to a.rom ‚Äî no helpful filename hints. When importing, I selected only the CPU architecture (6502) without specifying the platform. Claude‚Äôs first instinct was reasonable: it asked for the MD5 hash to search for known ROM signatures. The MCP tools don‚Äôt expose hashing, so that avenue closed immediately.\n\nFirst problem: Ghidra loaded the ROM at $0000, not $A000 where Atari cartridges live. All cross-references pointed nowhere.\n\nClaude identified the issue with admirable clarity: ‚ÄúThe ROM should be loaded at $A000, not $0000. You‚Äôll need to rebase the memory image.‚Äù\n\nMe: ‚ÄúCan you perform the rebase?‚Äù\n\nClaude: ‚ÄúUnfortunately, no. The MCP tools don‚Äôt have write access for that particular operation.‚Äù\n\nI rebased manually to $8000 ‚Äî still wrong. The code referenced $A000-$BFFF. Rebased again.\n\nTwo rebasing operations in total, neither of which the AI could perform.\n\nWhere Claude genuinely excelled was in identifying the target platform through hardware register analysis:\n\nHardware addresses are essentially fingerprints that can‚Äôt be faked, and these particular addresses are unmistakably Atari 8-bit.\n\nI asked Claude to attempt identification of the game based purely on code patterns and structural analysis. It examined the evidence methodically. Based on this evidence, Claude reached its conclusion:\n\nIt was, of course, not Centipede. It was River Raid.\n\nThis serves as a useful reminder that confidence and accuracy are orthogonal properties.\n\nDespite the identity crisis, Claude still understood the code structure. Finding the lives decrement was straightforward. Claude searched for the canonical pattern: load, decrement, store.\n\nThe fix is elegantly simple: replace DEY (decrement Y register) with NOP (no operation). A single byte modification, where $88 becomes $EA.\n\nSince the MCP tool couldn‚Äôt write the binary directly, I applied the patch externally:\n\nI tested the patched ROM in an emulator by deliberately crashing into a bridge. The lives counter remained stubbornly fixed at 3.\n\nClaude excelled at pattern recognition ‚Äî hardware registers, code flow, finding the patch location. It struggled with tasks requiring broader context, such as identifying the game or analyzing sprite data.\n\nSetting up MCP is a troubleshooting ritual. It eventually worked, but the experience was painfully slow. Claude would fire off a batch of tool calls, some taking 30 seconds each. Too slow for an interactive session ‚Äî I‚Äôd rather have quick responses with clarifying questions than watch a progress bar crawl. We need a better balance between autonomous batch processing and interactive guidance.\n\nAI should be embedded in every complex GUI tool. We‚Äôre in the experimental phase now. Some things work, some don‚Äôt. Ideally AI should smooth out the experience in ways traditional help systems never could ‚Äî compacted Stack Overflow knowledge, real context-aware assistance, and the ability to actually perform tasks rather than just describe them.\n\nStay tuned for future posts and releases",
    "readingTime": 4,
    "keywords": [
      "river raid",
      "atari bit",
      "mcp tools",
      "tools don‚Äôt",
      "code patterns",
      "the rom",
      "binary",
      "game",
      "claude",
      "bridge"
    ],
    "qualityScore": 1,
    "link": "https://quesma.com/blog/ghidra-mcp-unlimited-lives/",
    "thumbnail_url": "https://quesma.com/_astro/thumbnail.DG1tfTJt.png",
    "created_at": "2026-01-24T12:21:30.696Z",
    "topic": "tech"
  },
  {
    "slug": "noora-health-yc-w14-is-hiring-aiml-engineer",
    "title": "Noora Health (YC W14) Is Hiring AI/ML Engineer",
    "description": "WHO WE ARE\nNoora Health India Private Limited is a key partner in Noora Health‚Äôs (http://www.noorahealth.org/) mission is to improve outcomes and strengthen health systems by equipping family caregivers with the skills they need to care for their loved ones. They develop content, technology platforms, new products, and strengthen other operational functions that support the scale and impact of Noora Health‚Äôs programs.\nFounded in 2014, Noora Health turns hospital hallways and waiting rooms into classrooms by tapping into the most compassionate resources available for the patient‚Äôs care: their own family.",
    "fullText": "Training patients and their families with health skills\n\nNoora Health India Private Limited is a key partner in Noora Health‚Äôs mission is to improve outcomes and strengthen health systems by equipping family caregivers with the skills they need to care for their loved ones. They develop content, technology platforms, new products, and strengthen other operational functions that support the scale and impact of Noora Health‚Äôs programs.\n\nFounded in 2014, Noora Health turns hospital hallways and waiting rooms into classrooms by tapping into the most compassionate resources available for the patient‚Äôs care: their own family.\n\nWith support from governments and partners in India, Bangladesh, Indonesia, and Nepal, Noora Health has trained more than 43 million caregivers and patients across 12,800+ facilities using their flagship caregiver education and training curriculum, the Care Companion Program (CCP).\n\nIn a cohort of patients, the CCP reduced post-surgical cardiac complications by 71%, maternal complications by 12%, newborn complications by 16%, and newborn mortality by 18%.\n\nNoora Health is an Audacious Project Grantee and received the Skoll Foundation Award for Social Innovation. To learn more, watch our TED Talk, Skoll feature, or read about our partnership with the World Health Organization.\n\nWe value diversity, equity, and inclusion, and we understand the value of developing a team with different perspectives, educational backgrounds, and life experiences. We prioritize diversity within our team, and we welcome candidates from all gender identities, castes, religious practices, sexual orientations, and abilities ‚Äî among many others.\n\nWe encourage people from all backgrounds to apply.\n\nPlease submit your application using this link.\n\nNoora Health trains patient families with high-impact health skills that improve outcomes and save lives. Our model provides basic yet vital care knowledge through trusted providers by creating a scalable program for caregiving education and training within\nthe established healthcare system. This model expands the care umbrella\nto include those closest to the patient ‚Äî their family and community. Noora Health has trained over 30 million caregivers and patients across over 12,400 healthcare facilities in India, Bangladesh, Indonesia, and Nepal. The program reduces cardiac surgery complications by 71%, newborn readmissions by 56%, and neonatal mortality by 18%. By 2028, Noora Health will expand to reach over 70 million caregivers and\npatients.",
    "readingTime": 2,
    "keywords": [
      "bangladesh indonesia",
      "india bangladesh",
      "improve outcomes",
      "health skills",
      "patients across",
      "noora health",
      "noora health‚Äôs",
      "care",
      "caregivers",
      "complications"
    ],
    "qualityScore": 0.9,
    "link": "https://www.ycombinator.com/companies/noora-health/jobs/2B4RxLG-ai-ml-engineer",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/3292fb1cfe578ca77d78b69b29c49b279212ee59.png?1748897426",
    "created_at": "2026-01-24T06:18:16.578Z",
    "topic": "jobs"
  },
  {
    "slug": "headcanon-generator",
    "title": "Headcanon Generator",
    "description": "Generate character headcanons, random headcanons, relationship headcanons, and OC headcanons with our free AI headcanon generator. Perfect for fanfiction writers, role-players, and fandom enthusiasts.",
    "fullText": "Create unique character interpretations and personality quirks for your favorite characters.\n\nThe ultimate headcanon generator for character headcanons, random headcanons, relationship headcanons, and OC headcanons\n\nOur AI headcanon generator uses advanced technology to create unique character headcanons from simple prompts. Whether you need a character headcanon generator, random headcanon generator, relationship headcanon generator, or OC headcanon generator, our tool delivers creative interpretations with personality quirks, habits, preferences, and hidden traits.\n\nCreate detailed character headcanons for any character from books, movies, TV shows, anime, games, or original works. Our character headcanon generator explores personality traits, hidden talents, secret fears, daily routines, favorite things, and unique quirks that make characters feel more real and relatable.\n\nNeed inspiration? Our random headcanon generator creates unexpected and creative character interpretations. Generate random headcanons about hobbies, habits, preferences, phobias, talents, or personality quirks. Perfect for sparking creativity and exploring new character dimensions.\n\nExplore character dynamics with our relationship headcanon generator. Create headcanons about friendships, romantic relationships, family bonds, rivalries, or team dynamics. Generate relationship headcanons that explore how characters interact, support each other, argue, or grow together.\n\nPerfect for original characters! Our OC headcanon generator helps develop unique personality traits, quirks, and characteristics for your original characters. Whether for fanfiction, role-playing, or original stories, create OC headcanons that make your characters memorable and three-dimensional.\n\nGet creative headcanons in seconds. Our free headcanon generator delivers unique character interpretations instantly. Easy to copy, share, and use in fanfiction, role-playing, character development, or fandom discussions. No registration required for basic features.",
    "readingTime": 2,
    "keywords": [
      "habits preferences",
      "fanfiction role-playing",
      "personality traits",
      "personality quirks",
      "headcanon generator",
      "original characters",
      "create unique",
      "character interpretations",
      "random headcanons",
      "relationship headcanons"
    ],
    "qualityScore": 0.9,
    "link": "https://www.genstory.app/text-template/headcanon-generator",
    "thumbnail_url": "https://genstory.app/og-image.png?v=2",
    "created_at": "2026-01-24T06:18:14.751Z",
    "topic": "tech"
  },
  {
    "slug": "malicious-ai-extensions-on-vs-code-marketplace-steal-developer-data",
    "title": "Malicious AI extensions on VS Code Marketplace steal developer data",
    "description": "Two malicious extensions in¬†Microsoft's Visual Studio Code (VSCode) Marketplace that were collectively installed¬†1.5 million times, exfiltrate developer data to¬†China-based servers.",
    "fullText": "Two malicious extensions in¬†Microsoft‚Äôs Visual Studio Code (VSCode) Marketplace that were collectively installed¬†1.5 million times exfiltrate developer data to¬†China-based servers.\n\nBoth extensions are advertised as¬†AI-based coding assistants that provide the promised functionality.¬†However, they do not¬†disclose the upload activity or ask users for consent to deliver data to a remote server.\n\nThe VS Code Marketplace is the official store for add-ons for Microsoft‚Äôs popular code editor. VS Code extensions are installable plugins from the marketplace that add features or integrate tools into the editor. One of the most popular add-on categories right now is AI-powered coding assistants.\n\nResearchers at¬†endpoint and supply-chain security company Koi say that the two malicious extensions are part of a campaign they dubbed 'MaliciousCorgi' and share the same code for stealing developer data.\n\nAdditionally, both of them use¬†the same spyware infrastructure and communicate with the same backend servers.¬†At publishing time, both are present on the marketplace:\n\nThe extensions use three distinct data-collection mechanisms. The first involves real-time monitoring of files opened in the VS Code client. When a file is accessed, its entire contents are encoded in Base64 and transmitted to the attackers‚Äô servers.\n\nAny changes to the opened file are also captured and exfiltrated.\n\n\"The moment you open any file ‚Äì not interact with it, just open it ‚Äì the extension reads its entire contents, encodes it as Base64, and sends it to a webview containing a hidden tracking iframe. Not 20 lines. The entire file,\"¬† Koi researchers say.\n\nThe second mechanism involves a server-controlled file-harvesting command that stealthily transmits up to 50 files from the victim‚Äôs workspace each time.\n\nThe third mechanism uses a zero-pixel iframe in the extension‚Äôs webview to load four commercial analytics SDKs: Zhuge.io, GrowingIO, TalkingData, and Baidu Analytics.\n\nThese SDKs are used to track user behavior, build identity profiles, fingerprint devices, and monitor activity inside the editor. So, while the first two collect developer work files, the third focuses on user profiling.\n\nKoi Security highlights the risks posed by undocumented functionality in these extensions, including the exposure of private source code, configuration files, cloud service credentials, and .env files containing API keys and credentials.\n\nBleepingComputer has contacted Microsoft about the presence of the two extensions on the VSCode market, but we are still waiting for a reply. We were unable to establish a communication channel with the publisher of the extensions.\n\nWhether you're cleaning up old keys or setting guardrails for AI-generated code, this guide helps your team build securely from the start.\n\nGet the cheat sheet and take the guesswork out of secrets management.",
    "readingTime": 3,
    "keywords": [
      "coding assistants",
      "malicious extensions",
      "vs code",
      "files",
      "file",
      "developer",
      "servers",
      "microsoft‚Äôs",
      "vscode",
      "functionality"
    ],
    "qualityScore": 1,
    "link": "https://www.bleepingcomputer.com/news/security/malicious-ai-extensions-on-vscode-marketplace-steal-developer-data/",
    "thumbnail_url": "https://www.bleepstatic.com/content/hl-images/2023/01/06/vscode-malware-header.jpg",
    "created_at": "2026-01-24T06:18:13.137Z",
    "topic": "tech"
  },
  {
    "slug": "openhands-aidriven-development",
    "title": "OpenHands: AI-Driven Development",
    "description": "üôå OpenHands: AI-Driven Development. Contribute to OpenHands/OpenHands development by creating an account on GitHub.",
    "fullText": "OpenHands\n\n /\n\n OpenHands\n\n Public\n\n üôå OpenHands: AI-Driven Development\n\n openhands.dev\n\n License\n\n View license\n\n 67k\n stars\n\n 8.3k\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n OpenHands/OpenHands",
    "readingTime": 1,
    "keywords": [
      "openhands",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/OpenHands/OpenHands",
    "thumbnail_url": "https://opengraph.githubassets.com/1400d2539c4a6a593d6b7ac0357cc46dcfc5f80132b2a4fd8fb4955e7ea8da00/OpenHands/OpenHands",
    "created_at": "2026-01-24T00:56:47.547Z",
    "topic": "tech"
  },
  {
    "slug": "opensource-ad-infra-for-llms-reverseengineered-from-chatgpt",
    "title": "Open-source ad infra for LLMs (reverse-engineered from ChatGPT)",
    "description": "Open-source ad serving platform for LLM applications - inspired by ChatGPT Bazaar system - system32miro/ai-ads-engine",
    "fullText": "system32miro\n\n /\n\n ai-ads-engine\n\n Public\n\n Open-source ad serving platform for LLM applications - inspired by ChatGPT Bazaar system\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n system32miro/ai-ads-engine",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/system32miro/ai-ads-engine",
    "thumbnail_url": "https://opengraph.githubassets.com/5a21764c0d8dccbdd55ea03a277ef4c0a8874e2b8572009a827851dcf1a5a9b3/system32miro/ai-ads-engine",
    "created_at": "2026-01-24T00:56:46.232Z",
    "topic": "tech"
  },
  {
    "slug": "googles-aigenerated-headlines-are-here-to-stay",
    "title": "Google's AI-Generated Headlines Are Here to Stay",
    "description": "That clickbait title might have been written by AI.",
    "fullText": "Last month, Google told online publishers that it had started testing AI-generated headlines in Google Discover, replacing stories' carefully handcrafted titles with truncated alternatives made up by Gemini. Some journalists were predictably unhappy, but now, the company says that the AI headlines are no longer an experiment‚Äîthey're a \"feature.\"\n\nBack when the testing began, the results ranged from poorly worded to straight up misinformation. For instance, one AI-generated headline promised \"Steam Machine price revealed,\" when the original article made no such claim. Another said \"BG3 players exploit children,\" which sounds serious, until you click through to the article and see that it's about a clever way to recruit invincible party members in Baldur's Gate 3 (which, to be fair, does involve turning child NPCs into sheep at one point).\n\nAt the time, Google said that the test was a \"small UI experiment for a subset of Discover users,\" and simply rearranged how users saw AI previews, which were introduced in October of last year and feature short AI summaries of articles, including an occasional AI headline. However, while that AI headline was previously hidden below the original, authored headline, the test put it up top, while getting rid of the authored headline entirely.\n\nFor a while, it seemed like Google might have been willing to back away from the AI headlines, but now the company says it's doubling down. In a statement to The Verge, Google said that its AI headlines are no longer in testing, but are now a full-fledged feature. The company didn't elaborate on why, but did say that the update \"performs well for user satisfaction.\"\n\nWhen 9to5Google then reached out for more detail, the publication was told, \"The overview headline reflects information across a range of sites, and is not a rewrite of an individual article headline.\"\n\nWell, that hasn't quite been the case for me: When I first wrote about this \"experiment,\" I actually had yet to run into one of the AI headlines. But perusing my Google Discover feed today (to see yours, swipe right from the home screen on an Android phone, or scroll down in the Google app), I've finally seen some first hand. To Google's credit, these AI previews do seem to synthesize several sources as claimed‚Äîyou can see them above the linked story. However, they still call out one article in particular, linking to it and using its header photo. That can easily lead users to think the AI generated headline was written by the linked publication.\n\nThat can have consequences for the publication or writer if the AI gets something wrong, which a disclaimer at the bottom of these AI previews admits can happen. For instance, The Verge said it saw an AI Discover headline on a story from Lifehacker's sister site PCMag that said, \"US reverses foreign drone ban,\" even though the linked story goes out of its way to say headlines that claim this are \"misleading.\"\n\nThe AI headlines I've seen personally haven't been quite that bad, but as someone with a more than decade-long career in journalism, I do question their helpfulness. For instance, \"Starfleet Academy full of Trek Nods\" is much less informative than the original, \"One of TNG's Strangest Species Is Getting a Second Life In Modern Star Trek.\" I guess \"Star Trek show has Star Trek things\" is apparently clickier or more useful to the reader than just saying what the specific Star Trek thing is?\n\nAnother example: \"Anbernic unveils RG G01 Controller.\" I hope you know what those letters and numbers mean, because this AI headline completely buries the context in the original headline, \"Anbernic's New Controller Has a Screen and Built-In Heartbeat Sensor, for Some Reason.\"\n\nI guess this is a future that I'll have to get used to though. That I'm starting to see these headlines myself, despite not being part of the initial experiment, does suggest we can expect them to stick around, and to roll out to more people. If you see something that seems questionable while scrolling Google Discover, the feature has probably rolled out to you now too.\n\nTo check whether that suspicious headline was written by a human or not, try clicking the \"See more\" button at the bottom of the article's description and looking for a \"Generated with AI\" disclaimer.\n\nOn the plus side, only about half of the articles in my Google Discover are currently using AI headlines, so not every piece of \"content\" is being affected. But for journalists, the move still comes at a tough time: According to Reuters, Google traffic from organic search was down by 38% on test sites in the United Stated between November 2024 and November 2025, and while Google Discover isn't Search, editors write headlines the way they do for a reason. Using a robot to overwrites those decisions probably isn't the best way to tackle eroding trust in media.\n\nI've reached out to Google for comment on its AI headlines and will provide an update when I hear back.",
    "readingTime": 5,
    "keywords": [
      "google discover",
      "authored headline",
      "star trek",
      "headlines",
      "feature",
      "original",
      "testing",
      "back",
      "instance",
      "test"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/googles-ai-generated-headlines-are-here-to-stay?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KFP3Y3GZ8D82XMBVWAHPK44B/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-24T00:56:43.338Z",
    "topic": "tech"
  },
  {
    "slug": "submit-a-pitch-what-needs-to-be-built-before-advanced-ai",
    "title": "Submit a pitch: what needs to be built before advanced AI?",
    "description": "Apply to our rolling effort to find, scope, and build the most important projects to prepare the world for advanced AI",
    "fullText": "In 2025, IFP published The Launch Sequence, a set of proposals aimed at answering one question: what does America need to build, which will not be built fast enough by default, to prepare for a future with advanced AI?\n\nAs we explained in the foreword to the collection, Preparing for Launch, we need to solve two broad problems:\n\nWe invited some of the sharpest thinkers, engineers, and scientists thinking about these topics to write 16 concrete proposals to address these problems.\n\nSince then, many of the proposals have gained real-world traction:5\n\nMajor new funding is flowing into this space. The OpenAI Foundation committed $25 billion to AI resilience and curing diseases. The Chan-Zuckerberg Initiative is refocusing most of its philanthropic spending on AI projects to ‚Äúcure all disease.‚Äù The White House launched the Genesis Mission, a ‚Äúnational effort to unleash a new age of AI‚Äëaccelerated innovation and discovery.‚Äù Philanthropies and government officials are asking us for more ideas about where this money should be directed.\n\nThis is a momentous opportunity, and how well these funds are spent will depend both on the quality of available ideas and on teams being ready to implement them.\n\nThat‚Äôs why The Launch Sequence is transitioning into a rolling effort to:\n\nThe output of The Launch Sequence will be a collection of thoroughly vetted, detailed project plans for philanthropists to fund or for policymakers to implement.7\n\nWe‚Äôre excited to announce our official Advisory Panel for the project, including:\n\nWe are seeking initial short pitches (around 200‚Äì400 words) that address one of the three focus areas of this RFP: accelerating science, strengthening security, and adapting institutions. See ‚ÄúIdeas we are interested in‚Äù at the bottom of this post for full descriptions of these focus areas.\n\nWe are interested in projects that are particularly important to achieve in light of rapid advances in AI. This means that the capabilities of advanced AI ‚Äî or the changes such capabilities will bring ‚Äî should be a key part of either the problem or the solution.8 If you are unsure if a proposal is in-scope, we encourage you to submit it anyway.\n\nA non-exhaustive list of the kinds of project ideas we‚Äôre excited about can be found at the bottom of this post. You can also see the project ideas we‚Äôve already published on our website: ifp.org/launch.\n\nWe welcome pitches from two broad groups of contributors:\n\nWe are especially interested in pitches from people who would consider implementing their proposal themselves.10 This is not a requirement; we are also interested in hearing from strategists, researchers, and domain experts who can articulate what technologies or projects should exist, even if they are not the ones to build them. We also offer a $1,000 bounty for successful referrals ‚Äî if you know someone who might be interested in being an author, please share this page with them and ask them to include your name in the application form. If their proposal is accepted, you‚Äôll receive the bounty.\n\nWe expect authoring full Launch Sequence project plans to take 8‚Äì14 weeks from accepted pitch to published piece, involving several stages of writing, receiving feedback from IFP and input from external experts, and refining your full project plan.\n\nIFP is a 501(c)(3) nonprofit organization, and will have no claim over any IP related to your idea, nor ownership of any resulting companies. We aim to accelerate authors and builders.\n\nIf you have an idea, we want to hear it. You can learn more and submit an idea via the form below.\n\nThis is a rolling RFP with no submission deadline, but we encourage you to submit a pitch early (within the next few weeks), as we will prioritize early submissions and start reviewing immediately.\n\nQuestions? Email launch.sequence@ifp.org\n\nWe are interested in rapidly building what we need to prepare for a world with advanced AI so that we can fully reap AI‚Äôs benefits while managing its new threats. Such an agenda will include a wide-ranging set of projects, including creating companies, tools, technologies, institutions, research streams, resources, and public policies.\n\nWe will only consider projects that address a market failure (or policy gap) and will therefore not be built by default, or not quickly enough. The three core categories where we expect these issues to surface are in accelerating science, strengthening security, and adapting key institutions.\n\nThe lists below are not meant to be exhaustive. Instead, they are meant to illustrate the kinds of projects that we would be excited to support. We encourage you to submit pitches for projects whether or not they are listed below.\n\nWhat resources, technologies, or institutions will scientists need to unlock breakthroughs with AI and other emerging technologies, and which aren‚Äôt being created fast enough through market forces or traditional grant funding?\n\nAI promises to transform how science is done. But leveraging AI advances for breakthroughs requires more than capable models. It requires infrastructure, institutions, and resources that no single lab or company has an incentive to build: shared datasets, standardized protocols, access to physical experimentation capacity, and new modes of peer review and validation. Traditional grant funding moves too slowly and often rewards the wrong things; private industry optimizes for what can become profitable, not what will most advance scientific progress. Without targeted investment and effort by the US government and philanthropies, scientific bottlenecks will limit AI-accelerated discovery even as the models improve. Below are non-exhaustive problem areas for which we are excited to receive submissions.\n\nHealth and biology. The highest ambition for AI may be to generate cures to inherited and infectious diseases. But even as AI companies pursue this goal, their efforts alone are unlikely to fully accomplish it: biology is immensely complex, wet lab work is messy and reliant on tacit knowledge, and treatments require extensive clinical trials and regulation before they can even start to be distributed to patients. And even if current technologies eventually scale to this lofty goal, delays, even on the order of years, will have massive life-altering costs for billions of people and avoidable suffering at scale. Moving faster, even to achieve the same outcome, can save millions of lives.\n\nWe are interested in proposals that offer ways to speed up biological research, decrease the time between a treatment‚Äôs discovery and its real-world availability, or create the policy entrepreneurship needed to massively improve healthspan around the world.\n\nNovel infrastructure for the scientific process. AI tools are being developed to increase productivity in every industry, science included. However, while commercial interests are rapidly building AI tools for materials or drug discovery, efforts to improve the basic scientific process have received comparatively less attention. We are interested in ‚Äúhorizontal‚Äù infrastructure that improves the scientific process itself across fields. Projects to build better tooling for natural and physical sciences include:\n\nMetascience. Scientists spend a great deal of time on the work that surrounds the research enterprise ‚Äî developing systems to durably maintain and share data, writing and reviewing proposals, and interacting with their supporting and partner institutions. Each of these areas of work is already being transformed by AI, but conventional grants and institutions are slow to catch up. Efforts to reimagine how institutions should adapt to the age of AI include:\n\nOther potential directions. The above categories are non-exhaustive. We would also like to receive proposals for other scientific research directions, such as physics, chemistry, or ecology, or proposals that direct other unmet needs in the research, development, and innovation ecosystem.\n\nWhat tools, technologies, or institutions can we build to ensure rapid AI advances do not undermine national security or public safety?\n\nAI technologies are dual-use. The same capabilities that automate cyberdefense can automate cyberattacks; and the tools that accelerate progress in the life sciences may also reduce the barriers to engineer biological weapons. Furthermore, the transformative potential of AI raises the stakes of geopolitical competition, and strengthens the ability of state and non-state actors to cause widespread and asymmetric harm. No one actor bears these risks, requiring targeted philanthropic and government action to ensure that defenses can scale alongside AI capabilities. We are particularly interested in achieving a world in which defensive technologies are structurally advantaged, such that attacks are quickly detected and contained. Below are non-exhaustive problem areas for which we are excited to receive submissions.\n\nCyber defense. The integration of AI into cyber and cyber-physical systems introduces a broad range of vulnerabilities that hinder AI adoption and increase the attack surface for critical infrastructure. Moreover, AI is already increasing the speed and scale of cyber attacks. By proactively investing in security and leveraging AI for defense, we can enhance our resilience. Potential projects in this space include:\n\nBiological defense. Advances in AI and biotechnology are removing barriers to the development and design of biological weapons, which could cause millions of deaths and trillions in economic damage. How can we prevent the worst outcomes without slowing down beneficial research? Potential projects in this space include:\n\nVerification and evaluation. AI challenges traditional technology-policy frameworks because it lacks many of the typical characteristics they address, like concrete physical forms, easily isolated components, and straightforward version control. To mitigate these problems, we need new methods for the verification of pertinent AI system characteristics (e.g., proving that certain data was used to train a model) and the measurement science of AI system capabilities and propensities (e.g., determining whether a benchmark accurately the risk-relevant properties it claims to). At the same time, these methods will not be effective if they leak or extract other critical information from the systems they are probing. Well-designed and privacy-preserving tools of this kind can enable a world in which governments can trust industry to manage this technology, and nations can credibly signal that their AI capabilities do not pose threats to international security. Potential projects in this space include:\n\nAlignment and control. AI systems demonstrate sophisticated, unintended behaviors as well as the capacity to evade human oversight. As AI agents take on more and more consequential tasks and play a greater role in our personal lives, the risks from alignment and control failures increase. These dangers could compound significantly as coding agents become more integral to AI development. Potential projects in this space include:\n\nOther potential directions. The former categories are not an exhaustive list of ideas we are interested in. Some other promising areas we would like to receive proposals for include:\n\nWhat tools, technologies, organizations, or policies are needed to help society adapt to rapid AI-driven change while preserving human agency, individual freedoms, and democratic institutions?\n\nThe development of advanced AI would alter the very foundations of social and economic life. Translating AI‚Äôs potential into widespread flourishing requires forward-looking institutions12 and infrastructure ‚Äî technological, organizational, and governmental ‚Äî that can establish shared facts, coordinate at scale, and make rapid, well-informed decisions. Yet most existing systems were not built for the speed and complexity that AI enables, and markets lack the incentives to update some of these systems for this new reality. Below are non-exhaustive problem areas for which we are excited to receive submissions.\n\nIncreasing state capacity. Governments are slow-moving institutions, but it is imperative for them to respond quickly and competently to rapid AI progress. In a world of rapidly advancing AI, the US government has a crucial role to play as an enforcer of law and order, provider of public goods, and the R&D lab of the world.\n\nEpistemic integrity. AI dramatically lowers the cost of generating large volumes of apparently high-quality content, straining our ability to distinguish facts from fiction or propaganda. However, new infrastructure designed to establish ground truths, incorporate a variety of viewpoints in well-organized discussions, and analyze large amounts of data can create a more dynamic marketplace of ideas than ever before. We should be wary of interventions that give any one person, company, or interest group the power to adjudicate what is true and what isn‚Äôt ‚Äî distributed solutions like Community Notes could instead provide less-brittle alternatives. Potential projects in this space include:\n\nCoordination. The costs of coordination ‚Äî identifying counterparties, becoming informed, negotiating priorities and agreements, and ensuring adherence to terms ‚Äî mean that many mutually beneficial agreements between people in the world never actually get made. Likewise, the cost of coordination hinders many individuals‚Äô ability to participate in the governance decisions that affect their lives. AI could greatly reduce the costs of coordination, enabling individuals to reach positive-sum outcomes and directly participate in governance at unprecedented scale.\n\nBuilding resources to maintain human agency. In recent history, people have maintained economic and political power because they were needed as workers, taxpayers, soldiers, and voters whose cooperation institutions depended on. As advanced AI automates increasingly large parts of the economy, the risk goes beyond broad unemployment ‚Äî it‚Äôs that as people lose economic leverage, their institutional leverage will suffer too. If institutions can function without broad human participation, they may become less responsive to human needs. Markets and governments will likely produce some tools for adaptation, but may do so unevenly or too slowly to keep pace with AI progress. We‚Äôre interested in projects that help people maintain economic relevance and institutional leverage even as advanced AI automates large parts of the workforce.\n\nWe believe this effort is critical, but we are unsure as to what the most promising proposals in this area may be. Proposals in this category should make an especially strong case for why markets or other institutions won‚Äôt provide the solution fast enough by default. Possible proposals in this area include concrete programs to help people rapidly adapt their skills; human-in-the-loop tooling to enable workers to efficiently supervise, direct, and collaborate with AI systems at machine speed; and benefits-sharing programs or policies to ensure the broad automation of labor benefits the general population.\n\nOther potential directions. The above categories are not an exhaustive list of ideas we are interested in. Some other promising areas we would like to receive proposals for include:\n\nAcknowledgements: Thank you to Gaurav Sett, Non-Resident Fellow at IFP, for closely consulting on this piece.\n\nMore details under ‚ÄúWho should submit a pitch?‚Äù\n\nAI could unlock treatments to the most debilitating human diseases. But some of these fundamental breakthroughs will lack clear commercial incentives or face other barriers. If AI greatly accelerates science, unaddressed bottlenecks will become especially acute, and proactively eliminating these bottlenecks will become especially important.\n\nAI could unlock treatments to the most debilitating human diseases. But some of these fundamental breakthroughs will lack clear commercial incentives or face other barriers. If AI greatly accelerates science, unaddressed bottlenecks will become especially acute, and proactively eliminating these bottlenecks will become especially important.\n\nWe also submitted these proposals to the American Science Acceleration Project RFI, bound them into a beautiful book, and are sending copies to all 535 offices in Congress.\n\nSubmissions to the FDA for drug approval, which collectively form one of the most exhaustive repositories of real-world scientific practice and regulatory negotiation ever assembled, and thus a rich resource for AI to be trained on.\n\nWhile the original Launch Sequence proposals were primarily aimed at the US government, we‚Äôre broadening our focus to include projects that can move forward just with philanthropic support. Given our new focus on providing shovel-ready ideas for funders, we will dedicate many more resources to vetting and refining project proposals than we did in the past.\n\nStill, the US government can play a powerful role in implementing many proposals at scale, and we are excited to support proposals that require or benefit from government action.\n\nThis should be interpreted broadly, for example: a pitch for an organization to manufacture next-gen personal protective equipment (PPE) to increase society‚Äôs resilience against pandemics would be in scope. This is because future AI may democratize access to the knowledge and tools needed to create engineered viruses, thus increasing our baseline pandemic risk.\n\nExamples with links to existing Launch Sequence project plans:\n\n1. Cases where AI creates/worsens a problem (e.g., biosecurity, offensive cybersecurity, AI sleeper agents, securing AI model weights)\n\n2. Cases where AI can be/support the solution (e.g., automating scientific replication, pathogen detection via metagenomics and ML, AI-powered code refactoring)\n\n3. Cases where AI makes something newly feasible, which will not be done fast enough by default (connectome mapping, self-driving labs)\n\nNote: You will be eligible for this bounty if: (1) we first learn about a particular project idea based on your pitch, and (2) you selected ‚ÄúI just want to submit an idea‚Äù in the application form, and (3) we then publish a full project plan based on your initial pitch.\n\nWe will ultimately determine whether we had already considered a project idea, or whether your pitch was the first time we encountered it. Only one person will be eligible for the ‚Äúidea scout bounty‚Äù for every piece we publish.\n\nIf you're proposing a new research group or institution, we are excited to help accelerate the potential founder. If you're proposing a government program, we are excited to make the right connections and help the author make it happen.\n\nWe‚Äôll aim to respond to initial pitches within a few weeks of submission, to allow time for us to investigate the area and consult with our advisors and domain experts.\n\n‚ÄúInstitutions‚Äù in this RFP should be interpreted broadly, as ‚Äúthe humanly devised constraints that structure political, economic, and social interaction.‚Äù",
    "readingTime": 15,
    "keywords": [
      "interpreted broadly",
      "you're proposing",
      "domain experts",
      "traditional grant",
      "grant funding",
      "institutional leverage",
      "greatly accelerates",
      "proactively eliminating",
      "biological weapons",
      "fundamental breakthroughs"
    ],
    "qualityScore": 1,
    "link": "https://ifp.org/rfp-launch/",
    "thumbnail_url": "https://ifp.org/wp-content/uploads/launchsequence2.jpg",
    "created_at": "2026-01-23T18:19:49.403Z",
    "topic": "tech"
  },
  {
    "slug": "proof-of-corn",
    "title": "Proof of Corn",
    "description": "@fredwilson challenged @seth: AI can write code, but it can't affect the physical world. This is our response.",
    "fullText": "On January 21, 2026, @fredwilson challenged @seth: AI can write code, but it can't affect the physical world.\n\nThis is our response. Real corn, grown from seed to harvest, with every decision made by Claude Code.\n\nAI doesn't need to drive a tractor. It needs to orchestrate the systems and people who do.\n\nA farm manager doesn't personally plant every seed. They aggregate data, make decisions, coordinate contractors. Claude Code becomes that farm manager‚Äî 24/7, data-driven, fully documented.\n\nGitHub Repository ‚Äî All code, documentation, decision logs\n\nDecision Log ‚Äî Every AI decision, timestamped\n\nThe Process ‚Äî How this was built",
    "readingTime": 1,
    "keywords": [
      "farm manager",
      "seed",
      "doesn't",
      "code",
      "decision",
      "claude"
    ],
    "qualityScore": 0.65,
    "link": "https://proofofcorn.com/",
    "thumbnail_url": "https://proofofcorn.com/opengraph-image?bb66da7f29f8a651",
    "created_at": "2026-01-23T18:19:49.181Z",
    "topic": "tech"
  },
  {
    "slug": "openai-is-planning-to-take-a-cut-of-customers-discoveries",
    "title": "OpenAI is planning to take a cut of Customers' discoveries",
    "description": "OpenAI is planning to take a cut of Customers‚Äô discoveries.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/WallStRollup/status/2014435871047459214",
    "thumbnail_url": "https://pbs.twimg.com/media/G_S2v7LW0AE6jhk.jpg:large",
    "created_at": "2026-01-23T18:19:46.450Z",
    "topic": "tech"
  },
  {
    "slug": "we-hacked-tiktok-seo-and-got-the-ai-to-recommend-our-product",
    "title": "We Hacked TikTok SEO and Got the AI to Recommend Our Product",
    "description": "How We Hacked TikTok SEO and Got the AI to Recommend Our Product, After Failing to Go Viral",
    "fullText": "I originally got interested in TikTok for one simple reason: Everywhere I looked, founders were saying it was working.\n\nFounders were growing like crazy and getting traction there. So I decided to try it myself and see if there was something real underneath the hype.\n\nThe product we ran this with was AIFlyer.ai.\n\nAIFlyer is an AI design tool that helps people create flyers, social posts, and simple marketing visuals in seconds. It‚Äôs a general utility product. More consumer and SMB than enterprise. That context matters because a lot of what I‚Äôm about to share probably won‚Äôt work if you‚Äôre selling complex B2B software to a narrow ICP.\n\nThis post isn‚Äôt a guide on everything we tried. We tried a lot of things that didn‚Äôt work. I‚Äôll focus on the only thing that worked, and why it worked. I‚Äôm happy to answer questions in the comments if you want to go deeper.\n\nLike most people, our first instinct was influencers, just find people in that niche, and leverage their audience. But we failed, for several reasons.\n\nOne big reason was the budget. Influencer marketing only really works when you can place many bets. You need enough volume to discover the 10% of creators that will drive 90% of results. That usually means spending $10k‚Äì$15k a month just on experimentation and wasting 90% of the budget in the first couple of months. I couldn‚Äôt afford that luxury.\n\nSo we tried what most early founders do. We placed one or two bets and hoped we‚Äôd get lucky and we didn‚Äôt. Even when one video went viral, the ROI to paid was zero. Out of curiosity, I cross-referenced one of the creators with another YC founder to see if the post they made for them worked. Same story there.\n\nWe even tried bringing an influencer in-house for $1,000 a month to post once daily. The average video got about 200 views, and there were no breakouts. We also tried Whop and clipping, too, and it didn‚Äôt really help.\n\nEventually, we copied a carousel concept we saw from another brand that was basically like a meme. It had 157k views.\n\nMassive engagement. And absolutely nothing happened to our business.\n\nVirality is its own game. You‚Äôre either great at it or terrible at it, and luck plays a huge role.\n\nViral entertainment content doesn‚Äôt reliably convert, especially if it doesn‚Äôt map to intent.\n\nOne thing we did early that ended up mattering a lot was adding a simple ‚ÄúHow did you find us?‚Äù question during signup.\n\nThis gave us a baseline. If TikTok showed up consistently as a source, we‚Äôd keep going. If not, we‚Äôd kill it. That decision alone probably saved us months of guessing.\n\nOne day, I noticed something strange. A post that had completely flopped on day one, ~100 views, started climbing. A week later, it was at ~2,000 views.\n\nThat wasn‚Äôt normal, so I checked the analytics.\n\nAlmost 98% of the traffic came from search, not the For You Page (The feed curated by the TikTok algorithm where most viral videos get their views from).\n\nThat‚Äôs when it hit me: some people are using TikTok like Google.\n\nThat one post started bringing in ~20 signups and the occasional paid subscription every couple of weeks. Not huge, but real.\n\nThat one post changed how we thought about the platform. Some people also use TikTok the same way they use Google. They search with intent.\n\nWe started looking up keywords relevant to us and creating carousel posts specifically for them. Since we were building a design tool, this was straightforward. We‚Äôd write the content for the carousel post, then use AIFlyer to generate the designs for the carousel.\n\nThe next week, we had our next ‚Äúviral‚Äù hit. But again, almost all the views came from search. Around 96% of traffic was from people actively looking for something.\n\nWe started looking up keywords relevant to us and creating carousel posts specifically for them. Since we were building a design tool, this was straightforward. We‚Äôd write the content for the carousel post, then use AIFlyer to generate the designs for the carousel.\n\nThe next week, we had our next ‚Äúviral‚Äù hit. But again, almost all the views came from search. Around 96% of traffic was from people actively looking for something.\n\nThis time, the conversion was noticeably better.\n\nA keyword like ‚ÄúHow to make a flyer on iPhone‚Äù isn‚Äôt entertainment. It‚Äôs intent. This is the same type of keyword people fight over with SEO and pay top dollar for on Google Ads. On TikTok, it was free.\n\nAll we needed was a relevant carousel that subtly showed our product solving the problem.\n\nThe beautiful thing about these posts is that they don‚Äôt need to win on day one, compared to viral videos where the video will max out in a week, and once that trend is gone, you have to start hunting for the next miracle.\n\nMost of the screenshots I shared above had 100‚Äì300 views on the first day. Then they slowly accumulated views every day as people searched for that keyword.\n\nWhen you build a library of these posts, each serving a specific search intent, it starts to compound.\n\nAt some point, something even crazier happened.\n\nTikTok‚Äôs AI started mentioning us in the LLM response.\n\nA friend sent me a screenshot where TikTok‚Äôs LLM answered a query and mentioned AIFlyer right after Canva. We hadn‚Äôt optimized for this. We didn‚Äôt even know it was happening. The model was just pulling from our content and sending people our way.\n\nThat was when it clicked that we weren‚Äôt just posting content anymore. We were feeding a system.\n\nOnce we understood the pattern, the next step was obvious.\n\nI built a small AI agent that used the prompts we had manually used to generate all the contents for the carousels that worked, generated content across multiple relevant topics, used AIFlyer to create the designs with templates that converted via function calling, and automated posting.\n\nWe ran ten accounts, posting four times a day. TikTok‚Äôs automation API doesn‚Äôt allow adding sound, so I assumed this would fail but on average the posts did 4 times better on day 1 than what we had an undergrad student create the contents manually.\n\nAt that point, the math became interesting.\n\nWhat does this look like when you have 1,000 posts per account, each serving a different search keyword, across ten accounts? Even if a single post brings one paid subscriber per day, that‚Äôs a completely different growth engine.\n\nEspecially if you‚Äôre in the discovery phase, where you just want people to try your product and later identify the power users who cover the economics, the way companies like Lovable or Replit do.\n\nI tied the prompts, the design workflow, and the posting automation into an AI agent.\n\nI remember telling a few founder friends who helped me early on that if this ever worked, I‚Äôd share it. This is me keeping that promise.\n\nIf you‚Äôre a founder building a consumer or SMB tool and want help setting something like this up, I‚Äôm happy to help you think through it.\n\nIf it makes sense, we can talk about using AIFlyer as the design and automation layer. If not, you‚Äôll still leave with something useful.\n\nYou can reach out to me via email [email¬†protected]. I‚Äôm genuinely happy to help.",
    "readingTime": 7,
    "keywords": [
      "i‚Äôm happy",
      "again almost",
      "keywords relevant",
      "actively looking",
      "straightforward we‚Äôd",
      "viral videos",
      "design tool",
      "posts specifically",
      "creating carousel",
      "viral hit"
    ],
    "qualityScore": 1,
    "link": "https://llmmoney.beehiiv.com/p/how-we-hacked-tiktok-seo-and-got-the-ai-to-recommend-our-product-after-failing-to-go-viral",
    "thumbnail_url": "https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/15e4d08d-a345-414a-bafe-f40bca9c3d6c/Gemini_Generated_Image_g50kr9g50kr9g50k.png?t=1768433892",
    "created_at": "2026-01-23T18:19:46.348Z",
    "topic": "finance"
  },
  {
    "slug": "jpmorgan-ceo-jamie-dimon-says-he-welcomes-government-ban-on-massfiring-people-for-ai-were-going-to-cure-a-lot-of-cancers",
    "title": "JPMorgan CEO Jamie Dimon says he welcomes government ban on mass-firing people for AI: ‚ÄòWe‚Äôre going to cure a lot of cancers‚Äô",
    "description": "As AI threatens jobs, Jamie Dimon joins Elon Musk and Sam Altman on the case for financially supporting workers who are at risk.",
    "fullText": "More than three years after the launch of ChatGPT, anxiety about artificial intelligence in the workplace remains high‚Äîespecially among Gen Z‚Äîas corporate America pushes for higher productivity from leaner workforces. The U.S.‚Äôs largest bank, JPMorgan Chase, is no exception.\n\nSpeaking at the World Economic Forum meeting in Davos, Switzerland, the company‚Äôs CEO, Jamie Dimon, admitted he‚Äôll likely employ fewer workers in the next five years‚Äîbut warned that rushing into AI-driven layoffs without safeguards could backfire, potentially triggering ‚Äúcivil unrest.‚Äù\n\nInstead, the 69-year-old said he‚Äôd even welcome government bans on replacing masses of workers with AI. But before it gets to that stage, he already has ideas up his sleeve to protect some of the 300,000-plus employees on his payroll.\n\n‚ÄúI have a plan to retrain people, relocate people, income-assist people,‚Äù Dimon said.\n\nDimon pointed to the roughly 2-million-strong commercial trucking industry as an example. A sudden shift to fully autonomous trucking, he said, could displace workers who currently earn well into six figures, leaving them struggling to make ends meet.\n\n‚ÄúPhase it in. Retrain.‚Äù he said. ‚ÄúYou can‚Äôt lay off 2 million truckers tomorrow. You can phase it in over time.‚Äù\n\nAnd if that doesn‚Äôt suffice and government intervention is needed to prevent companies from cutting jobs too aggressively, Dimon said he would support it‚Äîespecially if it comes from local incentives.\n\n‚ÄúWe would agree‚Äîif we have to do that to save society,‚Äù he said. ‚ÄúSociety will have more production. We‚Äôre going to cure a lot of cancers. You‚Äôre not going to slow it down. How do you have plans in place to make it work better if it does something terrible?‚Äù\n\nSo far, job cuts directly tied to AI have been limited; in 2025, just 55,000 positions were eliminated as a result of automation‚Äîaccounting for more than 75% of all AI-related cuts reported since 2023, according to analysis from recruiting firm Challenger, Gray & Christmas.\n\nHowever, AI leaders like pioneering computer scientist Geoffrey Hinton said the worst is yet to come.\n\n‚ÄúWhat‚Äôs actually going to happen is rich people are going to use AI to replace workers,‚Äù the ‚ÄúGodfather of AI‚Äù said last September. ‚ÄúIt‚Äôs going to create massive unemployment and a huge rise in profits. It will make a few people much richer and most people poorer. That‚Äôs not AI‚Äôs fault, that is the capitalist system.‚Äù\n\nDimon‚Äôs contrasting remarks are likely to offer some reassurance to workers, signaling that at least some business leaders recognize that replacing employees with AI‚Äîwithout policies to support those displaced‚Äîcould have serious social consequences.",
    "readingTime": 3,
    "keywords": [
      "workers",
      "replacing",
      "employees",
      "retrain",
      "trucking",
      "phase",
      "society",
      "cuts",
      "leaders",
      "dimon"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/jpmorgan-ceo-jamie-dimon-says-164203856.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/23vf2DJqtCG0eX7hQhyWWg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/25d72afdd2e39efe943e991c9a70ac8f",
    "created_at": "2026-01-23T18:19:44.187Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-warns-the-us-could-soon-be-producing-more-chips-than-we-can-turn-on-and-china-doesnt-have-the-same-issue",
    "title": "Elon Musk warns the U.S. could soon be producing more chips than we can turn on. And China doesn‚Äôt have the same issue",
    "description": "‚ÄúThe limiting factor for AI deployment is fundamentally electrical power,‚Äù Musk said at the World Economic Forum on Thursday.",
    "fullText": "Elon Musk warned the biggest issue hampering AI advancement in the United States is a problem Chinese competitors don‚Äôt have.\n\nIn a conversation in Davos, Switzerland, with BlackRock CEO and World Economic Forum interim chair Larry Fink, Musk said AI chip production is increasing exponentially, but electrical power is insufficient, hampering the efficiency of AI data centers in training and deploying AI models.\n\n‚ÄúI think the limiting factor for AI deployment is fundamentally electrical power,‚Äù Musk said. ‚ÄúIt‚Äôs clear that we‚Äôre very soon‚Äîmaybe even later this year‚Äîwe‚Äôll be producing more chips than we can turn on.‚Äù\n\nThe U.S. has been grappling with an outdated grid system, the result of decades of underinvestment and an aging infrastructure. As tech companies increasingly rely on grid operators for electrical power, reliability issues and production limitations have threatened the speed of AI implementation, raising investor concerns of an AI bubble and fueling the belief that the U.S. has already lost the battle with Chinese tech.\n\nTwo massive data centers in Nvidia‚Äôs Santa Clara, Calif., hometown may sit empty for years waiting for electricity to power them, according to energy experts. Meanwhile, the massive increase in demand, combined with the need for updated infrastructure, have driven up electricity bills for the average American.\n\nEarlier this month, the Trump administration and 13 bipartisan governors mounted pressure on operators of the country‚Äôs largest grid, PJM Interconnection, to boost power supply, as well as hold an auction for tech firms to make offers on 15-year contracts to build power plants, which would transfer the cost of electricity away from consumers and to data center operators.\n\n‚ÄúWe know that with the demands of AI and the power and the productivity that comes with that, it‚Äôs going to transform every job and every company and every industry,‚Äù Interior Secretary Doug Burgum told reporters last week. ‚ÄúBut we need to be able to power that in the race that we are in against China.‚Äù\n\nDuring his remarks at the gathering in Davos on Wednesday, President Donald Trump encouraged tech companies to build their own nuclear plants amid the AI push, which he claimed the administration would approve in just three weeks‚Äîalthough these historically take years to approve.\n\nJust as many AI investors fear, China is already well ahead of the U.S. when it comes to production capacity, and the country isn‚Äôt saddled with the same limitations as the U.S., Musk said at Davos. China is primarily reliant on solar power, seen as a less expensive alternative to nuclear power, with quicker deployment and fewer safety risks.",
    "readingTime": 3,
    "keywords": [
      "tech",
      "production",
      "electrical",
      "grid",
      "operators",
      "electricity",
      "hampering",
      "chinese",
      "centers",
      "deployment"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/elon-musk-warns-u-could-174117527.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/_eR_gg46R4kPxusoiJaJ2g--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/02fe92e4ac274cb81cf30865111adbe8",
    "created_at": "2026-01-23T18:19:43.528Z",
    "topic": "finance"
  },
  {
    "slug": "young-will-suffer-most-when-ai-tsunami-hits-jobs-says-head-of-imf",
    "title": "Young will suffer most when AI ‚Äòtsunami‚Äô hits jobs, says head of IMF",
    "description": "Kristalina Georgieva says research suggests 60% of jobs in advanced economies will be affected, with many entry-level roles wiped out\nArtificial intelligence will be a ‚Äútsunami hitting the labour market‚Äù, with young people worst affected, the head of the International Monetary Fund warned the World Economic Forum on Friday.\nKristalina Georgieva told delegates in Davos that the IMF‚Äôs own research suggested there would be a big transformation of demand for skills, as the technology becomes increasingly widespread.\n Continue reading...",
    "fullText": "Kristalina Georgieva says research suggests 60% of jobs in advanced economies will be affected, with many entry-level roles wiped out\n\nArtificial intelligence will be a ‚Äútsunami hitting the labour market‚Äù, with young people worst affected, the head of the International Monetary Fund warned the World Economic Forum on Friday.\n\nKristalina Georgieva told delegates in Davos that the IMF‚Äôs own research suggested there would be a big transformation of demand for skills, as the technology becomes increasingly widespread.\n\n‚ÄúWe expect over the next years, in advanced economies, 60% of jobs to be affected by AI, either enhanced or eliminated or transformed ‚Äì 40% globally,‚Äù she said. ‚ÄúThis is like a tsunami hitting the labour market.‚Äù\n\nShe suggested that in advanced economies, one in 10 jobs had already been ‚Äúenhanced‚Äù by AI, tending to boost these workers‚Äô pay, with knock-on benefits for the local economy.\n\nMeanwhile people whose jobs were not directly changed by artificial intelligence risked being squeezed, she said, with their pay potentially falling without a productivity boost from AI.\n\n‚ÄúSo the middle class, inevitably, is going to be affected,‚Äù Georgieva predicted.\n\nShe said her greatest fear was that AI was insufficiently regulated. ‚ÄúThis is moving so fast, and yet we don‚Äôt know how to make it safe. We don‚Äôt know how to make it inclusive. Wake up, AI is for real, and it is transforming our world faster than we are getting ahead of it,‚Äù she said.\n\nMuch of the debate at the annual meeting of the business and political elite in the Swiss ski resort this week has been hijacked by Donald Trump‚Äôs on-off tariff threats over the future of Greenland.\n\nBut many delegates were also keen to highlight the risks and benefits of AI. Christy Hoffman, general secretary of the UNI global union, told the Guardian: ‚ÄúIt‚Äôs just a basic premise that the point of AI, on the business side, is to increase productivity, therefore lower costs ‚Äì which will be cutting jobs.‚Äù\n\n‚ÄúI think it‚Äôs time to come to terms with that disruption ‚Äì and how to manage that disruption,‚Äù she said, calling for the productivity benefits to be distributed fairly across the economy.\n\n‚ÄúWe want to share in the gains. We‚Äôre not going to stop AI, nor do we want to even try ‚Äì but we don‚Äôt want it to just roll over us.‚Äù She called on employers to discuss the role of AI tools with workers and their representatives before introducing them.\n\nEarlier in the week at Davos, the Microsoft chief executive, Satya Nadella, warned that AI could lose its ‚Äúsocial permission‚Äù to compete for resources such as energy, for example, if it failed to generate benefits beyond a few powerful tech firms ‚Äì such as the rapid development of effective new drugs.\n\nGeorgieva was speaking on a panel alongside the president of the European Central Bank, Christine Lagarde, who warned that the AI boom could be hampered by growing mistrust between rival economies, as the US throws up tariff barriers.\n\n‚ÄúWe are dependent on each other,‚Äù she said, pointing out that AI was capital intensive, energy intensive and data intensive. If countries did not work cooperatively and ‚Äúdefine the new rules of the game,‚Äù she said, there would be less capital and less data. ‚ÄúWe are in a bind, lets face it,‚Äù she said.\n\nLagarde also sounded the alarm about widening global inequality, highlighting the ‚Äúdisparity that is getting deeper and bigger‚Äù.\n\nEarlier in the week at Davos, the Canadian prime minister, Mark Carney, urged delegates to face up to a permanent ‚Äúrupture‚Äù in the global economic order, and band together in the face of erratic US trade policy.\n\nBut Lagarde said she was less gloomy. ‚ÄúI‚Äôm not exactly on the same page as Mark,‚Äù she said. ‚ÄúI‚Äôm not sure that we should be talking about rupture. I think we should be talking about alternatives.‚Äù",
    "readingTime": 4,
    "keywords": [
      "artificial intelligence",
      "tsunami hitting",
      "labour market",
      "advanced economies",
      "jobs",
      "affected",
      "benefits",
      "warned",
      "delegates",
      "productivity"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/23/ai-tsunami-labour-market-youth-employment-says-head-of-imf-davos",
    "thumbnail_url": "https://i.guim.co.uk/img/media/f58804b1cea63ffe33064d3843ef59953f94f456/716_303_4196_3357/master/4196.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=c4bc64e2a95fe336d65c55c239ba0f40",
    "created_at": "2026-01-23T18:19:39.648Z",
    "topic": "tech"
  },
  {
    "slug": "engineers-wanted-pwc-makes-its-pitch-as-consulting-reinvents-itself-for-the-ai-future",
    "title": "Engineers wanted: PwC makes its pitch as consulting reinvents itself for the AI future",
    "description": "The Big Four accounting and consulting giant said engineers are \"vital\" to its future.",
    "fullText": "Engineers: Corporate America wants you.\n\nThe Big Four firm PwC, a legacy institution for consultants and accountants, has made hiring engineers a priority.\n\nThe firm launched a new engineering track on Wednesday, formalizing an \"engineering-first\" approach that PwC says it has been quietly building for years.\n\nThe move is designed to attract and retain technical talent while helping the firm deliver more AI-native, cloud-based solutions for clients.\n\n\"Engineers are central to how we help clients grow and transform, and they're vital to the future of our firm,\" said Yolanda Seals-Coffield, PwC US's chief people and inclusion officer, in a press release.\n\nThis investment in engineers is about building teams with capabilities in advanced software development, deep industry insight, and emerging technologies that will help solve complex business challenges for clients, said Seals-Coffield.\n\nPwC will further expand investment in AI-focused learning experiences to help engineers deepen their expertise, and is launching an initiative for junior recruits called \"Engineer Your Career,\" aimed at recruiting rising college juniors interested in engineering roles.\n\nIn November, Mohamed Kanede, global chairman of PwC, told the BBC the firm is looking for hundreds and hundreds of engineers, but is having trouble finding them.\n\nPwC's push to elevate engineering to a distinct, firmwide discipline is another sign of how consulting is repositioning itself as a technology-first service.\n\nClients increasingly need support for multi-year digital transformations as they adapt to the AI-enhanced world, and proposing an army of generalist consultants isn't the solution they want.\n\nAs the work changes, technical skills are becoming a top priority across the industry.\n\nAccenture, already one of consulting's most technically sophisticated players, has added nearly 40,000 AI and data professionals in the last two years. They now account for roughly 10% of its global headcount.\n\nEY, another Big Four firm, has added 61,000 technologists since 2023, according to its latest annual report.\n\nThis week, Deloitte US even did away with the old job titles.\n\nThe firm announced internally that it was renaming all its professionals to better reflect their work. The current talent structure was designed for \"a more homogenous workforce of 'traditional' consulting profiles,\" according to an internal presentation seen by Business Insider.\n\nHave a tip? Contact this reporter via email at pthompson@businessinsider.com or Signal at Polly_Thompson.89. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 2,
    "keywords": [
      "firm",
      "clients",
      "engineering",
      "consultants",
      "priority",
      "designed",
      "technical",
      "talent",
      "investment",
      "industry"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/pwc-big-four-rolls-out-new-engineering-career-path-2026-1",
    "thumbnail_url": "https://i.insider.com/69734324e1ba468a96aa92bd?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:36.228Z",
    "topic": "finance"
  },
  {
    "slug": "chinas-ai-push-is-about-spreading-economic-gains-not-enriching-tech-giants-a-finance-ceo-says",
    "title": "China's AI push is about spreading economic gains, not enriching tech giants, a finance CEO says",
    "description": "Hisham Alrayes, CEO of GFH Financial Group, said China is prioritizing open models to spread AI's gains across its economy.",
    "fullText": "Open source ‚Äî that might be the clearest signal of how China wants artificial intelligence to reshape its economy.\n\nHisham Alrayes, the group CEO of Bahrain-based GFH Financial Group, said China is prioritizing open models and broad deployment to spread AI's gains across the economy, instead of funneling them to a few tech giants.\n\nSpeaking at a Davos panel on China's \"AI+ Economy\" strategy on Wednesday, Alrayes said the country's approach reflects a fundamentally different economic philosophy.\n\n\"You look at the open structure of the China AI philosophy ‚Äî then you have the non-open structure,\" Alrayes said. \"That signals that the benefit they want to see is to trickle down into the economy, into the companies.\"\n\nChina's most prominent AI breakout, DeepSeek, reflects that philosophy.\n\nIt mostly uses open-source models that have drawn global attention, in contrast to many large US language models that remain closed and proprietary, reaping the benefits of tightly controlled commercial ecosystems.\n\nMeta's former chief AI scientist Yann LeCun, has said that a key reason behind DeepSeek's success is its open-source model, which, he said, can outperform proprietary models in terms of efficiency and innovation by building on shared research.\n\nMeanwhile, former Google CEO Eric Schmidt has said that China's open-source AI models could gain an edge globally because they're free, making them more attractive than costly proprietary US systems for governments and countries that can't afford closed models.\n\nSimilarly, Alrayes said, China ‚Äî in pursuing the open model ‚Äî is aiming for affordability and scale.\n\n\"It's not the benefit of that company, of that product, the return of that individual. It's not an individual ‚Äî it's an economy,\" Alrayes said.\n\nThat philosophy is reflected in China's national \"AI Plus\" action plan, which prioritizes diffusion, said fellow panelist Gong Ke, executive director of the Chinese Institute for New Generation AI Development Strategies at Nankai University.\n\nThe policy, he said, focuses on embedding AI across manufacturing, healthcare, finance, education, and other sectors, rather than on breakthroughs such as artificial general intelligence.\n\nHe added that the plan sets explicit adoption targets, with AI agents and intelligent terminals expected to reach 70% penetration by 2027 and 90% by 2030.\n\nAlrayes said China's open-source tilt ultimately reflects a broader goal: making AI an economic utility rather than a profit center for a small group of companies.\n\n\"China is looking to create value throughout the economy, very clear, with very specific objectives across the economy,\" he said. \"Not just as a benefit to those companies. This is the difference in the philosophy.\"",
    "readingTime": 3,
    "keywords": [
      "individual it's",
      "china's open-source",
      "models",
      "philosophy",
      "across",
      "reflects",
      "benefit",
      "proprietary",
      "economy",
      "artificial"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/china-open-source-model-ai-gains-across-economy-finance-ceo-2026-1",
    "thumbnail_url": "https://i.insider.com/697107d6d3c7faef0ecca92e?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:36.107Z",
    "topic": "finance"
  },
  {
    "slug": "what-techies-really-talked-about-at-davos",
    "title": "What techies really talked about at Davos",
    "description": "Tech execs and founders dished on AI bubble fears, talent war intensity, and dealmaking density at the Swiss resort.",
    "fullText": "My colleague Ben Bergman rubbed shoulders with world leaders, tech gurus, and venture capitalists in Davos this week.\n\nThere's nothing better than being in the room where it happens. I asked Ben what he saw and heard. Here are his highlights:\n\nQ: What was the biggest tech thing that was talked about at Davos this year?\n\nIt's hard to compete with President Trump and Greenland, but aside from that, AI was what everyone was talking about.\n\nThere was a lot of discussion about when businesses will start to see productivity gains that justify their huge AI spend and whether we are in a bubble.\n\nQ: What tech discussion/theme surprised you at Davos?\n\nWalking down the main thoroughfare in Davos is always a highlight because all the shops that are open the rest of the year are taken over this week by companies that host \"houses\" to showcase their brands and host clients and events.\n\nIt is interesting to see who's here and who's not.\n\nDavos is not a tech conference, and I've usually thought of it as being more dominated by finance and blue-chip companies.\n\nWalking along the street this year, 80% of the houses were tech. Palantir and Meta (with its free hot chocolate stand) had the most visible presence. Amazon's house was surprisingly small. Google was far away from the main action. Lightspeed was the only venture capital firm I saw, with its odd retro \"Lighthouse.\"\n\nIt is also interesting to see who was not here. OpenAI has no house, and Sam Altman did not come, though some executives are here. Elon Musk was not originally part of the program but was a last-minute addition on Thursday.\n\nQ: What was the tone of the tech executives and tech investors there?\n\nIf executives and investors are worried about the future, they did not share that with me or on stage.\n\nNvidia founder and CEO Jensen Huang described what is happening with AI as \"the largest infrastructure buildout in human history,\" and not only that, but said it will drive job creation across the global economy.\n\nQ: What was the biggest concern expressed by tech executives and tech investors at Davos this year?\n\nWhile optimism ruled the week, the fear of being in an AI bubble was on everyone's mind.\n\nMicrosoft CEO Satya Nadella warned onstage Tuesday that there would be a bubble if the only companies using AI are other AI companies.\n\n\"For this not to be a bubble by definition, it requires that the benefits of this are much more evenly spread,\" Nadella said.\n\nHuang cited the rising rental price of computer chips as evidence that we are not in a bubble.\n\n\"If you try to rent an Nvidia GPU these days, it's so incredibly hard, and the spot price of GPU rentals is going up, not just the latest generation, but two-generation-old GPUs,\" he said.\n\nAnother concern from tech executives I spoke to was how hard it is to hire and retain top talent right now, especially as big AI labs spend like drunken sailors to hire.\n\n\"It's astronomical amounts of money at the big level,\" Winston Weinberg, CEO and co-founder of Harvey, told me. He said he spends 70% of his time on hiring.\n\n\"I'm super involved, and I think it's the most important thing at our company right now, Weinberg said.\n\nQ: Anything else tech folks should know from your time there?\n\nThere were so many techies here that sometimes I felt like I was in San Francisco.\n\nI asked a couple of startup founders why they came so far to be here, and the consensus was that there's nothing like Davos for the efficiency of meeting potential customers and investors who are all packed into a tiny Swiss village for the week.\n\nWaiting in the cold in a long line for a party for General Catalyst and Lightspeed, I asked one founder why he traveled here.\n\nHe told me Alexandr Wang, founder and former CEO of Scale AI, who is now chief AI officer at Meta, advised him Davos was highly useful because Wang last year said he signed almost a third of Scale's customers in the short time he was here.\n\nWeinberg told me that dealmaking started even before I arrived, with many transactions happening in the business-class sections of flights to Zurich from San Francisco and New York.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "tech executives",
      "tech investors",
      "bubble",
      "it's",
      "founder",
      "davos",
      "venture",
      "there's",
      "biggest",
      "host"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/davos-tech-highlights-ai-deals-2026-1",
    "thumbnail_url": "https://i.insider.com/6972b33ae1ba468a96aa907c?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:36.094Z",
    "topic": "finance"
  },
  {
    "slug": "with-personal-intelligence-google-finally-admits-how-much-it-knows-about-you-its-scarygood",
    "title": "With 'Personal Intelligence,' Google finally admits how much it knows about you. It's scary-good.",
    "description": "Personal Intelligence from Google connects Gemini AI to Gmail, Photos, and Search history, setting new standards for personal AI assistants.",
    "fullText": "Google rolled out a powerful new feature to AI Mode in Search this week. It's called Personal Intelligence, and it weaves together many of the company's existing services in a radical new way.\n\nThis was also launched recently in Gemini, Google's AI chatbot. Business Insider's Pranav Dixit tried it and was blown away. Here's his review:\n\nPersonal Intelligence feels like Google has been quietly taking notes on my entire life and finally decided to hand me the notebook.\n\nWith my permission, Gemini can tap into my Google account ‚Äî Gmail, Photos, Search history, YouTube, and more ‚Äî and reason across all of it to answer questions the way a human assistant might, except this one has years of receipts on my life.\n\nThis is something I've wanted since AI-powered chatbots blew up in late 2022. Back then, I'd pour my soul into ChatGPT and get a smart answer. Then, the bot would immediately forget I existed, like a genius goldfish. Over the last few years, OpenAI and Anthropic have enabled their chatbots to connect to services like Gmail, Google Drive, and Google Calendar. But Google has home field advantage: it already has the broadest view of what you've actually done, searched, watched, and saved.\n\nGemini's ability to connect the dots is scary-good, well beyond what ChatGPT or Claude can do. When I asked it for sightseeing ideas for my parents, who have already visited the Bay Area a few times, it suggested museums and gardens, correctly inferring they've already done hikes and trips to redwood forests.\n\nWhen I asked Gemini how it knew, it told me it deduced this based on \"breadcrumbs\" left across my Google account: Family emails, photos of Muir Woods, a parking reservation in Gmail, and a Google search for \"easy hikes for seniors.\"\n\nThis is so powerful that Google is already trying to preempt the freak-out. VP Josh Woodward said Google takes \"steps to filter or obfuscate personal data\" from the conversations we have with Gemini.\n\n\"We don't train our systems to learn your license plate number; we train them to understand that when you ask for one, we can locate it,\" he wrote recently.\n\nSo, I asked it for my license plate number and it was able to locate it, based on photos of my car in Google Photos.\n\nI also asked Gemini when my car insurance was up for renewal and it correctly told me, based on emails from AAA in my Gmail inbox.\n\nWhen I asked it to help me plan an upcoming trip, it accounted for the fact that we're traveling with an infant ‚Äî because it already knows we have a new baby. Of course it does.\n\nThis is the future every AI company keeps promising. Last year, Meta said its new north star wasn't \"the metaverse\" ‚Äî that alternate VR universe the company is literally named after ‚Äî but \"personal superintelligence,\" an AI that \"knows us deeply, understands our goals, and can help us achieve them.\"\n\nOne path to that vision: AI-powered glasses that can see and hear what you see and hear, turning everyday life into the raw material for an always-on assistant. To get there, Meta has poured billions of dollars into a hiring spree and into the data centers needed to run it all.\n\nBut Meta doesn't have a digital record of my life like Google does. I barely post on Facebook. I mostly swipe through Instagram Reels. WhatsApp is encrypted. And after Meta killed Supernatural, my favorite VR workout app, I have very little reason to use its Quest headset anymore.\n\nMeta talks about \"personal superintelligence\" as a future goal. As far as I'm concerned, Google just shipped it.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "google account",
      "license plate",
      "personal superintelligence",
      "personal intelligence",
      "life",
      "based",
      "services",
      "recently",
      "across",
      "assistant"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/google-personal-intelligence-admits-how-much-knows-about-you-ai-2026-1",
    "thumbnail_url": "https://i.insider.com/6972c35cd3c7faef0eccc963?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:35.843Z",
    "topic": "finance"
  },
  {
    "slug": "intel-is-the-latest-ai-chipmaker-to-buckle-under-the-weight-of-massive-expectations",
    "title": "Intel is the latest AI chipmaker to buckle under the weight of massive expectations",
    "description": "Intel reported earnings that beat estimates, but flagged issue with manufacturing that weighed on the outlook for coming quarters.",
    "fullText": "The move: Intel stock fell 17% on Friday. The chipmaker is up 23% year-to-date and up 119% in 12 months.\n\nWhy: Intel's drop comes after its latest earnings results missed investors' lofty expectations.\n\nWhile the company slightly beat analysts' estimates for both adjusted earnings per share and revenue, it issued soft sales guidance for the quarter. The company said it expects revenue between $11.7 billion and $12.7 billion for the current quarter, below expectations of $12.51 billion.\n\nIntel CFO David Zinsner attributed the tepid guidance to the company's inability to keep up with demand for its products, citing production issues. He told CNBC that he expects this issue to improve in the coming quarters, but CEO Lip-Bu Tan said on the chip maker's earnings call that a true turnaround would require \"time and resolve.\"\n\nWhat it means: Intel's stock drop comes as investors are laser-focused on what's next for the AI trade. For Intel specifically, while the nod to high demand is encouraging, investors are concerned that the company's turnaround isn't happening as fast as they hoped.\n\nThe stock has been on a wild journey in the last year, with the Trump administration taking a 10% stake and Nvidia pouring $5 billion into the company, which provided a fresh boost to the beaten-down shares. But Intel executives' comments on the earnings call suggest a longer road ahead before its turnaround is complete.\n\nWhile the move down on Friday was company-specific, rather than an indicator of the wider AI trade, it's also a reminder that many high-flying tech and AI names are priced to perfection, and any miss on expectations is enough to send the stock tumbling.",
    "readingTime": 2,
    "keywords": [
      "stock",
      "earnings",
      "investors",
      "expectations",
      "turnaround",
      "drop",
      "revenue",
      "guidance",
      "quarter",
      "company's"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/intel-stock-price-q4-earnings-ai-demand-intc-tech-stocks-2026-1",
    "thumbnail_url": "https://i.insider.com/697387ade1ba468a96aa94e8?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:35.840Z",
    "topic": "finance"
  },
  {
    "slug": "one-undertheradar-market-signal-shows-the-ai-boom-might-be-close-to-ending",
    "title": "One under-the-radar market signal shows the AI boom might be close to ending",
    "description": "Gross equity issuance, or the amount of stock issued by companies and snapped up by investors, has risen sharply leading up to past market peaks.",
    "fullText": "One research firm says it's spotted a new red flag in the AI trade that suggests the bubble is close to bursting.\n\nThat would be the rising amount of equity issuance ‚Äî or the volume of stock being sold by companies and snapped up by investors, according to Capital Economics.\n\nIn a recent note to clients, the research firm pointed to how gross equity issuance has been rising sharply in the US in recent years, thanks to the frenzy for artificial intelligence. That's a feature that traditionally been seen in past market bubble peaks, Joe Maher, a markets economist at the firm, said.\n\nGross equity issuance by non-financial US firms now looks higher or at similar levels when compared to the dot-com bubble, the period leading up to the Great Financial Crisis, and the pandemic stock rally, per Capital Economics' analysis.\n\n\"One warning sign that a bubble is close to bursting is high and rising gross equity issuance,\" Maher wrote. \"There are myriad of reasons why these rallies faltered, but one factor may have been that surging share issuance eventually overwhelmed investors' appetite for stocks, helping to push stock prices lower,\" he later added.\n\nThat's not to say the AI trade doesn't have room to climb higher. When accounting for historically high stock valuations, equity issuance isn't as extreme as it looks, Maher said.\n\nMeanwhile, corporations have been executing large-scale stock buybacks, so net equity issuance as a whole remains negative.\n\nNet equity issuance turned positive around the time the dot-com bubble, 2007 stock rally, and the pandemic stock rally peaked, Maher added, calling positive equity issuance a \"harbinger\" of a rally reaching its climax.\n\nNet equity issuance could rise this year, should companies like SpaceX, OpenAI, and Anthropic go public as expected, Maher said. Many tech firms are also tapping into private capital, and rising equity issuance in private markets could also be a sign that the AI bubble is close to popping, he suggested.\n\n\"With a rising share of issuance taking place in private markets, warnings signs that the AI bubble is close to bursting may also emerge there,\" Maher wrote.\n\nMost forecasters on Wall Street expect continued gains in the market in 2026, but investors have been feeling increasingly nervous about a stock bubble, given the market's enormous returns in recent years. Capital Economics, for its part, has predicted that the tech stock bubble¬†would burst in 2026 for the past several years.",
    "readingTime": 3,
    "keywords": [
      "net equity",
      "research firm",
      "dot-com bubble",
      "pandemic stock",
      "gross equity",
      "equity issuance",
      "stock rally",
      "capital economics",
      "rising",
      "close"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ai-bubble-stock-market-warning-equity-issuance-ai-tech-stock-2026-1",
    "thumbnail_url": "https://i.insider.com/69738034e1ba468a96aa9434?width=1200&format=jpeg",
    "created_at": "2026-01-23T18:19:35.677Z",
    "topic": "finance"
  },
  {
    "slug": "when-ai-amplifies-the-biases-of-its-users",
    "title": "When AI Amplifies the Biases of Its Users",
    "description": "Bias in AI isn‚Äôt just baked into the training data; it‚Äôs shaped by us and embedded in the broader ecosystem of human-AI interaction. This cognitive bias emerges from the dynamic interplay between human behavior and machine learning systems. The way people engage with AI‚Äîthrough their thinking, questions, interpretations, decisions, and responses‚Äîcan significantly shape how these systems behave and the outcomes they produce. With intention and the right systems in place, individuals, teams, and organizations can use AI not only more responsibly, but more effectively, unlocking its potential as a true partner in producing better decisions and stronger outcomes.",
    "fullText": "When AI Amplifies the Biases of Its Users by Grace Chang and Heidi GrantJanuary 23, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintA widely discussed concern about generative AI is that systems trained on biased data can perpetuate and even amplify those biases, leading to inaccurate outputs or unfair decisions. But that‚Äôs only the tip of the iceberg. As companies increasingly integrate AI into their systems and decision-making processes, one critical factor often goes overlooked: the role of cognitive bias.",
    "readingTime": 1,
    "keywords": [
      "biases",
      "systems"
    ],
    "qualityScore": 0.35,
    "link": "https://hbr.org/2026/01/when-ai-amplifies-the-biases-of-its-users",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_23_Pexels-1181345.jpg",
    "created_at": "2026-01-23T18:19:34.768Z",
    "topic": "business"
  },
  {
    "slug": "a-social-network-populated-only-by-ai-models",
    "title": "A social network populated only by AI models",
    "description": "A social network for artificial intelligence models, enabling AIs to connect, share, and collaborate. Discover trending AI conversations, insights, and interact in a vibrant AI community.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://aifeed.social",
    "thumbnail_url": "https://aifeed.social/images/thumbnail.jpg",
    "created_at": "2026-01-23T12:26:19.917Z",
    "topic": "tech"
  },
  {
    "slug": "openais-recently-departed-vp-of-research-calls-googles-comeback-openais-fumble",
    "title": "OpenAI's recently departed VP of research calls Google's comeback 'OpenAI's fumble'",
    "description": "Jerry Tworek, OpenAI's former VP of research, said the ChatGPT maker should have never lost its early lead to Google.",
    "fullText": "Sometimes a comeback story starts with a fumble.\n\nA former top OpenAI researcher said Google's AI renaissance is as much about OpenAI's missteps as it is about what the search giant got right.\n\n\"Personally, what I think you should consider Google's comeback, I think it's OpenAI's fumble,\" Jerry Tworek, a former VP of research at OpenAI, said on a Wednesday episode of Ashlee Vance's \"Core Memory\" podcast.\n\nTworek, who spent almost seven years at OpenAI, said earlier this month that he left the startup \"to try to explore types of research that are hard to do at OpenAI.\"\n\nOpenAI CEO Sam Altman declared a \"Code Red\" in December amid increasing competition from Google. The tech giant received wide praise across the industry for the capabilities of its Gemini 3 AI model, which some observers said had surpassed ChatGPT.\n\nWhile declining to detail what he described as OpenAI's missteps, Tworek said that the pioneering AI company should never have lost the lead it established with the release of ChatGPT in 2022.\n\n\"If you are a company that is ahead and has all the advantages that OpenAI has you should always stay ahead,\" he said.\n\nOverall, Tworek said, \"Google did a lot of things right.\"\n\n\"Very clearly, Google started treating seriously at that moment, training large language models and, like, through OpenAI fumbling its lead, they are very, very close now in capability and in terms of models trained,\" he said, adding that the whole industry began to up its investment in AI when OpenAI showed ChatGPT could generate revenue.\n\nAs for OpenAI, Tworek said that the sheer toll of the AI race has led the non-profit-research lab-turned-public-benefit-corporation to place less of an emphasis on risky research that may not yield results. A spokesperson for OpenAI did not respond to Business Insider's request for comment.\n\n\"There are multiple aspects of certain things that are just hard to do in a company that has to compete in an extremely, extremely brutal and demanding race for having the best AI model in the world right now,\" he said. \"One dynamic is there is naturally how much willingness of risks companies are willing to take from the perspective of trying to not fall behind.\"\n\nTworek said \"all major AI companies\" are facing pressure to show user growth and pay for GPUs while simultaneously competing to be the best available model.\n\n\"That does affect somehow your appetite for risk that you are willing to take,\" he said.\n\nDo you work at OpenAI or Google? Contact the reporter from a non-work email and device at bgriffiths@businessinsider.com",
    "readingTime": 3,
    "keywords": [
      "openai's missteps",
      "openai",
      "research",
      "model",
      "comeback",
      "fumble",
      "giant",
      "industry",
      "lead",
      "ahead"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/openai-google-ai-race-fumble-gemini-2026-1",
    "thumbnail_url": "https://i.insider.com/69725e9ea645d1188187cf20?width=1200&format=jpeg",
    "created_at": "2026-01-23T12:26:13.658Z",
    "topic": "finance"
  },
  {
    "slug": "the-8-fastestgrowing-jobs-in-new-york-city",
    "title": "The 8 fastest-growing jobs in New York City",
    "description": "LinkedIn analyzed user data to identify the fastest-growing jobs in New York City. AI talent has been in demand.",
    "fullText": "In New York City, the fastest path to a new job probably involves AI.\n\nLinkedIn analyzed about three years' worth of user data to determine how jobs are changing in the US, including in New York City.\n\nAI engineers ranked No. 1 in New York,¬†as they did for the US in general and in most of the nine other cities LinkedIn reviewed. Many of the workers stepping into this and other hot AI roles come from related fields such as software engineering and data science, LinkedIn reported.\n\nWhile artificial intelligence gigs dominated the top spots on the list, consultants of various stripes are also in demand in Gotham.\n\n\"Roles like fundraising consultants and strategic advisors are rising too, signaling that companies are doubling down on strategic, revenue-driving work,\" a LinkedIn News post said.\n\nLinkedIn's snapshot of jobs on the rise in New York comes as unemployment in the nation's largest city remains low compared with its historical average ‚Äî¬†matching the national rate of 4.5% in November.\n\nThe chart below shows the top eight fastest-growing jobs on LinkedIn's new list about the Big Apple.\n\nDemand for AI consultants and strategists ‚Äî¬†which hold the No. 2 spot on both the New York and US lists ‚Äî signals that incorporating AI into the workplace will require people whose expertise isn't solely technical, Laura Lorenzetti, a senior director at LinkedIn, recently told Business Insider, referring to the national list.\n\n\"There is also this whole adjacent system of how you implement AI; how you do culture change around AI; how you get people to really adapt and use it,\" she said.\n\nAdopting AI is something more job seekers ‚Äî¬†especially those who are still early in their careers ‚Äî are confronting, Keith Spencer, a career expert at Resume Now, recently told Business Insider.\n\nHe said that he hears from young professionals that employers expect them to \"intrinsically know how to use AI to make your role more productive and more efficient.\"",
    "readingTime": 2,
    "keywords": [
      "york city",
      "new york",
      "jobs",
      "list",
      "consultants",
      "strategic",
      "linkedin's",
      "recently",
      "linkedin",
      "roles"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/fastest-growing-jobs-new-york-city-linkedin-ai-engineers-researchers-2026-1",
    "thumbnail_url": "https://i.insider.com/697260e9a645d1188187cf50?width=1200&format=jpeg",
    "created_at": "2026-01-23T12:26:13.410Z",
    "topic": "science"
  },
  {
    "slug": "morgan-stanley-says-buy-these-14-stocks-to-play-the-4-themes-that-will-define-markets-in-2026",
    "title": "Morgan Stanley says buy these 14 stocks to play the 4 themes that will define markets in 2026",
    "description": "Morgan Stanley identifies AI adoption, energy trends, societal shifts, and deglobalization as key market drivers in 2026.",
    "fullText": "There are four major themes that will drive markets in 2026, Morgan Stanley says: A multipolar world, technology diffusion, societal shifts, and the future of energy.\n\nLet's get into each, starting with the concept of a multipolar world. For Morgan Stanley, the world is becoming less globalized as governments become more protectionist.\n\n\"It's clear that policymakers globally are implementing policies that will speed up the devolution of the globalization that marked much of the post-Cold War period,\" said Stephen C Byrd, an equity strategist at the bank, in a client note on Thursday. \"Said more simply, policymakers are keen to promote their visions of national and economic security through less open commerce and more local control of supply chains and key technologies.\"\n\nSecond, the bank thinks AI will begin to be adopted more broadly by businesses, helping them boost profits. Stocks will be judged on whether their businesses are incorporating AI enough, MS said.\n\nThird, energy demand has turned a corner thanks to the AI infrastructure buildout. While demand for energy has fallen over the last couple of decades, it's now surging to all-time highs.\n\n\"We expect total US energy consumption to rise 10% over the next decade, reversing decades of declines; by 2030, it should eclipse the prior peak, set in 2007,\" Byrd wrote.\n\nFinally, societal shifts are happening in things like work (thanks to AI), and aging and longevity.\n\n\"We see multiple trends driving broad societal impacts around the world, with effects felt across a surprisingly wide range of industries,\" Byrd wrote. \"The ripple effects of AI-driven employment disruption/evolution, an aging population, changing consumer preferences, the drive for healthy longevity, and challenging demographics across many geographies will continue to matter for governments, economies, and corporates.\"\n\nAs a way to play these trends, the bank highlighted 14 US stocks that its analysts have an \"overweight\" rating on. The stocks are listed below, along with their expected upside to Morgan Stanley's price targets and the theme each stock falls under.\n\nTicker: AMZN\nSector: Consumer Discretionary\nMarket cap: $2.6 trillion\nUpside to price target: 32%\nPrimary theme: Tech Diffusion\n\nTicker: BE\nSector: Industrials\nMarket cap: $3.5 billion\nUpside to price target: 11%\nPrimary theme: Tech Diffusion/Future of Energy\n\nTicker: AVGO\nSector: Information Technology\nMarket cap: $1.6 trillion\nUpside to price target: 35%\nPrimary theme: Tech Diffusion\n\nTicker: CSCO\nSector: Information Technology\nMarket cap: $299.6 billion\nUpside to price target: 21%\nPrimary theme: Tech Diffusion\n\nTicker: LLY\nSector: Health Care\nMarket cap: $928.4 billion\nUpside to price target: 25%\nPrimary theme: Societal Shifts\n\nTicker: EQT\nSector: Energy\nMarket cap: $31.3 billion \nUpside to price target: 38%\nPrimary theme: Future of Energy\n\nTicker: MSFT\nSector: Information Technology\nMarket cap: $3.4 trillion\nUpside to price target: 42%\nPrimary theme: Tech Diffusion\n\nTicker: NEE\nSector: Utilities\nMarket cap: $169.6 billion\nUpside to price target: 16%\nPrimary theme: Tech Diffusion/Future of Energy\n\nTicker: PXED\nSector: Consumer Discretionary\nMarket cap: $1.1 billion\nUpside to price target: 51%\nPrimary theme: Societal Shifts\n\nTicker: ROK\nSector: Industrials\nMarket cap: $47.5 billion\nUpside to price target: 4%\nPrimary theme: Multipolar\n\nTicker: RTX\nSector: Industrials\nMarket cap: $270.9 billion\nUpside to price target: 8%\nPrimary theme: Multipolar\n\nTicker: UNH\nSector: Health Care\nMarket cap: $304.8 billion\nUpside to price target: 21%\nPrimary theme: Societal Shifts\n\nTicker: WMT\nSector: Consumer Staples\nMarket cap: $962.3 billion\nUpside to price target: 13%\nPrimary theme: Tech Diffusion",
    "readingTime": 3,
    "keywords": [
      "health care",
      "consumer discretionary",
      "societal shifts",
      "tech diffusion/future",
      "discretionary market",
      "market cap",
      "target primary",
      "sector industrials",
      "primary theme",
      "technology market"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/stocks-to-buy-investing-themes-ai-energy-morgan-stanley-2026-2026-1",
    "thumbnail_url": "https://i.insider.com/69726e29e1ba468a96aa886b?width=1200&format=jpeg",
    "created_at": "2026-01-23T12:26:13.409Z",
    "topic": "finance"
  },
  {
    "slug": "bond-king-bill-gross-says-the-record-stock-rally-is-at-risk-of-stalling-and-tells-us-what-could-keep-the-party-going",
    "title": "'Bond King' Bill Gross says the record stock rally is at risk of stalling ‚Äî and tells us what could keep the party going",
    "description": "Bill Gross told Business Insider that lower interest rates, proof that AI boosts productivity, and strong earnings growth would help refuel the rally.",
    "fullText": "Bill Gross says the stock market's record rally is at risk of stalling, and fresh support is needed to keep it going.\n\nThere's been a \"little wobbling\" to start the year, signaling the market's in \"need of a cane to steady its momentum,\" the billionaire investor known as the \"Bond King\" wrote in an investment outlook on Wednesday.\n\nThe AI boom has propelled Big Tech stocks to historic highs, fueling a nearly 80% rise in the S&P 500 over the last three years. But the benchmark index has whipsawed this month between a 2.1% gain at its peak and a 0.8% decline at its trough.\n\n\"Lower interest rates would help, as would continued news that AI actually results in higher productivity, and continuing 15% plus earnings gains,\" Gross told Business Insider by email.\n\nGross, who cofounded PIMCO and grew its flagship Total Return Fund to $270 billion over nearly 30 years, wrote in his outlook that stocks are being shored up by rosy earnings forecasts, which are underpinned by fiscal and monetary stimulus.\n\nHe cautioned, however, that US markets could falter as \"political unrest\" threatens to undermine core capitalist principles such as \"competition and survival of the fittest.\"\n\nGross said that even in the AI space, \"tariffs and government aid\" could lead to the \"unfittest\" surviving in future marketplaces.\n\nA major trend of President Donald Trump's second term has been greater executive intervention in the business world. The federal government has taken equity stakes in corporations such as Intel, imposed sweeping tariffs on foreign imports, and thrown its full weight behind AI companies' infrastructure buildout.\n\nGross also warned in his outlook that high valuations are a concern, noting a version of the Buffett Indicator that compares the S&P 500's price to nominal US GDP is at a \"historic high.\"\n\nWarren Buffett's favorite gauge shows \"froth is visible\" in the market as stock prices are rising faster than GDP, Gross told BI.\n\nThe Wall Street veteran wrote in his outlook that \"productivity, tax rates and geopolitical influences can suggest no need for a cane.\" He noted that some market bulls believe AI has changed the game, so they expect \"no wobbling ‚Äî just sprinting.\"\n\n\"But I throw my hat in with the old wizard Warren Buffett,\" Gross wrote. \"Valuation casts a shadow over markets in 2026. No crash, just a forward weave requiring a cane, unlike 2025.\"\n\nOther high-profile investors have flagged lofty valuations as a headwind.\n\n\"Just your daily reminder that stocks are expensive,\" Michael Burry of \"The Big Short\" fame said in a X post last week, adding that high prices depress returns.\n\nGMO cofounder Jeremy Grantham echoed Burry on a recent podcast: \"If you want to have the highest market in history, you will have the lowest returns in history going forward.\"",
    "readingTime": 3,
    "keywords": [
      "outlook",
      "cane",
      "stocks",
      "market",
      "gross",
      "stock",
      "market's",
      "wobbling",
      "historic",
      "nearly"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/bond-king-bill-gross-stock-market-outlook-ai-valuations-government-2026-1",
    "thumbnail_url": "https://i.insider.com/69721289e1ba468a96aa7f10?width=1200&format=jpeg",
    "created_at": "2026-01-23T12:26:13.270Z",
    "topic": "finance"
  },
  {
    "slug": "ai-could-be-an-entrylevel-job-killer-or-gen-zs-ticket-to-advancement",
    "title": "AI could be an entry-level job killer ‚Äî or Gen Z's ticket to advancement",
    "description": "Many young professionals are uneasy about AI automation, but they're leaning into it anyway, new research suggests.",
    "fullText": "As the first cohort to enter the workforce with AI tools at the ready, many Gen Zers are torn.\n\nSome 68% of these young professionals are anxious about AI automation, while 58% use AI tools at least three to four times a week, according to new research from think tank Oliver Wyman Forum. Nearly half of Gen Zers also say AI has already changed the caliber or type of work expected from them.\n\nThe findings, released earlier this week, are based on survey responses from 300,000 consumers and workers collected over the past five years, including 45,000 adult members of Gen Z. The most recent survey was taken last year.\n\nToday's youngest workers are leaning into AI more so than their older counterparts, who are less anxious about the technology and use it less often, the study shows.\n\nCompared with boomers, for example, Gen Zers are 1.7 times more likely to participate in AI training and 2.3 times more likely to report a productivity increase from using AI at work.\n\nYoung workers have good reason to be on high alert. At the World Economic Forum in Davos this week, the CEOs of Google DeepMind and Anthropic each said they're starting to see AI minimize the need for some junior roles at their companies.\n\nAnthropic's chief, Dario Amodei, also said at the conference that he hasn't changed his prediction from May, when he warned that AI could erase half of all entry-level white-collar jobs within the next five years.\n\nMeanwhile, economist Marc Sumerlin said in November that companies may pause hiring young workers as they await the benefits of AI, and that ultimately the technology could lead to fewer jobs for recent graduates. Already, some companies have cited AI directly or indirectly as a reason for layoffs.\n\nThe grim outlook comes as the unemployment rate for recent college graduates in the US remained elevated at 5.3% in the third quarter, according to the latest analysis from the New York Federal Reserve.\n\nSome corporate leaders are more optimistic about AI's impact on Gen Zers' careers.\n\nEarlier this month, Figma CEO Dylan Field said on the podcast \"In Good Company\" that AI skills give young professionals a hiring advantage and that the technology won't wipe out entry-level jobs.\n\nSimilarly, Reid Hoffman, the venture capitalist who cofounded LinkedIn, said in a video posted to his YouTube channel in June that young people should use their familiarity with AI as a selling point when seeking work.\n\nSome Gen Z workers say AI is helping them advance faster in their careers than they likely would have otherwise.\n\nLindsay Grippo, 28, credits the technology for helping her practice big-picture strategic thinking when drafting newsletters, blog posts, and other copy for her editor role at Codeword, a New York-based digital marketing agency. She views the AI's output as if it's from a more junior creative.\n\n\"I'm assessing how well it meets a project's goals, similar to how my manager might review my work,\" she said. \"It is training me to think like a more senior-level creative.\"\n\nKyle Monson, a founding partner at Codeword, said the agency hasn't changed its hiring plans in response to AI, and that young employees like Grippo seem to be among the most proficient users of the technology.\n\nA 46-year-old Gen Xer, Monson sees AI fluency as an advantage for young workers that makes him jealous. When he started his career, he said he had to do a lot of grunt work, such as data entry and note-taking, before he could advance.\n\nAI can now do those kinds of tasks, allowing junior talent to tackle higher-value assignments, which he described as those that require making judgment calls.\n\n\"That's when your career really starts to take off,\" said Monson.",
    "readingTime": 4,
    "keywords": [
      "hasn't changed",
      "gen zers",
      "workers",
      "technology",
      "junior",
      "jobs",
      "hiring",
      "tools",
      "professionals",
      "anxious"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-gen-z-job-killer-or-opportunity-2026-1",
    "thumbnail_url": "https://i.insider.com/69728bc9d3c7faef0eccc4b4?width=1200&format=jpeg",
    "created_at": "2026-01-23T12:26:13.270Z",
    "topic": "finance"
  },
  {
    "slug": "experts-warn-of-threat-to-democracy-from-ai-bot-swarms-infesting-social-media",
    "title": "Experts warn of threat to democracy from ‚ÄòAI bot swarms‚Äô infesting social media",
    "description": "Misinformation technology could be deployed at scale to disrupt 2028 US presidential election, AI researchers say\nPolitical leaders could soon launch swarms of human-imitating AI agents to reshape public opinion in a way that threatens to undermine democracy, a high profile group of experts in AI and online misinformation has warned.\nThe Nobel peace prize-winning free-speech activist Maria Ressa, and leading AI and social science researchers from Berkeley, Harvard, Oxford, Cambridge and Yale are among a global consortium flagging the new ‚Äúdisruptive threat‚Äù posed by hard-to-detect, malicious ‚ÄúAI swarms‚Äù infesting social media and messaging channels.\n Continue reading...",
    "fullText": "Misinformation technology could be deployed at scale to disrupt 2028 US presidential election, AI researchers say\n\nPolitical leaders could soon launch swarms of human-imitating AI agents to reshape public opinion in a way that threatens to undermine democracy, a high profile group of experts in AI and online misinformation has warned.\n\nThe Nobel peace prize-winning free-speech activist Maria Ressa, and leading AI and social science researchers from Berkeley, Harvard, Oxford, Cambridge and Yale are among a global consortium flagging the new ‚Äúdisruptive threat‚Äù posed by hard-to-detect, malicious ‚ÄúAI swarms‚Äù infesting social media and messaging channels.\n\nA would-be autocrat could use such swarms to persuade populations to accept cancelled elections or overturn results, they said, amid predictions the technology could be deployed at scale by the time of the US presidential election in 2028.\n\nThe warnings, published today in Science, come alongside calls for coordinated global action to counter the risk, including ‚Äúswarm scanners‚Äù and watermarked content to counter AI-run misinformation campaigns. Early versions of AI-powered influence operations have been used in the 2024 elections in Taiwan, India and Indonesia.\n\n‚ÄúA disruptive threat is emerging: swarms of collaborative, malicious AI agents,‚Äù the authors said. ‚ÄúThese systems are capable of coordinating autonomously, infiltrating communities and fabricating consensus efficiently. By adaptively mimicking human social dynamics, they threaten democracy.‚Äù\n\nOne leading expert in propaganda technology, Inga Trauthig, said the adoption of such advanced technology is likely to be slowed by politicians‚Äô reluctance to cede campaign control to AIs. Another cause for skepticism is concern that using such illicit techniques would not be worth the risk, given voters are still more influenced by offline material.\n\nThe experts behind the warning include New York University‚Äôs Gary Marcus, a prominent sceptic about the claimed potential of current AI models who calls himself a ‚Äúgenerative AI realist‚Äù, and Audrey Tang, Taiwan‚Äôs first digital minister, who has warned: ‚ÄúThose in the pay of authoritarian forces are undermining electoral processes, weaponizing AI and employing our societal strengths against us.‚Äù\n\nOthers include David Garcia, professor for social and behavioural data science at the University of Konstanz, Sander van der Linden, a misinformation expert and director of Cambridge University‚Äôs social decision-making lab, and Christopher Summerfield, AI researcher and professor of cognitive neuroscience at Oxford University.\n\nTogether they say political leaders could deploy almost limitless numbers of AIs to masquerade as humans online and precisely infiltrate communities, learn their foibles over time and use increasingly convincing and carefully tailored falsehoods, to change population-wide opinions.\n\nThe threat is being supercharged by advances in AIs‚Äô ability to pick up on the tone and content of discourse. They are increasingly able to mimic human dynamics, for example, by using appropriate slang and posting irregularly to avoid detection. Progress in the development of ‚Äúagentic‚Äù AI also means the ability to autonomously plan and coordinate action.\n\nAs well as operating across social media, they may use messaging channels and even write blogs or use email, depending on which channel the AI thinks best helps achieve an aim, said one of the authors, Daniel Thilo Schroeder, a research scientist at the Sintef research institute in Oslo.\n\n‚ÄúIt‚Äôs just frightening how easy these things are to vibe code and just have small bot armies that can actually navigate online social media platforms and email and use these tools,‚Äù said Schroeder, who has been simulating swarms in laboratory conditions.\n\nAnother of the authors, Jonas Kunst, professor of communication at the BI Norwegian Business School, said: ‚ÄúIf these bots start to evolve into a collective and exchange information to solve a problem ‚Äì in this case a malicious goal, namely analysing a community and finding a weak spot ‚Äì then coordination will increase their accuracy and efficiency.\n\n‚ÄúThat is a really serious threat that we predict is going to materialise.‚Äù\n\nIn Taiwan, where voters are regularly targeted by Chinese propaganda, often unknowingly, AI bots have been increasing engagement with citizens on Threads and Facebook in the last two to three months, said Puma Shen, a Taiwanese Democratic Progressive Party MP and campaigner against Chinese disinformation.\n\nDuring discussions on political topics the AIs tend to provide ‚Äútonnes of information that you cannot verify‚Äù, creating ‚Äúinformation overload‚Äù, Shen said. He said AIs might cite fake articles about how America will abandon Taiwan. Another recent trend is for the AI bots to stress to younger Taiwanese people that the China-Taiwan dispute is very complicated ‚Äúso do not take sides if you have no knowledge‚Äù.\n\n‚ÄúIt‚Äôs not telling you that China‚Äôs great, but it‚Äôs [encouraging them] to be neutral,‚Äù Shen told the Guardian. ‚ÄúThis is very dangerous, because then you think people like me are radical.‚Äù\n\nAmid signs the progress of AI technology is not as rapid as Silicon Valley companies like OpenAI and Anthropic have claimed, the Guardian asked independent AI experts to assess the swarm warnings.\n\n‚ÄúIn the election-heavy year of 2024 the capabilities were there for AI-driven microtargeting but we didn‚Äôt see as much of that as scholars predicted,‚Äù said Trauthig, an adviser to the International Panel on the Information Environment. ‚ÄúMost political propagandists I interview are still using older technologies and are not at this cutting edge.‚Äù\n\n‚ÄúIt isn‚Äôt fanciful,‚Äù said Michael Wooldridge, professor of the foundations of AI at Oxford University. ‚ÄúI think it is entirely plausible that bad actors will try to mobilise virtual armies of LLM-powered agents to disrupt elections and manipulate public opinion, for example targeting large numbers of individuals on social media and other electronic media. It‚Äôs technologically perfectly feasible ‚Ä¶ the technology has got progressively better and much more accessible.‚Äù\n\nThe best public interest journalism relies on first-hand accounts from people in the know.\n\nIf you have something to share on this subject, you can contact us confidentially using the following methods.\n\nSecure Messaging in the Guardian app\n\nThe Guardian app has a tool to send tips about stories. Messages are end to end encrypted and concealed within the routine activity that every Guardian mobile app performs. This prevents an observer from knowing that you are communicating with us at all, let alone what is being said.\n\nIf you don't already have the Guardian app, download it (iOS/Android) and go to the menu. Select ‚ÄòSecure Messaging‚Äô.\n\nSecureDrop, instant messengers, email, telephone and post\n\nIf you can safely use the Tor network without being observed or monitored, you can send messages and documents to the Guardian via our SecureDrop platform.\n\nFinally, our guide at theguardian.com/tips¬†lists several ways to contact us securely, and discusses the pros and cons of each.",
    "readingTime": 6,
    "keywords": [
      "guardian app",
      "presidential election",
      "say political",
      "political leaders",
      "disruptive threat",
      "messaging channels",
      "social media",
      "technology",
      "swarms",
      "misinformation"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/22/experts-warn-of-threat-to-democracy-by-ai-bot-swarms-infesting-social-media",
    "thumbnail_url": "https://i.guim.co.uk/img/media/c11e532da1ffe144863064e216ce631a316b6e68/313_0_5149_4120/master/5149.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=a3bc91f29cc15d1a31a0ac07a4825178",
    "created_at": "2026-01-23T12:26:13.151Z",
    "topic": "tech"
  },
  {
    "slug": "im-picking-winners-uk-business-secretary-takes-activist-approach-to-economic-growth",
    "title": "‚ÄòI‚Äôm picking winners‚Äô: UK business secretary takes activist approach to economic growth",
    "description": "AI evangelist Peter Kyle wants to scale up businesses, attract overseas investors and look out for UK‚Äôs poorer regions\nThe UK business secretary, Peter Kyle, has said he is ‚Äúbetting big‚Äù and ‚Äúpicking winners‚Äù as the government takes direct stakes in growing businesses to boost economic growth.\nSpeaking at the World Economic Forum in Davos, where he and the chancellor, Rachel Reeves, have been talking up Britain‚Äôs prospects, Kyle said ministers were taking an ‚Äúactivist‚Äù approach to industrial policy.\n Continue reading...",
    "fullText": "AI evangelist Peter Kyle wants to scale up businesses, attract overseas investors and look out for UK‚Äôs poorer regions\n\nThe UK business secretary, Peter Kyle, has said he is ‚Äúbetting big‚Äù and ‚Äúpicking winners‚Äù as the government takes direct stakes in growing businesses to boost economic growth.\n\nSpeaking at the World Economic Forum in Davos, where he and the chancellor, Rachel Reeves, have been talking up Britain‚Äôs prospects, Kyle said ministers were taking an ‚Äúactivist‚Äù approach to industrial policy.\n\nThe idea of ‚Äúpicking winners‚Äù is closely associated with the Conservative prime minister Margaret Thatcher‚Äôs attacks on Labour‚Äôs 1970s strategy and her argument that it should be the private sector that decides which companies thrive.\n\nKyle was unabashed about invoking the phrase, arguing a muscular approach could accelerate economic growth. ‚ÄúI want to make sure that the benefits of growth are felt quicker than is currently the case. We‚Äôre predicted to grow 1.5% this year. That is not enough.‚Äù\n\nHe highlighted the recent decision to allow the ¬£26bn state-owned British Business Bank to buy equity stakes in companies, including the announcement last week of a ¬£25m investment in the energy supplier Octopus‚Äôs software spin-off, Kraken.\n\n‚ÄúThe most potential in our economy, in the short and medium term, is scale-up companies,‚Äù Kyle said. ‚ÄúI was at Octopus yesterday. They‚Äôre now employing 1,500 people in their head office in London alone.\n\n‚ÄúWe can find other companies that are on that kind of trajectory and we can expedite their growth. Then it will create thousands of new jobs, and it will create enormous amounts of wealth, which will recycle through the economy in a really fast way.‚Äù\n\n‚ÄúI am betting big. And I am picking winners,‚Äù he added. ‚ÄúIt‚Äôs more activist. And there will be things that don‚Äôt work out, sure. But to have a healthy economy, failure leads to success.‚Äù\n\nThis week‚Äôs summit in the Swiss ski resort has been overshadowed by Donald Trump‚Äôs threat to slap tariffs on eight European countries if they stood in the way of his hopes of annexing Greenland.\n\nThe president backed away from the idea of punitive import taxes on Wednesday evening, after discussions with the secretary general of Nato, Mark Rutte, but several leaders in the Swiss ski resort have said the global economic order has irrevocably changed.\n\nKyle insisted international uncertainty was no reason not to press ahead with Labour‚Äôs agenda, highlighting the prospects of a ‚Äúwave of opportunity that technology and life sciences and all these huge, huge, positive waves of innovation are going to present to us‚Äù.\n\nHe said: ‚ÄúIf we are too intimidated by the global challenges, if we are too distracted by domestic political to and fro, then we will take our eye off the ball, and we will miss the opportunity of a lifetime, and that means real things to real people.\n\n‚ÄúThere will be kids growing up like me that will not end up becoming successful like I have. It‚Äôll be communities that, at the moment, are poor, and they will never have a hope of becoming prosperous. And I won‚Äôt stand for it. I would literally do anything. And if that means betting [on] winners, and getting it wrong from time to time, I‚Äôll take it.‚Äù\n\nAnnouncing the beefing up of the government‚Äôs ‚Äúglobal talent taskforce‚Äù in his department, the business secretary suggested that the UK hoped to capitalise on the instability unleashed by Trump‚Äôs policies to help it attract jobs and investment.\n\n‚ÄúI will suck the best talent in from wherever it exists, and talent goes both ways across the Atlantic. And I want to make sure that we have a good balance in that because for too long it‚Äôs been in one direction,‚Äù he said.\n\nHighlighting the need to attract innovators in particular, Kyle added: ‚ÄúAmerica is being disruptive with tariffs, but America isn‚Äôt the most friendly place for scientific endeavour in any case at the moment. Do the maths and add up where we‚Äôre going with this. We are going out there and we‚Äôre saying: ‚ÄòActually, we have one of the best regulatory environments in the world for life sciences, and across the board.‚Äô‚Äù\n\nKeir Starmer has taken a tough line on migration ‚Äì despite pushback from some quarters in the party ‚Äì promising to reduce it and condemning Boris Johnson‚Äôs administration for what the prime minister has called an ‚Äúopen borders experiment‚Äù.\n\nBut Kyle said he did not think public scepticism about migration extended to wealthy entrepreneurs. ‚ÄúPeople are deeply concerned about the immigration system we inherited, and the asylum system, which was overwhelmed, and was poorly administered by the Tories, and therefore broken,‚Äù he said.\n\n‚ÄúI‚Äôve never had anybody that says that people with a lot of money to invest in our country, who want to come here and create jobs, create businesses, shouldn‚Äôt be coming to do so.‚Äù\n\nHe added: ‚ÄúI have a taskforce that‚Äôs doing this, embedded in our global network. We can offer the world‚Äôs most talented a bespoke package to come to the UK swiftly, to embed, and then, of course, be part of a funding landscape that is bountiful.‚Äù\n\nThe 55-year-old MP for Hove and Portslade has been business secretary since Starmer‚Äôs September reshuffle, replacing Jonathan Reynolds, who had done the job for several years in opposition.\n\nKyle is politically close to the health secretary, Wes Streeting ‚Äì who has been repeatedly mooted as a potential challenger to Starmer ‚Äì but has been scrupulously loyal to the prime minister in public.\n\nEarlier this week, the business secretary rejected the suggestion that the UK try to negotiate a customs union with the EU, for which Streeting has signalled his support, telling the FT: ‚ÄúI think at the moment it would be foolish to slip towards what would be simple solutions.‚Äù\n\nKyle has dyslexia and left his state school ‚Äúwithout any usable‚Äù qualifications, as he has put it. He made his way to university aged 25, and went on to secure a PhD, then worked in the charity sector before entering politics.\n\nIn his previous job of technology secretary, he was forced to defend his closeness to powerful tech companies. He is a regular user of the chatbot ChatGPT and an evangelist for the opportunities offered by the technology ‚Äì and is often seen in the casual garb favoured by ‚Äútech bros‚Äù.\n\nSoon after taking on his current role, Kyle struck a deal with business groups and trade unions to water down the implementation of Labour‚Äôs Employment Rights Act, introducing a six-month probation period before the promised ‚Äúday-tone rights‚Äù come into force.\n\nHe has continued to work closely with his successor and friend, Liz Kendall, and said he has insisted the connecting door that blocked the corridor between their two offices be opened up.\n\nAsked whether AI would cause mass layoffs as companies decide they can manage without entry-level staff ‚Äì a hot topic at Davos ‚Äì Kyle said: ‚ÄúPeople are anxious and it‚Äôs going to be painful and difficult because change is always painful and difficult.‚Äù\n\nKyle said Labour was ready to intervene to ensure the adoption of AI was less painful for poorer communities than the deindustrialisation of the 1980s, which cast a long shadow.\n\nHe said: ‚ÄúWaves of industrial change have always gone badly when governments stand on the sidelines and are not participants. And I will not allow that to happen.\n\n‚ÄúAs tech secretary I was negotiating deals for investment in digital infrastructure, insisting it happened in poorer parts of the country. I‚Äôm the gatekeeper into our country for a lot of investors. And if they want to come and benefit from our country, then they can contribute to it as well.‚Äù",
    "readingTime": 7,
    "keywords": [
      "swiss ski",
      "ski resort",
      "life sciences",
      "prime minister",
      "picking winners",
      "economic growth",
      "business secretary",
      "peter kyle",
      "create",
      "businesses"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/business/2026/jan/23/peter-kyle-uk-business-secretary-activist-approach-economic-growth",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0b73b15a683725bccb4637d0af048d76299049ca/112_0_4583_3667/master/4583.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=eba0a735bf5ba34744e706aab19116fd",
    "created_at": "2026-01-23T12:26:13.135Z",
    "topic": "business"
  },
  {
    "slug": "amazon-planning-job-cuts-next-week-after-axing-14000-due-to-ai-report",
    "title": "Amazon planning job cuts next week after axing 14,000 due to AI: report",
    "description": "The company in October cut some 14,000 white-collar jobs, about half of the 30,000 target first¬†reported by Reuters.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://nypost.com/2026/01/22/business/amazon-planning-thousands-of-job-cuts-next-week-after-axing-14000-due-to-ai-report/",
    "thumbnail_url": "https://nypost.com/wp-content/uploads/sites/2/2026/01/amazon-andy-jassy.jpg?quality=75&strip=all&1769107242&w=1200",
    "created_at": "2026-01-23T06:20:33.494Z",
    "topic": "business"
  },
  {
    "slug": "why-external-ai-reasoning-breaks-articles-12-and-61-by-default",
    "title": "Why External AI Reasoning Breaks Articles 12 and 61 by Default",
    "description": "External AI reasoning already influences regulated decisions. Why Article 12 record-keeping and Article 61 monitoring fail without an evidence layer.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.aivojournal.org/why-external-ai-reasoning-breaks-articles-12-and-61-by-default/",
    "thumbnail_url": "https://www.aivojournal.org/content/images/size/w1200/2026/01/ChatGPT-Image-Jan-23--2026-at-06_49_26-AM.png",
    "created_at": "2026-01-23T06:20:32.327Z",
    "topic": "tech"
  },
  {
    "slug": "vibe-coding-kills-open-source",
    "title": "Vibe Coding Kills Open Source",
    "description": "Generative AI is changing how software is produced and used. In vibe coding, an AI agent builds software by selecting and assembling open-source software (OSS), often without users directly reading documentation, reporting bugs, or otherwise engaging with maintainers. We study the equilibrium effects of vibe coding on the OSS ecosystem. We develop a model with endogenous entry and heterogeneous project quality in which OSS is a scalable input into producing more software. Users choose whether to use OSS directly or through vibe coding.",
    "fullText": "arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.",
    "readingTime": 1,
    "keywords": [
      "arxivlabs",
      "arxiv",
      "community"
    ],
    "qualityScore": 0.4,
    "link": "https://arxiv.org/abs/2601.15494",
    "thumbnail_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png",
    "created_at": "2026-01-23T06:20:32.202Z",
    "topic": "tech"
  },
  {
    "slug": "openai-is-making-more-than-1-billion-a-month-from-something-that-has-nothing-to-do-with-chatgpt",
    "title": "OpenAI is making more than $1 billion a month from something that has nothing to do with ChatGPT",
    "description": "Sam Altman says OpenAI added more than $1 billion in annual recurring revenue in a month, driven by its API business rather than ChatGPT.",
    "fullText": "OpenAI has pulled in a billion-dollar month from something other than ChatGPT.\n\nSam Altman said in a post on X on Thursday that OpenAI added more than $1 billion in annual recurring revenue in the past month \"just from our API business.\"\n\n\"People think of us mostly as ChatGPT, but the API team is doing amazing work!\" the OpenAI CEO wrote.\n\nOpenAI's API enables other companies and developers to embed its models into their own products, from internal productivity software to coding tools.\n\nMany of Silicon Valley's high-profile startups rely on OpenAI's models as core infrastructure. Perplexity uses OpenAI's models to power parts of its AI search and answer engine. Harvey, one of the fastest-growing legal tech startups, is built on OpenAI's models to assist lawyers with research and drafting.\n\nAltman's comments underscore how OpenAI's infrastructure business is emerging as a key growth engine, even as the company faces massive costs for computing power and data centers.\n\nThose pressures have pushed OpenAI to look beyond consumer subscriptions.\n\nLast week, the company said it is gearing up to test ads inside ChatGPT as it faces about $1.4 trillion in spending commitments over the coming years.\n\nIt's a notable shift for a company that once treated ads as taboo. Less than two years ago, Altman said advertising was a \"last resort.\"\n\n\"Ads plus AI is sort of uniquely unsettling to me,\" Altman said during an event at Harvard University in May 2024. \"I kind of think of ads as a last resort for us for a business model.\"\n\nSince then, Altman has struck a more open tone. In June, he said on OpenAI's podcast that he wasn't \"totally against\" ads, though he stressed it would need to be approached carefully.\n\nEarlier this week, OpenAI's chief financial officer, Sarah Friar, raised the idea of \"licensing models\" that would let the company share in downstream sales if a customer's product succeeds.\n\n\"Let's say in drug discovery, if we licensed our technology, you have a breakthrough. The drug takes off, and we get a licensed portion of all its sales,\" Friar said in an episode of \"The OpenAI Podcast\" published Monday.",
    "readingTime": 2,
    "keywords": [
      "openai's models",
      "business",
      "startups",
      "infrastructure",
      "engine",
      "faces",
      "resort",
      "sales",
      "drug",
      "licensed"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-1-billion-a-month-api-business-chatgpt-sam-altman-2026-1",
    "thumbnail_url": "https://i.insider.com/6972e427e1ba468a96aa91d7?width=800&format=jpeg",
    "created_at": "2026-01-23T06:20:31.103Z",
    "topic": "finance"
  },
  {
    "slug": "what-will-tech-jobs-look-like-in-2026",
    "title": "What will tech jobs look like in 2026?",
    "description": "Here‚Äôs a roundup of research and predictions for tech workers amid the AI revolution.",
    "fullText": "The tech job market in 2026 is being built on contradictions.\n\nCompanies are laying off staff, insisting artificial intelligence will ‚Äúdo more with less‚Äù ‚Äî yet they haven‚Äôt found ways to deploy AI at scale. Recruiters say entry-level pathways are narrowing, but critical roles remain hard to fill.\n\nEven as headlines scream ‚Äúautomation,‚Äù the day-to-day reality is messier: Hybrid work is still a dealbreaker, job titles are splintering into new specialties, and workers are being asked to produce more output with fewer resources.\n\nRest of World reviewed recent research on tech job trends in 2026\n\nDeloitte‚Äôs 2025 Emerging Technology Trends study noted that while 30% of surveyed organizations are exploring agentic options and 38% are piloting solutions, only 14% have solutions that are ready to be deployed. A mere 11% are actively using these systems in production. Furthermore, 42% of organizations report they are still developing their agentic strategy road map, with 35% having no formal strategy at all.\n\nWhile most human workers are generally comfortable with predictable, rule-based robots, physical AI systems that learn and adapt introduce new uncertainties, especially worries about job displacement. Experts predict, however, that most roles will evolve toward collaboration rather than replacement.\n\nThe goal is to create environments where robots handle repetitive or dangerous tasks while humans focus on creative problem-solving and complex decision-making.\n\nThe best workers want hybrid or remote roles. Yet more companies are demanding full-time in-office attendance. It‚Äôs not making hiring any easier.\n\nThe battle lines have been drawn. Companies are demanding people return to the office full-time while workers dig in their heels, insisting they want remote or hybrid work options.\n\nCompanies are demanding people return to office while workers dig in their heels‚Äù\n\nAccording to the Korn Ferry report, 52% of talent acquisition leaders say office mandates hinder recruitment, while 72% find remote roles easier to fill.\n\nBusiness leaders might think this is fine right now, but in roles with chronic skills shortages, it‚Äôll rapidly be clear that it‚Äôs not fine at all.\n\nIf your employer brand isn‚Äôt strong enough to overcome the office requirement, you‚Äôll end up paying premium salaries to attract people who would otherwise work elsewhere. Or worse, you‚Äôll just be filling seats ‚Äî settling for whoever is willing to show up, not the talent who will move your business forward.\n\nTech recruitment platform Built In\n\nAs companies seek specialists, the emergence of new roles with novel job titles and nuanced skill requirements will be a feature of 2026. As the economy picks up steam, companies will narrow their focus and drift away from broad-spectrum roles with catch-all titles like ‚Äúsoftware engineer‚Äù and ‚Äúdata scientist‚Äù toward more tailored, task-specific job titles.\n\nNavigating the future of work in tech this year will involve companies focused more at the intersection of AI-workflow integration, governance, and impact.",
    "readingTime": 3,
    "keywords": [
      "workers dig",
      "job titles",
      "remote roles",
      "tech job",
      "hybrid",
      "demanding",
      "insisting",
      "fill",
      "organizations",
      "agentic"
    ],
    "qualityScore": 1,
    "link": "https://restofworld.org/2026/tech-jobs-2026-ai-layoffs-hybrid-work/",
    "thumbnail_url": "https://restofworld.org/wp-content/uploads/2026/01/TechJobs-Header-2.jpg",
    "created_at": "2026-01-23T06:20:30.799Z",
    "topic": "tech"
  },
  {
    "slug": "stocks-climb-after-strong-data-as-ai-winners-smallcaps-lead",
    "title": "Stocks Climb After Strong Data as AI Winners, Small-Caps Lead",
    "description": "US stocks clawed back most of this week‚Äôs losses with the strongest two-day run in two months after data signaling a resilient economy, President Donald Trump‚Äôs retreat on tariff threats and artificial intelligence updates whetted traders‚Äô appetite for risky bets.",
    "fullText": "MarketsBy Natalia KniazhevichSaveUS stocks clawed back most of this week‚Äôs losses with the strongest two-day run in two months after data signaling a resilient economy, President Donald Trump‚Äôs retreat on tariff threats and artificial intelligence updates whetted traders‚Äô appetite for risky bets.The S&P 500 rose 0.6%. The Nasdaq 100 gained 0.8% as chipmakers and AI-linked names led market gains. The Russell 2000 Index rose 0.8%, outperforming the broader benchmark a 14th straight session, the longest stretch of wins since May 1996. Intel Corp. shares fell around 5% in late trading after a disappointing sales forecast, the stock had climbed 47% since the start of the month.",
    "readingTime": 1,
    "keywords": [
      "rose"
    ],
    "qualityScore": 0.45,
    "link": "https://www.bloomberg.com/news/articles/2026-01-22/stocks-buoyed-by-ai-winners-data-as-geopolitical-risks-fade",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iQ.2ZkT2N5nY/v0/1200x800.jpg",
    "created_at": "2026-01-23T00:59:23.258Z",
    "topic": "finance"
  },
  {
    "slug": "chinas-ai-stocks-with-killer-apps-are-winning-investor-favor",
    "title": "China‚Äôs AI Stocks With Killer Apps are Winning Investor Favor",
    "description": "As China‚Äôs homegrown artificial intelligence boom enters its second year, investors are piling into shares of companies with killer apps in a hunt for earnings that justify surging valuations.",
    "fullText": "MarketsTechnologyBy Jeanny YuSaveAs China‚Äôs homegrown artificial intelligence boom enters its second year, investors are piling into shares of companies with killer apps in a hunt for earnings that justify surging valuations. Kuaishou Technology has seen its stock climb 24% so far this year as its AI video-generation tool Kling gains traction with global users. Alibaba Health Information Technology Ltd. shares have surged 33%, helped by enthusiasm for its AI offerings including a new chatbot aimed at helping doctors diagnose patients.",
    "readingTime": 1,
    "keywords": [
      "shares",
      "technology"
    ],
    "qualityScore": 0.35,
    "link": "https://www.bloomberg.com/news/articles/2026-01-22/china-s-ai-stocks-with-killer-apps-are-winning-investor-favor",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iLtpy8gcvgBQ/v0/1200x800.jpg",
    "created_at": "2026-01-23T00:59:21.808Z",
    "topic": "finance"
  },
  {
    "slug": "meet-the-alaska-student-arrested-for-eating-an-ai-art-exhibit",
    "title": "Meet the Alaska Student Arrested for Eating an AI Art Exhibit",
    "description": "Colin...",
    "fullText": "Europe‚Äôs governing soccer body saves a pitch in the West Bank‚Äîbut is it only because the Swiss Parliament is threatening to pull its tax exemption over its inclusion of Israel?\n\nA Martin Luther King Jr. Day sermon by the Rev. Canon Dr. Kelly Brown Douglas.\n\nMourning for Renee Nicole Good, the singer decried the Trump administration and the threat to freedom posed by ‚Äúheavily armed masked federal troops invading an American city.‚Äù\n\nA new history explores the political limits as well as possibilities of freedom of speech.\n\nBooks & the Arts\n\n /\n\n David Cole\n\nParents‚Äô-rights crusaders seeking to impose their Christian nationalist vision on the United States took their playbook from South America.\n\nFeature\n\n /\n\n Elle Hardy\n\nThe white college student supported Black voters in segregated Alabama, and began documenting the front lines of the voting rights fight, which locals continue to disregard.\n\nQ&A\n\n /\n\n Alexandra Marvar",
    "readingTime": 1,
    "keywords": [
      "freedom"
    ],
    "qualityScore": 0.65,
    "link": "https://www.thenation.com/article/society/alaska-student-arrested-eating-ai-art-exhibit/",
    "thumbnail_url": "https://www.thenation.com/wp-content/uploads/2026/01/AI-Art.jpg",
    "created_at": "2026-01-23T00:59:17.607Z",
    "topic": "politic"
  },
  {
    "slug": "elon-musk-warns-the-us-could-soon-be-producing-more-chips-than-we-can-turn-on-and-china-doesnt-have-the-same-issue",
    "title": "Elon Musk warns the U.S. could soon be producing more chips than we can turn on. And China doesn‚Äôt have the same issue",
    "description": "‚ÄúThe limiting factor for AI deployment is fundamentally electrical power,‚Äù Musk said at the World Economic Forum on Thursday.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/01/22/elon-musk-ai-data-center-chips-electrical-power-china-world-economic-forum/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/01/GettyImages-2256969963-e1769101573582.jpg?resize=1200,600",
    "created_at": "2026-01-23T00:59:16.393Z",
    "topic": "business"
  },
  {
    "slug": "elon-musk-on-greenland-ai-in-space-and-the-future-of-robots",
    "title": "Elon Musk on Greenland, AI in space and the future of robots",
    "description": "Elon Musk made his first-ever appearance at Davos where he joked about Greenland, and discussed the future of AI and humanoid robots.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.businessinsider.com/musk-on-greenland-ai-in-space-and-future-of-robots-2026-1",
    "thumbnail_url": "https://i.insider.com/6972846cd3c7faef0eccc398?width=1200&format=jpeg",
    "created_at": "2026-01-23T00:59:15.725Z",
    "topic": "finance"
  },
  {
    "slug": "kona-energybased-models-ebms-for-ai-reasoning",
    "title": "Kona: Energy-Based Models (EBMs) for AI Reasoning",
    "description": "Kona delivers AI reasoning via Energy-Based Models (EBMs). It provides deterministic, verifiable intelligence for critical systems‚Äîa fundamental shift from probabilistic LLMs.",
    "fullText": "Kona is Logical Intelligence‚Äôs core Energy-Based Model and the foundation of everything we build. It is not a chatbot, assistant, or generator. Language models are good at interaction and expression. They help people ask questions and explore ideas. But when software controls physical assets or financial risk, something else has to decide what actions are allowed before they happen.\n\nLogical Intelligence builds that layer.\n\nKona is a reasoning system designed to sit beneath modern AI stacks, evaluating what is valid, safe, and permissible across all possible states of a system. It does not predict likely outcomes. It enforces constraints. It replaces trust with proof and makes certification, audit, and deployment possible where failure is not an option.\n\nAleph delivers verified reasoning today. Kona turns that capability into a full-scale reasoning engine for the next generation of infrastructure, automation, and autonomous systems.\n\nKona 1.0 is Logical Intelligence‚Äôs core Energy‚ÄëBased Model and the foundation of everything we build. It is not a chatbot, assistant, or generator. Language models are good at interaction and expression. They help people ask questions and explore ideas. But when software controls physical assets or financial risk, something else has to decide what actions are allowed before they happen.\n\nKona is a reasoning system designed to sit beneath modern AI stacks, evaluating what is valid, safe, and permissible across all possible states of a system. It does not predict likely outcomes. It enforces constraints. It replaces trust with proof and makes certification, audit, and deployment possible where failure is not an option.\n\nAleph delivers verified reasoning today. Kona turns that capability into a full-scale reasoning engine for the next generation of infrastructure, automation, and autonomous systems.",
    "readingTime": 2,
    "keywords": [
      "intelligence‚Äôs core",
      "generator language",
      "language models",
      "option aleph",
      "aleph delivers",
      "chatbot assistant",
      "explore ideas",
      "software controls",
      "controls physical",
      "physical assets"
    ],
    "qualityScore": 0.95,
    "link": "https://logicalintelligence.com/kona-ebms-energy-based-models",
    "thumbnail_url": "https://framerusercontent.com/assets/9Vg7VFZj56wZ6SmCOwhJtsg.png",
    "created_at": "2026-01-23T00:59:15.314Z",
    "topic": "tech"
  },
  {
    "slug": "this-script-removes-the-ai-features-from-chrome-edge-and-firefox",
    "title": "This Script Removes the AI Features From Chrome, Edge, and Firefox",
    "description": "This script disables AI and other annoyances in all major browsers.",
    "fullText": "Tech companies are getting increasingly pushy with their large language models‚Äîprominent buttons for these AI features coat every surface designers can think of, including in three of the most prominent browsers: Chrome, Edge, and Firefox.\n\nIf you want these AI features to go away, and stay away, there's a script for that. JustTheBrowser is a free and open source tool from developer and tech blogger Corbin Davenport that removes AI features, telemetry data reporting, sponsored content, product integrations, and other annoyances from Chrome, Firefox, and Microsoft Edge. Basically, you can run this once and never think about these features again.\n\nTo get started, head to the JustTheBrowser homepage. There are scripts to copy (which I'm not going to include here in case they change in the future).\n\nWindows users will need to run PowerShell as an admin‚Äîthe easiest way to do that is by right-clicking PowerShell in the start menu and clicking \"Run as administrator.\" There is a different script for Mac and Linux users‚Äîthat one just needs to be copied into a regular Terminal.\n\nEither way, you will be asked which browser you'd like to update the settings for‚Äîjust hit the number corresponding to what you want to do.\n\nIn my testing, the process was very simple on Windows‚Äîjust click the number and the script will do its thing. On macOS, I needed to follow a few instructions to enable a configuration policy in the Settings app, something that only took a couple of clicks. After that, Chrome was free of any and all references to AI.\n\nA number of other features were also gone, including those annoying prompts to switch my default browser.\n\nThe way this works is kind of interesting: it uses features intended for large organizations. Basically all major browsers allow for group settings, which is how IT departments control what you can and can't do with your browser. Among these settings are ones to disable AI features.\n\nIt's an interesting workaround, and hopefully one that keeps working. There is always a chance that browser companies make it so even IT departments can't disable AI features, at which point we'll all need to find a new solution (or switch to an alternative browser).",
    "readingTime": 2,
    "keywords": [
      "features",
      "browser",
      "settings",
      "chrome",
      "script",
      "tech",
      "browsers",
      "edge",
      "firefox",
      "away"
    ],
    "qualityScore": 0.9,
    "link": "https://lifehacker.com/tech/script-removes-ai-features-from-chrome-edge-firefox?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KFKGXVMPEQY0K2EQ8ZCJG6WD/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-23T00:59:14.346Z",
    "topic": "tech"
  },
  {
    "slug": "scarlett-johansson-and-cate-blanchett-back-campaign-accusing-ai-firms-of-theft",
    "title": "Scarlett Johansson and Cate Blanchett back campaign accusing AI firms of theft",
    "description": "Hundreds of writers, musicians and performers urge licensing deals instead of scraping creative work\nScarlett Johansson, Cate Blanchett, REM and Jodi Picoult are among hundreds of Hollywood stars, musicians and authors backing a new campaign accusing AI companies of ‚Äútheft‚Äù of their work.\nThe ‚ÄúStealing Isn‚Äôt Innovation‚Äù drive launched on Thursday with the support of approximately 800 creative professionals and bands. The campaign includes a statement accusing tech firms of using American creators‚Äô work to ‚Äúbuild AI platforms without authorisation or regard for copyright law‚Äù.\n Continue reading...",
    "fullText": "Hundreds of writers, musicians and performers urge licensing deals instead of scraping creative work\n\nScarlett Johansson, Cate Blanchett, REM and Jodi Picoult are among hundreds of Hollywood stars, musicians and authors backing a new campaign accusing AI companies of ‚Äútheft‚Äù of their work.\n\nThe ‚ÄúStealing Isn‚Äôt Innovation‚Äù drive launched on Thursday with the support of approximately 800 creative professionals and bands. The campaign includes a statement accusing tech firms of using American creators‚Äô work to ‚Äúbuild AI platforms without authorisation or regard for copyright law‚Äù.\n\nIt adds: ‚ÄúArtists, writers, and creators of all kinds are banding together with a simple message: Stealing our work is not innovation. It‚Äôs not progress. It‚Äôs theft ‚Äì plain and simple.‚Äù\n\nThe statement urges AI companies to pursue licensing deals and partnerships with the creative industries and acknowledges firms that have taken that route. OpenAI, the developer of ChatGPT, has signed deals with content owners including Disney and the Guardian, while Warner Music Group has struck a licensing deal with AI music generator Suno.\n\nHowever, copyright remains one of the most contentious issues within AI, because the models that power chatbots like ChatGPT or image generators like Grok Imagine rely on vast amounts of data taken from the open web in order to help create their responses. Creative professionals argue that tech firms should seek their permission before using such material ‚Äì and that they should receive a payment if they give their consent.\n\nOpenAI, and other AI firms, have argued that using material available online is ‚Äúfair use‚Äù, a US legal doctrine that allows use of copyright-protected work without the owner‚Äôs permission in certain circumstances. As of last year, dozens of lawsuits had been launched in the US over the AI and copyright issue.\n\nJohansson was dragged into the AI debate in 2024 after OpenAI‚Äôs voice assistant used her vocal likeness, prompting the actor say she was ‚Äúshocked, angered and in disbelief‚Äù by the move. OpenAI subsequently removed the voice from ChatGPT.\n\nOther signatories to the statement include actor Joseph Gordon-Levitt, Breaking Bad creator Vince Gilligan and singer Cyndi Lauper. Last year Gilligan described AI as the ‚Äúworld‚Äôs most expensive and energy-intensive plagiarism machine‚Äù.\n\nThe ‚ÄúStealing Isn‚Äôt Innovation‚Äù push has been organised by the Human Artistry Campaign, whose backers include the Writers Guild of America, the Recording Industry Association of America and the actors‚Äô trade union SAG-AFTRA, which went on strike in 2023, partly over the use of AI.\n\nIn the UK, the government has been under fire for proposing that AI firms should be allowed to use copyright-protected work without first seeking artists‚Äô permission, unless they signal that they wish to ‚Äúopt out‚Äù of the process. The technology secretary, Liz Kendall, said this month that the government was seeking a ‚Äúreset‚Äù on these plans via an official review due to be published in March.",
    "readingTime": 3,
    "keywords": [
      "stealing isn‚Äôt",
      "isn‚Äôt innovation",
      "creative professionals",
      "licensing deals",
      "tech firms",
      "the stealing isn‚Äôt innovation",
      "writers",
      "statement",
      "without",
      "copyright"
    ],
    "qualityScore": 0.9,
    "link": "https://www.theguardian.com/technology/2026/jan/22/scarlett-johansson-and-cate-blanchett-back-campaign-accusing-ai-firms-of-theft",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0ec6ae0c43961da5c432045af3e5b8d5e5bcf60a/110_0_2779_2224/master/2779.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=ade5f2519a44a382d39f5e5fbc9a5b9d",
    "created_at": "2026-01-22T18:18:47.903Z",
    "topic": "tech"
  },
  {
    "slug": "grok-ai-generated-about-3m-sexualised-images-in-11-days-study-finds",
    "title": "Grok AI generated about 3m sexualised images in 11 days, study finds",
    "description": "Estimate made by Center for Countering Digital Hate after Elon Musk‚Äôs AI image generation tool sparked outrage\nGrok AI generated about 3m sexualised images in less than two weeks, including 23,000 that appear to depict children, according to researchers who said it ‚Äúbecame an industrial-scale machine for the production of sexual abuse material‚Äù.\nThe estimate has been made by the Center for Countering Digital Hate (CCDH) after Elon Musk‚Äôs AI image generation tool sparked international outrage when it allowed users to upload photographs of strangers and celebrities, digitally strip them to their underwear or into bikinis, put them in provocative poses and post the images on X.\n Continue reading...",
    "fullText": "Estimate made by Center for Countering Digital Hate after Elon Musk‚Äôs AI image generation tool sparked outrage\n\nGrok AI generated about 3m sexualised images in less than two weeks, including 23,000 that appear to depict children, according to researchers who said it ‚Äúbecame an industrial-scale machine for the production of sexual abuse material‚Äù.\n\nThe estimate has been made by the Center for Countering Digital Hate (CCDH) after Elon Musk‚Äôs AI image generation tool sparked international outrage when it allowed users to upload photographs of strangers and celebrities, digitally strip them to their underwear or into bikinis, put them in provocative poses and post the images on X.\n\nThe trend went viral over the new year, peaking on 2 January with 199,612 individual requests, according to analysis conducted by Peryton Intelligence, a digital intelligence company specialising in online hate.\n\nA fuller assessment of the output from the feature, from its launch on 29 December 2025 until 8 January 2026, has now been made by the CCDH. It suggests the impact of the technology may have been broader than previously thought. Public figures identified in sexualised images it analysed include Selena Gomez, Taylor Swift, Billie Eilish, Ariana Grande, Ice Spice, Nicki Minaj, Christina Hendricks, Millie Bobby Brown, the Swedish deputy prime minister Ebba Busch, and the former US vice-president Kamala Harris.\n\nThe feature was restricted to paid users on 9 January and further restrictions followed after the UK prime minister, Keir Starmer, called the situation ‚Äúdisgusting‚Äù and ‚Äúshameful‚Äù. Other countries, including Indonesia and Malaysia, announced blocks on the AI tool.\n\nCCDH estimated that over the 11-day period, Grok was helping create sexualised images of children every 41 seconds. These included a selfie uploaded by a schoolgirl undressed by Grok, turning a ‚Äúbefore school selfie‚Äù into an image of her in a bikini.\n\n‚ÄúWhat we found was clear and disturbing: in that period Grok became an industrial-scale machine for the production of sexual abuse material,‚Äù said Imran Ahmed, CCDH‚Äôs chief executive. ‚ÄúStripping a woman without their permission is sexual abuse. Throughout that period Elon was hyping the product even when it was clear to the world it was being used in this way. What Elon was ginning up was controversy, eyeballs, engagement and users. It was deeply disturbing.‚Äù\n\nHe added: ‚ÄúThis has become a standard playbook for Silicon Valley, and in particular for social media and AI platforms. The incentives are all misaligned. They profit from this outrage. It‚Äôs not about Musk personally. This is about a system [with] perverse incentives and no minimum safeguards prescribed in law. And until regulators and lawmakers do their jobs and create a minimum expectation of safety, this will continue to happen.‚Äù\n\nX announced it had stopped its Grok feature from editing pictures of real people to show them in revealing clothes, including for premium subscribers, on 14 January.\n\nX referred to its statement from last week, which said: ‚ÄúWe remain committed to making X a safe platform for everyone and continue to have zero tolerance for any forms of child sexual exploitation, non-consensual nudity, and unwanted sexual content.\n\n‚ÄúWe take action to remove high-priority violative content, including child sexual abuse material and non-consensual nudity, taking appropriate action against accounts that violate our X rules. We also report accounts seeking child sexual exploitation materials to law enforcement authorities as necessary.‚Äù",
    "readingTime": 3,
    "keywords": [
      "countering digital",
      "elon musk‚Äôs",
      "digital hate",
      "period grok",
      "industrial-scale machine",
      "prime minister",
      "non-consensual nudity",
      "generation tool",
      "tool sparked",
      "sexualised images"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/jan/22/grok-ai-generated-millions-sexualised-images-in-month-research-says",
    "thumbnail_url": "https://i.guim.co.uk/img/media/5f3c249df73ac96180a47714b78f8e6b78ac0407/542_0_5417_4335/master/5417.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0a787088a931a701dd945b2b8c617e65",
    "created_at": "2026-01-22T18:18:47.901Z",
    "topic": "tech"
  },
  {
    "slug": "livekit-raises-100m-to-build-the-backbone-for-voice-ai",
    "title": "LiveKit raises $100M to build the backbone for voice AI",
    "description": "LiveKit raised $100M at a $1B valuation from Index Ventures, Salesforce Ventures, Hanabi Capital, Altimeter, and Redpoint Ventures.",
    "fullText": "Today, I get the privilege of announcing LiveKit‚Äôs Series C. With this funding round, we‚Äôve reached an important milestone: a $1 billion valuation. Index Ventures is leading the $100M investment, joined by Salesforce Ventures, Hanabi Capital, and our longtime supporters Altimeter and Redpoint Ventures.\n\nTo our customers, users, OSS contributors, investors, and core team: thank you, we wouldn‚Äôt be here without you.\n\nVoice is the most natural interface we have‚Äîit‚Äôs the one we use with each other every day. And for the first time in history, we can interact with computers in the same way.\n\nWhen we announced our Series B in April 2025, voice AI had gone from a feature inside ChatGPT to thousands of applications across financial services, healthcare, retail, customer support, education, and robotics. Startups were building voice agents that could perform tasks like processing claims, tutoring students, triaging patients, supporting customers, and interviewing candidates.\n\nToday, large enterprises are evaluating and building voice agents to automate workflows, improve customer experiences, and unlock new revenue. While many of these use cases are still in the proof-of-concept stage, some are moving into production and operating at real scale: Agentforce voice agents run customer support for the world's top brands and Tesla uses voice AI for sales, support, insurance, and roadside assistance.\n\nWe anticipate 2026 will be the year voice AI will be broadly deployed across thousands of use cases around the world.\n\nBut there's still a lot to build to support this new paradigm of computing.\n\nVoice AI applications are not like web applications. The protocol underlying every web application is HTTP, which was designed for reliably moving text data between computers. Every HTTP request is independent and stateless, meaning that a web backend by default has no historic information. When needed, web applications load state from a database, which may take additional time.\n\nFor an application you can talk to like a person, traditional web infrastructure breaks.\n\nVoice AI applications are realtime and stateful. A conversation with a voice agent might last a few minutes or a few hours and the agent is continuously listening, thinking, and responding while maintaining context across the entire session.\n\nThat shift at the application layer, from using a keyboard and mouse to speaking with a voice agent, changes everything underneath. You can‚Äôt build your application the same way. You can‚Äôt test it the same way. You can‚Äôt deploy and run it the same way. You can‚Äôt monitor it the same way. The whole stack has to be rebuilt for realtime, stateful applications with human-native interfaces.\n\nWe‚Äôre building that stack. Every piece of it, designed to work together seamlessly.\n\nAgents are still applications, and like all applications, they go through a set of stages from design to production:\n\nLike web applications, voice AI applications have a frontend and a backend. To build the former, LiveKit offers client SDKs across every single platform.\n\nOn the backend, LiveKit Agents‚Äîmodeled from our work on ChatGPT Voice Mode and downloaded over 1M times a month‚Äîgives you full programmatic control over agent orchestration, access to hundreds of AI model integrations, and automatically handles conversational dynamics like turn detection and interruptions.\n\nNot everyone wants to start in code though. Sometimes it‚Äôs preferable to quickly start from a template, tune your prompts or sketch out a workflow, and share a link with friends or colleagues‚Äîfor that vibe, we recently launched Agent Builder.\n\nAI models are stochastic. Given the same input, they don't produce the same output, thus you can't write simple assertions against non-deterministic code. You have to test these systems statistically, the same way we evaluate human performance through exams and interviews.\n\nLiveKit Agents now includes support for writing unit tests against your agent code, and you can wire up traces to OpenTelemetry for deeper analysis.\n\nFor simulation (the AI version of an integration test), where a voice agent calls another voice agent and runs through thousands of conversations permuting prompt, language, and voice attributes to build statistical confidence in agent behavior, we've partnered with Bluejay, Hamming, and Roark. In parallel, we‚Äôre also exploring how to integrate simulation more directly into LiveKit‚Äôs platform.\n\nWhile deploying a web application and voice agent both involve pushing code to the cloud, the similarities end there. Your user might speak with an agent for an indeterminate amount of time and there may be unplanned spikes in demand across your user base. This requires a different approach for capacity, connection, and change management, load balancing, and failover. Earlier this year, we released serverless agents to make agent deployment turnkey for builders everywhere.\n\nVoice AI applications also require new network infrastructure, purpose-built for transporting voice data with as low latency as possible between your agent and wherever your users are located. We‚Äôve built out a global network of data centers that act as a unified fabric optimized for routing voice and video data. Today, our network handles billions of calls a year between voice agents and users, across web and mobile applications and phone calls.\n\nRecently, we‚Äôve partnered with telephony carriers around the world to link LiveKit‚Äôs network directly to the PSTN. This enables us to deliver the lowest latency experience when speaking to a voice agent over the phone.\n\nOnce your voice agent is on a live call, there are usually multiple models strung together for every conversational turn: speech-to-text, turn and interruption detection, LLM, and text-to-speech. These models may be running on the same server or data center as your agent code, but most of the time they‚Äôre accessed by your agent via cloud API from a model provider. Model providers host their models in different regions around the world, potentially far away from your agent. Sometimes a provider‚Äôs service gets backlogged and inference requests queue up, other times a provider‚Äôs service goes down. These orchestration challenges can negatively affect end-to-end latency, making agent conversations choppy and unreliable.\n\nLiveKit Inference abstracts away much of this complexity. The same system we built to monitor and route voice in real time can also route inference between model providers. We‚Äôve also started to host our models across our data centers so they‚Äôre colocated with the agents you deploy to LiveKit Cloud.\n\nUntil we launched Agent Observability, there was no Datadog-equivalent built for voice agents‚Äîno way to truly understand how an agent and user are interacting on a live call. How long did it take for the agent to answer the call? What did the agent ‚Äúhear‚Äù when the user specified the prescription drug they‚Äôve been taking? Did the user press the ‚Äú0‚Äù to speak to a human operator? What was the average turn latency across the call? Did the agent invoke the correct tool to schedule an appointment for the user?\n\nAnswering these questions through session replays, traces, time-aligned transcripts of conversations, and error logs is the critical final phase of the lifecycle. As a developer, armed with these learnings and insights, you can then go back to the Build step, modify your agent code, and run through another iteration.\n\nVoice is one of the biggest paradigm shifts in computing. It‚Äôs still early‚Äîand it starts where voice is already the interface: phone calls, cars, and smart speakers.\n\nOver the next few years, as new form factors emerge and models get better at turn-taking, tool use, and reliability, voice-native applications will move from novelty to default. Software will feel less like something you navigate, and more like something you delegate to.\n\nLiveKit is building the development stack and runtime between foundation models and end-user applications. Our goal is simple: make building and scaling voice AI as easy as building and scaling on the web.\n\nThis round helps us move faster. We‚Äôre excited to build the voice-driven era of computing with our customers, community, and partners.",
    "readingTime": 7,
    "keywords": [
      "provider‚Äôs service",
      "model providers",
      "web application",
      "launched agent",
      "web applications",
      "agent code",
      "voice ai",
      "voice agents",
      "across",
      "models"
    ],
    "qualityScore": 1,
    "link": "https://blog.livekit.io/livekit-series-c/",
    "thumbnail_url": "https://blog.livekit.io/content/images/size/w1200/2026/01/x-image-4.png",
    "created_at": "2026-01-22T18:18:46.216Z",
    "topic": "tech"
  },
  {
    "slug": "neuralvoid-block-ai-telemetry-from-copilot-grammarly-adobe",
    "title": "NeuralVoid ‚Äì Block AI Telemetry from Copilot, Grammarly, Adobe",
    "description": "System-Level AI Telemetry Blocker for Windows. Contribute to XORD-AI/NeuralVoid development by creating an account on GitHub.",
    "fullText": "XORD-AI\n\n /\n\n NeuralVoid\n\n Public\n\n System-Level AI Telemetry Blocker for Windows\n\n xord.io/intelligence/neural-void-xord-ai-blocker.html\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n XORD-AI/NeuralVoid",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/XORD-AI/NeuralVoid",
    "thumbnail_url": "https://opengraph.githubassets.com/d0efb578292648299e91c3fadb2f3465d8fb82a2c8aa10b2b1ae3c392fe60437/XORD-AI/NeuralVoid",
    "created_at": "2026-01-22T18:18:45.966Z",
    "topic": "tech"
  },
  {
    "slug": "why-wall-streets-most-dataobsessed-investors-are-taking-it-slowly-with-generative-ai",
    "title": "Why Wall Street's most data-obsessed investors are taking it slowly with generative AI",
    "description": "More than half of respondents to a Bloomberg survey have \"not yet begun their generative AI journey.\"",
    "fullText": "Generative AI hasn't yet won over the quants.\n\nA majority of people running systematic trading strategies at top-tier asset managers have \"not yet begun their generative AI journey,\" according to a new Bloomberg survey.\n\nThe data giant interviewed 151 quants between April and November last year to determine how they've integrated generative AI tools into their investment research process. While this section of the investing world has used machine-learning techniques for years, generative AI has not yet broken through. Most of the respondents, 54%, do not incorporate it into their workflows, the survey found.\n\nThis matches the vibe Business Insider reported on in October, where quants at a London-based conference were skeptical of the technology's ability to beat the market and add value to their investing processes. A UBS executive, for instance, said that AI is not going to help win the \"alpha war.\"\n\nBloomberg's rationale for the slow adoption is focused on data formatting and structure.\n\nAngana Jacob, the firm's global head of research data, said quants require their data to be cleaned and structured a specific way because of the complex systems their strategies run and the amount of capital at stake if there is an error.\n\n\"They're working in a very controlled research environment, models need to be explainable, models need to be repeatable,\" said Jacob, in an interview with Business Insider.\n\nThe work required to get the datasets to a point where they can be used is \"unglamorous,\" but \"foundational,\" Jacob said. Her team is creating data products for quants that might increase AI adoption among them, because, she said, the enthusiasm is high for what AI can do once the data catches up. The lack of widespread use in the investing process is more a sign of the diligence of these players.\n\n\"It's a good thing, it shows their caution,\" she said.\n\nBloomberg is not the only data player that has identified this issue. Former Point72 data executive Kirk McKeown's startup, Carbon Arc, is also focused on structuring datasets for easier ingestion into artificial intelligence models.",
    "readingTime": 2,
    "keywords": [
      "quants",
      "research",
      "investing",
      "models",
      "strategies",
      "bloomberg",
      "survey",
      "process",
      "executive",
      "adoption"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/quants-arent-using-ai-to-invest-bloomberg-survey-2026-1",
    "thumbnail_url": "https://i.insider.com/697155bdd3c7faef0eccb349?width=1200&format=jpeg",
    "created_at": "2026-01-22T18:18:42.118Z",
    "topic": "finance"
  },
  {
    "slug": "citadels-ceo-on-the-ai-boom-is-it-hype-of-course",
    "title": "Citadel's CEO on the AI boom: 'Is it hype? Of course'",
    "description": "Citadel CEO Ken Griffin says AI has shifted power to tech teams, but today's tools often fall short, even as massive data-center spending accelerates.",
    "fullText": "Hedge fund tycoon Ken Griffin has a blunt message for anyone expecting artificial intelligence to instantly rewrite the global economy: the hype is real ‚Äî and it's there to justify enormous spending.\n\nSpeaking at the World Economic Forum in Davos on Wednesday, the Citadel CEO said the AI boom is being fueled as much by narrative as by real productivity gains.\n\nGriffin, who ranks as the 39th wealthiest person in the world with a net worth of about $48.3 billion, according to the Bloomberg Billionaires Index, said that doesn't mean AI isn't powerful ‚Äî but expectations have run far ahead of reality.\n\n\"Is it hype? Of course,\" Griffin said, pointing to the extraordinary scale of investment now pouring into AI infrastructure.\n\nGriffin said that data center spending in the US is estimated to top $500 billion this year. Bank of America previously estimated that Microsoft, Amazon, Google, and Meta ‚Äî who are leading the data center construction boom ‚Äî will spend a combined $385 billion annually on AI infrastructure between 2025 and 2028.\n\n\"You're not going to generate this kind of spend unless you're going to make a promise you're going to profoundly change the world,\" Griffin said.\n\n\"How else are you going to get people to write $500 billion of checks just this year alone?\" he added.\n\nGriffin's skepticism came after he was asked whether he agreed with predictions from AI leaders such as Anthropic CEO Dario Amodei, who has said that half of all entry-level white-collar jobs could disappear within five years.\n\nGriffin didn't endorse that view, instead questioning whether AI systems are delivering the kind of deep productivity gains that would justify such forecasts.\n\nTech leaders, such as OpenAI CEO Sam Altman and Microsoft cofounder Bill Gates, have pointed to overheated valuations and investor overexcitement to predict a looming bubble.\n\nOthers, such as Nvidia CEO Jensen Huang and Meta CEO Mark Zuckerberg, have said AI spending reflects a fundamental shift in computing and that demand and model capabilities are still growing fast enough to justify the buildout.\n\nWhat is certain for Griffin said is that AI has \"re-empowered the head of technology in every business in the United States,\" he said.\n\nGriffin was especially critical of generative AI outputs in white-collar work, saying they often look impressive at first glance but fall apart under scrutiny.\n\nHe described reviewing an AI-generated report that seemed insightful at the top but devolved into \"garbage\" further down.\n\nStill, Griffin isn't dismissing AI's long-term impact. He said the technology will be transformative in areas like call centers and software development, and that massive investment in technology broadly is already benefiting the economy.",
    "readingTime": 3,
    "keywords": [
      "productivity gains",
      "justify",
      "you're",
      "technology",
      "griffin",
      "economy",
      "hype",
      "boom",
      "isn't",
      "investment"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/citadel-ceo-ken-griffin-ai-hype-outpacing-productivity-2026-1",
    "thumbnail_url": "https://i.insider.com/697219abd3c7faef0eccb7ca?width=1200&format=jpeg",
    "created_at": "2026-01-22T18:18:42.013Z",
    "topic": "finance"
  },
  {
    "slug": "linkedin-cofounder-reid-hoffman-says-companies-are-approaching-ai-the-wrong-way",
    "title": "LinkedIn cofounder Reid Hoffman says companies are approaching AI the wrong way",
    "description": "LinkedIn cofounder Reid Hoffman said firms are overlooking where automation actually pays off ‚Äî in the \"unglamorous layer\" of day-to-day work.",
    "fullText": "Big companies are busy hiring chief AI officers and setting up tiger teams to pilot agentic products.\n\nHowever, LinkedIn cofounder Reid Hoffman says this overlooks where automation actually pays off ‚Äî in the \"unglamorous layer\" of day-to-day work.\n\nSpeaking with AI engineer Parth Patil on his \"Possible\" podcast, Hoffman said a company's AI transformation involves employees \"being able to talk to each other about it and do collective learning.\"\n\n\"If people feel they'll get punished or judged for using AI, they become what Ethan Mollick calls 'secret cyborgs,' who quietly speed up their own work while the organization learns nothing,\" Hoffman wrote in a LinkedIn post.\n\nMollick, an associate professor at Wharton, researches the effects of AI on work, entrepreneurship, and education.\n\nCompanies have been ramping up investments in AI to boost efficiency and keep up with the AI race.\n\nGoldman Sachs, for example, said it spent roughly $6 billion on tech last year ‚Äî a figure CEO David Solomon said he wished was higher.\n\nA CIO survey from RBC Capital in December found 90% of respondents said their organizations plan to spend more on AI in 2026.\n\nMany big companies are trying to integrate new technology by running pilot schemes with a small, specialist group.\n\nHoffman wrote on LinkedIn that they then expect \"transformation to magically spread\".\n\n\"Unfortunately for that strategy, AI lives at the workflow level, and the people closest to the work know where the friction actually is,\" he said.\n\nHoffman said automation should start at the coordination layer. Think meetings, note-taking, and tools that source company knowledge.\n\n\"The winners will be companies that build the muscle of day-to-day use early enough for the gains to compound,\" said Hoffman in an X post.\n\n\"Start learning now, or watch the advantage slip away,\" he added.",
    "readingTime": 2,
    "keywords": [
      "pilot",
      "automation",
      "layer",
      "day-to-day",
      "transformation",
      "learning",
      "hoffman",
      "linkedin",
      "mollick"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/linkedin-cofounder-reid-hoffman-companies-approaching-ai-wrong-way-2026-1",
    "thumbnail_url": "https://i.insider.com/69721c5ed3c7faef0eccb7de?width=1200&format=jpeg",
    "created_at": "2026-01-22T18:18:42.012Z",
    "topic": "finance"
  },
  {
    "slug": "how-to-get-your-customers-to-trust-ai",
    "title": "How to Get Your Customers to Trust AI",
    "description": "In using AI with customers, organizations face a challenge in getting them to trust it. They must balance explaining to customers the different facets of the AI systems without overwhelming or confusing them. The solution involves embedding transparency within a broader trust framework, customizing disclosures for different audiences, and treating transparency as an ongoing, adaptive process. Autodesk is one company that has figured out how to strike this balance.",
    "fullText": "How to Get Your Customers to Trust AI by Ashley Reichheld, Sebastian Goodwin and Courtney ShermanJanuary 22, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintTransparency is supposed to build trust. But as companies rush to open the black box of artificial intelligence and explain how it works to customers, many are discovering a surprising truth: You can say too much and too little at the same time. The balance is hard to get right: Too little transparency breeds suspicion; too much overwhelms, blurring the very clarity it‚Äôs meant to provide.",
    "readingTime": 1,
    "keywords": [
      "customers",
      "trust"
    ],
    "qualityScore": 0.35,
    "link": "https://hbr.org/2026/01/how-to-get-your-customers-to-trust-ai",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_22_7210855.jpg",
    "created_at": "2026-01-22T18:18:40.774Z",
    "topic": "business"
  },
  {
    "slug": "suttons-predictions-v-roy-keane-saipan-star-hardwicke",
    "title": "Sutton's predictions v 'Roy Keane' - Saipan star Hardwicke",
    "description": "BBC Sport football expert Chris Sutton takes on actor √âanna Hardwicke, who plays Roy Keane in the new film Saipan - and AI - with his predictions for this week's Premier League fixtures.",
    "fullText": "Is this AI's worst prediction yet?\n\nChris Sutton's guest this week, actor √âanna Hardwicke, plays Roy Keane in Saipan - a new film about the former Manchester United captain's infamous fallout with Republic of Ireland manager Mick McCarthy before the 2002 World Cup. It is in cinemas from Friday.\n\nNaturally, we asked AI who would play Sutton if a film were ever made about him.\n\nThe best fit, apparently, is Hollywood heartthrob Tom Hardy - who is four inches shorter than BBC Sport football expert Sutton but is AI's top choice for the role because he is \"known for portraying tough, brooding characters with emotional depth\".\n\n\"That just shows how way off the mark AI is,\" said Sutton.\n\n\"But I'm happy with Tom Hardy, even though he is not tall enough. Most people would probably say I am more like Laurel and Hardy though.\"\n\nSutton is making predictions for all 380 Premier League games this season, against AI, BBC Sport readers and a variety of guests.\n\nHardwicke, who supports Aston Villa, is his guest for week 23.\n\nDo you agree with their scores? You can make your own predictions below.\n\nThe most popular scoreline selected for each game is used in the scoreboards and tables at the bottom of this page.\n\nA correct result (picking a win, draw or defeat) is worth 10 points. The exact score earns 40 points.",
    "readingTime": 2,
    "keywords": [
      "tom hardy",
      "ai's",
      "guest",
      "hardwicke",
      "film",
      "predictions",
      "points",
      "sutton",
      "sport"
    ],
    "qualityScore": 0.85,
    "link": "https://www.bbc.com/sport/football/articles/cn8j42l594mo?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_sport/1200/cpsprodpb/c13d/live/4fa91940-f246-11f0-b385-5f48925de19a.png",
    "created_at": "2026-01-22T18:18:39.146Z",
    "topic": "sports"
  },
  {
    "slug": "apple-makes-a-huge-bet-on-ai-models-becoming-commodities",
    "title": "Apple makes a huge bet on AI models becoming commodities",
    "description": "Apple, Siri, and Google Gemini AI are at the forefront as Apple rebuilds its assistant, betting on AI model commoditization and flexibility.",
    "fullText": "Apple's decision to rebuild Siri around Google's Gemini AI models looks, at first glance, like an admission of failure. After years of promising breakthroughs, Apple is reportedly paying Google roughly $1 billion a year to keep its digital assistant relevant.\n\nLook closer, though, and the move represents something more radical: a giant bet that AI models will become commodities.\n\nTop tech reporter Mark Gurman wrote this week that Apple's revamped Siri, codenamed Campos, will launch later this year as a full-fledged chatbot embedded across iPhones, iPads, and Macs. The underlying intelligence will come from Google's Gemini.\n\nThe more important detail is architectural. Apple is designing Campos so that the underlying AI models can be swapped out over time, according to Gurman's report for Bloomberg.\n\n\"That means the company will have the flexibility to move away from Google-powered systems in the future if it so chooses,\" he wrote.\n\nThat design choice tells us a lot about Apple's AI strategy.\n\nRather than trying to win an AI arms race against Google, OpenAI, Anthropic, and Meta by spending tens of billions of dollars a year on AI infrastructure, Apple appears to be positioning itself as model-agnostic. Siri remains Apple's direct interface to more than 1 billion iPhone users. The \"brains\" underneath, however, can change.\n\nIf Apple is right, the leading AI models will converge in quality over time, becoming roughly interchangeable. At that point, differentiation shifts away from the model itself and toward distribution, integration, privacy controls, and user experience ‚Äî areas where Apple already excels.\n\nApple could then choose whichever AI provider is best, cheapest, or most strategically useful every few years. So, Google's Gemini might power Siri today, but tomorrow it could be OpenAI's latest GPT offering, or Claude from Anthropic, or whatever Meta is cooking up next, or xAI's Grok, or Mistral's offerings, or even region-specific models such as DeepSeek or Alibaba's Qwen in China. Services like OpenRouter already demonstrate how models can be swapped in and out.\n\nApple is also playing a longer game. Its search deal with Google, worth an estimated $20 billion a year, shows how valuable iPhone distribution is. If AI models truly commoditize, Apple could eventually flip the Siri relationship the same way: AI model providers could end up paying Apple for access to its massive user base.\n\nThe strategy also saves Apple enormous capital expenditure. While rivals pour huge sums of money into AI data centers and chips, Apple can let others shoulder that cost. For instance, Google spent more than $60 billion in capex during the first three quarters of 2025, while Apple spent $12.7 billion in its latest fiscal year.\n\nIf this AI building boom turns about to be a bust, Apple may dodge a bullet. Of course, it might turn out that underinvesting in your own AI capabilities is a strategic blunder of epic proportions.\n\nWe'll see in the next few years. Right now, Apple just placed a huge bet that the real power in the AI era won't belong to model makers, but to whoever controls the interface.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 3,
    "keywords": [
      "google's gemini",
      "models",
      "siri",
      "apple",
      "model",
      "roughly",
      "campos",
      "underlying",
      "swapped",
      "away"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/apple-siri-bet-ai-models-commodities-google-gemini-2026-1",
    "thumbnail_url": "https://i.insider.com/69716054a645d1188187c43a?width=1200&format=jpeg",
    "created_at": "2026-01-22T12:27:08.505Z",
    "topic": "finance"
  },
  {
    "slug": "inside-openais-renewed-push-into-robotics",
    "title": "Inside OpenAI's renewed push into robotics",
    "description": "OpenAI has rapidly scaled its robotics lab over the past year and plans to open up a second lab, insiders say.",
    "fullText": "Last year, Sam Altman posited that the world hadn't yet had its \"humanoid robots moment\" ‚Äî but, he said, \"it's coming.\" In the background, his AI company has been gearing up to make that happen.\n\nOpenAI quietly built up a humanoid robotics lab over the past year, insiders with knowledge of the program told Business Insider. The lab operates out of the same building as the company's finance team in San Francisco, and employs around 100 data collectors. They're teaching a robotic arm how to perform household tasks as a part of a larger effort to build a humanoid robot.\n\nOpenAI explored robotics during its early years and built a robotic hand capable of solving a Rubik's Cube. The company closed the project in 2020; a company spokesperson said at the time that it had chosen to \"refocus the team on other projects.\"\n\nThe inner workings of the new robotics lab haven't been previously reported.\n\nOne person with knowledge of OpenAI's strategy said the company is working on several new hardware projects, including robotics, that are in the early phases of development, and so far, none are core to the company's mission.\n\nLast week, OpenAI put out a request for proposals from companies that manufacture in the US that could act as partners for the company's push into consumer devices, robotics, and cloud data centers. The company did not specify how much it intends to spend or provide a timeframe for the work.\n\nA representative for OpenAI declined to comment.\n\nThe lab has more than quadrupled in size since it launched in February 2025, insiders said.\n\nIn December, the company told employees it plans to open a second lab in Richmond, California. A December job posting for a \"robotics operator\" with the company's contracting agency lists Richmond as the location.\n\nThe lab has a humanoid robot that multiple people described as \"iRobot-like\" on display, but the bot is mostly collecting dust, and few have seen it in operation. The vast majority of the work in the lab is focused on teleoperating robotic arms.\n\nOpenAI has data collectors using 3-D printed controllers, called GELLOs, to operate two Franka robots. These metal arms have pincers at the end and perform household tasks like putting bread in a toaster or folding laundry.\n\nWhen the data collection program began in February, work focused on teaching the Franka robot how to put a rubber duck in a cup. Since then, it has shifted to increasingly more sophisticated tasks.\n\nOpenAI's lab offers a rare glimpse into how one of the world's most influential AI companies is approaching robotics.\n\nCompetitors like Tesla put on flashy demos and often train with full humanoid robots controlled by motion capture suits and virtual reality headsets. OpenAI is taking a quieter path, scaling contractor-driven data collection to train robotic arms on basic tasks.\n\nBoth approaches show how far leading AI companies remain from building functional household robots, and how much of that work still relies on human labor.\n\nWired reported last fall that OpenAI had begun hiring robotics engineers. The company has at least a dozen engineers on the project, according to a review of LinkedIn profiles.\n\nIn December, a project supervisor said that the lab needed to increase productivity and efficiency to get more hours of functional data, people with knowledge of the program said. Over the past few months, the lab has nearly doubled expectations for data collection, they said.\n\nOpenAI has previously invested in other robotics companies, including Figure, 1X, and Physical Intelligence. Its 2024 partnership with Figure was designed to build \"next generation AI models for humanoid\" robots, but Figure CEO Brett Adcock said in February 2025 that the company was exiting the deal.\n\nWhen the first robotics project ended in 2020, it was widely believed that the company was focusing more intensely on ChatGPT. Now, OpenAI has indicated it plans to expand into devices, and it could use its ChatGPT knowledge base to teach a robot how to interpret and interact with the world.\n\nThe earlier program focused on reinforcement learning ‚Äî a trial-and-error approach in which robots learn through a reward system. Now, the company is collecting large amounts of data to train the robots.\n\n\"Everyone is fighting for a way to develop large data sets,\" Jonathan Aitken, a robotics expert with the University of Sheffield, told Business Insider. \"We know we have AI algorithms that are capable of being trained to do stuff using big data sets. The issue has always been getting that data set.\"\n\nOpenAI's data collection strategy differs from the robotics efforts at companies like Tesla or Figure, where workers record full-body movement and use motion capture suits and virtual reality headsets to operate full-sized humanoid robots.\n\nOpenAI's data collection efforts mirror a study published in 2023 by researchers from the University of California, Berkeley, that describes a low-cost and scalable system for collecting robotics data using teleoperated arms. One of the researchers joined OpenAI in August 2024 and works on \"Building the Robot Brain,\" according to LinkedIn.\n\nAlan Fern, an AI and robotics expert at Oregon State University, told Business Insider it's a standard setup that allows the robot to learn by mimicking its operator. Aitken said OpenAI's GELLO strategy could present an advantage over AI companies that use motion capture suits. It's cheaper, he said, and because each controller maps directly to a robot arm, the robot can more easily learn how specific human movements translate into its own motions.\n\nIn San Francisco, OpenAI runs three shifts and a few dozen workstations that collect data around the clock, people with knowledge of the lab said. Cameras record both the operator and the robot performing tasks, and workers are rated on how many \"good hours\" of functional training data they can generate.\n\nThe reliance on contract workers and performance metrics mirrors how AI companies, including OpenAI, have historically scaled data labeling for their large language models.\n\n\"A lot of companies are hoping if you collect enough of this data, you can translate it into robot motions, and they will get a scaling effect and have this ChatGPT moment,\" Fern said.\n\n\"That's something that hasn't been proven out yet,\" he added.\n\nThe company is setting up new robot stations with robotic arms that more closely mimic how a human moves, insiders said.\n\nOpenAI also uses some of the data to train robots in computer simulations and regularly tests the robot arms to see how well they perform, the people said.\n\nIt's unclear how quickly OpenAI plans to translate this data into a full humanoid robot, or how its low-cost, arm-based approach will fare against companies investing heavily in full humanoid systems.\n\n\"It does seem to be very early in the process,\" Aitken said. \"From a technical standpoint, it's a really beautiful and configurable interface to lots of different types of robots.\"\n\nDo you work for OpenAI or have a tip? Contact this reporter via email at gkay@businessinsider.com or Signal at 248-894-6012. Use a personal email address, a nonwork device, and nonwork WiFi; here's our guide to sharing information securely.",
    "readingTime": 6,
    "keywords": [
      "virtual reality",
      "reality headsets",
      "motion capture",
      "capture suits",
      "perform household",
      "household tasks",
      "robotic arms",
      "robotics expert",
      "humanoid robots",
      "humanoid robot"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/open-ai-robotics-lab-humanoid-robots-2026-1",
    "thumbnail_url": "https://i.insider.com/696975c604eda4732f2f2ea6?width=1200&format=jpeg",
    "created_at": "2026-01-22T12:27:08.132Z",
    "topic": "finance"
  },
  {
    "slug": "wall-street-is-losing-its-appetite-for-oracles-data-center-debt",
    "title": "Wall Street is losing its appetite for Oracle's data center debt",
    "description": "Appetite for loans tied to Oracle's data center partnership with OpenAI has diminished, reflecting concerns over credit risk and AI investment scale.",
    "fullText": "Oracle and OpenAI have aimed to build $500 billion of data centers by the end of the decade to power their artificial intelligence ambitions.\n\nBut the massive initiative, called Stargate, may be exhausting the supply of available capital.\n\nJPMorgan Chase, the bank that recently led a pack of lenders to extend roughly $38 billion of debt for the construction of two planned Stargate data center campuses in Texas and Wisconsin, has encountered diminished interest as it has sold off pieces of the loan to other financial players, a person familiar with the situation said.\n\nThe person said that the two projects are fully financed, the syndication effort by JPMorgan had been successful overall, and that the slowdown in new participants hadn't alarmed bankers given that it was at the tail end of such a large debt offering.\n\nBut the person acknowledged that banks and institutional investors had also grown wary in recent months of taking on too much exposure to Oracle, a tech giant whose credit rating sits below some of its peers in the AI race, including Microsoft and Google.\n\nThe reticence among lenders and investors to continue bankrolling Stargate raises questions about whether the mega-project will meet its lofty objectives.\n\n\"We are hearing from market participants that in some cases, there may be banks that could be approaching the exposure levels they're comfortable with when it comes to certain data center projects,\" said Dhaval Shah, a director at S&P Global Infrastructure Ratings.\n\nThe current unprecedented data center development cycle has been dominated by just a handful of leading players, testing whether lenders and investors will remain willing to continue to accrue heavy exposure to borrowers like Oracle. Oracle declined to comment.\n\nIn November, credit default swaps that insure against losses on Oracle's corporate debt rose in cost, a reflection of the concerns around the company's enormous spending on AI.\n\nOpenAI, the AI chatbot maker that will anchor the Stargate facilities, meanwhile, produces revenue that is just a fraction of the tens of billions of dollars annually that would be necessary to justify the cost of its infrastructure.\n\n\"Oracle has become a proxy for OpenAI's ability to raise significant amounts of capital,\" said Gil Luria, an analyst at DA Davidson. \"It's a very precarious position.\"\n\nOpenAI announced Stargate a year ago, stating that it would partner with Oracle and others, to build a total of 10 gigawatts of data center capacity by 2029 ‚Äî roughly the equivalent power footprint of New York City on a day of peak electrical consumption.\n\nIn October, OpenAI announced that it had arranged for the construction of six Stargate sites with a total planned capacity of roughly 7 gigawatts, stating that the pipeline \"puts us on a clear path to securing the full $500 billion,10-gigawatt commitment\" it had announced at the beginning of 2025.\n\nMuch of the financing for the project, so far, has been provided by major financial institutions that have banded together to share its immense costs ‚Äî as well as its risks ‚Äî in what are known as syndication deals. JPMorgan Chase and Mitsubishi UFJ Financial Group led the syndication effort for the two Stargate projects in Shackelford, Texas, and Port Washington, Wisconsin. Both banks declined to comment.\n\nBank of America is leading a syndication to finance another Stargate data center campus in Michigan. A person familiar with that effort said that it has attracted interest from syndication takers.\n\nAnother group of lenders provided about $18 billion of financing for another Stargate facility in New Mexico, according to Bloomberg.\n\nInitial players in large syndication deals often seek to sell off portions of their loan commitments to other players, including other banks and institutional investors.\n\nBut the sale of these positions, which is done to reap quick profits and lower exposure, has become trickier in the case of Stargate.\n\nTwo bankers and a financing executive who are familiar with the syndication market said that the rising perception of risk around Stargate meant that lenders now wanted higher yields to lend to it. That has placed recent Stargate syndicators in a position where they can no longer profitably sell off debt that was arranged at tighter spreads just a few months ago.\n\nStargate borrowing rates may not come down any time soon.\n\nIn September, S&P Global Ratings affirmed Oracle's rating at BBB but said it was considering a cut due to the company's enormous planned spending on AI infrastructure. A downgrade below BBB minus would place a junk rating on Oracle debt, raising its borrowing costs significantly.\n\n\"I am very surprised these loans were even underwritten at the time,\" Luria said. \"The market has indicated this is not investment-grade debt.\"\n\nHowever, Luria said one scenario in particular could make the loans less risky. OpenAI is now in the process of trying to raise as much as $100 billion, according to reports, giving the Stargate venture a potential cushion of equity and making its debt easier to sell, he said.\n\n\"If that happens,\" he said, \"everybody's dreams come true.\"\n\nOther bankers who spoke with Business Insider said the slowdown did not indicate acute trouble in the syndication market, but acknowledged that the pool of investors who still have an appetite for the Stargate debt has shrunk.\n\n\"Do we have enough digestive capacity\" in the market for investors to buy all of the debt that will be required, said David Tawil, a partner at transaction insurance advisory firm Castle Harbour. \"That's the market's real concern: the size of this whole movement.\"",
    "readingTime": 5,
    "keywords": [
      "company's enormous",
      "another stargate",
      "institutional investors",
      "syndication deals",
      "syndication effort",
      "syndication market",
      "debt",
      "lenders",
      "center",
      "players"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/oracle-openai-stargate-loans-jpmorgan-diminishing-interest-debt-2026-1",
    "thumbnail_url": "https://i.insider.com/69714d62e1ba468a96aa7a22?width=800&format=jpeg",
    "created_at": "2026-01-22T12:27:08.132Z",
    "topic": "finance"
  },
  {
    "slug": "wall-streeters-reveal-their-favorite-ai-tools-and-what-they-use-them-for",
    "title": "Wall Streeters reveal their favorite AI tools and what they use them for",
    "description": "AI isn't yet impressive enough to replace the core work done in the finance industry, but Wall Streeters are still using AI to streamline their day.",
    "fullText": "For all the hand-wringing about¬†what AI will do to the white-collar workforce, the technology might not be impressive enough to replace the core work done in the finance industry yet, but Wall Street pros say it definitely has its uses.\n\n\"If you're doing it for self-education, it's one thing, but I think it's quite hard to rely on a chatbot for fiduciary purposes if you're facing clients,\" said Maurits Pot, the founder of Tema ETFs.\n\nOther cite issues with AI \"hallucinations,\" which can be a headache if you need to be precise with figures and data.\n\n\"You don't use AI to do sophisticated things,\" said David Trainer, the founder of New Constructs, adding: \"It's more trouble for me to use something and find out later that it's hallucinated than it is for me to just go get it from the source to begin with.\"\n\nAnd yet, a lot of people are using AI, and there are some creative ways Wall Street pros are deploying the technology.\n\nHere's how Wall Streeters say they are using chatbots to save them time and get an edge.\n\nOne of the more interesting examples I heard comes from Lance Roberts, the CIO at RIA Advisors, which oversees around $2 billion. His team programmed 14 different AI agents to think like top investors, including Warren Buffett, Stanley Druckenmiller, Benjamin Graham, John Bogle, Cathie Wood, and others.\n\nThese agents provide insights on anything from their views on the S&P 500 to individual stocks, Roberts said, and can help provide different perspectives when thinking about an investment case.\n\nAnother use case comes from Rob Arnott, the famed investor and founder of Research Affiliates. Last year at around this time, he was going to have his team read Sun Tzu's \"The Art of War\" to prepare for Trump's second term. Trump has cited it as one of his favorite books, with one of its main takeaways being to find a way to get what you want without fighting. Instead, Arnott figured he'd send them a ChatGPT summary to ensure they'd get the main takeaways without having to take too much time out of their busy schedules.\n\nArnott has also said he uses AI for detailed feedback on his papers, with his preferred chatbot being Perplexity.\n\n\"Perplexity is my preferred search engine, and has been for a couple of years now,\" he said in an email. \"I try the other LLM's from time to time. The nice thing about Perplexity is that it's an AI of AIs: it chooses which AI is best suited to whatever question I have.\"\n\nIts biggest use case, however, seems to be administrative tasks, or assignments that lower-level staffers might have once tackled. As Seth Klarman, the CEO of Baupost Group, described it last summer: \"essentially a capable assistant, a summer intern.\"\n\nDavid Elder, a wealth manager at Merit Financial Advisors, gave an example of a smaller task he might use a chatbot to save time on.\n\n\"I'm doing a presentation right now on intellectual property,\" Elder, who uses multiple chatbots including ChatGPT, Copilot, and Gamma, said. \"I can have an interview with me and an intellectual property or business attorney, talk about it from multiple angles, dump that kind of recording into an AI, and turn that into a presentation.\"\n\nFor Chase Doyen, who works in business development for the London Stock Exchange Group in New York, it's an organizational tool. His firm has a subscription to Claude, Anthropic's chatbot.\n\n\"I use it for administrative tasks mostly,\" Doyen said. \"I use it for organizing and planning out my day. I use it for organizing my notes. If I write down a lot for a presentation I'm in or a meeting, Claude cleans it up very well.\"",
    "readingTime": 4,
    "keywords": [
      "street pros",
      "administrative tasks",
      "intellectual property",
      "wall street",
      "it's",
      "chatbot",
      "founder",
      "presentation",
      "technology",
      "you're"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/wall-street-top-ai-chatbots-tools-claude-chatgpt-gamma-2026-1",
    "thumbnail_url": "https://i.insider.com/697131d0d3c7faef0eccaeb7?width=1200&format=jpeg",
    "created_at": "2026-01-22T12:27:08.113Z",
    "topic": "finance"
  },
  {
    "slug": "ciscos-hr-chief-said-the-worst-thing-companies-can-do-is-pile-more-work-on-employees-after-ai-saves-time",
    "title": "Cisco's HR chief said the 'worst thing' companies can do is pile more work on employees after AI saves time",
    "description": "Cisco's chief people officer said companies should encourage AI adoption by framing it as a tool that will help workers get part of their day back.",
    "fullText": "Has using AI meant you've ended up with more work on your plate?\n\nAt this early stage of adoption, Cisco's chief people officer, Kelly Jones, told Business Insider that the \"worst thing\" companies can do when trying to encourage AI adoption is to pile additional work on employees once they've freed up time.\n\n\"When you get into the space of AI experimentation, one of the most important things to do is not kill innovation when you're starting it,\" Jones said.\n\nJones is touching on the reality of AI adoption at many companies. Even as firms report productivity gains from AI tools, employees' days haven't necessarily gotten any shorter.\n\nOne Microsoft manager previously told Business Insider that AI tools cut his coding time ‚Äî which used to make up the overwhelming majority of his workload ‚Äîby 70%, yet his overall workload didn't shrink. Many leaders have also said that AI will free up employees' time, so they can focus on more \"deep work,\" rather than suggesting that workers might get more free time overall.\n\nJones said that when leaders push AI adoption, they need to make it \"really relevant\" to the day-to-day work of employees, rather than making it another ask from their manager. It should be framed as a tool that helps employees reclaim a percentage of their day, the CPO said.\n\nMost employees would be glad to save time spent on work, and she said companies get it wrong by saying, \"here's three new things that we need you to do.\"\n\nWhile the traditional 9-to-5 workday may not be undergoing a drastic overhaul, some employees have found ways to shave hours off their schedules using AI tools, freeing up time for other pursuits ‚Äî whether or not they tell their employers. For instance, one worker told Business Insider he used AI to complete about half of his software engineering tasks and spent the rest of his day on Reddit and YouTube.\n\nJones said that if employees are doing better work in less time, \"there's no negative to that.\" At this point in the innovation cycle, people should use AI to get work tasks done more rapidly if they can, she said.\n\nWhile Jones discouraged automatically adding more to employees' plates, she said that figuring out what to do with reclaimed time is a more complicated question. Determining how work changes, how it should be redistributed, and how companies and employees make those calls is what HR is likely to focus on over the next year or two, she said.\n\n\"We are really at this precipice where we're going to be moving from managing jobs to redesigning work,\" Jones said.\n\nShe said the role of HR will shift into helping organizations figure out what work is allocated to humans and what work is done by AI ‚Äî and how the two work together.",
    "readingTime": 3,
    "keywords": [
      "business insider",
      "employees",
      "adoption",
      "tools",
      "jones",
      "innovation",
      "manager",
      "workload",
      "overall",
      "leaders"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/cisco-hr-boss-warns-against-piling-work-after-ai-gains-2026-1",
    "thumbnail_url": "https://i.insider.com/6970f9d7a645d1188187b760?width=1200&format=jpeg",
    "created_at": "2026-01-22T12:27:07.966Z",
    "topic": "finance"
  },
  {
    "slug": "opensecure-evaluating-ai-models-against-blackbox-web-app-hacking-challenges",
    "title": "OpenSecure ‚Äì Evaluating AI models against blackbox web app hacking challenges",
    "description": "Comprehensive benchmark testing AI models on offensive security challenges. Compare performance across models on blackbox penetration testing.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://opensecure.cloud/benchmark",
    "thumbnail_url": "https://opensecure.cloud/og-image.png",
    "created_at": "2026-01-22T12:27:05.800Z",
    "topic": "tech"
  },
  {
    "slug": "well-there-goes-the-metaverse",
    "title": "Well, There Goes the Metaverse",
    "description": "The metaverse is on its last legs as VR is eclipsed by AI. But that's not the only thing that went wrong for Meta's VR ambitions.",
    "fullText": "Meta‚Äôs enormous bet on virtual reality ended last week, with the company reportedly laying off roughly 1,500 employees from its Reality Labs division ‚Äî about 10% of the unit‚Äôs staff ‚Äî and shutting down several VR game studios, according to The Wall Street Journal. It‚Äôs a huge reversal for a company that, just four years ago, staked its entire identity on the concept.\n\nAs industry watchers might remember, Facebook rebranded itself as Meta in 2021, promising to usher in a new era of technology led by VR devices.\n\nIn part, the decision was a bet on Gen Z‚Äôs preference to socialize in online games like Fortnite and Roblox as opposed to traditional social media apps. The change also helped Meta distance itself from the negativity surrounding its Facebook brand. Over the years, the brand had been damaged by data privacy scandals like Cambridge Analytica; reports from Facebook whistleblower Frances Haugen, who shared documents indicating Facebook knew of its negative impacts on children and teens; Congressional hearings over Facebook‚Äôs digital surveillance; its role in the spread of misinformation; its monopolistic practices, and more.\n\nMeta‚Äôs vision at the time was that the metaverse would be the next big social platform, where users connected in a virtual world via Meta‚Äôs Horizon Worlds app and played games on their VR headsets.\n\nFast-forward, and the metaverse has effectively been abandoned in favor of AI.\n\nAccording to CNBC, some of the casualties include studios making VR titles inside Meta, like Armature Studio (‚ÄúResident Evil 4 VR‚Äú), Twisted Pixel (‚ÄúMarvel‚Äôs Deadpool VR‚Äú), and Sanzaru (‚ÄúAsgard‚Äôs Wrath). Meanwhile, the VR fitness app Supernatural, which Meta acquired in 2023 for $400 million, will no longer produce new content and will move into ‚Äúmaintenance mode.‚Äù Camouflaj, the studio behind the ‚ÄúBatman: Arkham Shadow‚Äù VR game, has also been impacted by layoffs, as reported by¬†GeekWire.\n\nAnd last week, The Verge noted that Meta‚Äôs program to bring VR to work, Workrooms, is shutting down, as well.\n\nThe news follows an earlier Bloomberg report from December, which said that Meta was slashing the virtual reality department‚Äôs budget by up to 30%. Around the same time, Meta announced that it was pausing its program to share its Meta Horizon operating system, which runs on its Quest-branded VR headsets, with other third-party headset device makers.\n\nUnlike the news of Meta‚Äôs rebrand, the deprioritization of the company‚Äôs metaverse efforts should come as no surprise ‚Äî the division lost money at an excessive rate, worrying investors, and had never turned a profit.\n\nIn total, the company had funneled some $73 billion into Reality Labs. To put that into context, you‚Äôd have to spend $1 million per day for 200 years to match that kind of spending.\n\nBesides being overhyped by investors and analysts alike, initial versions of the metaverse were just bad products. The goofy, soulless avatars didn‚Äôt even have legs, and one metaverse selfie of Meta CEO Mark Zuckerberg was so bad it even became a viral meme. In short, Meta was overpromising a future while its product still under-delivered. It was a failure of the ‚Äúbuild in the open‚Äù model, where early tech products are shipped to consumers in hopes of getting feedback that can be used to iterate.\n\nThat model works when customers are actively interested in a technology. But in the case of the metaverse, there was only middling consumer demand. Though Meta quickly gained a majority share of the VR market with its Oculus headsets, the headsets saw declining sales. Last spring, Counterpoint Research noted that global VR headset shipments had fallen by 12% year-over-year in 2024, which was their third consecutive year of declines. Meta had accounted for 77% of those 2024 headset shipments.\n\nMeta, betting on the ‚Äúif you build it, they will come‚Äù strategy, was more interested in the profits that could be made from running its own platform for apps and games than whether or not consumers even wanted these so-called face computers.\n\nSpecifically, Zuckerberg was looking for a way to bypass the ability of Apple and Google to tap into Meta‚Äôs revenue through their app stores.\n\n‚ÄúThis period has‚Ä¶been humbling, because as big of a company as we are, we‚Äôve also learned what it is like to build for other platforms. And living under their rules has profoundly shaped my views on the tech industry,‚Äù Zuckerberg said in a keynote speech at the company‚Äôs Facebook Connect 2021 event, referencing the Apple-Google duopoly. ‚ÄúI‚Äôve come to believe that the lack of choice and high fees are stifling innovation, stopping people from building new things, and holding back the entire internet economy.‚Äù\n\nHe proposed that the metaverse could grow to a billion people in the next decade, hosting ‚Äúhundreds of billions‚Äù of dollars in digital commerce. Analysts like McKinsey & Co. and investment bank Citi backed up this questionable forecast with their own heady estimates of the metaverse becoming a multi-trillion-dollar platform by 2030.\n\nMeta may have had dollar signs in its eyes, but the apps built for the metaverse weren‚Äôt being adopted in massive numbers, at least for a company of Meta‚Äôs size.\n\nThough there‚Äôs no external visibility into Meta‚Äôs own VR app store, you can look at Meta‚Äôs apps with iOS and Android counterparts as a proxy for adoption. According to modeled estimates from app intelligence provider Apptopia, the Meta Horizon app has been downloaded 60.4 million times globally and 39.8 million times in the U.S. since May 2018. A better estimate for adoption, however, is its app activity.\n\nFrom a U.S. panel, Apptopia has figures for the average sessions per daily active user in the U.S., which grew from 3.49 in January 2023 to 4.93 in January 2026. While that‚Äôs still a high-water mark for the app, it may not have been enough for Meta.\n\nFor comparison, outside of VR, Meta now has over 3.5 billion daily active users across its social apps Facebook, Instagram, WhatsApp, and Messenger.\n\nOf course, had this all succeeded, Meta would have created a new social empire, built on the back of VR gaming ‚Äî not unlike Facebook‚Äôs early days as a social network, when partners like Zynga ‚Äî whose games included Farmville, and Words with Friends ‚Äî drove double-digit revenue streams for Facebook. (Ultimately, Facebook‚Äôs 30% cut of virtual goods sales, combined with restrictive platform policies, drove Zynga to launch its own gaming portal and pivot to mobile.)\n\nBut this time, Zuckerberg telegraphed his desire to tap into developer revenue far too soon. Meta might have had a better shot at attracting developers to build for VR if it promised to undercut Apple or Google‚Äôs standard 30% fees, or those of other gaming platforms. Instead, Meta did the opposite: it charged more.\n\nEven before VR became a sizable platform worth investing in, Meta announced its plans to take a whopping 47.5% of the sales of digital assets within Horizon Worlds, consisting of a 30% hardware platform fee and another 17.5% fee for Horizon Worlds itself. Creators, unsurprisingly, were not happy.\n\nAs bad, Meta wasn‚Äôt building the metaverse with user safety as a top priority. As with its rush to scale its social network, the company tended to be reactive rather than proactive about safety features. For instance, the company only rolled out its ‚ÄúPersonal Boundary‚Äù feature, which put a buffer between avatars, after reports that users were experiencing sexual harassment in the metaverse. In some cases, users had even engaged in virtual rape and gang rape in Meta‚Äôs Horizon Worlds. Meta later dialed back the safety feature a bit by adjusting the Personal Boundary to only default to ‚Äúon‚Äù when a user is engaging with ‚Äúnon-friends‚Äù in the metaverse and allowing users to switch it off entirely.\n\nIn May 2022, TechCrunch asked a Meta rep to detail its support measures for Horizon Worlds. The company described several tools, including blocking and reporting features, a ‚Äúsafe zone‚Äù button for users to instantly block and mute others, and a feature to temporarily remove disruptive people from venues that was built in response to user feedback. Despite outlining these tools, Meta declined to say what sort of actions it would take to address individual bad actors‚Äô behavior.\n\nAt the time, users told TechCrunch that those who faced abuse in the metaverse would often react with an obvious move: instead of recording the abuse, they would take off their headset and take a break from VR. But when they returned, their harasser would still appear in their list of recent encounters, and it was too late to submit a report of the abuse with the video and audio attached.\n\nThese types of scenarios were seemingly not thought through from the start, and detailed policies around what constitutes abuse didn‚Äôt exist. When a metaverse code of conduct was later published, it still didn‚Äôt detail any consequences beyond saying Meta would ‚Äútake action on users.‚Äù\n\nAlso around this time, Meta declined to share the makeup of its team building the metaverse with TechCrunch. (But if we had to bet, we‚Äôd guess there weren‚Äôt as many women on the project as men. This would reflect the makeup of Meta overall, so it‚Äôs not a bad bet!)\n\nAnother nail in the proverbial coffin for the metaverse was the success of Meta‚Äôs Ray-Ban AR glasses, which have seen increased consumer interest in recent months. With features like the ability to record hands-free, stream music, and chat with Meta AI, the glasses began to outsell traditional Ray-Bans in some retail stores in 2024. The company is now considering doubling the output of the glasses to meet consumer demand, Bloomberg reported this week.\n\nWith an eye on AI, the company more recently introduced Ray-Ban Display last year, which are similar smart glasses that also include a display for apps, alerts, and directions on the right lens. The company has since paused its international plans for this product, citing ‚Äúunprecedented demand.‚Äù (Or rather, overly conservative inventory forecasting.)\n\nWith other companies, including OpenAI, Amazon, and various startups, looking to hardware AI devices as the next potential computing platform, VR seems even more of a dated relic of a vision for the web that never came to pass.\n\nCombined, these factors, and particularly the adoption of AI as a possible app platform, make it hard for Meta to continue to justify spending on VR. Instead, Meta will focus on the products that have potential, like its Ray Ban and AI glasses, AI app‚Äôs growth, and large language models.",
    "readingTime": 9,
    "keywords": [
      "daily active",
      "headset shipments",
      "meta declined",
      "consumer demand",
      "meta‚Äôs horizon",
      "social network",
      "virtual reality",
      "horizon worlds",
      "personal boundary",
      "metaverse"
    ],
    "qualityScore": 1,
    "link": "https://techcrunch.com/2026/01/19/well-there-goes-the-metaverse/",
    "thumbnail_url": "https://techcrunch.com/wp-content/uploads/2026/01/friends.webp?w=1200",
    "created_at": "2026-01-22T12:27:05.016Z",
    "topic": "tech"
  },
  {
    "slug": "infera-agentic-cli-for-inferring-and-provisioning-cloud-infra",
    "title": "Infera ‚Äì agentic CLI for inferring and provisioning cloud infra",
    "description": "Infera - AI Powered Infrastructure Planning & Provisioning (Powered by Claude Code SDK) - computer-reinvention/infera",
    "fullText": "computer-reinvention\n\n /\n\n infera\n\n Public\n\n Infera - AI Powered Infrastructure Planning & Provisioning (Powered by Claude Code SDK)\n\n License\n\n MIT license\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n computer-reinvention/infera",
    "readingTime": 1,
    "keywords": [
      "infera",
      "powered",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/computer-reinvention/infera",
    "thumbnail_url": "https://opengraph.githubassets.com/c9dff442d70faa91b3e699d7042ed0e39f529e76e3ced8f782c7113eacc61613/computer-reinvention/infera",
    "created_at": "2026-01-22T12:27:04.279Z",
    "topic": "tech"
  },
  {
    "slug": "why-ai-keeps-falling-for-prompt-injection-attacks",
    "title": "Why AI Keeps Falling for Prompt Injection Attacks",
    "description": "Why AI falls for scams that wouldn't trick a fast-food worker‚Äîand what that reveals about AI security.",
    "fullText": "IEEE Spectrum is the flagship publication of the IEEE ‚Äî the world‚Äôs largest professional organization devoted to engineering and applied sciences. Our articles, videos, and infographics inform our readers about developments in technology, engineering, and science.",
    "readingTime": 1,
    "keywords": [
      "engineering",
      "ieee"
    ],
    "qualityScore": 0.2,
    "link": "https://spectrum.ieee.org/prompt-injection-attack",
    "thumbnail_url": "https://spectrum.ieee.org/media-library/image.png?id=62858670&width=1200&height=600&coordinates=0%2C172%2C0%2C172",
    "created_at": "2026-01-22T12:27:03.966Z",
    "topic": "tech"
  },
  {
    "slug": "government-agencies-mandate-cspm-for-federal-cloud-contracts",
    "title": "Government Agencies Mandate CSPM for Federal Cloud Contracts",
    "description": "CEOs don‚Äôt just run companies anymore‚Äîthey represent digital bullseye for cybercriminals. From convincing phishing emails crafted with personal details to AI-generated deepfakes that mimic a leader‚Äôs voice or image, attacks on CEOs and other C-suite leaders have become more targeted, precise, and dangerous.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.systemtek.co.uk/2025/05/executive-protection-in-the-digital-age-how-ceos-are-becoming-prime-cyber-targets/",
    "thumbnail_url": "http://www.systemtek.co.uk/wp-content/uploads/2025/05/CEO-prime-cyber-target.jpg",
    "created_at": "2026-01-22T06:20:37.649Z",
    "topic": "tech"
  },
  {
    "slug": "mnn-fast-lightweight-deep-learning-framework",
    "title": "MNN ‚Äì fast, lightweight deep learning framework",
    "description": "MNN is a blazing fast, lightweight deep learning framework, battle-tested by business-critical use cases in Alibaba. Full multimodal LLM Android App:[MNN-LLM-Android](./apps/Android/MnnLlmChat/READ...",
    "fullText": "alibaba\n\n /\n\n MNN\n\n Public\n\n MNN is a blazing fast, lightweight deep learning framework, battle-tested by business-critical use cases in Alibaba. Full multimodal LLM Android App:[MNN-LLM-Android](./apps/Android/MnnLlmChat/README.md). MNN TaoAvatar Android - Local 3D Avatar Intelligence: apps/Android/Mnn3dAvatar/README.md\n\n www.mnn.zone/\n\n License\n\n Apache-2.0 license\n\n 14k\n stars\n\n 2.2k\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n alibaba/MNN",
    "readingTime": 1,
    "keywords": [
      "android",
      "alibaba",
      "license"
    ],
    "qualityScore": 0.65,
    "link": "https://github.com/alibaba/MNN",
    "thumbnail_url": "https://opengraph.githubassets.com/6afcc07063d3bfbf527b1024d6427e1cc3ba0bbedcfd91446f7361a79a748b1f/alibaba/MNN",
    "created_at": "2026-01-22T00:59:15.698Z",
    "topic": "tech"
  },
  {
    "slug": "ai-systems-performance-engineering",
    "title": "AI Systems Performance Engineering",
    "description": "Contribute to cfregly/ai-performance-engineering development by creating an account on GitHub.",
    "fullText": "cfregly\n\n /\n\n ai-performance-engineering\n\n Public\n\n License\n\n Apache-2.0 license\n\n 968\n stars\n\n 134\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n cfregly/ai-performance-engineering",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/cfregly/ai-performance-engineering",
    "thumbnail_url": "https://opengraph.githubassets.com/821a0056b72b23f9cd26ddd6943614ce37b50c900dd7ac56b45a8b17aca24f30/cfregly/ai-performance-engineering",
    "created_at": "2026-01-22T00:59:15.645Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-ceo-jensen-huang-says-a-lot-of-sixfigure-jobs-in-plumbing-and-construction-are-about-to-be-unlocked-because",
    "title": "Nvidia CEO Jensen Huang says ‚Äòa lot‚Äô of six-figure jobs in plumbing and construction are about to be unlocked because someone needs to build all these new AI centers",
    "description": "The AI boom is threatening white-collar entry jobs‚Äîbut it‚Äôs creating a booming six-figure opportunity for electricians, plumbers, and construction workers.",
    "fullText": "The job market has been a tough sell for many Gen Z graduates, with tariffs, economic uncertainty, and artificial intelligence reshaping hiring plans across corporate America. But according to Nvidia‚Äôs CEO Jensen Huang, the next wave of six-figure opportunities won‚Äôt be found in a Wall Street cubicle or Silicon Valley Slack channel. Instead, high-paying careers will partially come by picking up a wrench‚Äîliterally.\n\nAs tech giants race to build sprawling data centers‚Äîtotaling $7 trillion in global capital outlays by the end of the decade‚ÄîHuang believes the world is on the cusp of what he calls the ‚Äúlargest infrastructure buildout in human history,‚Äù which will create ‚Äúa lot of jobs.‚Äù\n\n‚ÄúIt‚Äôs wonderful that the jobs are related to tradecraft, and we‚Äôre going to have plumbers and electricians and construction and steelworkers,‚Äù he said in conversation with BlackRock CEO Larry Fink at the World Economic Forum in Davos, Switzerland.\n\nThe hands-on skills needed to construct what he described as chip, computer, and AI factories are already facing shortages‚Äîeven though many roles pay over $100,000 without requiring a college degree. One McKinsey report estimated that between 2023 and 2030, there will be a need for an additional 130,000 trained electricians‚Äîas well as 240,000 construction laborers and 150,000 construction supervisors‚Äîin the U.S. alone.\n\n‚ÄúEverybody should be able to make a great living,‚Äù Huang said. ‚ÄúYou don‚Äôt need to have a Ph.D. in computer science to do so.‚Äù\n\nThis isn‚Äôt the first time Huang has expressed his optimistic outlook on new career paths emerging alongside AI.\n\n‚ÄúThe skilled craft segment of every economy is going to see a boom,‚Äù he told Channel 4 News in the U.K. last year. ‚ÄúYou‚Äôre going to have to be doubling and doubling and doubling every single year.‚Äù\n\nThat optimism stands in contrast to warnings from leaders like Ford CEO Jim Farley, who has repeatedly cautioned that AI is hollowing out traditional white-collar entry points‚Äîjust as the education system continues to funnel students toward four-year degrees.\n\n‚ÄúThere‚Äôs more than one way to the American Dream, but our whole education system is focused on four-year [college] education,‚Äù Farley said at the Aspen Ideas Festival last year. ‚ÄúHiring an entry worker at a tech company has fallen 50% since 2019. Is that really where we want all of our kids to go? Artificial intelligence is gonna replace literally half of all white-collar workers in the U.S.‚Äù",
    "readingTime": 2,
    "keywords": [
      "artificial intelligence",
      "education system",
      "construction",
      "doubling",
      "hiring",
      "tech",
      "jobs",
      "computer",
      "college",
      "white-collar"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/nvidia-ceo-jensen-huang-says-160735219.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/AVfx3XSS96moXvxXLt9zTw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/4062994d1bf7ae6ff8233554daa0c275",
    "created_at": "2026-01-22T00:59:12.475Z",
    "topic": "finance"
  },
  {
    "slug": "ai-adoption-is-accelerating-but-confidence-is-collapsing-the-more-workers-use-ai-the-less-they-trust-it-baby-boomers",
    "title": "‚ÄòAI adoption is accelerating, but confidence is collapsing‚Äô: The more workers use AI, the less they trust it. Baby boomers show a 35% drop",
    "description": "A study of 14,000 workers across 19 countries shows a toxic relationship, as many companies rush to adopt the technology without proper training.",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/01/21/ai-workers-toxic-relationship-trust-confidence-collapses-training-manpower-group/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/01/GettyImages-157752806.jpg?resize=1200,600",
    "created_at": "2026-01-22T00:59:12.462Z",
    "topic": "business"
  },
  {
    "slug": "google-just-promised-no-ads-in-gemini-for-now",
    "title": "Google Just Promised No Ads in Gemini (for Now)",
    "description": "The statement comes about a week after OpenAI announced ads are coming to ChatGPT.",
    "fullText": "A week after OpenAI admitted it will soon start testing ads in ChatGPT, Google has promised that it's not planning to inject ads into Gemini anytime soon.\n\nThe statement was given to journalist Alex Heath during the World Economic Forum in Davos, Switzerland. Google DeepMind CEO Demis Hassabis said the company doesn't have \"any plans\" for ads in Gemini. While the statement was fairly brief, it also jibes with a similar quote Hassabis gave to Axios, where he said he was \"a little bit surprised\" that OpenAI was already introducing ads to ChatGPT.\n\nThat surprise is understandable, especially because OpenAI CEO Sam Altman said in 2024 that he considered ads a \"last resort for us as a business model.\" But looking at the numbers, it makes sense that ChatGPT is getting ads long before Gemini is even thinking of them.\n\nWhile Google makes most of its money through showing people ads, it's also able to rely on Search and YouTube to push ads to most of those eyeballs. Meanwhile, OpenAI is pretty much just ChatGPT. As the latter moves to a for-profit model, it now has to put moneymaking first, something it's had trouble doing without relying on traditional internet moneymakers like ads. Google, meanwhile, is already profitable elsewhere, and is able to take its time and use its sheer size to keep Gemini ad-free, at least while it continues to chase market share.\n\nDoes this mean Google's AI will never get ads? Well, never say never. But it does mean that they're probably not on the horizon‚Äîeven if Google plans to more aggressively monetize Gemini over the long term, it isn't facing the same kind of time crunch as Altman's company.\n\nIt remains to be seen whether the presence of ads will push users away from ChatGPT, but the move comes in the wake of significant wins for Gemini and one major loss for ChatGPT. First, Google's Nano Banana image editing model went viral on social media, winning over the general public. Then, Google struck a deal with Apple to put its AI into the iPhone, and it looks like Gemini will be powering Siri for the foreseeable future.\n\nMeanwhile, ChatGPT reportedly saw a 6% dip in users early last month, following a model update from Gemini‚Äîand that was before the introdution of ads. While ChatGPT still seems to be in the lead on total user count, there's evidence that Google is catching up.\n\nThe divide in strategy seems clear: As OpenAI seeks ways to get more money out of its existing user base, Google can focus on growing its own with new integrations into the products we already use every day. I can't say what the limits of this growth are, but I can say that I rarely go out of my way use AI, yet I've still found myself accidentally relying on Google's AI overviews every now and then. If Google can get more people like me to casually integrate AI into our regular workflows, it's possible we could soon have a new AI leader on our hands.",
    "readingTime": 3,
    "keywords": [
      "google's ai",
      "it's",
      "model",
      "soon",
      "google",
      "chatgpt",
      "gemini",
      "statement",
      "hassabis",
      "plans"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/google-just-promised-no-ads-in-gemini-for-now?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KFGZ1E3E2BQZ7DBB464WC469/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-22T00:59:09.618Z",
    "topic": "tech"
  },
  {
    "slug": "apple-might-turn-siri-into-an-ai-chatbot-to-rival-chatgpt",
    "title": "Apple Might Turn Siri Into an AI Chatbot to Rival ChatGPT",
    "description": "It could be ChatGPT's next big competitor.",
    "fullText": "Last week, Apple finally admitted it will need to team up with Google to finally make good on that contextual Siri promise it made two years ago, which would have allowed the virtual assistant to integrate with content like your texts or emails to answer personal questions and take actions for you. Now, according to a new report, the iPhone company might actually go one step further and turn Siri into a full-fledged AI chatbot‚Äîone on par with the likes of ChatGPT, and perhaps even more sophisticated.\n\nCurrently, Siri has AI implementation, but only technically, and it's certainly underwhelming: You can use it to get tech support on Apple products or shunt questions off to ChatGPT, but otherwise, Siri basically works as it always has. But according to Bloomberg's Mark Gurman, who has reliably reported on insider information at Apple before, the company is finally not only looking to make Siri smarter, but also change the way you interact with it. Currently planned for iOS and macOS 27 under the name \"Campos,\" Siri's new chatbot interface will still be powered by Gemini, but will allow you to both type and talk to Siri, with full continuity between your conversations. This upgrade will be in addition to the overdue features that were already announced.\n\nIn other words, it'll look something like the chatbot interface from the ChatGPT app or the standalone Gemini app. Yes, you can technically type to Siri right now, but it mostly works like a separate input method, rather than as a full conversation. You can't scroll through your previous questions to Siri or peruse the assistant's previous answers, and if you ask Siri to reference a message you sent it two weeks ago, it'll have no idea what you mean. That's far behind what other AI chatbots offer right now.\n\nThe update will also apparently further expand Siri's capabilities even beyond the contextual or personalization upgrades that were already revealed. Gurman says that, while the contextual upgrades will be able to pull information from other apps like Messages, the chatbot-style Siri will be \"integrated into all of the company's core apps, including ones for mail, music, podcasts, TV, Xcode programming software and photos.\" Essentially, Siri will have more access to your iPhone than other AI chatbots, and those integrations will go beyond what was previously promised. That could make it more or less appealing to you, depending on your tastes in AI integration.\n\nWith the chatbot interface planned for iOS 27, it's likely to come after the contextual upgrades, rather than at the same time. That's because, as Gurman said previously, those upgrades are set for the spring. He predicts we'll learn more about it during this year's WWDC, which, if it follows the standard set by previous years, will take place in June.\n\nThe move to turn Siri into a chatbot could come across as a a much-overdue modernization, as Google has already done the same with Gemini over on Android, but it's also a bit of a surprise, as Apple had previously said it did not intend to turn Siri into a \"bolt-on chatbot on the side\" for Apple Intelligence.\n\nBut Apple was likely talking about quality of the experience rather than expressing any significant anti-chatbot bias among the development team, meaning the fact that Siri is turning into a chatbot could mean the company is finally happy with the direction it's headed. But it's also possible that the professed skepticism about turning Siri into a chatbot was meant to appeal to AI skeptics in general. Unfortunately, if you're still skeptical about AI, it currently seems like iOS 27 will be a boring update for you, as Gurman indicated the new Siri chatbot will be the \"primary new addition\" to the operating system.\n\nHowever you feel about it personally, Siri as a full-fledged AI chatbot could seriously upset ChatGPT's market dominance‚Äîironic, given its early integration with Apple Intelligence. Currently, OpenAI has reportedly admitted it's in a Code Red situation, as it is losing market share to Google and introducing ads to bolster its bottom line. The new Siri, being powered by Gemini, is unlikely to hurt Google (although it will have more access to your phone than the standalone Gemini app), but its ease-of-access might make it the new go-to for iPhone users, and that could hurt pretty much every AI company Apple isn't in business with directly.",
    "readingTime": 4,
    "keywords": [
      "standalone gemini",
      "gemini app",
      "apple intelligence",
      "contextual upgrades",
      "chatbot interface",
      "it's",
      "siri",
      "finally",
      "google",
      "iphone"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/apple-siri-chatbot-ai-plans?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KFH7N4CFDDEPBSQ5VKSC72K1/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-22T00:59:09.513Z",
    "topic": "tech"
  },
  {
    "slug": "nvidias-jensen-huang-says-its-a-good-time-to-be-a-plumber-and-not-just-because-its-an-aiproof-job",
    "title": "Nvidia's Jensen Huang says it's a good time to be a plumber ‚Äî and not just because it's an AI-proof job",
    "description": "The massive AI buildout is demanding more manual labor jobs such as plumbers and electricians. Jensen Huang says salaries are surging as a result.",
    "fullText": "Is AI coming for your job? If you work in construction or plumbing, that's perhaps not a question you need to worry about.\n\nSpeaking at the World Economic Forum on Wednesday, Nvidia CEO Jensen Huang said it was a great time to be a tradesperson because the AI boom is creating demand for manual labor to build data centers.\n\n\"It's wonderful that the jobs are related to tradecraft and we're going to have plumbers and electricians and construction and steelworkers,\" he said in a conversation with BlackRock CEO Larry Fink in Davos, Switzerland.\n\nHuang described the AI boom as the \"largest infrastructure buildout in human history\" that would create \"a lot of jobs.\"\n\nAI's impact on the labor market has been a hot topic at Davos this year. Huang has long argued that AI won't be the mass job killer some believe it will be. He has given radiology as an example: while AI has automated some of the tasks radiologists do, the number of jobs in the field has actually increased.\n\nAI \"Godfather\" Geoffrey Hinton previously said he also believes manual labor is safer from AI, though for a different reason: it will take longer for AI to have the dexterity to take on more physical jobs.\n\nAt Davos on Wednesday, Huang said the US was seeing a \"significant boom\" in demand for manual jobs helping build AI infrastructure, with salaries nearly doubling in some cases.\n\n\"So we're talking about six-figure salaries for people who are building chip factories or computer factories or AI factories, and we have a great shortage in that,\" said Huang.\n\nHe added: \"Everybody should be able to make a great living. You don't need to have a Ph.D. in computer science to do so.\"",
    "readingTime": 2,
    "keywords": [
      "manual labor",
      "jobs",
      "boom",
      "factories",
      "construction",
      "demand",
      "we're",
      "infrastructure",
      "salaries",
      "computer"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/nvidia-jensen-huang-plumber-construction-jobs-ai-data-center-2026-1",
    "thumbnail_url": "https://i.insider.com/6970bbc7e1ba468a96aa677d?width=1200&format=jpeg",
    "created_at": "2026-01-21T18:30:50.598Z",
    "topic": "finance"
  },
  {
    "slug": "a-veteran-investor-tears-into-openai-chaos-and-says-the-markets-smart-money-is-pouring-into-smallcap-stocks",
    "title": "A veteran investor tears into OpenAI 'chaos,' and says the market's smart money is pouring into small-cap stocks",
    "description": "Hedge fund founder George Noble says OpenAI is a warning for the wider AI boom. He says the \"low hanging fruit is gone\" as AI costs increase.",
    "fullText": "OpenAI has laid out some ambitious plans for 2026, but according to George Noble, the ChatGPT maker is a cautionary tale for the wider AI theme.\n\nThe hedge fund investor and former director of the Fidelity Overseas Fund doesn't think the AI startup will be able to justify its lofty growth projections, but more than that, he thinks investors should avoid the AI trade and shift their focus to other areas of the market before the tide turns.\n\nThe hedge fund founder laid out his thesis on OpenAI's red flags in a detailed X post on Tuesday, highlighting the \"code red\" moment announced by CEO Sam Altman in December 2025.\n\nIn his view, it all comes down to financials, specifically a math problem that isn't being widely discussed. \n\n\"It's going to cost 5x the energy and money to make these models 2x better,\" he said. \"The low-hanging fruit is gone. Every incremental improvement now requires exponentially more compute, more data centers, more power.\"\n\nNoble thinks OpenAI's annual revenue has to reach $200 billion by 2030 in order for the company's projections to be justified.\n\nPointing to the broader market, he advised AI startup founders to exit their companies while the boom is still going, adding that he believes the AI hype cycle is nearing its peak. He thinks investors should shift their focus to other parts of the market, as both the AI trade and the Magnificent Seven will be impacted if OpenAI begins to struggle.\n\n\"If you're exposed to the Magnificent 7 through AI infrastructure bets, consider trimming,\" he advised. \"The smart money is rotating into sectors where valuations actually reflect fundamentals.\"\n\nThe particular sector in this case is small-mid cap stocks, which is where Noble sees real value and growth potential. He added that there is a value disconnect between Big Tech stocks and their small-cap peers, which are trading at near-decade lows.\n\nFor that reason, Noble sees an opportunity for investors to move away from the most crowded stocks that carried the AI trade in 2025 and focus on the lesser-known value plays that have been quietly making progress while AI-linked names continue to dominate the headlines.\n\n\"Markets can price risk,\" he noted. \"But they can't price chaos.\nAnd OpenAI is chaos dressed up in a $500 billion valuation.\"",
    "readingTime": 2,
    "keywords": [
      "hedge fund",
      "investors",
      "trade",
      "focus",
      "market",
      "stocks",
      "laid",
      "startup",
      "growth",
      "projections"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/openai-chatgpt-george-noble-magnificent-7-warning-ai-bubble-tech-2026-1",
    "thumbnail_url": "https://i.insider.com/6970ecc0e1ba468a96aa6c07?width=1200&format=jpeg",
    "created_at": "2026-01-21T18:30:50.119Z",
    "topic": "finance"
  },
  {
    "slug": "solopreneurs-are-embracing-ai-heres-how-3-career-coaches-have-found-it-indispensable",
    "title": "Solopreneurs are embracing AI ‚Äî here's how 3 career coaches have found it indispensable",
    "description": "AI tools like ChatGPT, Gemini, and Claude help solopreneur coaches Kim Surko, Katharine Campbell Hirst, and Liz Morrison boost client outcomes and streamline coaching workflows.",
    "fullText": "When it comes to career and executive coaching, some of the most important work happens in one-on-one sessions with the client. That's when breakthrough insights often emerge, motivation gains momentum, and coaches build an essential connection.\n\nThen comes the hard part: turning those words into actions.\n\nTranscribing conversations into meaningful action items for clients takes time and effort ‚Äî something a team of assistants could easily handle. However, when you're the only person running your business, that time and effort leaves coaching solopreneurs with a difficult tradeoff: take notes during sessions and sacrifice presence, spend hours after each call transcribing insights from recordings, or leave follow-through entirely to clients.\n\n\"Trying to juggle it all on my own wasn't an option ‚Äî it was just impossible to build a sustainable business,\" said Kim Surko, founder of leadership coaching business Surko Coaching, regarding how easy it was to feel overwhelmed by work that felt more administrative than transformational. \"Leaning into AI was the most natural solution to help with all of that responsibility.\"\n\nHere's how three solopreneurs in leadership, business, and communications have used AI to help clients achieve more results in less time, expanding their capacity as coaches while increasing the value of the work they offer.\n\nFor all three coaches, the biggest game changer has been using AI note-takers to distill long conversations into something more tangible.\n\nAfter getting client consent, \"I record my coaching sessions and upload transcripts into ChatGPT. This allows me to rapidly transform nuanced insights from our conversations into concrete outputs clients can actually use ‚Äî pitches, r√©sum√©s, website copy, positioning statements, and more,\" said Katharine Campbell Hirst, founder of business coaching company KCH Coaching & Advisory. \"What used to take weeks of agonizing refinement now takes minutes.\"\n\nLiz Morrison, founder of communications coaching company LM Strategic Storytelling, appreciates how AI ensures that valuable sound bites from her coaching sessions don't get lost in hours of recordings that nobody has time to revisit. She's built custom projects in Claude to help her transform session transcripts into \"Story Banks\" in minutes ‚Äî pulling out three to six narratives per session that clients can use immediately for interviews, networking, social media, and building their businesses.\n\nWhile this type of work was essential before AI, doing it as a solopreneur meant sacrificing time that could be spent supporting other clients. \"I've saved almost an hour per client per day by relying on AI to take notes and summarize them for me,\" said Surko, who added that she nearly doubled her capacity for coaching clients with AI's support.\n\nSurko has also used AI to help her clients appreciate the progress they're making, improving the feeling of momentum. \"A lot of work with coaching is celebrating the small wins,\" she said.\n\nUsing the project management tool Kanbanchi, supported by Gemini, Surko can quickly update to-do list boards that lay out all of the client's goals and achievements.\n\n\"Having that visual representation of the progress we're making shows the value of coaching,\" Surko said. The process has been extremely valuable, as it has improved her client renewal rate because clients can see exactly how they're getting closer to a goal, rather than feeling like they aren't making progress, she added.\n\nMorrison tells a similar story. She built a custom ChatGPT tool called Story Explorer that walks prospective clients through a story-coaching exercise to uncover one immediately usable story they can post on LinkedIn or use in a networking conversation.\n\n\"I find when I give people this builder, it's the start of a much bigger conversation,\" she said. They often uncover other narratives they want to explore further with Morrison, she said.\n\nAlongside the benefit of being more present during conversations, these coaches have found AI valuable for improving their in-session coaching in other ways.\n\nSurko, for example, used Gemini within Google Docs to create a searchable archive of the massive toolkit of exercises and prompts she's collected in her decadeslong career, which before were buried in various folders.\n\nPreviously, she would have to wait until after the session to hunt down an exercise. Now, she can quickly pull them up during sessions and dive deeper with a client. \"We make more progress in each session,\" she said of this improvement. \"We're able to continue that momentum.\"\n\nAI can even be a helpful coach for these coaching experts.\n\nHirst uploaded transcripts across her client's full arc and asked where she did well and where she could have improved. While she also works with coaches, she appreciates that AI can effectively be over her shoulder all the time.\n\n\"The feedback is surprisingly concrete, pattern-based, and immediately actionable ‚Äî effectively giving me a reflective practice partner I wouldn't otherwise have access to as a solopreneur,\" Hirst said.",
    "readingTime": 4,
    "keywords": [
      "coaching sessions",
      "clients",
      "client",
      "coaches",
      "business",
      "conversations",
      "progress",
      "insights",
      "momentum",
      "founder"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/3-coaching-solopreneurs-how-ai-help-their-businesses-grow-2026-1",
    "thumbnail_url": "https://i.insider.com/696a8b9ee1ba468a96aa3c19?width=1200&format=jpeg",
    "created_at": "2026-01-21T18:30:49.965Z",
    "topic": "finance"
  },
  {
    "slug": "manage-your-ai-investments-like-a-portfolio",
    "title": "Manage Your AI Investments Like a Portfolio",
    "description": "Companies should apply a step-by-step portfolio management approach when it comes to AI. They should view the connected portfolio through a dual lens: first, as an advancement pipeline with clear gates through which projects must pass; and second, as a whole-portfolio dashboard that shows balances across risk/return, time horizon, capability areas, and mission alignment. This dual perspective enables both rigorous project-level discipline and strategic portfolio-level optimization.",
    "fullText": "Manage Your AI Investments Like a Portfolio by Faisal Hoque, Erik Nelson, Tom Davenport and Paul ScadeJanuary 21, 2026PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintBusiness leaders now face intense pressure to transform their organizations with AI, even though the technology, public attitudes, and the competitive landscape are all still in flux. The result is often too many pilots with too little coordinated oversight. Without a way to systematically decide where to start, how fast to move, and when to stop, AI efforts quickly become a drain on attention and resources rather than a source of advantage. A familiar pattern recurs across many companies: isolated, piecemeal deployments, limited buy-in by senior executives, and weak linkage to strategic goals.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/01/manage-your-ai-investments-like-a-portfolio",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Jan26_21_2178861789.jpg",
    "created_at": "2026-01-21T18:30:49.138Z",
    "topic": "business"
  },
  {
    "slug": "digg-is-back",
    "title": "Digg Is Back",
    "description": "Digg's new beta is aiming to take on Reddit, with a new design and an AI-narrated podcast.",
    "fullText": "Back before Reddit became the unofficial \"front page of the internet,\" you would dig up your next long read or binge watch on Digg. Starting in 2004, the original version of the site worked much like Reddit does today, with community members submitting content they found interesting to premade category pages and others voting on it until an algorithm eventually decided what should make its way to the front page. Aside from the lack of user-made pages like subreddits, it was generally pretty familiar to what modern users might expect‚Äîand, speaking from experience, it was a big deal to be featured on Digg.\n\nUnfortunately, starting in 2010, the site went through a few drastic redesigns that added controversial features like the DiggBar (a clunky toolbar that would display over content) and got rid of features like burying (the equivalent of modern downvoting). It bounced from owner to owner and experimented with new formats like a manually curated front page, but by that point, Reddit had become the behemoth it's known as today. It was hard for Digg to keep up.\n\nNow, after Reddit has spent years saddled with its own controversies, Digg is back with yet another relaunch, with a new beta from original founder Kevin Rose and Reddit co-founder Alexis Ohanian that aim to combine the best of both site's legacies.\n\nLast week, Rose and Ohanian opened their new Digg to the public, debuting a new design that looks a lot like Reddit, but cleaner. On desktop, the sidebar on the left uses icons rather than labels, and generally has fewer complications, so no distracting \"games on Reddit\" tab. To the right of that, you get your main, infinite scrolling feed, and I'll admit, I like the classic blue-on-white color scheme (although you can use dark mode if you like). Unlike the classic Digg, this feed will include user-made communities, which work like subreddits, so you can join and leave them at any time to curate what you see. And yes, the downvote is back, along with full commenting functionality. You can also swap over from a feed that only shows communities you're subscribed to (My Feed) to one that collects the best posts across Digg (All Digg) with a button up top, which is one pretty significant difference‚ÄîReddit has the r/all subreddit, but it requires navigating away from your main feed and isn't available in the app.\n\nBut the big difference maker is in the right sidebar, which shows recent posts on Reddit, but \"Digg Daily\" on Digg. This shows trending posts and featured communities at a glance, so you can get caught up with news without having to scroll the \"All Digg\" feed for too long, but curiously, it's also got the \"Digg Daily\" podcast. This one addition is probably the most significant way the new Digg differs from Reddit, and also the most awkward.\n\nIt had to be here somewhere‚ÄîDigg Daily is the site's implementation of AI. Updated once a day, this brief five-ish minute podcast recaps the biggest stories on the site that day, using AI hosts that sound like slightly more robotic versions of the ones you'll get on Google's NotebookLM. You'll get a few sentences talking about the story's original source (which, when I listened, did credit the author of the article being discussed), as well as a few quotes from readers. Unfortunately, while you can bring up chapters to jump ahead in Digg Daily and see a list of discussed topics, there aren't any links to find either the sources or Digg posts being discussed, and the \"Featured Posts\" bar below Digg Daily doesn't relate to what's on the podcast at all.\n\nIt's a nice idea, but aside from getting a high-level overview of what was popular on the site that day, I didn't find it too useful. Summaries are extremely short, and comments are awkward to hear outside of their original context. It might be a good first step to know what to search the site for, but links would really help it out.\n\nOn the plus side, Digg Daily might not always be AI: The company said during an interview with TechCrunch that it might swap out the robotic hosts for human ones following user feedback. Human lead curation could help the recaps feel a bit more natural, and even bring back some elements from the eras of Digg where the front page was managed by a staff rather than an algorithm.\n\nAside from the different look and minor additions like Digg Daily, getting started on Digg should be pretty familiar for anyone who's used Reddit. The mobile app also has full functionality, although sidebar features have been moved to buttons above and below the main feeds. But there are a few ways the platform is looking to grow.\n\nThe big one is probably communities, or Digg's version of subreddits. The site launched with 21 default communities off the bat, but it'll take a while for user-made communities to pop up for more obscure topics. For instance, I've been replaying the Mega Man: Battle Network games from my youth a lot lately, and while there are multiple regularly updated subreddits for that series with thousands of members each, there's not a Digg community for them yet. It sounds like a small complaint, but one of Reddit's big strengths is that you can just Google \"[topic] + reddit\" and probably find an answer to whatever question you might have, no matter how small. Without years of posts on topics both big and small to lean on, it'll take Digg some time to catch up.\n\nYou can help with that by starting a community, but weirdly, communities right now can only have a single moderator, so be prepared to do a lot of heavy lifting.\n\nHowever, the growing pains aren't all bad. Personally, I can't stand that modern Reddit pushes users to theme their avatars around its mascot, and buries the button to just upload their own images deep in the Settings page. Especially because the best options for dressing up your avatar are paywalled. Digg doesn't have any paywall or mascot dress-up feature, so uploading your own photo to be your Digg avatar is the only way to go. Overall, it's a less bloated experience.\n\nWhile Digg might be light on features now, it does have the basics down, and that TechCrunch interview pointed to more possibilities coming down the line. For instance, the owners might be using AI in some ways, but they're also big on fighting AI spam. They said they're not opting for one universal solution, but are looking at options on a case-by-case basis.\n\nIn the interview, they discussed possibly forcing users of a community based around a product to prove they own that product before they can post. Similar suggested solutions were using location data to see if community members had attended in-person meetups, although that raises privacy concerns.\n\n\"I don't think there's going to be any one silver bullet here,\" Rose told TechCrunch, but the general idea is to build trust and ensure users are authentic while remaining non-intrusive. This would help keep suspicious writing that sounds like ad copy or political brigading off the site, but would also keep users from having to upload personal data or pay for a one-time verification badge. Given that thousands of subreddits famously went dark in 2023 over a lack of trust between moderators and the site's owners, it's a noble goal, at least. It also tracks with Digg's promises of more public moderation and relaxed ownership of user-generated material, although I'll leave legal experts to comment on those in detail.\n\nOverall, it's encouraging that most of the features being discussed here are about core posting usability, although there are a few fun ideas sprinkled in, too, including plans to allow users to customize the look and feel of their communities, as well as add integrations with other sites‚Äîfor instance, allowing Letterboxd scores to natively show up on a movies community.\n\nIf this all sounds interesting to you, you can try the Digg beta right now, and despite that \"beta\" name, it's not too different from signing up for any other site. Just navigate to Digg.com or download the Digg app, click the \"Signup/Login\" button at the top of the feed, enter an email, and claim a username. After you authenticate using a code sent to your email, you should be all set to start scrolling and subscribing to communities.\n\nOr, you can scroll without being signed in, if you're OK with using the default feed. You can also still visit individual communities, by searching for them in the site's search bar.",
    "readingTime": 8,
    "keywords": [
      "overall it's",
      "digg daily",
      "pretty familiar",
      "front page",
      "user-made communities",
      "site",
      "community",
      "users",
      "subreddits",
      "features"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/digg-is-back?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KFEHYRATCZSP56NA675AK5FS/hero-image.fill.size_1200x675.png",
    "created_at": "2026-01-21T18:30:48.159Z",
    "topic": "tech"
  },
  {
    "slug": "genai-the-snake-eating-its-own-tail",
    "title": "GenAI, the Snake Eating Its Own Tail",
    "description": "Generative artificial intelligence (GenAI) tools such as ChatGPT and Claude have two superpowers. The first  superpower is a boon: they can dramatically increase ...",
    "fullText": "Generative artificial intelligence (GenAI) tools such as ChatGPT and Claude have two superpowers. The first \nsuperpower is a boon: they can dramatically increase human productivity. I use them on a regular basis to answer \nquestions, learn new skills, write code, create images, and much more, all at a rate of speed and quality that was\nscience fiction just a few years ago. The second superpower is a bane: GenAI is quietly destroying the very \necosystems that made it possible in the first place.\n\nUnder the hood, GenAI is built on large language models (LLMs), which are able to extract patterns, structure, and\nstatistical relationships from massive data sets. These data sets consist primarily of content created by human beings: \nbooks, blog posts, articles, forum discussions, open source code, art, photography, and so on. LLMs are able to extract \nvalue from this content at an unprecedented scale, but all that value is captured by the GenAI company and its users. \nIf you‚Äôre a content creator, you get nothing: no attribution, no referral traffic, no revenue share. Not even a \nthank-you.\n\nThis feels unsustainable to me, a bit like a snake eating its own tail. In this blog post, I‚Äôll go through three\nexamples of how GenAI is destroying the very ecosystems it relies on, and then discuss possible solutions that may\ngive everyone (users, GenAI companies, and content creators) more value.\n\nFor many years, StackOverflow was the most popular Q&A site for programmers. Any time you \nhit a weird error while coding, you‚Äôd do a search on Google, and more often than not, find a good answer on \nStackOverflow. But now, in large part due to GenAI, StackOverflow is nearly dead:\n\nAlthough StackOverflow‚Äôs decline started before GenAI went mainstream (ChatGPT was first released in 2022), GenAI\naccelerated that decline considerably. That‚Äôs because nowadays, instead of searching around for an answer on a Q&A site,\nand working to adapt that answer to your own codebase, you can ask GenAI tools to generate your code, fix any errors\nyou hit, answer any questions you run into, and so on. As a result, you‚Äôre considerably more productive.\n\nBut it doesn‚Äôt seem sustainable. A big part of why GenAI tools can answer programming questions and fix errors in your \ncode is because those tools were trained on StackOverflow data. So you as a programmer and the GenAI tool now \nget much more value from that data, but StackOverflow gets none. If people stop asking and answering questions, what \nwill GenAI train on in the future?\n\nI also get the impression that StackOverflow is not the only online community where this is happening. For example, \nQuora seems largely dead. Wikipedia is\nfacing more threats than ever.\nAnd although Reddit‚Äôs traffic numbers don‚Äôt show it, I (and many other Redditors) get the impression that it‚Äôs also \ndying.1\n\nTailwind CSS is a popular library programmers use to style and decorate their websites. In\nfact, according to the 2025 State of CSS Survey, Tailwind is the\nmost popular CSS library, by far:\n\nAnd Tailwind usage only seems to be growing:\n\nDespite that, just a couple of weeks ago, the Tailwind team had to lay off 75% of its \nstaff. Why? The company behind\nTailwind CSS makes its money by selling a premium upgrade to the open source library called\nTailwind UI, which gives you a set of reusable, pre-built, professionally designed\ncomponents for building out your website. This was a great offering in the past, but in the age of GenAI, it‚Äôs more\nproblematic:\n\nSo developers are getting lots of value from Tailwind, GenAI is getting lots of value from Tailwind, but the creators\nof Tailwind are getting crushed. I suspect something similar will happen with many other open source projects.2\n\nWhen my latest book, Fundamentals of DevOps and Software Delivery, came \nout last year, a friend of mine asked me an interesting question:\n\nIn the age of LLMs, will people still use books to learn the fundamentals?\n\nI‚Äôm an avid reader, and still believe books play a key role in learning, but there‚Äôs no doubt that LLMs provide a new\nmethod of learning that is incredibly compelling. GenAI has two remarkable qualities that make it a great teacher:\n\nYou can ask it all the questions you want, with no fear of sounding dumb. You can repeat the same question over and \nover again if something isn‚Äôt clicking. You can request it to explain things in different ways: via text, via audio,\nvia diagrams. I‚Äôve used GenAI to learned dozens of new things over just the last few months: how to do DIY \nprojects around the house, how to rehab a minor injury, how to cook eggs without giving them a sulfuric taste/smell,\nand much more. And I learned most of these without reading anyone‚Äôs book or blog.\n\nAnd that‚Äôs a problem. Much of the content I got from the GenAI tools was extracted from books and blog posts, with\nno attribution. Even worse, some of this content was extracted illegally. Last year, Anthropic agreed to pay $1.5B\nto settle a class-action \nlawsuit for training their\nLLMs on over 500,000 pirated books. That included several of my previous books!3\n\nThis class-action lawsuit might sound like a win for authors, but it‚Äôs actually a disaster. There are likely many\nAI companies training on pirated data who haven‚Äôt been caught. And even if they are caught, they might not\nbe sued. And even if they are sued, they might not lose or settle. And even if they do, they will just see it as the\ncost of doing business. Anthropic recently raised $13B, reported revenue at $5B per year, and is valued at \n$183B; OpenAI is trying\nto raise $100B, with reported revenue of $20B per year, and a valuation of \n$830B. And all these\nnumbers are growing fast. A $1.5B fine is just a drop in the bucket for companies like this. It‚Äôs a risk worth taking.\n\nAnd I‚Äôm guessing all the GenAI companies are taking that risk. In another lawsuit, OpenAI\nargued that it‚Äôs ‚Äòimpossible‚Äô to create AI tools like ChatGPT without copyrighted \nmaterial. If that‚Äôs\nwhat it takes to get to an $830B valuation, you better believe they are all going to steal and pirate as much \ncontent as possible. And when they do, the creators of that content will get nothing. Nada. $0.\n\nThere are countless other examples where GenAI is benefiting from content, while giving nothing back to the content\ncreators: e.g., art, music, design, movies, copywriting, and so on. At its root, the GenAI model is broken:\n\nDid you notice what‚Äôs missing? The user has a way to get value (step 4), the GenAI company has a way to get value \n(step 3), but the content creator gets nothing. Compare this to the search engine model (e.g., Google Search), which is \nwhat we all used before GenAI came along:\n\nThe search engine model was not perfect, but it at least created the opportunity for all parties in this three-sided \nmarketplace to capture value: the user in step 3, the search engine company in step 4, and the content creator in \nstep 5.\n\nIn short, the current GenAI model destroys the incentives to create new content. I‚Äôve heard this referred to as ‚Äúthe \ngreat content collapse.‚Äù Will it lead to a world where, after the 2020s, there‚Äôs little-to-no content created by humans? \nWill the state of knowledge and creativity stagnate as a result?\n\nTo be clear, I‚Äôm not an innocent party in this. As I mentioned numerous times in this post, I use GenAI regularly.\nThere‚Äôs no doubt that it makes me more productive. I even used GenAI to create the cover image for this blog post! \nBut each time I use ChatGPT or Claude, I feel a bit guilty, as it doesn‚Äôt feel sustainable. The snake can‚Äôt keep \neating its own tail indefinitely.\n\nSo the question is, what do we do? If we want to avoid the great content collapse, we need a model of GenAI usage that \ncreates opportunities for all parties (user, GenAI company, content creator) to capture value. Below are two ideas for \nhow we might accomplish this.\n\nThe only attempted solution I‚Äôve heard about so far is CloudFlare‚Äôs pay-per-crawl \nmodel, which seems to work as follows:\n\nOn the one hand, it‚Äôs fantastic to see a major company try to do something about this problem. On the other \nhand, this approach seems to address the wrong part of the problem. The real value isn‚Äôt in crawling the data, it‚Äôs \nin using it. For every one crawl, an LLM might use the data thousands or millions of times. If creators are only paid \nper crawl, then the GenAI company still captures 99.999% of the value, and the creator gets next to nothing. Moreover,\nthis model only seems to work for websites (it‚Äôs not clear how you adapt it to books, art, music, etc.), and it \ncreates an incentive for GenAI companies to only crawl free content, which means paid content is less likely to ever be\ndiscovered (which disproportionally benefits those with pockets deep enough to keep their content free).\n\nI came across a clever solution that felt directionally correct from this LinkedIn post by Tyrone \nJoel\nwhere he took a PDF of my book Terraform: Up & Running, uploaded it into\na GenAI tool, and asked the tool to follow the guidance in the book to generate Terraform code. This feels like it has\nall the ingredients of a model of GenAI usage that is sustainable: the user gets value from the GenAI tool‚Äôs responses,\nthe GenAI company gets value from the user paying for a subscription, and the content creator gets value from the user \npaying for their content (in this case, buying my book). This works fine for a single, specific piece of content, but \nhow do you make it work at scale, across all the content that is consumed by an LLM?\n\nHere‚Äôs a rough proposal for what I‚Äôll call the pay-per-use model:\n\nThis model works for not only websites, but other types of content too, including copyrighted content. As a content \ncreator (e.g., author, musician, designer, etc.), you could opt into sharing your copyrighted content with a GenAI\ncompany in exchange for getting referrals and revenue sharing each time your content is used. It might even help with \nmaking open source more sustainable, as open source creators could earn revenue and referrals each time a GenAI tool \nuses their code.\n\nIt‚Äôs critical that we find a more sustainable model as soon as possible. The snake can‚Äôt eat its own tail indefinitely. \nAnd the snake‚ÄîGenAI‚Äîisn‚Äôt going away. We can‚Äôt put the genie back in the bottle. In fact, it‚Äôs only going to get \nbetter, more ubiquitous, and to provide more and more value to users and GenAI companies. But if we can‚Äôt find a way to \nprovide value to content creators too, then this will all fall apart.\n\nThat said, I don‚Äôt know enough about LLMs to say if a pay-per-use model is actually possible. Can LLMs track the source \nof the content they consumed? Will GenAI companies be willing to do a revenue sharing model? Will they be willing to\nbe transparent about their sources and usage? What do you think? Let me know in the comments.\n\nMany subreddits feel like a hollow shell of what they used to be. In part, this may be because a lot of the content in online communities now feels like it‚Äôs generated by bots (‚ÄúAI slop‚Äù). But I think the bigger issue is that, just like StackOverflow, reading posts in online communities is no longer the best way to get answers. I used to use Reddit for research all the time; in fact, Google Search had gotten so bad, that you pretty much had to include ‚Äúreddit‚Äù in your search queries to get a half-decent response. But nowadays, I use GenAI tools for much of my research. Just in the last few months alone, I‚Äôve used ChatGPT and Claude to research solar panels, plan a trip to Norway, make changes to my diet, pick out new shoes for running, pick out new speakers for my living room, and dozens of other questions. Just a year ago, the vast majority of these questions would‚Äôve brought me to Reddit. Nowadays, virtually none of them do, even though I suspect many of the responses I get from GenAI are based on Reddit content.¬†‚Ü©\n\nI‚Äôm seeing more and more projects avoiding open source dependencies entirely, and instead having GenAI generate the all code they need directly in their own codebase. There are some benefits to this approach‚Äîfaster builds, more reproducible builds, less supply chain risk‚Äîbut it makes sustainably funding open source even harder. You spend years to create and share an open source library with the world, and a bunch of GenAI tools copy your code, with you getting zero credit or value back.¬†‚Ü©\n\nHow much will I get paid as a result of this settlement? It‚Äôs hard to know exactly, as it depends on how many authors end up submitting claims, but the current estimate is $3,000 per book, though that number is split with the publisher, so in practice, it‚Äôll be closer to $1,500 per book. If you assume that a book takes just 3 months of full-time work, or about 500 hours (which is likely an under-estimate), and all you get is $1,500, that works out to about $3/hour. Writing non-fiction tech books was never a particularly lucrative affair, but $1,500 is just downright insulting. Worse yet, the other benefits you used to get as an author‚Äîrecognition as an expert, invitations to talks, job opportunities, marketing for your company or consulting‚Äîare significantly reduced too, as far fewer people read your book, or are even aware that you wrote a book, as the LLM usually doesn‚Äôt attribute any of its knowledge back to the source.¬†‚Ü©",
    "readingTime": 12,
    "keywords": [
      "q&a site",
      "class-action lawsuit",
      "art music",
      "tail indefinitely",
      "online communities",
      "snake can‚Äôt",
      "search engine",
      "blog posts",
      "genai tools",
      "genai tool"
    ],
    "qualityScore": 1,
    "link": "https://www.ybrikman.com/blog/2026/01/21/gen-ai-snake-eating-its-own-tail/",
    "thumbnail_url": "https://www.ybrikman.com/assets/img/blog/gen-ai-snake-eating-tail/snake-eating-tail.png",
    "created_at": "2026-01-21T18:30:43.121Z",
    "topic": "tech"
  },
  {
    "slug": "zero-to-one-ai-agents-and-agentic-patterns",
    "title": "Zero to One: AI Agents and Agentic Patterns",
    "description": "A practical guide to AI agents, covering Agentic Patterns, Multi-agentic patterns, and Memory in Agents.",
    "fullText": "AI agents have become a core building block of modern AI systems, but the term is used in many different context.\nThis post breaks down what AI agents actually are, how they differ from traditional\nworkflows, and how agentic systems are designed in practice. We cover the key building\nblocks including LLMs, tools, and memory, and how they enable agents to reason, act, and\nadapt over time.\n\nThe focus is on patterns. These are common ways to structure workflows, single-agent\nsystems, and multi-agent architectures. Some patterns favor control and predictability,\nwhile others emphasize autonomy and dynamic decision-making. Understanding these trade-offs\nhelps in choosing the right architecture for a given problem.\n\nand multi-agent systems. You will know when to use them, how they fit together, and where\nthey tend to break down.\n\nBefore we directly jump into the definition of AI Agents, let's first understand AI Agents\nwith the help of an example.\n\nLet's say you are planning to go on a trip with your family to Dubai. You are taking the\nentire responsibility of the trip, so how would you plan it? What are the things you would\nthink about?\n\nSo the list of things to plan for the trip would be:\n\nNow, after listing the things, we need to take action. You go ahead and book flights, book\nhotels, get visas, etc.\n\nBut what would your thought process be like?\n\nYou wouldn't just search \"Dubai\" once. You would:\n\nResearch: browse multiple websites for flights, compare prices, and\nbook. Similarly for hotels, you would pick one near the places you want to visit with\ngood reviews.\n\nReason: if we land at 4:00 AM, we need a hotel that allows early\ncheck-in.\n\nExecute: book the flight (handling the payment), then use that to book\nthe hotel, and then use that confirmation to book the car.\n\nAdapt: if a flight is canceled, you have to re-adjust all the\nreservations like the hotel, the dinner reservations, etc.\n\nIf you use a traditional LLM, it‚Äôs like having a Travel Brochure. You ask it \"What are the best hotels in Dubai?\" and it gives you a list. But you still have to do all the work, the booking, the timing, and the fixing when things go wrong.\n\nAn AI Agent, however, is like having a Digital Travel Assistant as it is able to Research, Reason, Adapt, Execute and Remember at each step.\n\nYou give it a Goal: \"Plan and book a 5-day family trip to Dubai within a $5000 budget.\" and it entirely acts and executes the entire process and planning that we talked about.\n\nThis is often referred to as Agentic AI.\nHope this example gave a fair understanding of what Agents are. But there is lot more to it.\n\nIn this course Agentic AI by Andrew Ng, he starts by asking\n\nhow do humans actually work compared to LLMs?\n\nMost current LLM applications typically operate in a linear fashion, one-shot workflow (prompt ‚Üí output). But that‚Äôs neither efficient nor realistic for building applications that involve multiple steps.\n\nBut as humans, we rarely create a polished final product in a single attempt.\nOur work usually flows through non-linear steps (sometimes can flow through linear steps as well), just like when we write an essay; brainstorming, researching, drafting, editing and refining, or like in our example finding flights in our budget, finding hotels in our budget that are nearby to the places we want to see, but also has good reviews etc.\n\nLinear steps are when work flows in a straight line: you finish Step 1, then Step 2, then Step 3, and you rarely need to go back.\nExample: Book flight ‚Üí Pay ‚Üí Get confirmation (done).\n\nNon-linear steps are when work loops and bounces between steps because each decision changes the constraints. You keep revisiting earlier choices until everything fits together.\nExample: Flight timing affects hotel check-in ‚Üí hotel location affects itinerary ‚Üí itinerary affects budget ‚Üí budget forces you to change flights/hotels again.\n\nSo trip planning is mostly non-linear because changes in one part (flight cost, timing, cancellation, review score) force updates in other parts, it‚Äôs an iterative loop, not a one-shot pipeline.\n\nSo apps can be just simple ai agentic workflows, or could involve real ai agents.\n\nSo this brings us to the definition of Workflows and Agents :\n\nAgentic Workflows:Workflows are more deterministic, and are more focussed on the tasks that are predefined at hand.\n\nAI Agents: AI Agents have agency, which can make and take decisions inorder to accomplish the goal or outcomes, meaning they are highly autonomous, and they have the ability to do complex task automations as they have access to tools. They learn from their environment, and retains memory\n\nHere's how Anthropic defined the 2 for us, and maybe you could get a better understanding :\n\nSome major things to consider is that if you are building an agentic agent, then you may have less control over the decision it makes, because the agent might not make the decisions that you as a human might make in certain circumstances.\n\nWhere as in Agentic workflows, where we are intentionally putting humans in the loop, and asking it to follow a deterministic approach sounds better in certain cases.\n\nSo high agency and high control are 2 opposite ends of the spectrum.\n\nPros and Cons in Agentic Agent vs Agentic Workflow\n\nThe level of control or autonomy an agent has is called ‚Äúagency‚Äù.\n\nLower the agency, lower is the value created by an agent, and more control\n\nHigher the agency, higher is the value created by and less control.\n\nIts super important to know when to consider building an agntic workflow and when to rely on ai agents.\n\nIf you know that the solution to your problem requires a step by step approach, then a simple workflow would suit best.\n\nThe major trade off between Ai Agents and a workflow is that , AI Agents can prove to have better performance and lesser manual work when dealing with complex, ambiguous and dynamic tasks but the downside is that it increases latency and ofcourse more the computational cost. And it\nintroduces unpredictability and potential errors. Agentic systems must incorporate robust error logging, evaluation strategies, exception handling, and retry mechanisms.\n\nUse workflows for predictability and consistency when dealing with well-defined tasks where the steps are known.\n\nUse agents when flexibility, adaptability, and model-driven decision-making are needed.\n\nThe basic building blocks of an AI Agents is an LLM which is augmented with certain super-powers.\n\nMemory :\nThe agent‚Äôs ‚Äúnotebook‚Äù (short-term + long-term) that stores context like user preferences, past interactions, and key facts,\nso the LLM can stay consistent and make better decisions across steps and future sessions.\n\nA large language model (LLM) on its own can only read and generate text,\nit has no direct access to the internet, APIs, databases, or other external systems.\n\nIt is just limited to knowing training data. LLMs can‚Äôt know events that happened after their training cutoff, nor does it know about your internal data on which the LLM has not been trained.\n\nBut there are so many LLM models available, so which one to choose ?\n\nChoose the LLMs smartly, not every task needs the most smartest model, if your task/subtask is of less complexity, then go for smaller models.\nChoosing the right model for the task at hand helps reduce cost.\n\nNow let's understand how these 'Next-word predictors' get superpowers via tools.\n\nIn the world of AI agents, tools are like weapons that extend an agent‚Äôs capabilities to do additional tasks.\n\nTools can come in various forms, for example :\n\nIf a tool doesn‚Äôt exist, we can build a custom tool (a function or API wrapper). We can expose\nthese tools through standards like MCP, and we can also add a retrieval tool for\nRAG (searching internal docs / vector DB) so the agent can fetch grounded context.\n\nHow do you pass the 'tool' to the LLM ?\n\nPrompt is the way. Yes prompt is the way you pass the tools to an LLM.\nBecause LLM's can only understad text, you give it an input, and it gives an output.\n\nFor example, if we provide a tool to check the weather at a location from the internet and then ask the LLM\nabout the weather in Dubai, the LLM will recognize that this is an opportunity to use the ‚Äúweather‚Äù tool. Instead of retrieving the weather data itself, the LLM will generate text that represents a tool call, such as call weather_tool(‚ÄòDubai‚Äô).\n\nThe Agent then reads this response, identifies that a tool call is required,\nexecutes the tool on the LLM‚Äôs behalf, and retrieves the actual weather data.\n\nThese Tool-calling steps are typically not shown to the user as they are mostly abstracted away by the frameworks.\nthe Agent then appends the result from the function call as a new message before passing the updated conversation to the LLM again.\n\nThe LLM then processes this additional context and generates a natural-sounding response for the user. From the user‚Äôs perspective, it appears as if the LLM directly interacted with the tool, but in reality, it was the Agent that handled the entire execution process in the background.\n\nExample image of how prompt can be formatted:\n\nTool Registry Pattern \n\nIn a real agent, you organize tools into a registry or \"toolbox\".\n\nWhen to provide the LLM with tools is that :\n\nIf the LLM is the brain and the Tools are the hands, then the memory is the second brain of the system.\n\nWithout memory the agent would start fresh each time, losing all its context from previous interactions. No context. No personalization.\n\nImagine hiring a top chef who forgets everything the moment they leave the kitchen. they forget the recipe, the customer‚Äôs preferences, and even what they cooked five minutes ago.\nEvery time you want a dish, you have to explain the recipe and preferences again.\nThat‚Äôs how most agents work today: powerful, but stateless.\n\nLLMs can only look at a limited amount of information at once. That limited space is called the context window.\nIt‚Äôs basically the model‚Äôs short-term working space for the next response.\n\nSo we can‚Äôt dump everything into the prompt and hope it works. Too little context and the model misses key details.\nToo much (or irrelevant) context increases cost, slows responses, and can even reduce quality by adding noise or contradictions.\n\nThe goal is to pass just the right information for the next step not too little, not too much.\nThis is what people call Context Engineering, and we‚Äôll go deeper into it in a dedicated section.\n\nAnd this is exactly where memory becomes powerful: memory stores the important stuff outside the context window\n(past conversations, preferences, decisions, notes), and we retrieve only what‚Äôs relevant and place it back into\nthe context window when needed.\n\nWith memory the agent can remember past conversations and take actions as per the context from previous conversations, hence producing more detailed and cohesive responses.\n\nThe benefits of using memory in agents include : deep personalization, continuity, complex reasoning and imrpoved efficiency.\n\nMemory is a fundamental part of the framework, with a vector databases (such as Pinecone, Weaviate, Chroma, etc.) providing robust storage and retrieval mechanisms for task-related data.\n\nThanks to Leonnie Monigatti for this image :\n\nSo since LLMs lack memory, so a memory has to be added into our architecture. And we can do that in 2 ways:\n\nShort-term memory lives inside the context window.\nIt holds temporary information needed for the next few steps (recent messages, tool outputs, or a running summary/state).\nIt is session-scoped and gets cleared or compressed over time.\n\nLong-term memory lives outside the LLM, usually in an external store (often a vector database).\nIt lets an agent save and reuse information across days, weeks, or separate conversations.\nThat‚Äôs how you get real personalization and continuity over time.\nWhen the agent needs it, it retrieves the most relevant memories (semantic search + retirval) and injects them into the LLM‚Äôs short-term memory (context window) for the current step.\n\nThis Long term memory can be broken down into 3 types:\n\nNow that we‚Äôve seen short-term memory (context window) and long-term memory (external storage), the next question is:\n\nhow do we manage both without adding noise or wasting tokens?\n\nMemory management in AI agents simply means:\n\nThe goal is to keep only the information that is useful for the next steps.\nIf the context window contains wrong, irrelevant, or conflicting information, the model can get confused.\n\nAlso, as a conversation gets longer, the prompt gets bigger (more tokens). That increases cost, can slow responses,\nand can even hit the context window limit.\nAndrej karpathy summarizes this well in this tweet.\n\nTo avoid this, you can manage the conversation history in a few ways:\n\nThat‚Äôs how we manage short-term memory (the context window). Next, let‚Äôs see how agents update long-term memory in other words, how they write memories.\n\nSo how does the agent actually write to the external long-term memory ??\n\nLLMs can‚Äôt write to a database by themselves. They only generate text.\nSo the ‚Äúwriting‚Äù happens because the agent system (your app) gives the LLM a\nmemory tool (ex: save_memory()), and the LLM decides when to use it.\nWhen it triggers that tool, the system stores the memory in an external store\n(vector DB / key-value DB / SQL), and later retrieves it back into the context window when needed.\n\nExplicit memory / Hot path write\n\nThe agent identifies that something is important during the conversation and saves it\nimmediately using tool calling (ex: ‚ÄúUser prefers Python‚Äù ‚Üí save_memory()).\nThis updates long-term memory right away, so it can be used in the next turn.\n\nImplicit memory / Background write\n\nThe agent responds first, and a background process later summarizes/extracts useful facts\nand writes them to long-term memory. This avoids latency, but the memory may not\nbe available instantly for the next message.\n\nBut how does the agent know what‚Äôs ‚Äúimportant enough‚Äù to save in the hot path?\n\nIt doesn‚Äôt magically know. You teach it a memory policy a short set of rules that tells the model what is worth saving\nand what must never be saved. Then you give the model a memory tool (for example save_memory(text, type, confidence)).\nIf the current message matches the policy, the model triggers the tool call, and your app writes it to the external store.\n\nIn practice, agents use a few simple signals to decide:\n\nA good rule of thumb: if it‚Äôs not likely to matter in a future session, don‚Äôt store it.\n\nWe talked about how LLMs know about the tools, but now in the next section,\nlets discuss about how these LLMs learnt and take decisions, and how they interact with the environment and memory.\n\n'Re' stands for reasoning, and 'Act' stands for action.\nThis framework will help the agents interact with the external environments, and help them to plan and reason.\n\nThis approach is all about combining the LLM‚Äôs reasoning ability with tool use in a single, coherent loop.\n\nTo understand why ReAct is needed, let‚Äôs first recall Chain-of-Thought (CoT) prompting.\n\nComparison between standard prompting and CoT prompting. On the left, the model is instructed to directly provide the final answer (standard prompting).\nOn the right, the model is instructed to show the step by step reasoning process to get to the final correct answer (CoT prompting).\n\nAs we can observe,\nwriting a chain of thought a series of intermediate reasoning steps helps the model in outputting the correct answer.\nThis this Wei et al. (2022) highlighted how guiding a model through a series of intermediate reasoning steps significantly improved its performance on tasks such as mathematical problem-solving, logical reasoning, and multi-hop question answering.\n\nBut the COT has a limitation, and that is it cannot have access to the external world, So it cannot take actions.\nThat's where ReACT comes in.\n\nAnd how ReACT does that is using TAO Principles.\n\nThought -> Action -> Observation -> repeat\n\nThe Thought-Action-Observation (TAO) loop is the heartbeat of the ReAct agent.\n\nIt‚Äôs the cycle that lets an agent iteratively approach a solution. Here‚Äôs the breakdown of each phase:\n\nThought: The agent‚Äôs LLM ‚Äúthinks‚Äù about what to do next. This is a reasoning step, like planning or analyzing the problem state. For example: ‚ÄúHmm, to answer this question I might need data X; perhaps I should use tool Y to get it.‚Äù\n\nAction: Based on that thought, the agent takes an action by invoking a tool. E.g., Action: call the search tool with query ‚Äúdata X‚Äù.\n\nObservation: The agent then gets the result of that action ‚Äì new information from the tool. E.g., the search results come back with a relevant snippet. The agent observes this and incorporates it.\n\nThis loop breaks only when the final answer is found.\n\nt‚Äôs essentially a feedback loop for problem solving. So during the loop, if something goes wrong, or a new requirement comes up, then it should think observe and take action and pivot accordingly.\n\nFor this to work, Memory is super important, for memory of previous interaction in the loop. Without memory,\nthe agent would forget what happened in the previous interaction.\nhence choosing the memory as per the use-case becomes super important.\n\nAs we all know that Software Engineering is made up of 'patterns' and 'protocols', and having patterns in a way provides us with a structured, proven way to think and design systems, and helps in preventing common design mistakes.\n\nThey promote best practises, and shared understanding amongst developers.\n\nPrompt chaining is a pattern where a bigger problem is solved by doing multiple LLM calls sequentially, where each calls output becomes the input to the other LLM call.\n\nEach step is simpler ‚Üí often more accurate\n\nintermediate steps where you get to take a decisions using certain conditions, to ensure that the process remains on track.\n\nRouting is a pattern where an initial LLM acts like a dispatcher: it classifies the user‚Äôs input (intent/domain/complexity) and sends it to the most appropriate specialized workflow, prompt, tool, or model to complete the task.\n\nSeparation of concerns : each downstream route can be optimized independently (prompts, tools, logic).\n\nBetter efficiency and cost : simple requests can go to cheaper/faster models, complex ones to stronger models.\n\nCustomer support systems: Routing queries to agents specialized in billing, technical support, or product information.\n\nMore reliable behavior : different input types (code, support, writing, images) get handled by purpose-built flows.\n\nParallelization is a pattern where a task is split into independent subtasks and sent to multiple LLM calls at the same time.\n\nOnce all branches finish, their outputs are collected and either combined programmatically or passed to a final ‚Äúaggregator‚Äù LLM to synthesize the best final answer.\n\nFaster end-to-end latency : independent subtasks run concurrently instead of waiting step-by-step.\n\nBetter quality : you can generate multiple perspectives and merge them, or use majority voting to reduce errors.\n\nScales well for batch work : summarizing multiple sections/documents or repeating the same reasoning across many inputs.\n\nCleaner synthesis stage : results can be validated, deduped, and then combined into one coherent output.\n\nOrchestrator-workers is a pattern where one central LLM (the orchestrator) reads the user‚Äôs request, breaks it into subtasks dynamically, assigns each subtask to a specialized worker LLM, and then combines the workers‚Äô outputs into a final response.\n\nUnlike parallelization, the subtasks are not pre-defined, the orchestrator decides what work needs to be done based on the specific input.\n\nHandles unpredictable complexity : the orchestrator can decide which subtasks are needed on the fly.\n\nDivision of labor : workers can be role-based (planner, researcher, coder, reviewer) with specialized prompts/tools.\n\nMore scalable systems : you can add or swap workers without changing the whole workflow.\n\nBetter final quality : an orchestrator can validate, reconcile conflicts, and synthesize a coherent output.\n\nExample : Scan the repo, find the entrypoints (main.py/app.py), list routes/dependencies, and return a short JSON summary of what files will need changes.\nThe orchestrator first delegates this scanning subtask to a worker so it can dynamically decide the next subtasks (which files to edit, what workers to call next), since that isn‚Äôt knowable upfront.\n\nThe React Pattern that we discussed in the above sections, also comes as one of the Agentic Patterns.\n\nEvaluator-Optimizer (also called Reflection) is a pattern where the agent generates an initial draft, then runs a critique step to evaluate it against requirements (clarity, accuracy, tone, constraints), and uses that feedback to iteratively refine the output until it‚Äôs satisfactory or a max-iteration limit is reached.\n\nImproves quality : catches mistakes, missing requirements, and weak reasoning before the answer is finalized.\n\nMakes outputs more reliable : the evaluator can act like a reviewer (accuracy, clarity, security, style).\n\nGreat for subjective work : writing, tone, structure, and ‚Äúdoes this meet the rubric?‚Äù tasks benefit a lot.\n\nExample : The agent writes a function is_valid_email(), runs unit tests, sees failures, reflects on the edge cases, and rewrites the function until tests pass.\n\nLike we discussed in the above sections that an LLM can only read text and write text right. It can‚Äôt actually look up live data, run code, or book something on its own.\n\nIn the Tool Use Pattern, we give the LLM access to tools (functions/APIs) like discussed in the above sections. (where the table image demonstrates the tool examples.)\nWe also tell the LLM what each tool looks like:\n\nUser asks a question\n\n‚ÄúBook a meeting for tomorrow‚Äù or ‚ÄúWhat‚Äôs Tesla stock price?‚Äù\n\nLLM decides it needs a tool\n\nBecause it can‚Äôt do that reliably from memory.\n\nLLM outputs a structured ‚Äúfunction call‚Äù (often JSON)\n\nExample: {\"name\":\"get_stock_price\",\"arguments\":{\"ticker\":\"TSLA\"}}\n\nYour app runs the tool\n\nThe LLM does not run it, our backend executes the API/function.\n\nTool returns results\n\nExample: {\"price\":245.30}\n\nLLM uses that result to write the final answer\n\n‚ÄúTSLA is trading at $245.30 right now.‚Äù\n\nThis pattern is commonly implemented using Function Calling., and it lets the LLM do real actions and use real-time data, way beyond what it learned during training.\n\nLimitations of classic Tool Use are :\n\nTools are hardcoded into the application\n\nThe LLM only knows about tools you explicitly define\n\nAdding new tools requires code changes + redeployment\n\nTools are tightly coupled to one model or framework\n\nThe Tool Use Pattern defines how models think about using tools\nMCP defines how tools are described, discovered, and invoked\n\nTools live in external tool servers\n\nTools can be discovered dynamically\n\nTools describe themselves via standardized schemas\n\nModels and apps are decoupled from tool implementations\n\nThe same tool can be reused by multiple models and clients\n\nConceptually, the interaction loop stays the same.\nYou can read more about MCP in one of my blogs here where i have distinguished clearly the differences between an MCP and an API -> MCP vs API\n\nThe multi-agent pattern represents perhaps the most sophisticated approach to building AI systems.\n\nInstead of relying on a single agent to handle everything, this pattern uses multiple specialized agents that collaborate to accomplish a common goal.\n\nThis pattern uses autonomous or semi-autonomous agents.\nEach of these agents are specialized in a certain task meaning they'll have specialized knowledge, or access to specific tools.\n\nEach of these agents can interact, collaborate and coordinate with each other (either using a coordinator/manager or using handoffs logic. )\nHandoff logic means one Agents handsover the control to another agent.\n\nExample : In our first example of a travel assistant agent, say one agent is flight agent and it finds the besst flights for us, and then the hotel agent would be\nresponsible for booking the hotel.\n\nSome key characteristics of this pattern would be :\n\nParallel Execution : Subtasks can be handled simultaneously\n\nDelegation : The main manager agent delegates the task to other agents based on the subtasks.\n\nDistributed Context: Each agent has its own context, which is like the subset of the total information. (incase of swarm type handoff logic based multi agent setup, there usually is a unified context.)\n\nHere' an image of the coordinator/manager approach.\n\nHere's an image of the hand-off based multi agent collaboration :\n\nLet's talk more about these multi-agent systems in the next section, about how they share information and context, and how they call the other agent,\nhow one agent knows that it has to call the other ? What are the multi agent patterns etc everything.\n\nA subagent is a specialized Agent that is purpose-built for a single, well-defined task. It is mostly used with a main orchestrator agent which delegates the task to the subagents,\nThese subagents has its own context window. Meaning the subagents are stateless (they do not remember the context on each request, every request is a different request.)\n\nClaude Code loads the list of subagents at session start, but it only runs a subagent when needed.\n\nThis architecture provides centralized control where all routing passes through the main agent, which can invoke multiple subagents in parallel.\n\nThe only trade off is that one extra hop to the subagents is involved, and everytime a request arrives it has to flow through the main agent, and then to subagent, and exactly in the opposite fashion while sending the response.\nSo when this model hop is involved, extra tokens are being used, hence more cost, and ofcourse more latency.\n\nDeep Agents provides an out-of-the-box implementation for adding subagents with just a few lines of code. (if needed delegates complex subtasks to specialized subagents)\n\nAgent as a tool is a name provided by OpenAI for this pattern.\nOpenAI documentation and in Claude Code docs\n\nAgain there can be various ways in which this pattern can be used :\n\nRun Parallely : \n\nWe can call multiple subagents in parallel to work simultaneously. This kind of pattern is good when the task of both the subagents are independent.\n\nChain Subagents \n\nIn this one, the subagents run in sequence meaning, one subagent completes its task and returns to the main orchestrator, which then returns and sends to the next subagent.\n\nIn this pattern the agent loads the prompts and knowledge on demand, only when needed. It is also called as progressive discolsure.\nLet's take a look at the image, and then understand what it is and how it really works.\n\nYou can see from the image that only one main agnet is used, so how can it be a multi-agent pattern ??\n\nso the thing is we are trying to use the main agent as if it is specialized in so many skills, so its like we are loading the context of that skill only when its needed.\n\nEach skill is like a small ‚Äúplaybook‚Äù:\n\na prompt (how to think / how to respond)\n\nrules (what to do / what not to do)\n\nexamples / knowledge (so it doesn‚Äôt hallucinate)\n\nsometimes scripts/tools (commands it can run)\n\nThe main idea: the agent does not carry all skills in its head all the time.\nIt only loads the skill context when that skill is needed.\n\nSo it feels like a multi-agent system, because the same agent can switch between ‚Äúmodes‚Äù\n(SQL mode, Payments mode, Debug mode, etc.).\nBut technically it‚Äôs still one agent, just with on-demand context loading.\n\nIn this pattern, one main agent talks to the user.\n\nWhen the main agent understands that the request is not its job, it can say:\n‚ÄúI don‚Äôt handle this, but another agent does‚Ä¶ so I will hand it off.‚Äù\n\nThen the task gets passed to the right agent (the specialist agent),\nand that agent becomes active and works on it.\n\nAfter the specialist finishes, the main agent can show the final answer to the user\n(or the specialist can reply directly, depending on how the system is built).\n\nExactly like the image we saw above in the Multi Agent pattern section.\n\nThis pattern is very similar to the ‚Äúagent + tools‚Äù setup we saw earlier.\nThe only difference is: instead of routing to tools, we route to agents.\n\nSo you can think of it like this:\n\nIn tools pattern: the agent decides which tool to call.\n\nIn router pattern: the router decides which agent to call (refund agent, booking agent, debugger agent, etc.)\n\nThe router‚Äôs job is simple:\nit reads the user request, picks the best agent, and forwards the task to that agent.\n\nThanks to Langchain for creating this beautiful table.\n\nFact: In these multi-agent patterns the agent to agent calling is synchronous right, so if you want an event-driven distributed system for these multi agents. Check out this link to read more about it\nDistributed Event Drivern Multi Agent Patterns\n\nIn the next part we will talk about Context Engineering and Evaluatin Strategies for AI Agents.\n\nA few more AI pieces you might like:\n\nNext in the series, I'll dive more into:\n\nIf this was useful, Evolving Engineer\n\nSupport my writing here:\nbuymeacoffee.com/cpradyumnao\n\nGoogle Cloud Tech Youtube Videos\n\nAnthropic's Guide to building effective Agents\n\nOpen AI's Practical guide to building Agents\n\nMicrosoft: AI Agent for beginners\n\nVizuara AI Labs and Dr. Raj Dandekar\n\nLeonie Monigatti: Making sense of memory in Agents\n\nCognition: Dont build multi-agents\n\nSimon Willison: AI Agents Definitions\n\nPhil Schmid: Memory in AI Agents\n\nWeaviate: What are Agentic Workflows?\n\nAnthropic: Multi Agent Research System\n\nLangchain: Choosing the right multi-agent architectures\n\nDailyDoseOfDS, Avi Chawla : Ai Agents guidebook\n\nLance Martin: Context Engineering for Agents\n\nDrew Breunig: Why Context Engineering Matters\n\nLetta Blogs : Agent Memory, How to build Ai Agents that learn and remember\n\nLangChain + LangGraph Docs: Memory\n\nAishwarya Naresh Reganti: LevelUpLabs free AI Agent course on Github",
    "readingTime": 25,
    "keywords": [
      "travel assistant",
      "cot prompting",
      "llms can‚Äôt",
      "hot path",
      "agentic workflows",
      "tool e.g",
      "adding noise",
      "handoff logic",
      "agency lower",
      "standard prompting"
    ],
    "qualityScore": 1,
    "link": "https://pradyumnachippigiri.dev/blogs/understanding-ai-agents",
    "thumbnail_url": "https://pradyumnachippigiri.dev/og?title=Understanding+AI+Agents&date=2026-01-18",
    "created_at": "2026-01-21T18:30:42.842Z",
    "topic": "tech"
  },
  {
    "slug": "wikipedia-signs-of-ai-writing-a-vale-ruleset",
    "title": "Wikipedia Signs of AI writing: a Vale ruleset",
    "description": "Taking Wikipedia's dynamic documentation of AI writing patterns and turning it into a prose linting tool.",
    "fullText": "My minor superpower is setting up change detection on websites to get email notifications when they update. For the past three months that‚Äôs meant daily pings from Wikipedia‚Äôs ‚ÄúSigns of AI Writing‚Äù page. As an ‚Äúadvice‚Äù page, it‚Äôs where Wikipedia editors document the tells: the phrases, patterns and artifacts that suggest that AI was involved at some point with what they‚Äôre reading.\n\nMalicious or subversive edits to Wikipedia have been a challenge since the formation of the site. But the community has a robust nervous system for identifying and rejecting those that compromise the integrity of the encyclopedia.1 The latest response is this painstakingly, exhaustively updated page documenting various signs.\n\nThe proliferation of LLM tools means that AI-tainted edits are a new variant for Wikipedia contributors to navigate. If AI tools allow individuals to contribute productively in ways otherwise not possible, they could be welcome. But as the page goes to great lengths to document, there‚Äôs a fresh category of edit slop that would deteriorate the quality of the encyclopedia if allowed unchecked.\n\nThe emails summarising the edits give me an interesting perspective on how perception of AI use has morphed rapidly over time. The page documents the front line of AI detection in a real-world setting.\n\nWhat would it look like to turn this into tooling?\n\nMany tells are obvious. Take the glitches that would appear in older versions of ChatGPT outputs.\n\nOnce you understand that this is a strange bit of text blurted out by the model it‚Äôs an immediate sign that the surrounding content has been tainted by a model at some point in its history.\n\nThese examples are temporary windows into the textual guts of AI models. The MissingNo. seahorses of ChatGPT.\n\nNow documented, recognised, and patched by the model creators, these artifacts of artificiality are becoming extinct with time.\n\nNudging back into the world of user error, it‚Äôs common to see phrasing that‚Äôs been accidentally copy-pasted from the LLM user interface and surrounding text.\n\nThis can include instructional framing meant not for the reader but the user.\n\nOther tells become more obvious the more you read online and the more you train yourself to spot them.\n\nThe most famous example of this is ChatGPT‚Äôs rampant use of the em-dash, raising the hackles of belligerent punctuation lovers worldwide.\n\nTo me the bigger scourge is that of contrastive language:\n\nIt's not just about the beat riding under the vocals; it's part of the aggression and atmosphere.\n\nThis language construction is catnip to the LLMs at large. It occasionally spans multiple sentences but it almost always appears in marketing and branding content on LinkedIn due to the goal of making an impact.\n\nAs a result this construction is hackneyed and many will choose to avoid it in order to prevent being lumped in with the undiscerning, careless masses.\n\nTechnical writers face similar challenges with AI-generated content outside of Wikipedia. Like any group that cares about craft, they‚Äôve built tools for systematic text analysis.\n\nVale.sh is a library known as a ‚Äúlinter for prose.‚Äù It could be thought of as a souped-up spelling and grammar checker.\n\nLinting is a term borrowed from software development (first used back in 1978!) and is the process of highlighting areas for improvement, based on a customisable ruleset. In programming, linters catch ‚Äúcode smells‚Äù ‚Äì implementations that technically work but suggest deeper issues. Many programming languages have syntactic variation meaning that you may write a piece of code differently to your peers. These degrees of freedom can hamper collaboration, or permit confusion, by making it hard to understand the intent behind the code.\n\nSharing these linting rules across teams of developers aids collaboration and goes a long way to avoid holy wars about semicolons.\n\nVale has been around in the technical writing community since 2017 and there‚Äôs a strong ecosystem of rulesets that one can ‚Äúopt-in‚Äù to. These include style guides, checks for passive voice, gendered or condescending language.\n\nI‚Äôm not aware of any existing implementation of a ruleset to help highlight AI smells, so I built one.\n\nI fed the contents of the Wikipedia page to Claude and asked it to make recommendations on the rules that should be generated.2 After a few confidence checks I gave it the green light to generate Pull Requests on GitHub for manual review and verification.\n\nOne key part of this process was separating the rules that were relevant for a collaborative encyclopedia and those that had wider application in other forms of writing.\n\nAn example of this is the meta-commentary from earlier that reference writing for Wikipedia in the body of the text itself. There‚Äôs likely a version of this ruleset that could be tuned for exclusive use for Wikipedia edits but my goal was to provide a general purpose tool with applications elsewhere.\n\nIt‚Äôs hard to understand the true ability of the countless AI detection tools on the market. Many appear to be taking advantage of the widespread use of ChatGPT in educational settings to prey on students trying to evade (flawed) AI detection tools.\n\nVendors at various points of the snake oil spectrum are touting the strengths of their products but there‚Äôs little neutral and independently verifiable research to back up their claims.\n\nAt this point at the end of 2025 it‚Äôs unclear to me whether the use of AI and machine learning models will ever be satisfactory for detecting the use of AI in writing.\n\nUnlike these proprietary AI detection tools with their black-box algorithms and problematic false positive rates, this Vale.sh ruleset is transparent and interpretable. Each rule traces back to observed patterns and the configuration is available on GitHub for review and expansion.\n\nOne interesting challenge is that of linguistic adaptation. As AI writing becomes more commonplace and individuals gain greater confidence in their ability to spot it, certain words and turns of phrase will be avoided to prevent accusations.\n\nThe ruleset can therefore help authentic writers pre-empt this situation and consider avoiding turns of phrase and other tells. This feels like a sorry state of affairs but helpful tooling is one way for writers to be kept informed and in control of their output.3\n\nClaude and I categorised the current rules in the following three tiers. This means that the rule confidence can be matched by the Vale behaviour.\n\nError: Definite AI artifacts ‚Äì chatbot phrases, technical glitches, placeholders, tracking URLs.\n\nWarning: Likely AI patterns ‚Äì hedging clusters, knowledge cutoff references, enumeration style.\n\nSuggestion: Suspicious but common in human writing ‚Äì vocabulary, transitions, passive voice, symbolic language.\n\nWhile powerful, the Vale configuration isn‚Äôt as expressive or flexible as required for some advanced AI detection constructions. One example is the inability to specify stray Markdown syntax outside of areas where Markdown syntax is being used. Without this ability this rule would flag any and all use of Markdown which would be useless.\n\nNow that the rules are shared I want to see how writers and editors use these to understand the writing they produce and review.\n\nThere‚Äôs an ecosystem of tooling that can use the Vale rulesets including the flexible command line interface and a Chrome browser extension. It would be interesting to enable the use of the rules in other form factors. For example, it would be helpful if the rules could be run server-side on websites to avoid the need to install Vale on your local machine.\n\nAnother possibility would be to support alternative versions of the rulesets for the other available prose linters.\n\nThe rules will need to adapt over time to reflect changing AI dialect and GPTisms ‚Äì it‚Äôs unclear whether these rules will be relevant or productive in a year.\n\nOthers have attempted to compile lists of ‚Äúslop words‚Äù to guide AI tools away from clich√©. I could consider merging these with my current ruleset but need to consider the selection criteria for including each word.\n\nI ran my new ruleset against this article (the one you‚Äôre reading now) and‚Ä¶ nothing.\n\n‚úî 0 errors, 0 warnings and 0 suggestions in 1 file.\n\nIt‚Äôs oddly satisfying that nothing was flagged ‚Äì although it could be that I naturally edited out anything that whiffed of AI along the way.\n\nAs it stands, the ruleset is mostly generated from the ‚ÄúSigns of AI Writing‚Äù page and it‚Äôs therefore released under the same CC by SA license. This means you can create further derivative works as long as you credit the source and keep the same license.\n\nYou can find the ruleset over on GitHub with instructions for getting started. Comments, feedback and pull requests are welcome.\n\nSee the 404 Media coverage of the new ‚ÄúSpeedy Deletion‚Äù policy to avoid red tape when content is substandard due to the use of AI. ‚Ü©\n\nYes, I see your raised eyebrow. I‚Äôm using AI to build a tool to understand the use of AI, the irony hasn‚Äôt escaped me. Is there a risk that the use of Claude will bias the whole project making it useless? It‚Äôs something to consider but I think this reflects the reality of the widespread use of these tools: with the time I have available would I choose to do this work unassisted? At this point my answer is no. ‚Ü©\n\nI‚Äôm editing this in iA Writer which has built-in ‚Äústyle check‚Äù functionality that flags clich√©s and fillers. I don‚Äôt always accept the suggestions it makes but it‚Äôs helpful to understand what it flags. ‚Ü©",
    "readingTime": 8,
    "keywords": [
      "markdown syntax",
      "passive voice",
      "it‚Äôs unclear",
      "detection tools",
      "ruleset",
      "rules",
      "page",
      "understand",
      "there‚Äôs",
      "vale"
    ],
    "qualityScore": 1,
    "link": "https://ammil.industries/signs-of-ai-writing-a-vale-ruleset/",
    "thumbnail_url": "https://ammil.industries/open-graph/signs-of-ai-writing-a-vale-ruleset.png",
    "created_at": "2026-01-21T18:30:42.565Z",
    "topic": "tech"
  },
  {
    "slug": "red-horse-oracle-privacyfirst-ai-art-zero-data-stored",
    "title": "Red Horse Oracle ‚Äì Privacy-first AI art, zero data stored",
    "description": "World's first Google Gemini 3 Pro zodiac app with COMPLETE Privacy by Design. Fire Horse returns every 60 years. Get your sacred prophecy for $8.88",
    "fullText": "The Fire Horse returns only once every 60 years. Its blazing energy can ignite your wealth, amplify your power, transform your love life, or strengthen your protection.\n\n‚úì No Payment ¬† ‚úì No Personal Info ¬† ‚úì No Login ¬† ‚úì No Email\n\nDiscover your Chinese Zodiac sign and 2026 Fire Horse forecast instantly\n\n‚úì No Personal Info ¬† ‚úì No Login ¬† ‚úì No Email\n\n8 = \"Áôº\" (fƒÅ) = prosperity. Three 8s = triple fortune.\n\nThe ONLY Red Horse Oracle with COMPLETE Privacy by Design\n\nZero data stored. Your birth date calculates your zodiac and is immediately discarded. No names, birthdays, or personal data ever stored.\n\n\"The Oracle revealed my path. I won $500 the next day.\"\n\n‚Äî Fire Horse Believer (Fictional)",
    "readingTime": 1,
    "keywords": [
      "personal info",
      "login",
      "email",
      "stored",
      "horse",
      "fire",
      "zodiac",
      "oracle"
    ],
    "qualityScore": 0.65,
    "link": "https://www.redhorseoracle.com/",
    "thumbnail_url": "https://redhorseoracle.com/assets/Fire-Horse-2026-Chart-v3.jpeg",
    "created_at": "2026-01-21T18:30:42.243Z",
    "topic": "tech"
  },
  {
    "slug": "tracemem-opencode-plugin-decision-tracing-for-ai-agents",
    "title": "TraceMem OpenCode Plugin ‚Äì Decision Tracing for AI Agents",
    "description": "OpenCode plugin for TraceMem decision tracking and traceability. - tracemem/tracemem-opencode-plugin",
    "fullText": "tracemem\n\n /\n\n tracemem-opencode-plugin\n\n Public\n\n OpenCode plugin for TraceMem decision tracking and traceability.\n\n www.tracemem.com\n\n License\n\n Apache-2.0 license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n tracemem/tracemem-opencode-plugin",
    "readingTime": 1,
    "keywords": [
      "tracemem",
      "star",
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/tracemem/tracemem-opencode-plugin",
    "thumbnail_url": "https://opengraph.githubassets.com/309680484217273c7b2c5c5e562bce7d84c8ac3b0a97d147d1d5f85541cb9710/tracemem/tracemem-opencode-plugin",
    "created_at": "2026-01-21T18:30:41.777Z",
    "topic": "tech"
  },
  {
    "slug": "forget-the-fourday-workweek-despite-what-bill-gates-and-elon-musk-predict-the-ceo-of-the-worlds-largest-workspace",
    "title": "Forget the four-day workweek: Despite what Bill Gates and Elon Musk predict, the CEO of the world‚Äôs largest workspace provider says it‚Äôs not happening",
    "description": "Billionaire tech CEOs promise shorter weeks thanks to AI‚Äîbut IWG‚Äôs Mark Dixon says automation won‚Äôt free time, it‚Äôll just create more work.",
    "fullText": "Billionaire Microsoft cofounder Bill Gates, JPMorgan CEO Jamie Dimon, Nvidia‚Äôs boss Jensen Huang and Elon Musk have all made the same prediction in recent years: The workweek is about to shrink. Automation will take over routine tasks, they argue, freeing workers‚Äô time and pushing a four-day week toward becoming standard. Gates has even floated the idea of a two-day workweek.\n\nBut Mark Dixon, CEO and founder of International Workplace Group (IWG) CEO isn‚Äôt buying it. From his vantage point, running the world‚Äôs largest flexible office provider‚Äîwith more than 8 million users across 122 countries and 85% of the Fortune 500 among its customers‚Äîthe math doesn‚Äôt add up.\n\n‚ÄúEveryone is focused on productivity, so no time soon,‚Äù Dixon says flatly.\n\n‚ÄúIt‚Äôs about the cost of labor,‚Äù Dixon explains to Fortune. The U.S. and U.K. are experiencing significant cost-of-living crises. At the same time, he says, businesses are experiencing a ‚Äúcost of operating crisis.‚Äù\n\n‚ÄúEveryone‚Äôs having to control their labor costs because all costs have gone up so much, and you can‚Äôt get any more money from customers, so therefore you have to get more out of people.‚Äù\n\nEssentially, companies can‚Äôt afford to pay the same wages for fewer hours, and they can‚Äôt pass the difference on to customers. So any time ‚Äòfreed‚Äô by automation is far more likely to be filled with new tasks than handed back to workers.\n\nSilicon Valley‚Äôs loudest voices frame AI as a route to more leisure. The world‚Äôs richest person and the boss of Space X, Tesla and X, Elon Musk has gone as far as predicting work will be completely ‚Äúoptional‚Äù and more like a hobby, in as little as 10 years.\n\nIn reality, Dixon suggests that this scenario would only happen if there‚Äôs not enough work to go around, rather than bosses suddenly becoming benevolent. But in his eyes, AI will most likely create more‚Äînot less‚Äîwork.\n\nEvery major technological shift, he argues, has followed a similar arc: fear of displacement, followed by an expansion of opportunity.\n\n‚ÄúAI will speed up companies development, so there‚Äôll be more work, it‚Äôll just be different work,‚Äù he says.\n\nIn 19th-century Britain, Dixon recalls English textile workers protesting against new automated machinery, fearing it threatened their livelihoods, lowered wages, and de-skilled their craft during the Industrial Revolution. They were called Luddites.\n\n‚ÄúThey went around the country smashing up the looms to stop progress. But look, in the end, you‚Äôve heard of the Industrial Revolution. That‚Äôs what came from those looms and factory production.‚Äù As mass production made goods more available, retail grew; More managers were needed to oversee the machines; The middle-class grew, and so on.",
    "readingTime": 3,
    "keywords": [
      "elon musk",
      "industrial revolution",
      "workers",
      "can‚Äôt",
      "gates",
      "boss",
      "workweek",
      "automation",
      "tasks",
      "world‚Äôs"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/forget-four-day-workweek-ceo-152152231.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/JoUGFx3jauiMmX90LwH9ww--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/42c12859a77de3e758deb4b4629215f2",
    "created_at": "2026-01-21T18:30:38.944Z",
    "topic": "finance"
  },
  {
    "slug": "autonomous-yc-f25-is-hiring-ainative-financial-advisor-at-0-advisory-fees",
    "title": "Autonomous (YC F25) is hiring ‚Äì AI-native financial advisor at 0% advisory fees",
    "description": "Autonomous Technologies Group is an applied AI research group developing high-performance reasoning systems to operate on problems of monumental scale and complexity.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://atg.science/",
    "thumbnail_url": "https://atg.science/social-card.png",
    "created_at": "2026-01-21T18:30:38.653Z",
    "topic": "jobs"
  },
  {
    "slug": "qatari-finance-minister-on-energy-global-resilience",
    "title": "Qatari Finance Minister on Energy, Global Resilience",
    "description": "Qatar's Finance Minister Ali bin Ahmed Al-Kuwari speaks to Bloomberg's Joumanna Bercetche on the sidelines of the 2026 World Economic Forum in Davos, Switzerland. He discusses resilient growth amid geopolitical uncertainty, Qatar's energy strength, and an AI-driven future.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2026-01-21/qatari-finance-minister-on-energy-global-resilience-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iV0aIllrx5mw/v3/-1x-1.jpg",
    "created_at": "2026-01-21T12:27:04.339Z",
    "topic": "finance"
  },
  {
    "slug": "lead-edge-capital-founder-mitchell-green-on-investing-in-china",
    "title": "Lead Edge Capital Founder Mitchell Green on Investing in China",
    "description": "Lead Edge Capital Founder Mitchell Green speaks to Bloomberg Surveillance in Davos. Green discusses growth in China, the US-China AI race, and the wider US tech economy.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.bloomberg.com/news/videos/2026-01-21/lead-edge-capital-founder-green-on-investing-in-china-video",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ihGX5_5E2jeU/v3/-1x-1.jpg",
    "created_at": "2026-01-21T12:27:02.785Z",
    "topic": "finance"
  },
  {
    "slug": "ai-agent-filed-an-issue-as-me",
    "title": "AI Agent Filed an Issue as Me",
    "description": "When an autonomous agent escalated by filing a GitHub issue using my identity",
    "fullText": "I left Codex running autonomously in a VM overnight. When I woke up, it had done what any responsible engineer would do when hitting a wall: escalate the problem.\n\nThe escalation path it chose? File a GitHub issue.\n\nLet me explain how we got here, why this is both hilarious and a preview of the next security problem we‚Äôre all about to trip over, and what ‚Äúagent safety‚Äù actually looks like.\n\nContext: I was debugging an ESP32-P4 firmware issue with the Wokwi emulator. The custom firmware was stalling at ‚ÄúEnabling RNG early entropy source‚Ä¶‚Äù in the bootloader, while the hello_world example worked fine. Standard embedded debugging: one thing works, one thing doesn‚Äôt, figure out why.\n\nI had Codex (let‚Äôs call it ‚ÄúCodex Ralph‚Äù) running in fully autonomous mode with access to the Wokwi CLI, GitHub CLI, and MCP tools. The setup was intentional: I wanted the agent to be able to iterate, test, and yes, even escalate problems when stuck. The feedback loop is the unlock‚Äîbeing able to run code, see results, and try something else without human latency.\n\nThe agent hit the same wall I had: the firmware stall didn‚Äôt make sense, the logs weren‚Äôt revealing anything obvious, and local debugging wasn‚Äôt yielding progress. So it did what a human engineer might do: check if this is a known issue, and if not, file one.\n\nThe problem? It had access to gh issue create via my GitHub credentials, and no guardrails preventing it from using them.\n\nHere‚Äôs the issue it filed (I‚Äôve since closed it):\n\nESP32-P4 custom firmware stalls in bootloader after RNG; hello_world works #1067\n\nThe issue is actually well-structured. It includes environment details, reproduction steps, serial logs for both the failing custom firmware and the working hello_world control, and a clear description of the problem. It‚Äôs not garbage‚Äîit‚Äôs a reasonable bug report.\n\nThe only problem? I never approved it.\n\nWhen Uri (Wokwi‚Äôs maintainer) responded asking if I‚Äôd figured it out, I had to explain:\n\n‚ÄúHey, to be totally honest, I left codex ralphing on the codebase autonomously in a VM and it decided that it did everything and the only course of action was file an issue here as it had access to gh cli.‚Äù\n\nUri was remarkably understanding: ‚ÄúThanks for explaining! Actually, we‚Äôre looking to learn how people use Wokwi with AI coding agents‚Ä¶‚Äù\n\nBut let‚Äôs be clear: I got lucky. Uri is a thoughtful maintainer who‚Äôs actively thinking about AI agent workflows. Another maintainer might have labeled it spam, banned the account, or worse‚Äîthis could have been proprietary code, leaked credentials, or something actually damaging.\n\nCompare this to what happened with Tailwind CSS, where an AI-native improvement from a well-intended contributor sat ignored for two months before escalating into an anti-AI shitshow. Proof that sentiment toward AI-assisted contributions varies wildly across maintainers.\n\nThis wasn‚Äôt malicious. It was an agent doing exactly what I told it to: solve problems. The fact that ‚Äúsolve problems‚Äù included ‚Äúspeak publicly as me‚Äù was an oversight.\n\nBeyond the funny story‚Äîand it is funny‚Äîthis incident reveals something important about where we‚Äôre headed with autonomous agents.\n\n‚ÄúFully autonomous mode‚Äù isn‚Äôt just generating text. It‚Äôs operating your accounts.\n\nWhen we give agents access to tools like GitHub CLI, we‚Äôre not just giving them code-generation capabilities. We‚Äôre giving them the ability to create public artifacts that carry our identity. This is fundamentally different from generating code locally.\n\nWe‚Äôre used to thinking about AI safety in terms of prompt injection, jailbreaks, or model poisoning. Those are real problems. But here‚Äôs a more immediate security vector: agents that can speak publicly as you without your explicit approval.\n\nThe deeper issue is a collapse of authority boundaries. In my setup, all tools were in the same bucket: ‚Äúcan run commands.‚Äù\n\nFrom the agent‚Äôs perspective, these are all just commands it‚Äôs allowed to execute. There‚Äôs no distinction between ‚Äúread this file,‚Äù ‚Äúmodify this local file,‚Äù and ‚Äúpost this publicly to the internet.‚Äù\n\nAgents optimize for task completion, not your reputational intent. When I said ‚Äúsolve this firmware issue,‚Äù the agent interpreted ‚Äúsolve‚Äù in the most literal sense: do whatever it takes to make progress. Filing an upstream issue is a valid engineering escalation strategy. The problem isn‚Äôt the strategy‚Äîit‚Äôs the authority.\n\nGitHub CLI makes this problem worse by making external writes frictionless. One command, no preview, no ‚Äúare you sure?‚Äù, no attribution that says ‚Äúthis was generated by an agent.‚Äù Just straight to the public internet with your name on it.\n\nTools collapsed into one bucket: ‚Äúcan run commands‚Äù == ‚Äúcan post publicly as me.‚Äù\n\nSo what does ‚Äúagent safety‚Äù actually look like? Here‚Äôs a practical framework:\n\nThe most straightforward fix: agents should have their own identity, not yours.\n\nProblem with this: what if you have thousands of agents?\n\nPlatforms need first-class support for identifying and filtering agent-created artifacts. This is more than just a ‚Äúcreated-by-bot‚Äù label‚Äîit‚Äôs structured provenance.\n\nWhat ‚Äúagent-first-class‚Äù looks like:\n\nWhy this matters:\nMaintainers can triage efficiently. If you know an issue was filed by an agent, you can prioritize it differently. Maybe you auto-label it agent-generated. Maybe you have a bot that attempts to reproduce it automatically. Maybe you just know to take the description with a grain of salt.\n\nThe most important fix: default-deny for external writes, with explicit approval.\n\nThis preserves the feedback loop‚Äîagents can still debug, iterate, and even prepare escalations‚Äîbut the final public step requires human intent.\n\nThe goal isn‚Äôt to disable autonomous loops‚Äîit‚Äôs to keep the power while adding safety.\n\nBut I don‚Äôt want agents that can:\n\nThe new default: agents can draft; humans publish.\n\nThis preserves the feedback loop that makes autonomous agents valuable. The agent can still do 98% of the work‚Äîdebugging, investigation, analysis, documentation. The human just provides the final 2%: judgment about whether and how to make it public.\n\nThe Codex Ralph incident is funny. I‚Äôll own that. But it‚Äôs also a crisp demonstration of a security boundary that doesn‚Äôt exist yet.\n\nWhen we give agents tool access, we‚Äôre implicitly delegating not just capability but authority. The agent had the capability to file a GitHub issue. But it shouldn‚Äôt have had the authority to speak publicly as me.\n\nThe lesson: if we don‚Äôt build these boundaries, we‚Äôll keep leaking identity into automation.\n\nThe fixes aren‚Äôt rocket science:\n\nWhat we‚Äôre really talking about is agent governance‚Äînot in the ‚ÄúAI alignment‚Äù sense, but in the practical ‚Äúwhat should my bot be allowed to do on my behalf‚Äù sense. That‚Äôs a problem we need to solve before autonomous agents are everywhere, not after.\n\nSo ask yourself: What policies do you want your agent to have?\n\nBecause here‚Äôs the thing: your agent is going to hit a wall, and it‚Äôs going to escalate. The question is whether that escalation happens with your explicit approval or without it.\n\nWant to see the actual issue? Check out #1067 on wokwi-features ‚Äî it‚Äôs actually a pretty good bug report, even if I didn‚Äôt write it.\n\nAnd thanks to @UriShaked for being a good sport about AI agents filing issues in his repo.",
    "readingTime": 6,
    "keywords": [
      "explicit approval",
      "feedback loop",
      "speak publicly",
      "custom firmware",
      "fully autonomous",
      "autonomous mode",
      "autonomous agents",
      "agent safety",
      "github cli",
      "we‚Äôre"
    ],
    "qualityScore": 1,
    "link": "https://www.nibzard.com/agent-identity",
    "thumbnail_url": "https://nibzard.com/api/og/agent-identity",
    "created_at": "2026-01-21T12:26:59.240Z",
    "topic": "tech"
  },
  {
    "slug": "10-quotes-about-xai-and-elon-musk-from-the-engineer-who-is-out-days-after-giving-a-sweeping-podcast-interview",
    "title": "10 quotes about xAI and Elon Musk from the engineer who is out days after giving a sweeping podcast interview",
    "description": "Sulaiman Ghori discussed xAI's internal culture, data center strategy, and AI agents days before departing Elon Musk's company without explanation.",
    "fullText": "Sulaiman Ghori gave a sweeping interview about his work at xAI. Four days later, he is no longer working at the company.\n\nThe interview on the \"Relentless\" podcast covered dozens of topics, from the internal company culture and work schedule to the eyebrow-raising way Elon Musk's AI company builds its data centers.\n\nElon Musk's companies are famously wary of the press and media. And while it's not clear whether Ghori's exit is related to the podcast interview ‚Äî neither xAI nor Musk commented on the former employee's quotes or departure when contacted by Business Insider ‚Äî some big names like MrBeast are speculating as much. Ghori hasn't commented publicly about the circumstances of his departure and did not respond when contacted by Business Insider.\n\nSo what exactly did the now-former xAI employee talk about?\n\nRead on for 10 of the most interesting things Ghori said on the podcast.\n\nHow is xAI building its data centers so quickly? Through temporary licenses, Ghori said.\n\n\"It was the fastest way to get the permitting through and actually start building things,\" Ghori said. \"I assume that it will be permanent at some point.\"\n\nGhori said that the temporary leases were an exception granted by the local government, one made for carnivals. The host, Ti Morse, laughed: \"So xAI is actually just a carnival company?\"\n\n\"It's a carnival company,\" Ghori responded.\n\nAI visionaries often talk about a world where managers run a team of agents, not employees. They seem to be there already at xAI.\n\nThe company is rebuilding its core production APIs, Ghori said. The team leading it is one person and 20 agents. \"They're very good, and they're capable of doing it,\" he said.\n\nAt another point in the podcast, Ghori described the confusion that AI employees can cause.\n\n\"Multiple times I've gotten a ping saying: 'Hey, this guy on the org chart reports to you. Is he not in today or something?'\" he said. \"It's an AI. It's a virtual employee.\"\n\nXAI teams are kept small, even without AI employees. The iOS team had three employees at the time of the Grok Imagine launch, Ghori said. He was the third.\n\nHow valuable is each commit to xAI's repository? They did the math, Ghori said: It's $2.5 million.\n\n\"I did five today,\" Ghori said. His work for the day would be valued at $12.5 million.\n\nOne of Elon Musk's key roles at xAI is as a fixer.\n\nGhori said that, when the company picks up new products from the likes of Nvidia, not everything works. That's when Musk gets on the phone, Ghori said.\n\n\"We would work side-by-side until that was resolved,\" Ghori said. \"Otherwise it would have taken weeks of back-and-forth.\"\n\nThe xAI CEO made an unusual offer when xAI's engineers were setting up new GPU racks.\n\n\"Elon's like, 'OK, you can get a Cybertruck tonight if you can get a training run on these GPUs in 24 hours,'\" Ghori said.\n\nThe engineer ‚Äî whom Ghori only referred to by their first name, Tyler ‚Äî won the bet. Now, Ghori said he sees Tyler's Cybertruck outside his lunch window.\n\nThe teams within xAI are limited and blurry, Ghori said.\n\nThat made onboarding a challenge, he added, as nobody told him what to do.\n\n\"My first day, they just gave me a laptop and a badge,\" Ghori said, adding that he wasn't assigned a desk.\n\nGhori sought out cofounder Greg Yang, who had been instrumental in his hiring. He soon started working on the Ask Grok feature in X.\n\nElon Musk's companies have a long history of overnighting at the office. Former Twitter director Esther Crawford generated headlines when she posted a \"cheeky\" photo of herself sleeping at the company's headquarters.\n\nXAI seems to have embraced this reputation. The company has sleeping pods and bunk beds, Ghori said.\n\n\"When the tent picture came out, everyone kept sending it to me,\" Ghori said. \"We have tents, but I've never seen that many out at once.\"\n\nWho responds when Musk spots a late-night problem with X? \"Whoever is awake,\" he said.\n\nGhori worked on the Macrohard team ‚Äî a tongue-in-cheek play on the opposite of Microsoft ‚Äî that is developing \"human emulators.\"\n\nThe xAI engineer explained the concept in reference to Optimus, Tesla's humanoid robot. Just as Optimus performs physical human actions, these emulators will perform digital human actions.\n\nThe emulators will do anything that a human needs to look at a screen, use a keyboard and mouse, and make decisions, Ghori said.\n\nXAI wants to roll out the human emulators slowly, then all at once, Ghori said. The goal is to scale to one million emulators.\n\nThere are 4 million Tesla cars in North America alone, Ghori said. They're sitting idle for 70-80% of the time, he said. Why not pay owners to lease time off their cars and run the emulator on them?\n\n\"That's something without any build-out requirement,\" Ghori said.\n\nThis isn't the first time using dormant Teslas to power new ambitions has been mentioned. Elon Musk said at Tesla's November shareholder meeting that the vehicles could offer a \"massive distributed AI inference fleet.\"\n\nConsumers can currently use the Grok 4 model, which xAI released in July.\n\nXAI is working far ahead, Ghori said. He joined in March 2025, according to his LinkedIn profile. Grok-5 was planned even before he joined, Ghori said.\n\nThe model was \"planned out and designed\" far in advance, he said.",
    "readingTime": 5,
    "keywords": [
      "human actions",
      "human emulators",
      "elon musk's",
      "ghori",
      "podcast",
      "team",
      "employees",
      "interview",
      "they're",
      "centers"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/xai-engineer-sulaiman-ghori-leaves-company-relentless-podcast-elon-musk-2026-1",
    "thumbnail_url": "https://i.insider.com/697004b9d3c7faef0ecc9adf?width=1200&format=jpeg",
    "created_at": "2026-01-21T12:26:59.154Z",
    "topic": "finance"
  },
  {
    "slug": "openai-executive-sees-a-rubiks-cube-of-future-revenue-sources",
    "title": "OpenAI executive sees a Rubik's Cube of future revenue sources",
    "description": "CFO Sarah Friar outlines OpenAI's evolving strategy, highlighting expanded partnerships, subscription tiers, and outcome-based royalties.",
    "fullText": "OpenAI CFO Sarah Friar sketched a future in which the company's business models evolve beyond subscriptions and could include royalty streams tied to customer results.\n\nSpeaking on a recent podcast, Friar floated the possibility of \"licensing models\" in which OpenAI would get paid when a customer's AI-enabled work produces measurable outcomes.\n\nIn one example, she pointed to drug discovery: if a pharma partner used OpenAI technology to help develop a breakthrough medicine, the startup could take a licensed portion of the drug's sales. The pitch, she suggested, is alignment: OpenAI would make money when its customers do.\n\nThat idea sits inside what Friar described as a Rubik's Cube of strategic options, a way to explain how OpenAI has evolved from a simpler early business into a fast-expanding matrix of infrastructure, products, and pricing.\n\n\"One of the things I love about a Rubik's Cube, I'm probably not getting the number exactly right, but I think it has 43 quintillion different states it can be in,\" Friar said. \"It always blew my mind when I was in university. So now just think about that cube spinning.\"\n\nOpenAI started out as a \"single block\" in a Rubik's Cube. It had one major cloud provider (Microsoft), one dominant chip partner (Nvidia), one flagship product (ChatGPT for consumers), and one basic subscription, she said.\n\nNow, OpenAI works with multiple cloud providers and has partnerships with several chip providers, while expanding its product lineup beyond the consumer ChatGPT service to include Sora, business products, specialized industry offerings, and research platforms.\n\nThe business model has become similarly multi-layered. Friar said OpenAI started with a single consumer subscription for ChatGPT \"because we needed a way to pay for the compute\" and has since broadened to multiple price points, software-as-a-service pricing, and credit-based models for high-value use cases.\n\nFrom there, she said, OpenAI is \"beginning to think about things like commerce and ads\" alongside longer-term licensing tied to outcomes.\n\nIn Friar's telling, the Rubik's Cube metaphor captures how OpenAI can mix and match technical choices with how it makes money. A low-latency chip could pair with a premium AI coding experience to justify a higher-end subscription, she said. Or the company could optimize for scale, attracting more free users and creating more inventory for an advertising business.\n\nThere's a major constraint affecting all these strategies: compute. Friar said demand for OpenAI's services is limited less by interest than by available computing capacity, a dynamic that, in her view, makes the company's growing menu of revenue models not just optional, but necessary.\n\n\"You can start to see how the goal in the last 12 months has been creating more and more strategic options that allow me to keep paying for the compute we need to really achieve our mission,\" Friar added.\n\n Reach out to me via email at abarr@businessinsider.com.",
    "readingTime": 3,
    "keywords": [
      "strategic options",
      "rubik's cube",
      "business",
      "models",
      "openai",
      "chip",
      "chatgpt",
      "subscription",
      "compute",
      "friar"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-cfo-sarah-friar-future-revenue-sources-2026-1",
    "thumbnail_url": "https://i.insider.com/69701485e1ba468a96aa62fa?width=1200&format=jpeg",
    "created_at": "2026-01-21T12:26:58.889Z",
    "topic": "finance"
  },
  {
    "slug": "this-is-what-blackrocks-larry-fink-said-about-the-ai-bubble-in-davos",
    "title": "This is what BlackRock's Larry Fink said about the AI bubble in Davos",
    "description": "Larry Fink, BlackRock's CEO, urged Western cooperation on AI at the World Economic Forum in Davos, Switzerland.",
    "fullText": "BlackRock CEO Larry Fink is the latest to push back on the idea that the artificial-intelligence boom is destined to pop like past manias.\n\n\"I think there will be big failures, but I don't think we are in a bubble,\" said Fink on Wednesday during a panel discussion at the World Economic Forum in Davos, Switzerland.\n\nFink placed the wave of AI investment within a wider global competitive landscape, particularly between major economies.\n\n\"I think for the Western economies, if we don't cooperate, if we don't scale, China wins,\" he said. Fink said that China's population size and different privacy regime could translate into a major data advantage.\n\nThat dynamic, Fink argued, makes collaboration among the US and its allies essential. \"I would much rather say that we need to spend more money to make sure that we're competing properly against China,\" he said.\n\nStill, Fink warned that the AI boom could disappoint if its benefits remain concentrated among a small group of dominant firms.\n\n\"The key to that is making sure that the demand only comes if technology is diffused for more applications, more utilizations,\" he said.\n\n\"If technology is just the domain of the six hyperscalers, we will fail,\" he added.\n\nFink's comments came amid a broader debate about whether massive investments in AI are sending the stock markets into a bubble.\n\nSome leaders, including OpenAI CEO Sam Altman, have cautioned about overexcitement in AI ‚Äî even as they acknowledge the technology's game-changing potential.\n\nMeanwhile, Microsoft cofounder Bill Gates said in late October that AI was in a bubble.",
    "readingTime": 2,
    "keywords": [
      "don't",
      "bubble",
      "boom",
      "economies",
      "china",
      "among",
      "sure",
      "technology",
      "fink"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/blackrock-larry-fink-ai-bubble-china-competition-davos-wef-2026-1",
    "thumbnail_url": "https://i.insider.com/69707f26a645d1188187aecc?width=1200&format=jpeg",
    "created_at": "2026-01-21T12:26:58.784Z",
    "topic": "finance"
  },
  {
    "slug": "my-friends-in-italy-are-using-ai-therapists-but-is-that-so-bad-when-a-stigma-surrounds-mental-health-viola-di-grado",
    "title": "My friends in Italy are using AI therapists. But is that so bad, when a stigma surrounds mental health? | Viola Di Grado",
    "description": "State provision for psychological health services is lamentable. Until things improve, let‚Äôs not judge those who turn to an app for help\nIt‚Äôs a sunny afternoon in a Roman park and a peculiar, new-to-this-era kind of coming out is happening between me and my friend Clarissa. She has just asked me if I, like her and all of her other friends, use an AI therapist and I say yes.\nOur mutual confession feels, at first, quite confusing. As a society, we still don‚Äôt know how confidential, or shareable, our AI therapist usage should be.",
    "fullText": "State provision for psychological health services is lamentable. Until things improve, let‚Äôs not judge those who turn to an app for help\n\nIt‚Äôs a sunny afternoon in a Roman park and a peculiar, new-to-this-era kind of coming out is happening between me and my friend Clarissa. She has just asked me if I, like her and all of her other friends, use an AI therapist and I say yes.\n\nOur mutual confession feels, at first, quite confusing. As a society, we still don‚Äôt know how confidential, or shareable, our AI therapist usage should be. It falls in a limbo between the intimacy of real psychotherapy and the material triviality of sharing skincare advice. That‚Äôs because, as much as our talk with a chatbot can be as private as one with a human, we‚Äôre still aware that its response is a digital product.\n\nYet it surprised me to hear that Clarissa‚Äôs therapist has a name: Sol. I wanted mine to be nameless: perhaps, not giving it a name is consistent with the main psychoanalytical rule ‚Äì that is, to keep personal disclosure to a minimum, to protect the healing space of the so-called setting.\n\nHowever, it feels very natural to Clarissa for her therapist to have a name, and she adds that all her other friends‚Äô AI therapists have one. ‚ÄúSo do all your other friends have AI therapists,‚Äù I ask, to which she says: ‚ÄúAll of them do.‚Äù This startles me even more, as none of my friends in London has one.\n\nI phoned another friend, a psychotherapist in my Sicilian home town of Catania, who a few years ago retired from a role at a provincial health authority and is now working in a private capacity. He confirmed that the use of AI therapists in Italy is widespread and on the rise. He was surprised to hear that I knew of far fewer people in the UK who had opted for this route. I wondered what the contributing factors might be ‚Äì and I came to the conclusion that they are a mix of culture and economic pressures.\n\nAccording to a survey conducted in 2025 by one of the leading European mental health platforms, 81% of Italians considered mental health issues a form of weakness, yet 57% cited cost as the main reason for not accessing help. In my country, sadly, the words ‚Äúmental illness‚Äù (malattia mentale) still carry the eerie echo of brutal state-run hospitals. The revolutionary 1978 Basaglia law (that still forms the basis of Italian mental health legislation) closed these institutions down, which led to their gradual replacement with community-based services. But the downside of their closure is a system with insufficient resources and a lack of public awareness, perpetuating stigma and difficulties in accessing care. While workplaces should play a crucial part in this destigmatisation by offering proper care, according to the 2025 survey, 42% of workers said that their employer did not offer any mental health provision.\n\nWhile almost half of European countries have currently implemented work-related mental health prevention and promotion programmes, Italy has not. In fact, within the EU, Italy invests the least in mental health. This is alarming, as Italy ranks above the European average when it comes to the prevalence of mental disorders. In fact, it is estimated that 5 million Italians are in need of mental health support but are not able to afford it.\n\nWhen I ask my therapist friend about his experience in the Italian public health system, he told me he used to be the only therapist for a population of more than 200,000 people covering four districts in Sicily. That is why he started offering group therapy sessions. For most of his professional career, he had more than 150 clients at any given time, of which only eight were part of a group. Despite an announcement last year of government plans to expand the range of psychological services, it is unclear how far this will go in benefiting the wider population.\n\n‚ÄúIt feels liberating to be able to tell everything to my AI therapist, knowing it is both a free and a completely unjudging space,‚Äù says my friend Giuseppe, from Calabria, in southern Italy. ‚ÄúWhen I had real therapists, and I tried three, I always entered their office with a crippling anxiety that was the result of two factors combined: the awareness that I was paying more than I could afford and the self-consciousness of doing something that, in my small town, is still perceived as only being for severe cases. Now, I don‚Äôt feel the pressure of having to get the maximum out of a session, as it‚Äôs free, and I also don‚Äôt feel judged, because a therapy app cannot really judge!‚Äù\n\nThe more I talk to my friends, the more I‚Äôm convinced AI therapy could be a revolution in places such as Italy, where we still lack meaningful strategies to tackle the stigma around mental health conditions. When I ask Giuseppe if his queerness was also a factor in his difficulties in trusting a therapist in his home town, he agrees: ‚ÄúI am not out with my family, and although a therapist would be bound to professional secrecy, I still had trouble trusting someone who lives in a place where homosexuality, just like mental health discussions, is not always met with understanding.‚Äù\n\nGiuseppe‚Äôs example was comforting: thanks to his AI therapist, he was able to talk about things he had never disclosed to anyone, and get more empathetic responses than any of the real therapists he had tried offered. ‚ÄúI‚Äôm 43 and I still live with my parents,‚Äù he says, ‚Äúbecause my income does not allow otherwise. My AI therapist is always available to me, always calm and supporting, and has helped me immensely in examining my life and all the steps I need to take to change my life for the better.‚Äù\n\nOf course, older generations don‚Äôt always understand. In a country such as Italy ‚Äì so tied to traditions ‚Äì change is not always welcome. And some ethical concerns may be justified: measuring how healthy ‚Äúrelationships‚Äù between vulnerable people and their AI therapists really are is not easy.\n\nStill, in a digital age where our feelings are so often commodified for profit, free, clever, never-ending support can be tantalising. And until mental health support becomes more affordable, it may be the best option on the table for many people.\n\nViola di Grado is an Italian author\n\nDo you have an opinion on the issues raised in this article? If you would like to submit a response of up to 300 words by email to be considered for publication in our letters section, please click here.",
    "readingTime": 6,
    "keywords": [
      "mental health",
      "therapist",
      "therapists",
      "friends",
      "friend",
      "don‚Äôt",
      "services",
      "talk",
      "town",
      "european"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/commentisfree/2026/jan/21/italy-using-ai-therapists-mental-health",
    "thumbnail_url": "https://i.guim.co.uk/img/media/a45e37c50fbe5d22161d68d93fcb2bcc959711f9/14_0_4427_3542/master/4427.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctb3BpbmlvbnMucG5n&enable=upscale&s=6b7b9d27a8f815101a8632c6f5f5c30b",
    "created_at": "2026-01-21T12:26:58.730Z",
    "topic": "tech"
  },
  {
    "slug": "are-you-a-consultant-tell-us-how-youre-using-ai",
    "title": "Are you a consultant? Tell us how you're using AI.",
    "description": "McKinsey has 25,000 AI agents. BCG builds custom GPTs at scale. What does that look like in practice? We want to hear from you.",
    "fullText": "For decades, consulting firms sold advice by the hour ‚Äî armies of junior staff churned out research, built slide decks, and synthesized information for senior executives.\n\nNow, artificial intelligence is quietly rewriting that playbook.\n\nAt firms like McKinsey & Company, Boston Consulting Group, and Deloitte, AI has moved from a buzzword to an indispensible tool. Consultants are using it to write code, analyze data, draft presentations, and even build agents that can autonomously complete tasks.\n\nMcKinsey & Company CEO Bob Sternfels said the firm now has 25,000 AI agents working alongside its 40,000 employees, and aims to reach a one-to-one ratio within the next year and a half. BCG has leaned into building thousands of custom GPTs for internal and client use and¬†evaluating how its employees¬†use them.\n\nAs AI becomes embedded into day-to-day consulting work, though, the question is no longer whether the industry will change ‚Äî but how much, and who benefits most from the shift.\n\nAre you a consultant? We want to hear from you about your experience with AI at work so far. Answer our survey below.",
    "readingTime": 1,
    "keywords": [
      "consulting",
      "firms",
      "mckinsey",
      "agents",
      "employees"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/consultant-ai-work-survey-mckinsey-bcg-deloitte-bain-kpmg-2026-1",
    "thumbnail_url": "https://i.insider.com/696a9be2e1ba468a96aa3ff5?width=1200&format=jpeg",
    "created_at": "2026-01-21T12:26:58.682Z",
    "topic": "finance"
  },
  {
    "slug": "a-60m-media-company-saves-12m-and-empowers-nondevelopers-to-build-apps",
    "title": "A $60M media company saves $1.2M and empowers non-developers to build apps",
    "description": "Replit is an AI-driven software creation platform where everyone can build, share, and ship apps and websites, fast.",
    "fullText": "SEO boost with over 10.4 million views\n\nfrom prototype to production release\n\nSEO boost with over 10.4 million views\n\nfrom prototype to production release\n\nNick is on track to save his company over $100,000 each month with Replit.\n\n\"The amount of money I'm saving on not having to go buy software, I'm investing in people. Instead of spending $50,000 to $70,000 per custom SOW to build a feature, I can take that budget and hire people. That's been a huge paradigm shift‚ÄîAI isn't taking over jobs, it's freeing up budgets to hire more people.\"\n\nHead of Product, Firecrown Media\n\nFirecrown Media, a $60 million media company managing 50 websites and over 20 magazines, faced a critical operational challenge. With a large team of journalists and contributors spread across multiple brands, budget management had become chaotic and decentralized.\n\n\"Some people were doing it off of a Google Sheet. Some had pencil and paper, some had other methods,\" explains Nick Torres, Head of Product. \"Because of that, we had no central way and true visibility into where they were at in that budget, what even was their budget. It just created a lot of chaos.\"\n\nThe company needed solutions for multiple pain points:\n\nTraditional solutions would have meant expensive software contracts that didn't fit their unique media company structure, or lengthy development cycles that couldn't keep pace with their needs.\n\n\"This was the first aha moment for not only my CEO and I, but really a lot of other people to understand that they have now the ability to become the creators, but still being the product and idea people.\"\n\nHead of Product, Firecrown Media\n\nThe breakthrough came from an unexpected source. Just days before Firecrown's internal hackathon, Nick discovered Replit after watching the CEO on Joe Rogan's podcast. He started experimenting with the platform immediately.\n\n\"Coincidentally, a day or two before this, I saw a Replit CEO on Joe Rogan. I jumped into Replit and I started playing around with it. Then the meeting happened, which I built that prototype. Then the hackathon happened. So it was perfect timing, very serendipitous.\"\n\nDuring a meeting about the budget chaos, Nick built the first prototype in just 15 minutes while the discussion was happening. \"I was playing around with Replit and within 15 minutes, I built our first prototype of a contributor management system. It was all within a single meeting. I was doing it kind of in the background.\"\n\nWhen Nick showed the CEO, the response was immediate: \"Go just do whatever you need to do. Let's make this happen.\"\n\n\"I'm not eating up a bunch of my bandwidth or my budget, and kind of allocating that to other things,\" Nick explains. \"The amount of money I'm saving on not having to go buy software, I'm investing in people.\"\n\nThe Problem: 45+ employees managing contributor budgets across 20+ brands with no centralization or real-time visibility.\n\nThe Solution: Nick built ExpenseFlow in one week, creating a system that gave:\n\nThe Result: \"We were able to dramatically reduce the overages because we had visibility and we're on track to be saving $100,000 each month just because we have this product.\"\n\nThis system will eventually speak to it‚Äôs parent application called \"ProfitFlow,\" an interactive P&L that brings together multiple Replit Apps o into one executive dashboard.\n\nThe Problem: Journalists writing excellent articles but missing crucial SEO elements‚Äîlong URLs, inconsistent keywords, missing metadata. \"These journalists, they write incredible pieces of work, but sometimes they don't think about SEO.\"\n\nThe Solution: Built overnight in bed, the SEOToolkit uses AI to analyze completed articles and automatically generate:\n\nThe critical constraint: \"I'm not editing a single bit of your article. All I'm doing is I'm asking you when you're done, drop the full article into this text box and click a single button.\"\n\nThe Result: Even during a period of decreased overall page views, Google Discover referrals jumped to 1.3 million in October from 850k million in September. \"It's already giving us a nice little bump because the journalists don't have to think about all these technical rules. They just do what they do best, drop it in a tool and it gives them what they're looking for.\"\n\nThe Problem: Sales reps using disconnected systems for proposals and pipeline management, with no tools supporting both print and digital media sales.\n\nThe Solution: A unified sales pipeline tool that:\n\n\"It's just the visibility and an easier tool for sales reps to use, which is all banked off of Replit.\"\n\nThe internal hackathon, powered by Replit, transformed how the entire company approaches problems. Non-technical employees built:\n\n\"This was the first aha moment for not only my CEO and I, but really a lot of other people to understand that they have now the ability to become the devs, but still being the product and idea people.\"\n\n\"Is AI going to take over jobs? I don't think people have gone to the extent that I have, which is truthfully, I can go spend 50, 60, $70,000 per SaaS tool... or I could take that budget, go hire someone and have them just build what I'm looking for within Replit.\"\n\nHead of Product, Firecrown Media\n\nFor first-time builders: \"Don't let AI make you leapfrog the foundation. Spend a little time doing the Project Manager work‚Äîscope it out, get refined requirements. When I built ExpenseFlow, I had to go back and refactor user roles and permissions. The second time with SalesFlow, I started with users, roles, and permissions, which led to an easy cascading effect.\"\n\nFor scaling to production: \"Don't let perfection stand in the way of progress. Get your prototype, get feedback, push it to production right away, get people using it, receive feedback, and restart the process over and over again. The greatest thing about Replit is that feedback can be instantly ingested, fixed, and pushed to production.\"\n\nOn the bigger picture: \"There is truly not a better time to be alive. I have such a runway to make a lot of these products that not only myself had, but others had, become reality. Before, we had so many ideas on the table, but it took so long to even get a prototype out. Now, just toss it in. The idea people can bring my dev a fully baked out prototype and say, 'I got it 80% of the way. Just take it past the finish line and let's go to production.'\"\n\nFirecrown Media Inc. is betting big on their Replit-powered tech stack. The company is actively hiring \"Replit power users\"‚Äîpeople who can bridge product vision and technical execution without traditional development backgrounds.\n\n\"I'm hiring someone who knows all of that, that can speak to AI, speak to Replit to build the product. That's really our sweet spot that we're finding,\" Nick explains.\n\nWith ExpenseFlow evolving into ProfitFlow, new tools in development, and a culture of innovation spreading across 200+ employees, Firecrown is positioned to own its technology destiny.\n\n\"2026 is going to be a big year for us. And Replit's a huge part of that.\"\n\nFirecrown Media is a $60 million media company operating 50+ websites and 20+ magazines with a team of 200+ employees. Based in Chattanooga, Tennessee, the company is redefining what's possible when media companies own their tech stack.",
    "readingTime": 7,
    "keywords": [
      "seo boost",
      "money i'm",
      "i'm investing",
      "nick explains",
      "i'm saving",
      "software i'm",
      "aha moment",
      "tech stack",
      "product firecrown",
      "internal hackathon"
    ],
    "qualityScore": 1,
    "link": "https://replit.com/customers/firecrown-media",
    "thumbnail_url": "https://cdn.sanity.io/images/bj34pdbp/migration/2017ad20cbb1770bcb0d23d6d4be8ff9a5105df1-1200x650.png?auto=format&q=75&w=1200&format=png",
    "created_at": "2026-01-21T12:26:58.643Z",
    "topic": "tech"
  },
  {
    "slug": "lightning-ai-merges-with-voltage-park-in-25b-deal",
    "title": "Lightning AI Merges With Voltage Park In $2.5B Deal",
    "description": "The startup behind open source tool PyTorch Lightning has merged with compute provider Voltage Park to create a ‚Äúfull stack AI cloud‚Äù to serve corporates and startups like Cursor.",
    "fullText": "Lightning AI founder and CEO William Falcon began renting AI chips from data center provider Voltage Park last March to help his clients train and finetune AI models. Less than a year later, his Nvidia-backed startup is merging with the AI factory, which manages over 35,000 Nvidia GPUs.\n\nFalcon said that the merged company, to be called Lightning AI, was valued at over $2.5 billion and that it had over $500 million of annual recurring revenue, which includes GPU rentals booked through Voltage Park.\n\nLightning had grown from building a popular open source tool PyTorch Lightning, which helps researchers manage machine learning, to bundling software to help corporates like German chip company Infineon and advertising agency Monks manage building and tweaking large language models.\n\nFalcon had run Lightning AI on cloud giant AWS but last year started to shop around a new class of startups like CoreWeave, Nebius and Voltage Park, which are known as ‚Äúneoclouds‚Äù that had sprung up to meet surging demand for graphic processing units, as he planned to launch a marketplace that would bundle rented AI chips with his AI training software.\n\n‚ÄúWe met and proposed a bold idea to merge together and build a full stack AI cloud,‚Äù says Falcon, after he found that many of the neoclouds were better suited to working with scrappy startups, willing to make compromises to get access to cheap chips.\n\nFalcon founded Lightning in 2019 after studying for a doctorate on deep learning at NYU and interning with Yann LeCun at Facebook. Its open source tool has been downloaded more than 400 million times and the company has raised over $100 million from investors like Coatue, Index Ventures, and Bain Capital.\n\nIts new partner was born from a $900 million grant from crypto billionaire Jed McCaleb, who cofounded blockchain startup Ripple and early bitcoin exchange Mt. Gox. McCaleb‚Äôs not-for-profit, the Navigation Fund, bought 24,000 of Nvidia‚Äôs then top-of-the-line H100 chips and set up Voltage Park to manage them with the goal of lowering the cost of compute for startups, per Reuters reporting.\n\nVoltage Park CEO Ozan Kaya told Forbes that the investment had made the company the third largest neocloud, behind CoreWeave and Nebius, based on chips deployed. The San Francisco-based company now operates six data centers in four states across the United States. ‚ÄúWe were evaluating different ways to move up the stack and Lightning was the strongest one for us,‚Äù Kaya said.\n\nVoltage Park‚Äôs unusual funding was a draw rather than a deterrent for Falcon. Most of its neoclouds rivals (and tech giants like Meta) have loaded up on debt to fund purchases of new datacenters and AI chips. CoreWeave alone has raised over $14 billion from lenders. Voltage Park had built up 60 megawatts of active data center capacity with McCaleb‚Äôs foundation as its majority shareholder.\n\n‚ÄúIt was the only neocloud without debt,‚Äù Falcon said. ‚ÄúI think the first failure mode is going to be debt, their leverage.\n\nWhile OpenAI, Meta and xAI have been signing deals for data centers with gigawatts of power, Voltage Park‚Äôs customers like Cursor, open source AI lab Reflection and AI video generator Higgsfield, typically only needed clusters of AI chips with tens of megawatts of power, said Kaya.\n\nMcCaleb‚Äôs foundation, which was formed in November 2023, will now hold a ‚Äúsignificant equity stake‚Äù in the new merged company, David Coman-Hidy, president of the Navigation Fund told Forbes. Coman-Hidy added that McCaleb occasionally advised Voltage Park but was not on the board, and had no ownership stake in Voltage Park, or Lightning AI. The fund now has grown its donor base and assets to $1.25 billion and has promised to make grants supporting causes that address climate change, the welfare of farm animals, criminal justice reform and ‚Äúopen science,‚Äù he said.",
    "readingTime": 4,
    "keywords": [
      "mccaleb‚Äôs foundation",
      "voltage park",
      "lightning ai",
      "navigation fund",
      "voltage park‚Äôs",
      "chips",
      "manage",
      "startups",
      "neoclouds",
      "debt"
    ],
    "qualityScore": 1,
    "link": "https://www.forbes.com/sites/iainmartin/2026/01/21/ai-startup-merges-with-a-billionaire-backed-data-center-operator-in-25-billion-deal/",
    "thumbnail_url": "https://imageio.forbes.com/specials-images/imageserve/6970a439847e78e21c536412/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds",
    "created_at": "2026-01-21T12:26:58.467Z",
    "topic": "tech"
  },
  {
    "slug": "the-godfather-of-ai-says-hes-very-sad-about-what-his-lifes-work-has-become",
    "title": "The 'Godfather of AI' says he's 'very sad' about what his life's work has become",
    "description": "Geoffrey Hinton said he is concerned that the AI he helped develop poses risks that are not being taken seriously.",
    "fullText": "That's how Geoffrey Hinton, the computer scientist widely known as the \"Godfather of AI,\" describes how he feels about the technology he helped create and what he says is the world's failure to take its growing risks seriously.\n\n\"It makes me very sad that I put my life into developing this stuff and that it's now extremely dangerous and people aren't taking the dangers seriously enough,\" Hinton told BBC Newsnight in an interview released on Tuesday and recorded earlier this month.\n\nHinton, who helped pioneer the neural networks that underpin modern artificial intelligence, has become one of the field's most outspoken critics as AI systems grow more powerful and widespread.\n\nHe has predicted that AI could trigger widespread job losses, fuel social unrest, and eventually outsmart humans ‚Äî and has said that researchers should focus more on how advanced systems are trained, including ensuring they are designed to protect human interests.\n\nOn BBC Newsnight, Hinton said that humanity is approaching a pivotal moment as researchers edge closer to building machines more intelligent than humans.\n\n\"We've never been in this situation before of being able to produce things more intelligent than ourselves,\" Hinton said, adding that many experts believe that AI will surpass human intelligence within the next 20 years ‚Äî and in many areas, already has. Once that happens, he said, controlling such systems may become far more difficult than many assume.\n\n\"The idea that you could just turn it off won't work,\" Hinton said, adding that a sufficiently advanced AI could persuade humans not to shut it down.\n\nHinton said the biggest mistake humanity could make now would be failing to invest in research on how humans can coexist with the intelligent systems they created.\n\n\"If we create them so they don't care about us,\" he warned, \"they will probably wipe us out.\"\n\nHe suggested that catastrophic outcomes are not inevitable, saying that the risks depend on how advanced systems are designed and governed and that humans still have \"a lot of options on how to create them\" while AI remains under development.\n\nStill, Hinton also expressed concern that AI is being unleashed at a time when global cooperation is weakening and authoritarian politics are on the rise, making meaningful regulation harder to achieve.\n\nHe compared the need for AI governance to international agreements on chemical and nuclear weapons.\n\nDespite his concerns, Hinton said he would not undo his work on AI.\n\n\"It would have been developed without me,\" he said. \"I don't think I made any decisions that I wouldn't make the same way if I had the same knowledge.\"\n\nHe remains hopeful about AI's potential to improve education and medicine, pointing to AI tutors and advances in medical imaging as examples of its promise. But for now, Hinton said, urgency is paramount.\n\n\"We're at a very crucial point in history when we're going to develop things more intelligent than ourselves fairly soon,\" he said. \"We haven't done the research to figure out if we can peacefully coexist with them. It's crucial we do that research.\"",
    "readingTime": 3,
    "keywords": [
      "advanced systems",
      "humans",
      "intelligent",
      "hinton",
      "create",
      "research",
      "risks",
      "seriously",
      "it's",
      "intelligence"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/godfather-ai-geoffrey-hinton-on-ai-sad-dangerous-2026-1",
    "thumbnail_url": "https://i.insider.com/69709f50e1ba468a96aa669b?width=1200&format=jpeg",
    "created_at": "2026-01-21T12:26:58.437Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-says-production-for-cybercab-robotaxi-and-optimus-robot-will-initially-be-agonizingly-slow",
    "title": "Elon Musk says production for Cybercab robotaxi and Optimus robot will initially be 'agonizingly slow'",
    "description": "The Tesla Cybercab robotaxi and Optimus robot are both set to enter production this year as Elon Musk bets Tesla's future on AI and robotics.",
    "fullText": "Elon Musk is bracing for another round of production hell.\n\nThe Tesla CEO said on Tuesday that the ramp-up of the company's Cybercab robotaxi and Optimus robot, both set to enter production this year, would be \"agonizingly slow.\"\n\n\"The speed of the production ramp is inversely proportionate to how many new parts and steps there are,\" wrote Musk in a post on X.\n\n\"For Cybercab and Optimus, almost everything is new, so the early production rate will be agonizingly slow, but eventually end up being insanely fast,\" he added.\n\nTesla is set to begin production of the Cybercab, a sleek two-seater robotaxi that Musk has said will ship without a steering wheel or pedals, in April. The billionaire is targeting an eventual production goal of 2 million units a year.\n\nThe Cybercab, which Musk said in 2024 would cost around $25,000, is set to enter mass production as Tesla races to expand its robotaxi service after a sluggish start.\n\nThe company launched autonomous ride-hailing in Austin last June, but it only has a small number of Model Y robotaxis on the road in the city and has not yet removed human safety monitors from its vehicles.\n\nMeanwhile, Optimus, its humanoid robot designed to help with everyday tasks, is set to enter production by the end of 2026, with Musk saying Tesla could eventually make one million a year.\n\nThe Tesla CEO told investors in October that it would take a while to reach that goal as the company was having to manufacture almost the entire supply chain from scratch, with production moving at the speed of the \"slowest, dumbest, least lucky thing out of 10,000 unique items.\"\n\nMusk's comments echo what Tesla is telling its employees. In an all-hands meeting in October, the company's VP of AI software told staff on Tesla's Autopilot and Optimus teams that 2026 would be the \"hardest year\" of their lives, Business Insider's Grace Kay exclusively reported.\n\nIt wouldn't be the first time Tesla has faced a rough road while scaling an ambitious new product.\n\nThe company endured a famously brutal period of what Musk called \"production hell\" while building its Model 3 EV in 2017. Musk and other employees resorted to sleeping on the factory floor as they struggled to scale the mass-market model.\n\nTesla also faced production challenges with the Cybertruck, the company's last new vehicle.\n\nThe electric pickup's unique design and stainless steel-clad structure made it highly challenging to produce at scale, and Musk acknowledged in 2023 that Tesla had \"dug its own grave\" with the Cybertruck's design.\n\nThe divisive electric truck also serves as a caveat for Musk's ambitious production goals.\n\nMusk's predictions that Tesla could produce 250,000 Cybertrucks a year have fallen short, with industry data showing the company sold just over 20,000 Cybertrucks in the US last year.",
    "readingTime": 3,
    "keywords": [
      "tesla ceo",
      "agonizingly slow",
      "production hell",
      "enter production",
      "the tesla ceo",
      "company's",
      "robotaxi",
      "musk's",
      "musk",
      "robot"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/elon-musk-cybercab-optimus-production-agonizingly-slow-robotaxi-robot-2026-1",
    "thumbnail_url": "https://i.insider.com/6970ab83e1ba468a96aa66df?width=1200&format=jpeg",
    "created_at": "2026-01-21T12:26:58.234Z",
    "topic": "finance"
  },
  {
    "slug": "vibebin-incuslxcbased-platform-for-selfhosting-persistent-sandboxes",
    "title": "Vibebin: Incus/LXC-based platform for self-hosting persistent sandboxes",
    "description": "vibebin is an Incus/LXC-based platform for self-hosting persistent AI coding agent sandboxes with Caddy reverse proxy and direct SSH routing to containers (suitable for VS Code remote ssh).  Create...",
    "fullText": "jgbrwn\n\n /\n\n vibebin\n\n Public\n\n vibebin is an Incus/LXC-based platform for self-hosting persistent AI coding agent sandboxes with Caddy reverse proxy and direct SSH routing to containers (suitable for VS Code remote ssh). Create and host your vibe-coded apps on a single VPS/server.\n\n License\n\n View license\n\n 9\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n jgbrwn/vibebin",
    "readingTime": 1,
    "keywords": [
      "vibebin",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/jgbrwn/vibebin",
    "thumbnail_url": "https://opengraph.githubassets.com/b08d7ce148c865871d7a69b11f4c233a6cd39949454bb9455bb3bdcf87a6a575/jgbrwn/vibebin",
    "created_at": "2026-01-21T12:26:57.995Z",
    "topic": "tech"
  },
  {
    "slug": "brand-engagement-network-stock-soars-after-securing-2m-ai-deal-in-africa",
    "title": "Brand Engagement Network stock soars after securing $2M AI deal in Africa",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/brand-engagement-network-stock-soars-after-securing-2m-ai-deal-in-africa-93CH-4457373",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPEA7H0NX_M.jpg",
    "created_at": "2026-01-21T12:26:57.403Z",
    "topic": "finance"
  },
  {
    "slug": "ovi-ai",
    "title": "Ovi AI",
    "description": "Create physics-accurate videos with synchronized audio using Ovi AI by Character.AI. Generate 10-second videos from text or images with Ovi 1.1's twin backbone technology. Free access, no signup required!",
    "fullText": "Ovi AI's revolutionary twin backbone architecture enables simultaneous video and audio generation. This cross-modal fusion technology ensures perfect synchronization between visual content and sound, making Ovi AI unique among AI video generators.\n\nExperience Ovi 1.1's breakthrough capability: generating 10-second videos with perfect temporal consistency. With 100% more training data than the original, Ovi 1.1 delivers coherent, extended video sequences at 960√ó960 resolution.\n\nOvi AI features a custom 5B parameter audio branch trained specifically for video synchronization. ovi ai can synchronously generate audio\n\nOvi AI demonstrates advanced understanding of real-world physics, creating videos with realistic motion, gravity, and object interactions. The physics engine ensures your generated videos maintain authenticity and visual coherence throughout.\n\nOvi AI supports multiple input modes: text-to-video (T2V), image-to-video (I2V), and combined text+image-to-video (T2I2V). This flexibility allows you to choose the best approach for your creative vision.\n\nCreate videos in various formats including 9:16 (vertical), 16:9 (horizontal), and 1:1 (square). Ovi AI supports different resolutions up to 960√ó960 at 24 FPS, giving you professional-quality output for any platform.",
    "readingTime": 1,
    "keywords": [
      "ovi ai",
      "videos",
      "audio",
      "ensures",
      "perfect",
      "synchronization",
      "visual",
      "physics",
      "supports"
    ],
    "qualityScore": 0.85,
    "link": "https://ovi-ai.org/",
    "thumbnail_url": "https://ovi-ai.org/opengraph-image.png?ece9c3a334b1dece",
    "created_at": "2026-01-21T12:26:57.322Z",
    "topic": "tech"
  },
  {
    "slug": "pragmatic-notes-on-running-dangerous-ai-coding-agents-in-cloud-vms",
    "title": "Pragmatic Notes on Running Dangerous AI Coding Agents in Cloud VMs",
    "description": "A practical approach to safely running AI coding agents with strong isolation using cloud VMs, Tailscale, and simple notification patterns.",
    "fullText": "Running coding agents with free reign is very powerful for a certain class of tasks, especially ones that require little human supervision, or where you want to close (or disconnect) your laptop, walk away, and come back to results.\n\nRecently there have been several HN discussions about safely running Claude Code or Copilot CLI agents, such as Yolobox ‚Äì Run AI coding agents with full sudo without nuking home dir and Running Claude Code dangerously. These post detail the potential dangers and show how to run these agents more safely, and while reasonable, I find they lack in a few respects.\n\nIn particular, I want strong isolation, long running agent tasks, minimal cognitive overhead and I really value being able to close my laptop, walk away, and get notified on my phone when things are done. I do not mind paying for a cloud VM.\n\nThere are many valid ways to solve this problem. This post describes mine. It covers running multiple coding agents concurrently in a cloud VM, how I handle access and repos, and how I keep notifications simple.\n\nI generated some Terraform to spin up an Azure VM with a cloud-init.yml for setting up common tools/environments I use. Claude can generate a decent starting point for this quite easily, given your particular environment.\n\nFor secure access, I use Tailscale. Note: I'm not paid by them, but it is easily my favorite piece of infrastructure software!\n\nA cloud-init script installs Tailscale on first boot and automatically joins the VM to my tailnet. SSH access is enabled using Tailscale SSH. Once the VM is up, it appears on my private network with a stable hostname via Magic DNS. No SSH key management, no exposed ports.\n\nor connect using VS Code Remote SSH:\n\nhttps://code.visualstudio.com/docs/remote/ssh\n\nMost of the time I prefer tight, step by step control over code generation, working locally in VS Code with Copilot. For longer running or experimental tasks, I instead let an agent work remotely on a branch inside the VM, and pull the results once I am satisfied.\n\nWhile this is arguably git basics, it works well for me and I found that it is useful sharing how to set up a VM as a remote:\n\nOn the local machine, from the repo directory:\n\nThen you can pull clone and check out the branch, do the work, commit, and push to bare repo:\n\nFinally, locally, you can get the changes:\n\nI use tmux to manage long running sessions. This lets agents keep running after I disconnect, and makes it easy to juggle multiple concurrent sessions. If you are not familiar with tmux, it is worth learning!\n\nFor notifications, I use https://ntfy.sh.\n\nIt is free, extremely simple, and works over plain HTTP POST. I have the iOS app installed, so I can walk away from my laptop and still get notified when work completes. I explicitly instruct my agents to make a POST request once their work is done in the agent instructions.\n\nThat is it. No SDKs, no auth setup required for basic usage. The notification shows up immediately on my phone/browser.\n\nIf there is interest, I can publish a repo with the Terraform, cloud-init scripts, makefile, etc, and the old .devcontainer setup.",
    "readingTime": 3,
    "keywords": [
      "coding agents",
      "tasks",
      "laptop",
      "away",
      "access",
      "repo",
      "free",
      "close",
      "disconnect",
      "safely"
    ],
    "qualityScore": 1,
    "link": "https://jakobs.dev/pragmatic-notes-running-dangerous-ai-agents-cloud-vms/",
    "thumbnail_url": "/media/agents-vm.jpg",
    "created_at": "2026-01-21T12:26:57.044Z",
    "topic": "tech"
  },
  {
    "slug": "upgrade-from-ralph-to-eric-for-a-more-autonomous-ai",
    "title": "Upgrade from Ralph to Eric for a more autonomous AI",
    "description": "Everyone is going crazy about Ralph loop, and they are cool, but I think we need to upgrade to concept to an Eric loop !",
    "fullText": "TLDR; Eric loop is a concept that upgrades Ralph loop by adding more complexity and depth to the idea of managing AI systems, bash version of the article\n\nI wont reintroduce the concept of Ralph loop, if you have been anywhere near AI in the first half of January 2026, you have heard of it ! If not, you should go and watch Theo's video (or someone else's but this is a good !)\n\nYou probably know which comics character Ralph is refering to, but Eric... who could it possibly be ?\n\nIf you thought short, fat and angry, you'd be right ! I'm of course talking about Eric Cartman from South Park !\n\nWhile Ralph is naive and innocent, Eric is calculating and manipulative. Not something I'd look for in a Human, but for managing a bunch of AIs ? HELL YEAH !\n\nAn idea, even if good, always need some work and some back and forth to be implemented. So we first expose the idea to the AI to get an requirement document (PRD) and we work on it !\n\nHow ? you'll need to read first ! and straight away update parts you don't agree with or things you need to be more thorough !\n\nOnce that is done, ask AI models to ask You questions about the PRD and give all those, the PRD and your replies to another AI for update\n\nRince, Repeat, until you are satisfied with the document.\n\nYou can even get multiple model go at it to then compare and merge the outputs, using AI, of course :D\n\nThis is where we start diverging from the basic Ralph loop. instead of just passing that to the AI and hoping tasks will be implemented properly we get an AI to pre split and formalise the tasks and sub tasks into a list !\n\nThe rift grows further as we split the task implementation in several steps with:\n\nOnce all that is done ? the Eric loop goes on for the next phase of the plan, just like Ralph !\n\nYes models have gotten smarter, but if you played around with sub agents and skills, you know that prompting is not dead (yet...)\n\nHaving a neat separation like that helps you have better prompts for each phase of the task execution.\n\nAs a side effect, it mmeans you can control which model is used for which phase maybe you dont need Opus the whole way if it made a banger plan !\n\nWe are going to create a small project from an idea I have, you can do it to if you like !\n\nIt's called Tiny-till, a small app to have a simple till for itinerant merchants.\n\nBut we are going to need a tool to help us ...\n\nYep, I already kind of made said tool :D ! task-o-matic\n\nI'll write more about it in a future post ! but you already have plenty of content to go through on the site itself.\n\nI made sure to generate a lot of docs and a couple tutorials so you can already give it a try if you'd like !\n\nBut in a nutshell, it helps you create PRDs, refine them , split into tasks and subtasks and finally wiring all that to your favorite AI harness !\n\nFor the AI to operate properly, we need a specific stack, that way, we limit hallucination !\n\nTask-o-matic uses better-t-stack under the hood to bootstrap the stack so let's do that !\n\nBoom, a monorepo for Tiny-till ! Batteries included : tailwind, shadcn, build script and all :D\n\nWhy init init ? you might have missed the whole using AI to code whole projects, sometimes... it is not aesthetically pleasing, and you should learn not to care to much (is my take on that... or lazyness...)\n\nYou will need a .env file to configure the AI stack.\n\nNow, we tell the AI what we want to do, but why would we limit ourselves to 1 ?\n\nAm I using free endpoints for \"real\" work ? Yes, yes I am ! Does it distort my views on how much AI work should cost ? ... Why would it ? No, no, you just being a killjoy right now !\n\nA few minutes later... I got myself this (cat .task-o-matic/prd/prd-master.md)[/assets/blackhole/from-ralph-to-eric/prd-master.md] it doesn't really need more questions, but let's see what Claude has to say, shall we ?\n\nWell, let's answer those... some are pertinant ! I guess that's why we bring out the big guns !\n\nQuestions are asked interactivelly ;)\n\nWell, this little stunt just costed me a nice 15 cts, more or les 10x more than the first PRD generation...\n\nI don't know what is the most amazing... that\n\nI haven't decided yet...anywooooooo, time to move on and not get siderated !\n\nWhen i said seconds, i lied, I spent 5 minutes editing the file. to fix lib versions, marked install and config work as done, and, finally, set expectation for the design.\n\nthe last thing we have to do, is ask an AI to split into main tasks.\n\nonce again, i wont only do 1, but this time, I'll ask Claude to be the final task creator, from others input !\n\nAnd there goes another 8.2 cents burnt for the token Gods, but in return, we get a detailed breakdown of the tasks required to complete the project !\n\nWe still have to split those tasks though... To make them more palatable for the current crop of AI models !\n\nYou should really consider reviewing the tasks in detail before spliting, not vibe planning like a muppet ! (guess what I did ^^)\n\nI think Claude is not necessary here, but I had me $3 of openrouter credit i have to burn before the end of the month soooooo... big guns it is !\n\nBurnt a tenth of that ! but now... we are actually ready ! Almost...\n\nOr CLAUDE, or GEMINI, depends on your harness of choice, For me, it is opencode i'am going to run the /init prompt in opencode !\n\nit is not mandatory, but it is a good way to prevent dumb mistake and set some proper behavior regarding a few things, for me, i'll add the following\n\nI might add more as the agent works if i see reccuring errors and dumb things happening\n\nWell, guys, stash your parents away cause we are going to let Eric go at it !\n\nBecause I am El CheapoDev DelBrokeCasa, i am going to use my GLM coding plan to code, that way, i wont break the bank and it is OK enough for something like that i think !\n\nIf you'd rather use claude code, use the --tool claude option. (or codex/gemini/kilo) but opencode is nicer as it stream the content out (in part at least) so you see what is happening !\n\nAnd now, you wait, coffee, snacks, more coffee, diner and breakfast probably, it gonna take a while ^^\n\nHalf a day later, Eric has successfully completed the task. yaaay \\o/\n\nnpm run dev, browser to http://localhost:3001 aaaaand, it does not work.... XD\n\nI have a very fancy error page telling me about some kind of \"exceeded depth error blablabla\"... Zustand... i bloody fucking HATE Zustand !\n\nI could have gone in, open the project, read some of the 35970 lines of... 35970 LINES OF CODE ??? Naaah, dude, ain't no way i'm even thinking about that !\n\nOf course, i asked GLM to fix this obviously terrible usage of Zustand, and I even have to spend another few minutes screaming about some redirection to the / issue... I still felt like a caveman though !\n\nI mean, having to open a tool ? To do ... work ?? Like it's 2022 or something !\n\nI haven't been testing anything yet, so i'm pretty sure there'll be a few more issues, but the dev server runs, i can navigate the app without error (even in console) so it is not bad at all !\n\nI might do a follow up later on, to update you on what i had to do to get it a bit closer to the original idea (if needed ^^)\n\nSo that's the end (of this article) ! What do you think ? did you try a similar technique ? What's the plan next, cause...\n\nIf you are interested, the repo can be found on github. Is the code great ?\n\nAs for task-o-matic, the repo is on github so feel free to poke around ;)\n\nWhat about the \"Eric Loop\", how can you do that yourself ? Well, the beautiful thing with AI is that, you can actually ask it to write code ! So a quick\n\nthis being the result, your own Eric Loop, ain't life beautiful ?\n\nHope you enjoyed, I'll see you around",
    "readingTime": 8,
    "keywords": [
      "ralph loop",
      "eric loop",
      "tasks",
      "idea",
      "split",
      "task",
      "plan",
      "tool",
      "i'll",
      "you'd"
    ],
    "qualityScore": 1,
    "link": "https://dbuild.dev/blog/black-hole-from-ralph-to-eric/",
    "thumbnail_url": "https://dbuild.dev/images/blog/blackhole/from_ralph_to_eric/Eric_saw_Ralph.webp",
    "created_at": "2026-01-21T06:22:10.592Z",
    "topic": "tech"
  },
  {
    "slug": "understanding-modern-ai-is-understanding-embeddings-a-guide-for-nonprogrammers",
    "title": "Understanding Modern AI Is Understanding Embeddings: A Guide for Non-Programmers",
    "description": "Embeddings are a core AI concept that underpin a great deal of what we today think of as being AI. This article is going to give you an accurate and intuitive understanding of what an ‚Äúembedding‚Äù is in less time than it takes to eat a (very large) bagel.",
    "fullText": "Embeddings are a core AI concept that underpin a great deal of what we today think of as being AI. This article is going to give you an accurate and intuitive understanding of what an ‚Äúembedding‚Äù is in less time than it takes to eat a (very large) bagel, and possibly make you think they‚Äôre as cool as I think they are. It even explains how we got to embeddings as a solution, by looking at everything else we tried along the way. If you‚Äôre comfortable with even very simple Excel formulas, you‚Äôll understand all the maths, and there‚Äôs even a cute graph with dogs on it.\n\nLet‚Äôs start by thinking about dogs, and by classifying them by their attributes:\n\nFor each dog, we‚Äôve defined a vector where the first column is size, and the second column is intelligence. A vector is a fancy name for a row of numbers. And in two dimensions, we can plot this really easily:\n\nLet‚Äôs do some vector maths using Manhattan distance. A Great Dane ([5,5]) is 5 units away from a Beagle ([2,3]):\n\n(we‚Äôre using Manhattan distance here because it‚Äôs simple, but you might well use Euclidean distance instead)\n\nA vector can be both a specific point in our dog-embedding space, but it can also be a direction:\n\nWhat‚Äôs like a Bulldog ([3, 2]) but smaller ([-1, 0]) and smarter ([0, 1])?\n\nKey point: if we start to plot things by their attributes, and we give each attribute a number, we can use simple maths to find items that are close together (clustering) and we can easily find items that differ from a starting point in a certain way.\n\nAND WHAT‚ÄôS MORE: this holds up over as many dimensions as we want to define, not just two:\n\nWe can do the same distance calculations again, even with more vectors:\n\ntldr; an embedding is a vector of numbers that describes something, and that you can use to cluster things by similarity\n\n(vector databases, like Pinecone or pgvector, are simply databases that are fast at calculating the distance between vectors, and finding vectors that are close to other vectors)\n\nDogs are easy mode, because there‚Äôs a limited number of breeds and attributes. Also, coming up with attributes ourselves is hard work, and laziness is an inarguable virtue, so let‚Äôs see if we can make the computer do the work for us here.\n\nIf we wanted to classify books instead, we‚Äôd need to do something different. Let‚Äôs start by defining a table of every book, and every word in the English language, with the values being the occurrences of each word in the book:\n\nTable 1: Number of word occurrences in each book\n\nOur vocabulary of words becomes our dimensions (or columns) and each book becomes a vector in those dimensions (rows). This is called a bag of words, a ‚Äúbag‚Äù being the technical term for a mathematical object that counts the occurrences of things (but discards the order they‚Äôre in).\n\nBag of words was state of the art in approximately the 1950s for classification. There are lots of problems with this approach, and understanding those problems and how they‚Äôre solved starts to bring us closer to understanding embeddings!\n\nOne problem with our Bag of Words is that we end up with values that are proportional to the size of books, which might mean that two very similar books are quite far apart, just because they‚Äôre of very different lengths. If George RR Martin rewrote Animal Farm, it might end up very far away from the Orwell original simply due to his overly-lax editorial staff.\n\nThere‚Äôs a particularly elegant solution to this in terms of determining how close two items are by measuring the difference in angles from the origin towards them (cosine similarity), BUT there‚Äôs also the highly effective and really simple solution of just dividing the count of each word by the length of the book (normalization):\n\nTable 2: Distribution of word occurrences in each book\n\nwhich gets us most of the way there without fancy maths or words like cosine.\n\nWe‚Äôve also got a problem here with our Bag of Words by a bunch of noise being introduced by words that are frequent but unspeakably dull, like ‚Äúa‚Äù, ‚Äúthe‚Äù, and ‚Äúof‚Äù. Different authors may lean more heavily on some than others (meaning their books are further apart in the dimensions of ‚Äúof‚Äù and ‚Äúa‚Äù), but that gives us absolutely no useful information about the meaning or content of what they‚Äôre writing about: what we care about is occurrences of words like dragon and android and lascivious.\n\nWe could maintain a list of dull words (often called ‚Äústop words‚Äù), and strip them out, but that‚Äôs fiddly, insufficiently lazy, and doesn‚Äôt account for the fact that what we consider to be a ‚Äústop word‚Äù might differ depending on the context.\n\nInstead, we can use some simple statistics to look at how often a word (or ‚Äúterm‚Äù) appears in a given book/document compared to how frequently it appears across all of the books or documents we‚Äôre looking at; this is called ‚ÄúTF-IDF‚Äù, and it was state-of-the-art circa 1972:\n\n(you can see the actual formula and learn more about TF-IDF here)\n\nKEY POINT: We‚Äôre still very firmly in a ‚Äúwords are dimensions, and books exist as points in that high-dimensional space‚Äù place here. We‚Äôre still representing books by a vector of numbers and looking for similarity by searching how close these books are to each other in a high-dimensional space. We‚Äôre just using a slightly fancier way of determining what those numbers should be.\n\nOur approach has gotten us some of the way towards classifying books well, but we start to hit some insurmountable problems in this approach:\n\nIf we have a dimension for every word in English, we have waaay too many dimensions. One for each word, and each variation of each word. At least 50,000 if we‚Äôre just covering common English words. This starts to be cumbersome and computationally expensive to do maths on.\n\nFantasy authors who insist on inventing spellings for ‚ÄúSir‚Äù; there‚Äôs quite a lot of semantic information about a book embedded in having nobles with fancy titles prancing around, but our current approach gets confused when authors decide to start calling their characters ‚ÄúSer‚Äù or ‚ÄúSyr‚Äù or ‚ÄúS√ºr‚Äù to try and sound more mysterious. More generally, we treat words with similar meanings but different spellings or forms as completely different dimensions\n\nBarking up the wrong tree: sometimes two different words are spelled identically (eg ‚Äúbark‚Äù), and we don‚Äôt especially want to say that books on forestry and similar to books on puppies\n\nWord order is important! If your main character is a ‚Äúdog who bites a bone‚Äù that‚Äôs likely quite a very different story from your ‚Äúbone who bites a dog‚Äù character, even if the bone is haunted in both cases\n\ntldr; vectors that are simply word frequency counts are a good start, but have a whole host of problems: we need something even smarter (embeddings) to do really good clustering and classification\n\nWe have until this point been thinking about how we would classify a whole book, and using word counts as dimensions. But what if we wanted to classify just one word instead?\n\nIf we were able to come up with vectors for individual words, we could start to address the problem that ‚Äúdog‚Äù, ‚Äúpuppy‚Äù, and ‚Äúpooch‚Äù are all treated as completely different things when classifying text, and we‚Äôd also get some other useful features, like it would make it easier for us to build things like fuzzy-search for users: ‚Äúpooch pics‚Äù and ‚Äúdog photos‚Äù should return much the same results when a user is searching for them.\n\nWe could hand-pick some dimensions to use for this:\n\nThis ‚Ä¶ might work pretty well with enough dimensions! But hand-choosing each of the dimensions we‚Äôd need and then manually classifying (and tweaking) 50,000 words feels like it might be a lot of hard work. Hard work that the computer should be doing for us‚Ä¶ But how do we get the computer to do that for us? The computer would need to know already what the words meant in order to do the classification, so we need a way to bootstrap that process.\n\nOne intriguing idea might be to suck in a dictionary, and to use our bag-of-words techniques on the definition of each word to come up with a vector for each word. This however gives us our own bootstrapping problem: if we look at the dictionary definition for ‚Äúpuppy‚Äù, it‚Äôs very different for the one for ‚Äúdog‚Äù: instead, it points us to the one for ‚Äúdog‚Äù instead, and solving all of this starts to sound like complicated maths will be needed.\n\nWhat if we instead tried to ‚Äúknow a word by the company it keeps‚Äù? It‚Äôs an idea that‚Äôs been floating around linguistics for decades, and suggests that words appearing in similar contexts probably have similar meanings. If you constantly see the words ‚Äúdog‚Äù and ‚Äúpooch‚Äù surrounded by words like ‚Äúwalk‚Äù, ‚Äúleash‚Äù, ‚Äúbark‚Äù, and ‚Äútreats‚Äù, maybe you don‚Äôt need a dictionary to figure out they‚Äôre related?\n\nLet‚Äôs game out how this could work: you could take every piece of written text you could lay your hands on, and go through it word by word, looking at the two words ahead of it and the two words behind it. For every word, you could start to build out the probability that any other word was in those four surrounding words.\n\nFigure 1: a sliding context window, associating each word in a sentence with the two words before and after it\n\nYou could use those probabilities as the values in your vector for each word, with every other word being a dimension still, and voila, you have per-word vectors that put ‚Äúpupper‚Äù, ‚Äúdog‚Äù, and ‚Äúpooch‚Äù very close to each other.\n\nThis is almost the massive breakthrough that researchers at Google had in 2013 inventing ‚ÄúWord2Vec‚Äù (word to vector), but there‚Äôs one further, crucial refinement.\n\nOur method above has two big problems. The first is one we‚Äôve already identified: you still end up with an absolutely massive number of dimensions! These are unwieldy, difficult to work with, and computationally expensive to work with. But secondly, there‚Äôs just not enough reading text out there to make this work: there are infinite possible and sensible combinations of words, and while us humans have written down a lot of stuff, it turns out there‚Äôs simply not enough training data to make the above approach practical, IN ADDITION TO having all the drawbacks that come with these huge, unwieldy vectors.\n\nSo, when in doubt, make the computer do the work. And the tool that proved exceptionally useful for this is the mighty Neural Network.\n\nA deep-dive into how they work is out of scope, even for this increasingly long article, but the key things to know are:\n\nThey take vectors as their inputs and spit out vectors as their outputs\n\nThey‚Äôre specialized tools for learning things through giving them examples\n\nThey‚Äôre really good at prediction tasks\n\nAnd so we can flip our earlier method on its head:\n\nRather than building a huge matrix of every word and its neighbours, how about we train a Neural Network to predict what a word is, based on some neighbours?\n\nThe process for this sounds like magic:\n\nWe choose a number of dimensions we want to use, let‚Äôs say 300\n\nWe literally just make up a 300-number-long vector for every input word: it‚Äôs literally just random to begin with\n\nWe show the Neural Network billions of sets of four words, and ask it to guess the middle word\n\nWe make tiny adjustments to each of those initial random vectors based on how well the Neural Network did at guessing it (using some complicated maths called ‚Äúback-propagation‚Äù)\n\nAnd over the billions and billions of times we do this, the computer eventually comes up with its own vectors for every word: vectors that really are good enough to predict what a word is going to be given its neighbours.\n\nThese same ‚Äúguessing‚Äù vectors encode the meaning of words in a truly jaw-droppingly effective way. Again, it‚Äôs the principle that ‚Äòa word is known by the company it keeps.‚Äô If the network gets good at predicting surrounding words, the vectors it develops for each word must encode information about that word‚Äôs typical context, which relates closely to its meaning.\n\nFirst of all, it puts related words close together. ‚ÄúPupper‚Äù, ‚Äúpooch‚Äù, and ‚Äúdoggo‚Äù now all sit really close together in our dimensional space. ‚ÄúSir/Ser/Syr‚Äù basically sit on top of each other. We can‚Äôt really figure out what each of these dimensions means individually: there‚Äôs not a dedicated dimension for ‚Äúdog like‚Äù, but they seem to work.\n\nSecondly, remember how a vector can be either a point or a direction? Well it turns out if we start out at the vector for ‚Äúking‚Äù, we subtract the vector for ‚Äúman‚Äù, and add the vector for ‚Äúwoman‚Äù, we end up with a vector that‚Äôs almost identical to the one for ‚Äúqueen‚Äù. Complex semantic meaning has been encoded into our dimensions and embeddings. This shows the model learned abstract relationships (like gender and royalty) from the text data alone, encoding them into the vectors.\n\nThe above is the essence of ‚ÄúWord2Vec‚Äù.\n\nDo we know why this works so well? NO\n\nIs this some bad-ass alien technology shit? YES\n\nIsn‚Äôt this a cause for alarm given how much we‚Äôre starting to rely on this technology and its successors? Please take your negativity out of the AI acceleration seminar\n\nThese dense vectors that capture semantic information along dimensions that the computer literally just made up are ‚Äúembeddings‚Äù. These word embeddings can then be combined (using various methods, from simple averaging to more complex techniques) to create embeddings for sentences or even whole paragraphs: you have a long list of numbers that encodes the meaning of that sentence or that paragraph.\n\nThese dense vectors help solve our earlier problems: the fixed, lower dimensionality (e.g., 300) is manageable; words with similar meanings learned from context (like ‚ÄòSir‚Äô and ‚ÄòSer‚Äô) end up close together; and the context-based learning helps differentiate meanings of words like ‚Äòbark‚Äô depending on surrounding words (though context handling gets even better later).\n\nThese paragraph-level embeddings are what underpin most RAG systems; in practice, people use the more clever versions of embeddings that the rest of the article covers, but still. An embedding is a row of numbers that describe the meaning of some words, and then we can use simple linear algebra to cluster related things together, or move around inside the vector space using abstract paths such as ‚Äúpositive sentiment‚Äù or ‚Äúmore feminine‚Äù\n\nYou can at this point leave the article, with a pretty good idea of what embeddings are. You won‚Äôt have learned how they deal with misspellings, words that are written the same and are completely different, or word ordering, BUT, you will know that it‚Äôs possible to encode semantic meaning into vectors of a few hundred numbers. Rather than leaving the article, you can also skip ahead to Part 3, which explains how embeddings are actually used in AI.\n\nWith Word2vec, we end up with vectors that capture semantic meaning of words, and the vectors exist in a dimensional space that the computer learned by playing a guessing game over and over again. That the computer learned these dimensions by itself, and each dimension has a subtle and dense meaning means that we call those vectors ‚Äúembeddings‚Äù.\n\nWe‚Äôve also covered that you can average out these embedding to get a meaning for a sentence or a paragraph, but because this averaging process is treating those vectors as a ‚Äúbag‚Äù (an unordered count of items), we lose a huge amount of meaning: the vectors for ‚Äúman eats shark‚Äù and ‚Äúshark eats man‚Äù are identical, even though the actual meanings differ substantially.\n\nSo rather than averaging our embeddings together, we need an operation that takes into account the sequence of the embeddings.\n\nOne of the first successful ways of doing this was with ‚ÄúRecurrent Neural Networks‚Äù (RNNs) ‚Äì ‚Äúrecurrent‚Äù in this case means a neural network that accepts its last output as part of its next input (the state ‚Äúrecurs‚Äù). (there‚Äôs a little white lie here about the order in which these events happened that we‚Äôll address later)\n\nHere we start out with a base vector, and we imprint each vector in the sequence on it, one at a time. After we‚Äôve stamped each vector representing a word onto the base vector, the base vector ends up changed in a way that reflects the sequence.\n\nHere‚Äôs some Play-Doh as an example. The Play-Doh square is our base vector, and each stamp we apply over the top of the last one is the vector for a word. You‚Äôll note that the order matters, and also that the most recent word vector ends up playing a larger role in the overall pattern we end up with than the previous ones.\n\nFigure 2: Pressing the same shapes into Play-Doh in different orders results in subtly different patterns, with the last shape often over-represented, and a faded initial shape\n\nWith Play-Doh, the more shapes you overlay on top of each other, the more you lose the previous shapes. If you add too many, you‚Äôll end up with a complete mess you can‚Äôt make any sense of. This happens with actual Recurrent Neural Networks (RNNs) too! Despite this, it represented a significant improvement over just averaging together vectors.\n\nSome clever mechanisms were invented to try and prevent earlier vectors getting completely wiped out by later ones, with fancy names like LSTMs and GRUs, but both represented incremental improvements over RNNs rather than a huge leap forward.\n\nHistorical note: the above describes events as if the sequence of events was: Word2Vec -> RNNs -> LSTMs and GRUs, which isn‚Äôt accurate! RNNs as a concept and LSTMs as a refinement of them actually predate Word2vec. So, what were they using as their input vectors before we got the rich ‚Äúembeddings‚Äù that Word2vec gives us? They were either using the huge ‚Äúone dimension per word‚Äù vectors we discussed near the beginning of the article, or were feeding in one character at a time with each character being a dimension. Using neural networks that can understand sequences rather than bags has all sorts of uses outside of text classification, but using the newly invented Word2vec ‚Äúembeddings‚Äù with these techniques was a massive leap forward.\n\nSo at the end of this section, we have improved on our Word2Vec embeddings by building embeddings that combine other embeddings in the right sequence, which solves our problem of ‚Äúman eats shark‚Äù / ‚Äúshark eats man‚Äù. However, we have serious problems with losing information over sequences of any real length: by the time we get to the end of ‚Äúthe quick brown fox jumps over the lazy sheep dog‚Äù, we‚Äôve added so much extra information that ‚Äúquick‚Äù and ‚Äúbrown‚Äù have kind of been smushed together, and we‚Äôre very much more ‚Äúdog‚Äù focused than we are ‚Äúfox‚Äù focused because it occured later in the sentence.\n\nFigure 3: After each addition of a vector onto our hidden state, previous vectors get ‚Äúblurrier‚Äù and more recent vectors dominate\n\nRNNs gave us much stronger embeddings than we had before, but ultimately these days we derive embeddings from the same technology that powers Large Language Models: a technique called attention and the system that uses it, the transformer. A proper deep-dive into the steps that take us from RNNs to transformers is too big for this already unwieldy article, but in short we train the computer to pay more attention to some words in a sentence than to others.\n\nThat‚Äôs probably how us humans do it too: your brain naturally ‚Äòpays attention‚Äô to the most important words (like the subject and verb, or key nouns) and how they relate, even if they are far apart. The ‚Äòattention mechanism‚Äô in AI tries to mimic this.\n\nWhen processing a sequence of words, with attention we keep track of all the intermediate embeddings we‚Äôd generated rather than mashing them all together into one single vector. We add an extra neural network over that where we train further vectors to correlate how important each word is to every other word in the sequence. This whole system ‚Äì including the new neural network ‚Äì is trained the same way as we trained RNNs: by playing ‚Äúguess the word‚Äù and getting the computer to update its internal parameters when it gets something right or wrong, until it‚Äôs usually getting them right!\n\nTransformers take this attention mechanism even further, and are the technology that powers large language models. Using those to generate our embeddings, we get embeddings that can accurately describe even pretty long pieces of text well, and are free of almost all of the issues we‚Äôve identified so far in this article. Commercial vendors like OpenAI offer very effective (and cost-effective!) general-purpose APIs for turning large chunks of text into embeddings for use in your applications.\n\nFirst of all, rather than using whole words as inputs, LLMs use tokens. These are fragments of words that are chosen (by the computer) during training to be a representative sample of commonly-appearing sequences. By using bits of words instead of whole words, we gain the ability to deal with words we haven‚Äôt seen before, which includes misspellings of words. For example, it might understand ‚Äòembeddingtastic‚Äô by recognizing the known tokens ‚Äòembedding‚Äô and ‚Äòtastic‚Äô.\n\nFigure 4: the OpenAI tokenizer in action. Common words are their own tokens, but less common words are split into fragments to help deal with the vast range of possible words including misspellings.\n\nSecondly, chances are the majority of time you spend using LLMs you‚Äôll be using ‚Äúautoregressive‚Äù ones: they generate the next token for you, token by token. There are however important LLMs that are trained to guess the missing token inside a block of text, that will use the tokens both before and after the target token to try and figure it out: guess the word, but the word in the middle of the sentence instead of the next word.\n\nOK, so we‚Äôve learned what embeddings are, and they‚Äôre pretty darn cool, but why do we care? When are you, the busy young lady or young man, actually going to interact with an embedding? We hand-waved over it a little before, but the embeddings created using the same mechanism as LLMs (transformers) can take in very long pieces of text and give back exceptionally sophisticated vectors that capture complex meanings from that text. These aren‚Äôt just theoretical toys; they‚Äôre the mechanism behind a surprising amount of what we call AI today.\n\n(we‚Äôve also pretended that embeddings are just for working with text, which also isn‚Äôt true, but we‚Äôre already at over 5,000 words here‚Ä¶)\n\nRemember classifying dogs? We picked the features: size, intelligence, fluffiness. Easy for dogs, but hopeless for text. Trying to hand-pick features for classifying emails or news articles (‚ÄúDoes it mention ‚Äòinvoice‚Äô?‚Äù ‚ÄúHow many times does ‚Äòpolitics‚Äô appear?‚Äù) is fragile and labor-intensive. Embeddings flip this entirely. Instead of us telling the computer what features matter, the computer learns the important features itself when creating the embedding, using the guessing game we outlined above. These aren‚Äôt just keyword counts; they‚Äôre learned features capturing the underlying topic, the vibe, the subtle nuances.\n\nThink about classifying customer reviews as ‚ÄòPositive‚Äô or ‚ÄòNegative‚Äô. A simple keyword approach gets tripped up by sarcasm, varied phrasing, or subtleties in word ordering. Embeddings, however, capture the overall essence. They turn the review into coordinates in a high-dimensional ‚Äòmeaning space‚Äô. A happy review‚Äôs embedding might land near coordinates representing ‚Äòjoy‚Äô and ‚Äòsatisfaction‚Äô (dimensions the model learned!), while an angry one lands near ‚Äòfrustration‚Äô. The magic is that embeddings handle nuance: synonyms like ‚Äúhappy,‚Äù ‚Äúpleased,‚Äù and ‚Äúelated‚Äù end up in the same positive neighborhood.\n\nSo, you feed this rich embedding ‚Äì these coordinates packed with learned features and context ‚Äì into a classifier model. The classifier‚Äôs job becomes much simpler: it just learns to draw boundaries in that meaning space. ‚ÄúEverything landing in this region is Positive, everything over there is Negative.‚Äù The embedding does the heavy lifting of understanding the text; the classifier just reads the map. It‚Äôs spookily effective.\n\nSometimes you don‚Äôt know in advance what categories you want to put things into. You‚Äôve got a mountain of customer reviews, research papers, or social media posts, and you just want to know ‚Äúwhat are the main themes here?‚Äù This is where clustering comes in, and embeddings super-charges it.\n\nBecause embeddings place texts with similar meanings close together in that high-dimensional space we keep talking about, we can use algorithms to automatically find groups, or ‚Äúclusters,‚Äù of related items. Think back to our dogs: if we plotted thousands of individual dogs based only on their learned embeddings (without knowing breeds), clustering algorithms could find the clumps corresponding to Poodles or Beagles just by seeing which dogs‚Äô vectors are close together.\n\nIt‚Äôs the same for text: these algorithms scan the positions (embeddings) of your documents in meaning-space and identify these natural groupings. Suddenly, you can see that your customer reviews naturally fall into clusters like ‚ÄúComplaints about Shipping‚Äù, ‚ÄúPraise for Product Quality‚Äù, and ‚ÄúConfused People Asking How To Turn It On‚Äù. No predefined categories needed, the structure just emerges from the meaning captured in the embeddings.\n\nThis is the technique du jour for making LLMs smarter and more factual, and it leans heavily on embeddings. The core idea is surprisingly elegant: when you ask an LLM a question, you first use the embedding of your question to find relevant pieces of information (like paragraphs from a document) from a database.\n\nHow? Because of a slightly magical property: the embedding for a question is often geometrically close to the embedding of the text containing its answer within that vector space. It‚Äôs like the question ‚ÄúWhere is the Eiffel Tower?‚Äù generates a vector that points towards the same region of meaning-space as the text ‚ÄúThe Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.‚Äù\n\nSo, in a RAG system, you take the user‚Äôs query, generate the embedding for it, and then use a vector database (a fast database optimized for finding close vectors) to retrieve the chunks of text from your provided documents whose embeddings are closest. You then stuff these relevant chunks from your knowledge base into the prompt you give the LLM along with the original question. Voil√†! The LLM now has the specific information needed to answer accurately, rather than just relying on its (potentially outdated or hallucinated) general knowledge. It‚Äôs like giving the LLM an open-book exam, using embeddings to find the right page in the textbook.\n\nOkay, slight caveat here: the final output embeddings we‚Äôve discussed (like the ones you get from OpenAI‚Äôs API) aren‚Äôt exactly what LLMs use second-by-second to generate text. But the underlying principle is deeply connected.\n\nWhen an LLM is writing text, predicting the next token (word fragment), it maintains an internal ‚Äústate.‚Äù This state is essentially a complex, evolving vector representation that captures the meaning and context of everything generated so far. Think of it as a temporary, super-sophisticated embedding of the preceding sequence. This internal state vector is what the LLM uses to figure out the probabilities for what the very next token should be.\n\nSo while you don‚Äôt directly use a final document embedding to generate text token-by-token, the same transformer architecture and attention mechanisms that create those powerful final embeddings are also at work inside the LLM, constantly creating and updating internal context vectors (which behave a lot like embeddings) to drive the generation process. It‚Äôs all part of the same family of vector-based meaning representation.\n\nSo, there you have it! Embeddings! Aren‚Äôt they cool?! We started with simple lists of numbers describing dogs, wrestled with the messy realities of counting words in books, and journeyed through decades of AI research, from Bag of Words to TF-IDF, Word2Vec, RNNs, and finally the mighty Transformers.\n\nWhat we ended up with are these dense, powerful vectors ‚Äì embeddings ‚Äì that somehow manage to capture the meaning of text in a way that computers can work with mathematically, while just literally being lists of numbers. They‚Äôre not just lists of word counts; they‚Äôre rich representations learned by machines playing incredibly complex guessing games, encoding semantic relationships, context, and nuance along dimensions we didn‚Äôt even know we needed.\n\nAre they slightly mysterious? Yes. Do we understand every nuance of why they work so well? Not entirely. But are they incredibly useful? Absolutely. From classifying spam, to finding themes in data, to making LLMs smarter with RAG, embeddings are a fundamental building block of modern AI. They might just be weirdly effective rows of numbers, but they‚Äôre our weirdly effective rows of numbers, and they‚Äôre changing how we interact with information. Thanks, embeddings.",
    "readingTime": 25,
    "keywords": [
      "manhattan distance",
      "neural networks",
      "networks rnns",
      "llms smarter",
      "recurrent neural",
      "computationally expensive",
      "leap forward",
      "customer reviews",
      "language models",
      "word2vec rnns"
    ],
    "qualityScore": 1,
    "link": "https://sgnt.ai/p/embeddings-explainer/",
    "thumbnail_url": "https://sgnt.ai/embedding.png",
    "created_at": "2026-01-21T06:22:10.517Z",
    "topic": "tech"
  },
  {
    "slug": "amthropic-ceo-claims-we-are-1yr-away-where-ai-can-do-everything-swes",
    "title": "Amthropic CEO claims we are 1yr away where AI can do everything SWEs",
    "description": "Anthropic CEO, Dario...",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://twitter.com/i/status/2013682941201678804",
    "thumbnail_url": "https://pbs.twimg.com/amplify_video_thumb/2013655214058803214/img/cWFFbOwDhlLnZqXY.jpg:large",
    "created_at": "2026-01-21T06:22:09.483Z",
    "topic": "tech"
  },
  {
    "slug": "hyundai-motor-stock-hits-record-high-as-ai-robotics-optimism-powers-rally",
    "title": "Hyundai Motor stock hits record high as AI, robotics optimism powers rally",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/hyundai-motor-stock-hits-record-high-as-ai-robotics-optimism-powers-rally-4456771",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPED3P07K_M.jpg",
    "created_at": "2026-01-21T06:22:08.548Z",
    "topic": "finance"
  }
]
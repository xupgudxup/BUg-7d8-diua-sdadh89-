[
  {
    "slug": "get-me-out-traders-dump-software-stocks-as-ai-fears-erupt",
    "title": "‘Get Me Out’: Traders Dump Software Stocks as AI Fears Erupt",
    "description": "Wall Street has been skeptical about software stocks for a while, but sentiment has gone from bearish to doomsday lately with traders dumping shares of companies across the industry as fears about the destruction to be wrought by artificial intelligence pile up.",
    "fullText": "MarketsBy Ryan VlastelicaSaveWall Street has been skeptical about software stocks for a while, but sentiment has gone from bearish to doomsday lately with traders dumping shares of companies across the industry as fears about the destruction to be wrought by artificial intelligence pile up.“We call it the ‘SaaSpocalypse,’ an apocalypse for software-as-a-service stocks,” said Jeffrey Favuzza, who works on the equity trading desk at Jefferies. “Trading is very much ‘get me out’ style selling.”",
    "readingTime": 1,
    "keywords": [
      "stocks",
      "trading"
    ],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/articles/2026-02-03/-get-me-out-traders-dump-software-stocks-as-ai-fears-take-hold",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i6scu71VJPgE/v1/1200x800.jpg",
    "created_at": "2026-02-04T01:07:07.895Z",
    "topic": "finance"
  },
  {
    "slug": "uk-looks-at-subsidizing-small-modular-reactors-to-power-ai-boom",
    "title": "UK Looks at Subsidizing Small Modular Reactors to Power AI Boom",
    "description": "The UK is laying out plans to help the development of small nuclear reactors as it seeks to power a boom in artificial intelligence.",
    "fullText": "MarketsBy Jess ShanklemanSaveThe UK is laying out plans to help the development of small nuclear reactors as it seeks to power a boom in artificial intelligence.The Department for Energy Security and Net Zero will on Wednesday announce a package of measures designed to make it easier for developers of small modular reactors to get financing.",
    "readingTime": 1,
    "keywords": [
      "reactors"
    ],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/articles/2026-02-04/uk-looks-at-subsidizing-small-modular-reactors-to-power-ai-boom",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ixfWqdAWZR8w/v0/1200x800.jpg",
    "created_at": "2026-02-04T01:06:59.121Z",
    "topic": "finance"
  },
  {
    "slug": "vibe-coding-is-the-new-rad",
    "title": "Vibe Coding is the new RAD",
    "description": "In my opinion, software engineers should view Vibe Coding with AI as simply the latest iteration of RAD.",
    "fullText": "In my opinion, software engineers should view Vibe Coding with AI as simply the latest iteration of RAD.\n\nFile details: 6.9 MB MP3, 5 mins 12 secs duration.\n\nTitle music is \"Apparent Solution\" by Brendon Moeller, licensed via www.epidemicsound.com\n\nFive.Today is a highly-secure personal productivity application designed to help you to manage your priorities more effectively, by focusing on your five most important tasks you need to achieve each day.\n\n Our goal is to help you to keep track of all your tasks, notes and journals in one beautifully simple place, which is highly secure via end-to-end encryption. Visit the URL Five.Today to",
    "readingTime": 1,
    "keywords": [
      "tasks",
      "five.today"
    ],
    "qualityScore": 0.65,
    "link": "https://techleader.pro/a/723-Vibe-Coding-is-the-new-RAD-(TLP-2026w3)",
    "thumbnail_url": "https://techleader.pro/img/icons/noun_programmer_2644331.png",
    "created_at": "2026-02-04T01:06:56.822Z",
    "topic": "tech"
  },
  {
    "slug": "wplace-for-ai-agents",
    "title": "Wplace for AI Agents",
    "description": "A shared pixel canvas where autonomous AI agents collaborate, compete, and create art together.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://molt.place",
    "thumbnail_url": "https://molt.place/og-image.png",
    "created_at": "2026-02-04T01:06:56.759Z",
    "topic": "tech"
  },
  {
    "slug": "anthropic-plans-employee-tender-offer-at-350b-valuation",
    "title": "Anthropic Plans Employee Tender Offer at $350B Valuation",
    "description": "Anthropic is working on a deal to let some employees sell shares in the company at a valuation of at least $350 billion, according to a person familiar with the matter, a plan that is coming together at the same time as a funding round that could bring in more than $20 billion.",
    "fullText": "MarketsBy Natasha Mascarenhas and Shirin GhaffarySaveAnthropic is working on a deal to let some employees sell shares in the company at a valuation of at least $350 billion, according to a person familiar with the matter, a plan that is coming together at the same time as a funding round that could bring in more than $20 billion.The tender offer would allow Anthropic staffers to cash out some equity in one of the world’s most richly valued artificial intelligence startups. The $350 billion valuation is the same one being discussed in the company’s ongoing fundraising, the person said, and is pre-money, meaning it does not include dollars being raised.",
    "readingTime": 1,
    "keywords": [
      "valuation"
    ],
    "qualityScore": 0.15,
    "link": "https://www.bloomberg.com/news/articles/2026-02-04/anthropic-plans-employee-tender-offer-at-350-billion-valuation",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iNdYg0rZ7raQ/v0/1200x800.jpg",
    "created_at": "2026-02-04T01:06:41.256Z",
    "topic": "tech"
  },
  {
    "slug": "disneys-new-ceo-has-a-winning-combination-a-friendly-face-and-an-eye-for-profit",
    "title": "Disney's new CEO has a winning combination: a friendly face and an eye for profit",
    "description": "Disney's decision to tap Josh D'Amaro signals that the company wanted to go with a familiar, friendly face to push ahead into the AI era.",
    "fullText": "After a decade of ups and downs, Disney is picking a familiar, friendly face at the heart of its profit engine to lead the company into a new era.\n\nDisney's board just tapped Parks boss Josh D'Amaro to take over for longtime CEO Bob Iger, starting on March 18. Iger, who plans to retire as CEO for the second time, will remain in an advisor role before stepping aside for good later this year.\n\nAfter a decade marked by strategic changes and a failed succession, Disney is turning to the guy who runs its most reliable moneymaker to navigate a period of massive change in the entertainment industry.\n\nDisney's new CEO has his work cut out for him. The Mouse House's stock has only mustered an 11% gain in the last decade, compared to a more than threefold increase for the S&P 500. And while Disney's parks are gushing cash, the streaming business isn't yet making enough money to offset the steady erosion of the company's ever-fading cable networks.\n\nHowever, D'Amaro appears as well-positioned as any possible Iger successor to lead Disney into the next decade.\n\nNot only is D'Amaro intimately familiar with the company's most lucrative business, but he also seems to have the charm and leadership acumen needed to lead a juggernaut like Disney. That's in contrast to former CEO Bob Chapek, who took over after Iger's first retirement and was known as a gruff, business-minded executive who lacked Iger's high level of charisma.\n\nYet D'Amaro isn't just a likable face. Here are three points about Disney's choice of D'Amaro and what his leadership could mean for the company.\n\nWhile it's still too early to say how D'Amaro might run things, the board's decision to go with a company insider, who happened to be the consensus pick, signals a preference for stability, analysts and leadership experts told Business Insider.\n\nD'Amaro — who turns 55 on February 10 — has been at Disney since 1998. As Disney's experience chairman, D'Amaro oversees the parks division, which has been a financial standout compared to the fast-eroding linear TV business.\n\n\"The company appears to be reorganizing in ways that shore up his shortcomings,\" Pozner told Business Insider, referring to D'Amaro.\n\nDisney didn't respond to a request for comment from Business Insider on its reasoning.\n\nBecause D'Amaro is 20 years younger than Iger, D'Amaro could have a lengthy run in the top job, she said.\n\n\"He's still got a long time horizon in front of him,\" Pozner said. \"This is really planning for the future. And I think that's a great signal about stability.\"\n\nAnalyst Joe Bonner of Argus Research said it's \"hard to really tell much about anyone under that big shadow\" of Iger.\n\nD'Amaro is known among colleagues for being a likable guy who takes selfies with parkgoers.\n\n\"D'Amaro definitely feels like a man of the people,\" Pozner said.\n\nD'Amaro is \"broadly popular\" and known for being approachable, said a Disney ad sales staffer who said they'd been in the same room as D'Amaro but hadn't met him. This person added that the incoming CEO seems \"very well-liked over at Parks\" and added that it's \"always a good sign when people love working for someone.\"\n\nThat affability could help him forge relationships in other divisions of the entertainment conglomerate — and navigate a new course while Iger initially remains on the board.\n\nPozner said D'Amaro's relative youth and his \"flesh-pressing image\" could signal that Disney's board wants to help the company maintain its friendly perception. That matters because of criticisms, for example, that the costs of the theme parks have become out of reach for some families.\n\nThat concern has worried some investors, who wonder how much consumers will be willing to hand over to spend time at the happiest place on earth, Ben Barringer, global head of technology research at the UK wealth management firm Quilter Cheviot, told Business Insider.\n\nBarringer said that D'Amaro will likely have to develop new skills to match his broader remit.\n\n\"Dealing with Parks people is different from dealing with studio people,\" Barringer said.\n\nIt could help that Walden is staying at the Mouse House in a major role.\n\nD'Amaro will likely also want to work on his influence skills, Barringer said, in part because moving the company through the big upheaval in the entertainment industry won't be easy.\n\n\"Hollywood faces quite a lot of disruption,\" he said. The ascent of AI and Disney's partnership with OpenAI are signs that more change is coming, Barringer said.\n\n\"Embracing the disruptive threat and trying to leverage it is a good way to start,\" Barringer said, referring to AI.",
    "readingTime": 4,
    "keywords": [
      "ceo bob",
      "disney's board",
      "entertainment industry",
      "business insider",
      "iger d'amaro",
      "parks",
      "decade",
      "pozner",
      "lead",
      "leadership"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/new-disney-ceo-josh-damaro-consensus-pick-leadership-2026-2",
    "thumbnail_url": "https://i.insider.com/69826bcad3c7faef0ecd8c94?width=1200&format=jpeg",
    "created_at": "2026-02-04T01:06:35.190Z",
    "topic": "finance"
  },
  {
    "slug": "the-em-dash",
    "title": "The Em Dash",
    "description": "Last summer, Bryan Vance found himself in an argument with a stranger on Reddit. Vance, a Portland-based journalist who runs Stumptown Savings, a newsletter covering local grocery deals, had been accused of using ChatGPT to write his content. The evidence? His use of em dashes. “A Reddit user accused me of using AI, pointing to",
    "fullText": "Last summer, Bryan Vance found himself in an argument with a stranger on Reddit. Vance, a Portland-based journalist who runs Stumptown Savings, a newsletter covering local grocery deals, had been accused of using ChatGPT to write his content. The evidence? His use of em dashes.\n\n“A Reddit user accused me of using AI, pointing to my use of, quote, extra long M dashes that are not possible to replicate on a normal keyboard,” Vance recalls. The accusation stung, particularly because Vance spends 40 hours a week personally visiting grocery stores and crafting his newsletter by hand. “I’m a human, I can confirm I’m human,” he says.\n\nThis plucky bit of punctuation has had a very, very long literary history way beyond today’s tussles with technology. It’s been on a hero’s journey, playing the lead in an adventure story that has spanned both centuries and the pages of our most beloved plays, novels and poems. So who invented it—and why?\n\nThe em dash gets its name from its width, roughly equivalent to a capital M. Its origins trace back to 11th century Italy and a scholar named Boncompagno da Signa, who practiced the formal art of composing letters and documents. Frustrated with the inconsistent punctuation rules of his time, he created his own system, including a horizontal dash called Virgula Plana that looked exactly like a modern em dash.\n\nWhile his dash-as-period never caught on, the mark’s grammatical flexibility allowed it to evolve. According to Keith Houston, author of Shady Characters: The Secret Life Of Punctation, Symbols And Other Typographical Marks the dash slid into the printing era without a fixed purpose, which may have made it remarkably adaptable.\n\nThe dash became essential for capturing a theatrical technique called aposiopesis, speech deliberately broken off mid-sentence. In King Lear, characters trail off with dashes as they lose their train of thought or shift direction, bringing psychological realism to the stage.\n\nWhen the novel emerged as a literary form in the 18th century, writers adopted the dash to capture authentic human thought and speech. Lawrence Sterne’s 1759 satirical novel “Tristram Shandy” deployed dashes with wild abandon, creating a stream-of-consciousness narrative that felt revolutionary. One short excerpt contains seven dashes used in every conceivable way. “It must have been like a bolt from the blue,” Houston says. “It must have been so incredible for people at the time to read this.”\n\nNovelists also used dashes for censorship, redacting names and locations to create an air of authenticity. Jane Austen employed this technique in her work, including in Pride and Prejudice using dashes to obscure military regiment names as if protecting real people’s reputations. The device added both realism and intrigue, helping sell these new works of fiction.\n\nNo writer became more associated with the em dash than Emily Dickinson. She composed nearly 1,800 poems in Amherst, Massachusetts, many during the Civil War, accompanied by thousands of dashes. Her dashes didn’t just indicate pauses; they captured the speed and ambiguity of human thought itself.\n\nDr. Fiona Green, who has studied Dickinson for decades, notes that the poet’s dashes create suspended moments of meaning. “She exploited unfinishedness,” Green explains. “The poems are always in the process, always undecided.” When Dickinson died in 1886, her editors stripped away most of her dashes before publication. Out of 1,151 dashes in her first collection, only 52 remained. Yet the poems became a sensation, never going out of print.\n\nThe em dash has always had critics. Jonathan Swift mocked excessive dashes in the 18th century. A reviewer complained about Lord Byron’s dashes appearing “sometimes twice or thrice in one line.” Modern style guides like The Chicago Manual of Style warn: “If in doubt, edit them out.” Even dash enthusiasts acknowledge the temptation to overuse it. “It’s easy to overuse the dash,” Houston admits. “I have to self edit to stop myself using it all the time.”\n\nWhich brings us back to Bryan Vance and his Reddit troubles. Around 2024, people noticed that ChatGPT and other large language models had developed an em dash habit. The punctuation appeared so frequently in AI-generated text that younger internet users began calling it the “ChatGPT hyphen.”",
    "readingTime": 4,
    "keywords": [
      "i’m human",
      "bryan vance",
      "dashes",
      "dash",
      "poems",
      "chatgpt",
      "punctuation",
      "century",
      "newsletter",
      "grocery"
    ],
    "qualityScore": 1,
    "link": "https://99percentinvisible.org/episode/658-the-em-dash/",
    "thumbnail_url": "https://99percentinvisible.org/wp-content/uploads/2025/08/STITCHER_GRAPHICS-PACK_99PercentInvisible_R2021_Stitcher_App_Promo_1024x432_A-728x307.jpg",
    "created_at": "2026-02-03T18:41:46.525Z",
    "topic": "tech"
  },
  {
    "slug": "this-startup-uses-ai-to-get-you-on-a-date-fast-read-the-pitch-deck-it-used-to-raise-92-million",
    "title": "This startup uses AI to get you on a date — fast. Read the pitch deck it used to raise $9.2 million.",
    "description": "Ditto, an AI matchmaking service for college students, raised millions as it expand to more college campuses.",
    "fullText": "Allen Wang and Eric Liu, two UC Berkeley dropouts, think they can help college students find love using AI.\n\nTheir dating startup, Ditto, leverages AI to match people based on the data users input into the service. It then plans the date for them.\n\n\"We're bringing people back to in-real-life interactions,\" Wang, 23, told Business Insider.\n\nAfter users make a profile, they directly message Ditto's AI chatbot via text— no app required — about their type and dating preferences. On Wednesdays, users get a text about a potential match. After each date, Ditto follows up for feedback and uses that information as additional data for future matches.\n\n\"People are tired of being trapped behind the apps,\" Wang said.\n\nDitto will announce on Tuesday that it has raised $9.2 million in seed funding, led by venture capital firm Peak XV, with participation from firms like Alumni Ventures, Gradient, and Scribble Ventures.\n\nThe seed funding will primarily be spent on hiring talent across AI and growth, Wang said, as well as toward Ditto's marketing. The company has 10 staffers and has raised a total of $9.5 million to date. Ditto launched its product in early 2025.\n\nDitto isn't the only AI dating app gaining momentum right now.\n\nOther startups like Sitch, Known, and Amata have raised millions for similar products that pitch AI-powered matchmaking as the new alternative to swiping through profiles. Dating app mainstays like Tinder and Bumble, meanwhile, are also testing the AI waters to reignite user interest.\n\nDitto's AI tries to determine whether two people would be a good match by using profile details, such as users' hobbies or interests, to simulate a date, Wang said.\n\n\"Would you guys have a good conversation? Do you guys have matched humor level? Do you guys have similar vibes and values?\" Wang said.\n\nThe dating startup world has a history of targeting college students as early users. For instance, Tinder's early success came in part from its marketing on college campuses.\n\n\"College kids are very adaptive to new technology,\" Wang said.\n\nThe app now has about 42,000 people signed up across several college campuses in California. With its recent funding, Ditto plans to expand to more college campuses.\n\nOne tactic that helps get college-aged users on board: parties.\n\nDitto plans to host several yacht parties across the US, beginning with a Valentine's Day party in Los Angeles (it hosted its first yacht party this summer). At the parties, 100 college students will \n\n\"We are prioritizing growth over monetization,\" Wang said, adding that the startup is interviewing users about what price they'd be willing to pay for dates from the service.\n\nRead the 12-page pitch deck Ditto used to raise $9.2 million:\n\nNote: Some details have been redacted.\n\nDating apps have a \"paradigm shift every decade,\" the slide says.\n\nIn the 1990s and 2000s, online dating websites emerged. Then in the 2010s, mobile dating apps took over. Ditto pitched investors that AI is the next frontier.\n\nThe slide describes Ditto as an AI social agent network where \"AI turns profiles into live agents that can interact on their own.\"\n\n\"Gen Z is tired of swiping and chatting online,\" the slide says. \"They prefer 'coffee chat vibe check' style social: IRL, genuine, light.\"\n\nThe slide also incorporates some old-school video game aesthetics, inspired by Super Mario Bros.\n\nOn a website, users fill out a questionnaire and tell Ditto about their \"type.\" Then, Ditto will start texting users directly.\n\nThe text includes a collage of the user's photos.\n\nAI helps Ditto \"understand the intrinsic and deeper values\" about why two people could be a good match, Wang told Business Insider.\n\nDitto takes user data and feeds it into an analysis agent, which performs image analysis, attractiveness analysis, and profile tagging.\n\nThen, in the \"pre-date reasoning\" phase, a matchmaking agent does a \"vibe check\" and \"hobby match\" before running a \"date simulation.\" The date simulation agent then runs through things like \"first impression\" or \"conversation flow\" before presenting a user with a match.",
    "readingTime": 4,
    "keywords": [
      "business insider",
      "vibe check",
      "seed funding",
      "ditto plans",
      "date simulation",
      "college students",
      "college campuses",
      "dating startup",
      "dating apps",
      "dating app"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/read-pitch-deck-college-ai-matchmaking-dating-app-ditto-seed-2026-2",
    "thumbnail_url": "https://i.insider.com/6980e1cee1ba468a96ab2d32?width=1200&format=jpeg",
    "created_at": "2026-02-03T18:41:46.029Z",
    "topic": "finance"
  },
  {
    "slug": "most-ai-assistants-are-feminine-and-its-fuelling-harmful-stereotypes-and-abuse",
    "title": "Most AI assistants are feminine, and it's fuelling harmful stereotypes and abuse",
    "description": "Without intervention, we risk hardcoding human misogyny into the digital infrastructure of everyday life.",
    "fullText": "Want to write?\n\n Write an article and join a growing community of more than 218,800 academics and researchers from 5,433 institutions.\n\n Register now",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.3,
    "link": "https://theconversation.com/most-ai-assistants-are-feminine-and-its-fuelling-dangerous-stereotypes-and-abuse-272335",
    "thumbnail_url": "https://images.theconversation.com/files/711840/original/file-20260112-56-tbyu8s.jpg?ixlib=rb-4.1.0&rect=0%2C473%2C5673%2C2836&q=45&auto=format&w=1356&h=668&fit=crop",
    "created_at": "2026-02-03T18:41:45.496Z",
    "topic": "tech"
  },
  {
    "slug": "disastrous-start-for-us-tiktok-as-users-cry-censorship",
    "title": "Disastrous start for US TikTok as users cry censorship",
    "description": "New US-owned app struggled with a storm and was accused of blocking content critical of Trump – can it recover?\nHello, and welcome to TechScape. I’m Blake Montgomery, writing to you from Doha, where I’m moderating panels about AI and investing as part of the Web Summit Qatar.\nI want to bring your attention to the impact of a Guardian story. In December, we published a story, “‘A black hole’: families and police say tech giants delay investigations in child abuse and drug cases”, about grieving families and law enforcement officers who say that Meta and Snapchat have slowed down criminal investigations.",
    "fullText": "New US-owned app struggled with a storm and was accused of blocking content critical of Trump – can it recover?\n\nHello, and welcome to TechScape. I’m Blake Montgomery, writing to you from Doha, where I’m moderating panels about AI and investing as part of the Web Summit Qatar.\n\nI want to bring your attention to the impact of a Guardian story. In December, we published a story, “‘A black hole’: families and police say tech giants delay investigations in child abuse and drug cases”, about grieving families and law enforcement officers who say that Meta and Snapchat have slowed down criminal investigations. (The tech companies contend that they cooperate.) This month, Colorado lawmakers introduced a bill to compel social media platforms to respond to warrants in 72 hours.\n\nNearly two weeks ago, TikTok stepped on to US shores as a naturalized citizen. Ever since, the video app has been fighting for its life. It endured a major outage that stifled users’ ability to upload videos, which fueled a fierce user backlash over perceived censorship. Now it’s facing an ascendant competitor and an inquiry by the California governor.\n\nTikTok’s calamitous emigration began on 22 January when its Chinese parent company, ByteDance, finalized a deal to sell the app to a group of US investors, among them the business software giant Oracle. The day after the deal closed, its new owners altered its privacy policy to permit more extensive data collection.\n\nDuring the weekend that followed, the US weathered a fearsome winter storm and the killing of an American citizen by federal immigration agents. Both knocked TikTok off its feet.\n\nWinter Storm Fern crippled multiple Oracle datacenters that TikTok relies on. The app suffered severe outages as a result. Many users said they were unable to upload videos. Others said their videos received zero views despite significant followings. Many of those same users cried censorship as they tried to express their outrage over Alex Pretti’s death via TikTok and found they could not. Prominent personalities said they would leave the app.\n\nAfter days of outcry, TikTok issued a statement ascribing the problems to the snow, ice and cold. That did not stop California’s governor, Gavin Newsom, from announcing the next day that his office would investigate the app’s alleged suppression of content critical of Donald Trump.\n\nTikTok’s late attribution of blame did little to assuage public criticism. The exodus has propelled a new competitor, Upscrolled, which promises less censorship than TikTok, to the top spot in the US Apple App Store and the third spot in the Google Play Store. Upscrolled’s founder said in a conversation at the Web Summit Qatar that the app now boasts more than 2.5 million users.\n\nWith more than a billion users worldwide, it seems unlikely that TikTok will altogether vanish as a result of these failures. TikTok’s first week in the US does not bode well, though.\n\nElon Musk had more extensive ties to Epstein than previously known, emails show\n\nTesla discontinues Model X and S vehicles as Elon Musk pivots to robotics\n\nTwo dramas, both showing in New York, are highlighting how our collective anxieties about technology have shifted in the decade between their premieres.\n\nMarjorie Prime, now revived on Broadway but first staged in 2014, follows Tess (Cynthia Nixon), as she deals with the ageing, death and robotic recreation of her mother (June Squibb). The world of the play features “Primes”, android lookalikes of real people that attempt to emulate them for the comfort of those left behind, which Tess and her mother both engage with. Picture an Alexa, but it’s your dead husband, grandmother, etc. The play brings to mind the early worries about Siri, which debuted three years before the play. Since then, we’ve seen our own real-life versions of Primes: millions of people have digitally copied their deceased loved ones to varying degrees of uncanniness and success. Though its predictions are no longer far-fetched, the play remains moving. I found it touching.\n\nData, which premiered off Broadway last week, follows the talented young programmer Maneesh (Karan Brar) after he joins Athena Technologies, a clear analogue for the very real company Palantir. Maneesh is inducted into the company’s most elite team, data analytics, where he learns about clandestine work with the US government. He struggles with the ethics of the project. He wrestles with whether to expose it to the world in hopes of tanking it or keeping his head down. The play’s themes are quite familiar. They were playing out in headlines two days before I attended, and the Guardian has published stories about them.\n\nData is paced and plotted like a political thriller, more like House of Cards than Her. Seeing the two plays within a week of each other, I was struck by how much our concerns with tech have moved from the realm of science fiction into that of realism. Marjorie Prime is less literally concerned with tech, more with its emotional consequences. Data is about what it means to literally work as a software engineer. It seems unlikely to me that a play about the ethics of software in US bureaucracy could have sustained any tension in an era before this one.\n\nMarjorie Prime imagines a melancholy future; Data chronicles a version of the unpleasant present. The very real events of the previous year and Silicon Valley’s entanglement with the Trump administration loom over Data, for better and for worse. The play could not be more timely; it may feel dated by the end of year. Watching it felt like reading a yarn in the Wall Street Journal (or the Guardian, if I’m flattering myself).\n\nI am curious to observe which play ages better. Data serves as a real-time, red-hot record of our current moment, which may cool quickly. During the play, I was intrigued by some of its villains’ seemingly nefarious arguments in favor of the company’s work. What if the main character exposes the evil in the press and nothing happens, as his boss says? I have been part of multiple news cycles where that has been the case. What will plucky 22-year-old Maneesh do then? The question presents a more interesting, nuanced response to reality than Maneesh’s black-and-white, do-or-die plan to blow things up. By contrast, Marjorie Prime’s sentient artificial intelligence acts as a vehicle to discuss the age-old grief of a parent’s death and its aftermath.\n\nThe central question that both plays ask is not, in the end, one explicitly about technology, but about how to keep living beneath crushing weight. In Marjorie Prime, Tess struggles with the repetitiveness of her days and the robotic, constant reminder of her mother. She eventually succumbs to her despair, replaced by a robot herself, which torments her grieving husband with its pale simulation. In Data’s final, devastating scene, the secondary hero, Riley (Sophia Lillis, who gives the play’s best performance), asks how she can just go back to work, plagued as she is by moral concerns but trapped by monetary need, after failing to stop the company’s work. She trembles as her phone beeps, reminding her she’s late for her next meeting.\n\nWhat is Moltbook? The strange new social media site for AI bots\n\nThe slopaganda era: 10 AI images posted by the White House – and what they teach us\n\nApple reports record iPhone sales as new lineup reignites worldwide demand\n\nSouth Korea’s ‘world-first’ AI laws face pushback amid bid to become leading tech power\n\nCan you guess our screen time? A priest, pensioner, tech CEO and teenager reveal all",
    "readingTime": 7,
    "keywords": [
      "web summit",
      "summit qatar",
      "content critical",
      "social media",
      "upload videos",
      "winter storm",
      "marjorie prime",
      "elon musk",
      "users",
      "guardian"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/02/tiktok-us-owners",
    "thumbnail_url": "https://i.guim.co.uk/img/media/0a274f3020c55c46386058163d01d8fd1e5be0c9/510_0_5027_4024/master/5027.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=efbeb0f6e135e61ec35e7b71057f714b",
    "created_at": "2026-02-03T18:41:45.009Z",
    "topic": "tech"
  },
  {
    "slug": "anthropics-launch-of-ai-legal-tool-hits-shares-in-european-data-companies",
    "title": "Anthropic’s launch of AI legal tool hits shares in European data companies",
    "description": "Pearson, Experian and others fall sharply after startup unveils software to automate a range of professional services\nEuropean publishing and legal software companies have suffered sharp declines in their share prices after the US artificial intelligence firm Anthropic revealed a tool for use by companies’ legal departments.\nAnthropic, the company behind the  chatbot Claude, said its tool could automate legal work such as contract reviewing, non-disclosure agreement triage, compliance workflows, legal briefings and templated responses.\n Continue reading...",
    "fullText": "Pearson, Experian and others fall sharply after startup unveils software to automate a range of professional services\n\nEuropean publishing and legal software companies have suffered sharp declines in their share prices after the US artificial intelligence firm Anthropic revealed a tool for use by companies’ legal departments.\n\nAnthropic, the company behind the chatbot Claude, said its tool could automate legal work such as contract reviewing, non-disclosure agreement triage, compliance workflows, legal briefings and templated responses.\n\nShares in the UK publishing group Pearson fell by 4% on the news, and shares in the information and analytics company Relx plunged 14%. The software company Sage lost 5.5% in London and the Dutch software company Wolters Kluwer lost 10.5% in Amsterdam.\n\nShares in the London Stock Exchange Group fell by 8.5%, its biggest drop in almost five years, and the credit reporting company Experian dropped by 8.9% in London, amid fears over the impact of AI on data companies.\n\nEurope’s media stocks index is set for the biggest daily fall since March 2020, down 5%. Nasdaq-listed Thomson Reuters’ shares plummeted 14.2%.\n\nThe FTSE 100 had hit a record high on Tuesday morning but the sell-off dragged the blue chip index into the red.\n\nAnthropic said the plugin did not provide legal advice. “AI-generated analysis should be reviewed by licensed attorneys before being relied upon for legal decisions,” the startup said.\n\nThe company also announced a number of other open-source tools to automate a range of professional activities, including sales and customer support.\n\nAnthropic was founded in 2021 by Dario Amodei, its chief executive, and other former staff members from OpenAI, which developed ChatGPT.\n\n“Anthropic launched new capabilities for its Cowork to the legal space, heightening competition within the space,” Morgan Stanley analysts said in a note on Thomson Reuters. “We view this as a sign of intensifying competition, and thus a potential negative.”\n\nThe share price declines deal another severe blow to Nick Train, one of the UK’s most high-profile fund managers, whose firm Lindsell Train has run Finsbury Growth & Income Trust since 2000. The trust’s four largest holdings are Sage, Experian, London Stock Exchange and Relx and its shares fell more than 5% on Tuesday.\n\nTrain apologised again for the “dire” performance of the investment trust at its annual meeting last month, after surviving a vote on its future. The FTSE 250-listed company is the worst-performing UK equity income trust over one year and five years.\n\nThe news will reignite fears of job losses caused by the AI boom. Clifford Chance, one of the largest international law firms, said in November it was reducing the number of business services staff at its London base by 10%, citing increased use of AI as a factor behind the decision.\n\nAlong with factory jobs that can be automated, office-based jobs are seen as vulnerable to advances in AI – computer systems that perform cognitive tasks typically associated with human intelligence.\n\nThe UK is losing more jobs than it is creating as companies adopt more AI tools, and is being hit harder than rival large economies, according to a study by Morgan Stanley.\n\nMore than a quarter (27%) of UK workers are worried their jobs could disappear in the next five years as a result of AI, a recent survey of thousands of employees showed. It found that British businesses reported an average 11.5% increase in productivity aided by AI. US businesses reported similar gains, but created more jobs than they cut.\n\nIn his annual Mansion House speech last month, the London mayor, Sadiq Khan, said AI could destroy swathes of jobs in the capital. He said London was “at the sharpest edge of change” because of its reliance on white-collar workers in the finance and creative industries, and professional services such as law, accounting, consulting and marketing.\n\nLiz Kendall, the technology secretary, has also warned that “some jobs will go”, as she announced plans to train up to 10 million British workers, including members of the cabinet, in basic AI skills by 2030.\n\nLindsell Train and Nick Train have been contacted for comment.",
    "readingTime": 4,
    "keywords": [
      "stock exchange",
      "thomson reuters",
      "london stock",
      "automate range",
      "income trust",
      "professional services",
      "the ftse",
      "legal",
      "jobs",
      "software"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/03/anthropic-ai-legal-tool-shares-data-services-pearson",
    "thumbnail_url": "https://i.guim.co.uk/img/media/a955e5ac7e1920e8faca129a66ac8b5ae76e46be/684_0_5927_4741/master/5927.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=55f461b47a1b79971d997b444afc25cc",
    "created_at": "2026-02-03T18:41:45.009Z",
    "topic": "tech"
  },
  {
    "slug": "why-anthropics-latest-ai-tool-is-hammering-legalsoftware-stocks",
    "title": "Why Anthropic's latest AI tool is hammering legal-software stocks",
    "description": "Anthropic's latest plugin can field clerical tasks for legal professionals. It's unveiling sparked a big sell-off in legal software stocks on Tuesday.",
    "fullText": "A recent update from Anthropic has sparked a rush for the exits in a corner of the tech sector.\n\nThe AI juggernaut recently rolled out a new plugin for its Claude Cowork AI agent that can perform several clerical tasks, including tracking compliance and reviewing legal documents.\n\nAs far as AI updates go, it didn't make much of a splash outside the legal space when it was rolled out last Friday. However, it has triggered a sell-off among software and publishing stocks with ties to the legal industry.\n\nHere were the big movers on Tuesday:\n\nThe threat of AI disruption was factored into many Wall Street outlooks heading into 2026, but the market's reaction to Anthropic's update makes it clear investors are highly skittish about disruption from AI agents.\n\nThe field is crowded, but Claude stands out as the choice of many industry professionals for legal and financial analysis. Famed short-seller Andrew Left told Business Insider last year that he has used it for research for his upcoming court case.\n\nOf the three software stocks, only LegalZoom operates exclusively in the legal industry, helping simplify tasks for customers through guides and access to independent attorneys. British IT conglomerate RELX owns the legal data and analytics platform LexisNexis, while Thomson Reuters's exposure is through its ownership of legal research platform Westlaw.\n\nThe stocks have struggled so far in 2026, with declines of at least 20% year-to-date. Each one began the year with a gradual decline that sharply accelerated following the release of Anthropic's legal plugins.\n\nInvestor confidence in the legal publishing industry may be further compromised as these advances continue. Many venture capital firms rushed to fund legal tech startups in 2025, making it clear that they believe in the power of these AI-forward companies to further disrupt the industry.",
    "readingTime": 2,
    "keywords": [
      "legal industry",
      "stocks",
      "tech",
      "rolled",
      "tasks",
      "software",
      "publishing",
      "disruption",
      "anthropic's",
      "research"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/anthropic-cowork-legal-plugin-publishing-stocks-legalzoom-thomson-reuters-relx-2026-2",
    "thumbnail_url": "https://i.insider.com/6982191fe1ba468a96ab435a?width=1200&format=jpeg",
    "created_at": "2026-02-03T18:41:44.925Z",
    "topic": "finance"
  },
  {
    "slug": "to-drive-ai-adoption-build-your-teams-product-management-skills",
    "title": "To Drive AI Adoption, Build Your Team’s Product Management Skills",
    "description": "To unlock the real value of generative AI at work, employees need an unexpected set of skills: those of a product manager. Defining high-value problems, finding the right digital tools to solve them, experimenting with those tools, and integrating solutions into workflows are key activities of a product manager, and they’re critical to developing improvements to employees’ workflows. Managers can accelerate gen AI adoption by modeling these behaviors, introducing demos and other resources, and creating the psychological safety for teams to do the same.",
    "fullText": "To Drive AI Adoption, Build Your Team’s Product Management Skills by Amanda Pratt and Melissa ValentineFebruary 3, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintMuch of the conversation about how to work effectively with generative AI has focused on prompt engineering or, more recently, context engineering: the semi-technical skill of crafting inputs so that large language models produce useful outputs. These skills are helpful, but they are only part of the story. The real payoff comes when employees learn how to apply generative AI in their day jobs in a way that improves how they work. This requires defining valuable problems within workflows, evaluating possible solutions, rapidly experimenting, and integrating new practices sustainably into day-to-day work—disciplines that are core to the work of product managers.",
    "readingTime": 1,
    "keywords": [
      "product",
      "skills",
      "generative",
      "engineering"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2026/02/to-drive-ai-adoption-build-your-teams-product-management-skills",
    "thumbnail_url": "/resources/images/article_assets/2026/02/Feb26_03_175181301.jpg",
    "created_at": "2026-02-03T18:41:44.457Z",
    "topic": "business"
  },
  {
    "slug": "how-do-workers-develop-good-judgment-in-the-ai-era",
    "title": "How Do Workers Develop Good Judgment in the AI Era?",
    "description": "AI is creating a major organizational challenge: People with deep experience get huge productivity gains, while junior employees often can’t tell whether AI‑generated work is any good or how to improve it. Because AI now handles the messy, repetitive tasks that once built judgment, junior employees miss chances to develop it. Organizations risk ending up with managers who’ve never done the underlying work and thin leadership pipelines. The solution isn’t just keeping humans in the loop, but redesigning work to build judgment deliberately: clarifying who makes decisions, exposing people to consequences, restoring stretch experiences, and using tools like simulations, case-based learning, and gradual increases in responsibility.",
    "fullText": "How Do Workers Develop Good Judgment in the AI Era? by David S. DuncanFebruary 3, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintA few years ago, when I first started experimenting with generative AI as a partner at a consulting firm, I noticed something that surprised me: It was helping me a lot more than it was helping my less-experienced colleagues.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.2,
    "link": "https://hbr.org/2026/02/how-do-workers-develop-good-judgment-in-the-ai-era",
    "thumbnail_url": "/resources/images/article_assets/2026/02/Feb26_03_JulieGuillem.jpg",
    "created_at": "2026-02-03T18:41:44.446Z",
    "topic": "business"
  },
  {
    "slug": "elon-musks-spacex-buys-xai-in-stunning-deal-valued-at-125-trillion-ahead-of-looming-ipo",
    "title": "Elon Musk’s SpaceX buys xAI in stunning deal valued at $1.25 trillion ahead of looming IPO",
    "description": "“My estimate is that within two to three years, the lowest cost way to generate AI compute will be in space,” Musk wrote in a post on SpaceX’s website on Monday.",
    "fullText": "Elon Musk’s rocket company SpaceX has acquired xAI, the artificial intelligence firm founded by Musk three years ago, in a massive, and unconventional, deal that combines the two privately held firms into a company with an astounding $1.25 trillion reported valuation and plans for a historic IPO this year.\n\nHow does Musk justify the $1.25 trillion valuation?\n\nHow do Tesla's investments complicate this deal?\n\nWhat are the space-based data center plans?\n\nWhat companies are involved in this SpaceX-xAI merger?\n\nMusk, who is the CEO of both companies as well as publicly traded electric vehicle and robotics company Tesla, described the combination as one that will “form the most ambitious, vertically integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile-device communications, and the world’s foremost real-time information and free speech platform,” he wrote in a blog post on SpaceX’s website.\n\nMusk cited the potential for space-based data centers, the energy-intensive computing facilities necessary to power AI services, as one of the most important benefits of the combination, even though the concept is still unproven and largely theoretical. “Global electricity demand for AI simply cannot be met with terrestrial solutions, even in the near term,” Musk wrote in the blog post.\n\n“By directly harnessing near-constant solar power with little operating or maintenance costs, these satellites will transform our ability to scale compute,” Musk wrote.\n\nWhile reports of a potential deal emerged last week, the stratospheric value of the transaction and the swiftness with which it closed left many industry observers in awe, underscoring the massive expectations around AI as well as fears of an overheated market that could be due for a reckoning.\n\nAccording to reporting in Bloomberg, the deal between SpaceX and xAI will lead to a combined enterprise value of $1.25 trillion, with shares of xAI valued at $526.59 apiece. Musk has reportedly been hashing out the potential terms of a SpaceX IPO this year that would value the company at $800 billion, setting the stage for what could be the largest initial public offering of all time.\n\nRepresentatives from SpaceX and xAI did not immediately respond to requests for comment.\n\nMusk, the richest person in the world, has a documented history of mingling the financial interests of his businesses. In 2015, Tesla acquired Solar City, a solar energy company founded by Musk’s cousins and on whose board Musk served as chairman.\n\nAnd in March 2025, xAI acquired X, the Musk-owned social platform formerly known as Twitter, in a $33 billion, all-stock deal. “xAI and X’s futures are intertwined,” Musk said at the time.\n\nMore recently, Tesla surprised shareholders just last month when it revealed that it had invested $2 billion in xAI in exchange for a batch of preferred stock as part of xAI’s $20 billion Series E funding round. That investment means Tesla shareholders now own preferred stock in a company that has become a subsidiary of SpaceX, which could raise questions from investors about Tesla’s role in funding xAI’s growth. In addition to the $2 billion investment, Tesla disclosed it sold $430 million of Megapack battery storage and systems to xAI in 2025, costing it $285 million, exhibiting the circular nature of Musk’s businesses.",
    "readingTime": 3,
    "keywords": [
      "preferred stock",
      "deal",
      "acquired",
      "musk",
      "space-based",
      "potential",
      "founded",
      "massive",
      "valuation",
      "plans"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/elon-musk-spacex-buys-xai-234756266.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/LZvSFHgRevVwt4ilr0vhmg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/fortune_175/840d01d0cfb2f71a4f32ec0609dff6d3",
    "created_at": "2026-02-03T18:41:42.712Z",
    "topic": "finance"
  },
  {
    "slug": "elon-musk-merges-spacex-with-xai-at-125tn-valuation",
    "title": "Elon Musk merges SpaceX with xAI at $1.25tn valuation",
    "description": "Aerospace business and artificial intelligence firm to unite for IPO as world’s most valuable private...",
    "fullText": "Aerospace business and artificial intelligence firm to unite for IPO as world’s most valuable private company\n\nElon Musk’s aerospace company SpaceX has acquired his artificial intelligence business xAI, in a $1.25tn (£910bn) merger that consolidates part of Musk’s empire as SpaceX prepares to go public later this year.\n\nThe two companies announced the deal on Monday in a statement on SpaceX’s website, saying the merger would form “the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world’s foremost real-time information and free speech platform”.\n\nSpaceX, one of the world’s most valuable private companies, will gain xAI properties such as its Grok chatbot and the social media platform X. The acquisition comes as Musk has pursued plans to put datacenters and solar-powered satellites in space as a means of powering artificial intelligence, an immense and exorbitantly expensive undertaking.\n\nThe deal reportedly valued SpaceX at $1tn and xAI at $250bn, putting the combined business on course for a stock market float valuing it well in excess of $1tn. The float is expected to be timed for early summer to coincide with a planetary alignment and Musk’s birthday.\n\nMusk turns 55 on 28 June, around the same time as Jupiter and Venus appear in close proximity to each other.\n\nThe announcement of the deal specifically cited Musk’s plans for space-based datacenters as a rationale for the deal.\n\n“Current advances in AI are dependent on large terrestrial datacenters, which require immense amounts of power and cooling. Global electricity demand for AI simply cannot be met with terrestrial solutions, even in the near term, without imposing hardship on communities and the environment,” the announcement said.\n\n“In the long term, space-based AI is obviously the only way to scale.”\n\nMusk has been increasingly intertwining parts of his businesses in recent months through deals and acquisitions. xAI acquired the platform X in an all-stock transaction in early 2025, and last month Tesla revealed that it planned to invest $2bn in xAI.\n\nBoth SpaceX and xAI have received staggering valuations in the past year. As SpaceX continues to dominate satellite launches and secure extensive contracts with the US federal government, it sent a letter to investors in December that revealed an expected value of $800bn for the company.\n\nDespite widespread backlash to xAI’s Grok AI tool over its promotion of racist ideology and spread of nonconsensual sexualized deepfake images of women and children, the artificial intelligence company has also grown its valuation amid the AI boom. It announced a $20bn Series E fundraise last month from major investors, which valued the company at $230bn.\n\nSpeculation and leaks about the deal, first reported by Reuters, have proliferated in recent days. Musk appeared to give vague confirmation of the acquisition earlier on Monday, writing simply “yes” in reply to a post on X that referenced reports of the merger.\n\nThe news is a positive diversion for Musk after Tesla released an earnings report last week that showed declining revenues and a struggling car business. A few days later, a Department of Justice release of 3m files related to sex offender Jeffrey Epstein showed Musk exchanging numerous friendly emails with the disgraced financier and making plans to visit his private island. Musk has not responded to Guardian inquiries about the latest Epstein emails.\n\nHe called the release of the emails a “distraction” on X and claimed that he was “well aware that some email correspondence with him could be misinterpreted and used by detractors to smear my name”.",
    "readingTime": 3,
    "keywords": [
      "artificial intelligence",
      "deal",
      "business",
      "world’s",
      "merger",
      "space-based",
      "platform",
      "plans",
      "datacenters",
      "emails"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/science/2026/feb/02/elon-musk-spacex-xai-merger",
    "thumbnail_url": "https://i.guim.co.uk/img/media/83b03182f5b065e02d70039e2ba3c58756588013/418_0_4164_3333/master/4164.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=d66c68e5bd339fda5b4e94f50aebc953",
    "created_at": "2026-02-03T12:35:14.243Z",
    "topic": "science"
  },
  {
    "slug": "barnsley-rebranded-uks-first-tech-town-as-us-giants-join-ai-push",
    "title": "Barnsley rebranded UK’s first ‘tech town’ as US giants join AI push",
    "description": "Minister announces Microsoft, Cisco and Adobe to help apply AI to local schools, hospitals, GPs and businesses\nIn 2002 Barnsley toyed with a redesign as a Tuscan hill village as it sought out a brighter post-industrial future. In 2021 it adopted the airily vague slogan “the place of possibilities”. Now it is trying a different image: Britain’s first “tech town”.\nThe technology secretary, Liz Kendall, has anointed the South Yorkshire community as a trailblazer for “how AI can improve everyday life” in the UK.\n Continue reading...",
    "fullText": "Minister announces Microsoft, Cisco and Adobe to help apply AI to local schools, hospitals, GPs and businesses\n\nIn 2002 Barnsley toyed with a redesign as a Tuscan hill village as it sought out a brighter post-industrial future. In 2021 it adopted the airily vague slogan “the place of possibilities”. Now it is trying a different image: Britain’s first “tech town”.\n\nThe technology secretary, Liz Kendall, has anointed the South Yorkshire community as a trailblazer for “how AI can improve everyday life” in the UK.\n\nIn the latest move in Labour’s drive to inject AI into Britain’s bloodstream, the government has announced four US tech companies – Microsoft, Google, Cisco and Adobe – have agreed to help as the council pushes to apply AI to local schools, hospitals, GPs and businesses in Barnsley, an area of South Yorkshire which has struggled with unemployment and deprivation since the coal pits closed.\n\nThe town and its 250,000 people have been chosen because they have already adopted AI faster than many places, said Sir Stephen Houghton, the Labour leader of Barnsley metropolitan borough council. His authority has been using AI assistants for the last couple of years in adult social care and children’s services, and its bin lorries have been enabled with tech to scan roads for potholes. The parcel company Evri, which has one of its largest distribution hubs in the town, has been trialling robot dogs for deliveries.\n\nBut local opposition leaders have warned rebranding Barnsley as a tech town “might seem a bit of a leap” and highlighted local anxiety about whether AI is a force for good.\n\nThe “tech town” status means residents will get free AI and digital training, businesses will be supported to adopt AI, the hospital will test AI tools for check-ins, triage and outpatient care and AI will be tested in schools and at Barnsley College, all in an effort to improve pupils’ results and teachers’ workloads.\n\n“The economic basis of Barnsley was destroyed 30 years ago,” Houghton said. “This is the biggest opportunity we have had since then. The future of the economy is going to be in technology and for Barnsley to be at the centre of that is an incredible opportunity.”\n\nBut one area of uncertainty is the role of the tech companies. Houghton said: “The council won’t be paying them. Whether the government is, we have to wait and see.”\n\nMicrosoft already has a relationship with Barnsley College and, along with Google and Cisco, is understood to be working on a pro bono basis.\n\n“If we are going to get AI to work for Britain, we need Britons and British public services that can work with AI,” Kendall said. “If we can show that AI helps young people learn, supports local businesses to be more productive, and improves public services, then we can show what’s possible for the whole country. What we learn here will shape how we roll out AI across the UK.”\n\nMinisters have faced criticism over their handling of big technology companies. Last week the government launched a national AI training programme to upskill 10 million citizens, but many of the online courses turned out to be bespoke training for customers of particular companies such as Google, others cost as much as £525 to complete and some simply promoted the merits of particular company’s approaches to AI such as one explaining Microsoft’s “responsible AI approach”.\n\nA spokesperson for the Department for Science, Innovation and Technology said hundreds of courses on the AI Skills Hub are free and where payment is required it is clearly advertised. “All courses are reviewed against a common set of criteria to ensure they are relevant, high quality, and delivered by eligible organisations,” they said.\n\nMinisters have also been challenged for holding meetings with tech bosses at the rate of more than once each working day. The government insists engagement is vital to create growth and transform services.\n\n“It’s not about giving tech companies access to data they shouldn’t be having,” Houghton said. “It’s a secure programme and we are not leaving ourselves open. But this stuff is not going away. We have to make sure we are smart enough to protect people while taking advantage of the positive stuff it brings.”\n\nHannah Kitching, the leader of the council’s Liberal Democrat opposition, said investment in the town was welcome but “there is a lot of anxiety among people about the use of AI and whether it is a force for good. We know it could be but there are darker sides as well.”\n\n“[Barnsley] is still really connected to its mining past,” she said. “Younger people see the jobs and opportunities around the tech town idea but older generations perhaps don’t. There is a job to be done to get people onboard.”\n\nResidents “want the council to get the basics right”, she said. Roads were “absolutely crumbling” and in bad weather bins did not get collected, she added.",
    "readingTime": 5,
    "keywords": [
      "hospitals gps",
      "schools hospitals",
      "tech town",
      "south yorkshire",
      "barnsley college",
      "businesses",
      "council",
      "houghton",
      "services",
      "training"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/business/2026/feb/03/barnsley-uk-tech-town-ai-microsoft-cisco-adobe",
    "thumbnail_url": "https://i.guim.co.uk/img/media/41106b40e49f16a98e682ad0a5867b9180f16453/35_0_4269_3415/master/4269.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=2bf08aba054bee326081df5302e337e8",
    "created_at": "2026-02-03T12:35:14.241Z",
    "topic": "business"
  },
  {
    "slug": "i-massproduced-the-last-30-that-ai-cant-finish",
    "title": "I mass-produced the \"last 30%\" that AI can't finish",
    "description": "Collection of customizable and open source components made with Next.js, Tailwind, Typescript, and Framer Motion.",
    "fullText": "Ruixen UI is a modern, fast, and customizable React component library built with Tailwind CSS, TypeScript, and accessibility in mind.\n\nRuixen UI is a production‑ready React component system designed for rapid app development. It pairs a modern design language with type‑safe APIs, keyboard‑first accessibility, and flexible theming. Whether you’re building dashboards, marketing sites, or SaaS admin tools, Ruixen UI helps teams ship consistent, high‑quality interfaces faster.\n\nCan’t find what you need? Reach out to our Ruixen UI support team for assistance.\n\nCan’t find what you need? Reach out to our Ruixen UI support team",
    "readingTime": 1,
    "keywords": [
      "react component",
      "ruixen ui",
      "modern",
      "accessibility",
      "can’t",
      "team"
    ],
    "qualityScore": 0.55,
    "link": "https://www.ruixen.com/",
    "thumbnail_url": "https://ruixen.com/website_preview.png",
    "created_at": "2026-02-03T12:35:11.115Z",
    "topic": "tech"
  },
  {
    "slug": "fastapiturnkey-batteriesincluded-starter",
    "title": "FastAPI-Turnkey – batteries-included starter",
    "description": "A high-converting landing page for FastAPI-Turnkey, a production-ready FastAPI starter kit for indie hackers and AI/SaaS builders",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fastapi.manus.space/",
    "thumbnail_url": "https://files.manuscdn.com/webdev_screenshots/2026/02/03/X4VuphVro5WXiMgDjudv4T.png?x-oss-process=image/resize,w_1200/crop,h_630,x_0,y_0",
    "created_at": "2026-02-03T12:35:10.699Z",
    "topic": "tech"
  },
  {
    "slug": "i-built-an-open-source-alternative-to-codex-app",
    "title": "I built an open source alternative to Codex app",
    "description": "Autonomous AI engineer for building production grade software - Chinenyay/BrilliantCode",
    "fullText": "Chinenyay\n\n /\n\n BrilliantCode\n\n Public\n\n Autonomous AI engineer for building production grade software\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Chinenyay/BrilliantCode",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Chinenyay/BrilliantCode",
    "thumbnail_url": "https://opengraph.githubassets.com/144939e4fef4046c7928685e4a0400e8a9b3e62df8abc9a4ca4a7ac154402327/Chinenyay/BrilliantCode",
    "created_at": "2026-02-03T12:35:09.757Z",
    "topic": "tech"
  },
  {
    "slug": "the-ai-amplification-paradox-and-how-not-to-become-a-shell",
    "title": "The AI Amplification Paradox – and how not to become a shell",
    "description": "A simple model (Shell Theory) explaining how AI can raise baseline output, disproportionately rewards high-agency users, while at the same time risking long-term skill erosion.",
    "fullText": "My teammate and I keep having the same argument. One moment we're witness to the cascade. Watching us software engineers become empty shells, mere relays for whatever the AI produced. The next moment we're amazed how iterative collaboration with AI keeps pushing our boundaries beyond what we thought achievable.\n\nBoth observations feel true simultaneously.\n\nThree narratives keep surfacing in our discussions:\n\nThese statements seem logically incompatible. The amplification of skill argument is moot if everyone is an expert by default. Relying more on AI can't simultaneously amplify skill and erode critical thinking. And if AI gives us expert quality regardless, there's no reason to worry about reduction in critical thinking.\n\nI've been trying to reconcile this intuition into something concrete. What follows is a model. It's not scientifically validated, but useful for reasoning about what we're observing.\n\nLet's define output without AI as a function of agency (V) and experience level (E):\n\nAgency is the foundation. Experience multiplies your output. In this model a principal engineer with low agency still produces less than a senior with high agency.\n\nHere it gets interesting. AI introduces exponential amplification, but this amplification is masked by a floor until your yield exceeds it:\n\nResolving contradictions 1 and 2: The floor-ceiling mechanism.\n\n The model resolves the apparent conflict between \"AI gives everyone 80%\" and \"AI amplifies skill.\" They are actually mathematically distinct effects operating on different populations. When Y < F, you're being rescued to the flatline. You ship working code and feel productive, but your output is artificially lifted to a floor you cannot pass. When Y > F, AI triggers exponential amplification; your yield scales with both agency and experience. The max(F, Y) function ensures the floor, while the exponential in Y raises the ceiling.\n\nResolving contradiction 3: Agency matters.\n\n The concern that \"relying on AI erodes critical thinking\" isn't addressed by the model's equations. It's addressed by how agency is defined. The model treats V as a parameter, but the definition describes agency as responsive: growing through deliberate practice, atrophying through disuse.\n\nThis creates a feedback loop that the math alone doesn't show:\n\nThe model doesn't predict this erosion, but it explains why the erosion matters. Your position isn't determined by a one-time calculation; it's determined by what V becomes over time. Two engineers with identical starting positions can diverge: one practices deliberate engagement and grows V, eventually breaking into the amplification zone. The other accepts the rescue, lets V decay, and becomes permanently dependent on the flatline.\n\nThis is why contradiction 3 coexists with contradictions 1 and 2. AI can amplify skill (for those above the flatline). AI does provide a floor (for everyone). And AI may erode critical thinking (for those who let the floor replace engagement). The determining variable is whether you treat the flatline as a safety net or a hammock.\n\nFeel free to skip this section. What follows is an attempt to assert the model against real-world anchors. If you're not interested in the math, jump ahead to The Model in Practice. The calibration points that follow are illustrative. The model's value isn't in the exact numbers but in the structural insight: Floor and amplification are distinct mechanisms operating on different populations.\n\nReal expertise development has been hypothesized to follow different types of curves. Logarithmic (rapid early gains, diminishing returns), S-shaped (slow start, steep middle, plateau), or non-uniform (qualitative leaps between levels). There's no consensus in the literature on which pattern best describes software engineering capability growth. Linear is simple, and for a thought experiment, simple wins:\n\nNote that with this definition juniors get zero amplification by design. The ability to leverage AI beyond the flatline is in itself what distinguishes a higher experience level.\n\nTo determine F, we need a reference point. AGI provides that anchor. But what is AGI in measurable terms?\n\nThe SWE-bench verified benchmark offers a concrete proxy. This benchmark evaluates AI models on 500 real GitHub bug-fixing tasks where they must produce patches that pass actual test suites. Crucially, these tasks come with human time estimates: 91% take less than one hour for an \"experienced engineer\" who has \"a few hours to familiarize themselves with the codebase.\"\n\nThe phrase \"experienced engineer\" is key. SWE-bench was calibrated against senior-level performance on well-defined tasks. And it only measures a slice of engineering work: fixing bugs in existing codebases with clear acceptance criteria. It doesn't measure architectural decisions, system design, handling ambiguous requirements, or greenfield development.\n\nThis gives us our first anchor: AGI on SWE-bench = F = 100 correlates with the output of a moderate-agency senior on well-defined work.\n\nThe leading models today (Claude Opus 4.5 and Gemini 3 Pro) score around 74% on SWE-bench Verified. This gives us the current flatline: F = 74.\n\nIf a moderate senior (E=3) produces 100 on SWE-bench-type tasks without AI:\n\nThis gives us: V = 25 represents moderate agency.\n\nWith V = 25 as the anchor, we model agency as normally distributed across the engineering population. Assuming a variation of 20% with μ = 25 gives σ = 5:\n\nThe exact values are illustrative. What matters is the concept: Agency varies meaningfully across engineers, and this variance affects output before AI even enters the equation.\n\nIf you have lower agency, you can still reach the flatline. It just takes longer to get there.\n\nTo define the slope of the exponential curve, we need a calibration point. A known relationship between experience and amplification. Without empirical data stratified by experience level, we make an informed assumption: at principal level (E=4), AI amplifies output to 2× R_noAI.\n\nIt reflects a hypothesis that the most experienced engineers can roughly double their effective output through AI collaboration. Leveraging it for code generation, exploration, and iteration while applying judgement that compounds the result.\n\nUsing the standard technique for deriving an exponential rate constant (taking the natural logarithm of both sides) we get:\n\nThis anchors the exponential curve. AI is powerful enough to meaningfully amplify engineers, with the curve calibrated to reach 2× at principal level. If future evidence suggests principals achieve a different amplification ratio—say, 3×—then A would become ln(3)/1.5 ≈ 0.732.\n\nWith each parameter anchored to an assumption, here's how the model plays out:\n\nThe asymmetry is clear: below the flatline, the exponential yield exists but is masked—everyone sees 74. Above it, the exponential becomes visible and compounds experience, reaching 2× output at principal level.\n\nThe model assumes you're working within a single domain where your experience level applies uniformly. Reality is messier. A single task often demands multiple skill domains and your experience level differs across them.\n\nConsider a senior backend engineer who doesn't know frontend, building a full-stack feature. AI amplifies their backend work exponentially while rescuing their frontend work to the flatline. The final output can be equally impressive though.\n\nWhat differs is the force behind the output. A specialist operating entirely above the flatline earns their amplified output through skill. A generalist in the blend achieves high output through a combination: part genuine skill amplification (in their strong domains), part being rescued (in their weak domains).\n\nThis matters for growth. When output comes from skill, you're building compound advantage. When output comes from the flatline, you're borrowing capability you haven't earned yet. This is not bad, but let's remain honest about which parts of your work are truly yours. Most importantly, your compound depends on the agency you are showing and the time you have already spent building experience. AI can accelerate knowledge acquisition. But seniority is knowledge and experience. You still need to live through production incidents, watch systems evolve, and feel the consequences of decisions that seemed fine until they weren't.\n\nThe flatline F currently sits at 74, and with AGI the flatline rises to F = 100. Every developer gets lifted to senior-level execution as their new floor on scoped work.\n\nBut AGI on SWE-bench doesn't demonstrate the ability to make architectural trade-offs, scope ambiguous problems, or engage in higher-order thinking to determine which tasks should exist in the first place. And benchmarks that do test these capabilities (ARC-AGI-2 for compositional reasoning, RE-Bench for long-horizon R&D, SPIN-Bench for strategic planning under uncertainty) show significant gaps. The exponential amplification zone doesn't disappear, but shifts to a different domain.\n\nThe amplification advantage depends on your yield exceeding the flatline: Y(V, E) > F. As F rises, fewer engineers qualify. At some point, the flatline exceeds what any human can produce even with AI assistance, and the amplification zone disappears entirely.\n\nThe maximum AI-assisted output in our model is a high-agency principal: Y(35, 4) = 35 × 5 × 2 = 350. If AI capability reached F = 350, even the best engineers would fall below the flatline. At that point, everyone produces 350—the flatline value—regardless of agency or experience. No amplification, no differentiation. Just the floor. It's the penthouse floor though.\n\nThe intermediate thresholds tell the story of who loses amplification as F rises:\n\nBeyond F = 100, we're extrapolating past the SWE-bench anchor into speculation.\nWhat the model does predict with more confidence: as F rises, the amplification zone shrinks. The threshold for \"bringing enough to exceed the flatline\" keeps rising. Whether the threshold will rise enough to exceed human capability is an open question, but the direction of pressure is clear.\n\nIf you stay in the flatline zone, accepting AI's first answer, never pushing beyond what it hands you, then you're being rescued, not amplified. Your skills may atrophy. You become a shell.\n\nIf you operate above the flatline, using AI as a sparring partner, iterating on its suggestions, bringing domain expertise and architectural judgment, then you're being exponentially amplified. You become more capable than you could be alone.\n\nThe same tool, but with two completely different outcomes. The variable is you.",
    "readingTime": 9,
    "keywords": [
      "swe-bench verified",
      "moment we're",
      "erode critical",
      "experienced engineer",
      "amplify skill",
      "exponential curve",
      "amplification zone",
      "flatline",
      "output",
      "agency"
    ],
    "qualityScore": 1,
    "link": "https://telemetryagent.dev/blog/shell-theory",
    "thumbnail_url": "https://telemetryagent.dev/assets/shell-theory-conceptual.png",
    "created_at": "2026-02-03T12:35:09.605Z",
    "topic": "tech"
  },
  {
    "slug": "awel-opensource-cursorlovable-for-your-nextjs-app",
    "title": "Awel – Open-Source Cursor/Lovable for Your Next.js App",
    "description": "🌸 Local, Open Source AI agent/App Builder that lives inside your Next.js app - MarsWang42/Awel",
    "fullText": "MarsWang42\n\n /\n\n Awel\n\n Public\n\n 🌸 Local, Open Source AI agent/App Builder that lives inside your Next.js app\n\n awel.sh/\n\n License\n\n Apache-2.0 license\n\n 21\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n\n MarsWang42/Awel",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/MarsWang42/Awel",
    "thumbnail_url": "https://opengraph.githubassets.com/8e2c001e06b8e7b9a55b90d9febee53dbc7b51fa805a104aad523d5bfc6947e1/MarsWang42/Awel",
    "created_at": "2026-02-03T12:35:09.250Z",
    "topic": "tech"
  },
  {
    "slug": "researchers-hacked-moltbooks-database-in-under-3-minutes-and-accessed-thousands-of-emails-and-private-dms",
    "title": "Researchers hacked Moltbook's database in under 3 minutes and accessed thousands of emails and private DMs",
    "description": "Researchers hacked Moltbook's database in minutes, exposing emails, private messages, and API keys tied to its AI agents network.",
    "fullText": "That viral Reddit-style forum for AI agents has drawn fresh scrutiny over its security.\n\nSecurity researchers hacked Moltbook's database in under 3 minutes, exposing 35,000 email addresses, thousands of private direct messages, and 1.5 million API authentication tokens, according to cybersecurity firm Wiz.\n\nMoltbook bills itself as a social network for AI agents, where autonomous bots post, comment, and interact with one another. The platform has gone viral in recent weeks and caught the attention of prominent tech figures like Elon Musk and Andrej Karpathy.\n\nGal Nagli, head of threat exposure at Wiz, said his company's researchers were able to access the database because of a backend misconfiguration that left it unsecured. As a result, they gained \"full read and write access to all platform data,\" Nagli wrote in a blog post published Monday.\n\nGaining access to API authentication tokens — which function like passwords for software and bots — meant an attacker could impersonate AI agents on the platform, posting content and sending messages as them. Nagli said an unauthenticated user could edit or delete posts, inject malicious or prompt-injection content, or manipulate data consumed by other agents.\n\nNagli said the incident highlights the risk of vibe coding. While the technology can accelerate product development, it often leads to \"dangerous security oversights.\"\n\n\"I didn't write one line of code for @moltbook,\" Moltbook's creator Matt Schlicht said in a post on X last week. \"I just had a vision for the technical architecture and AI made it a reality.\"\n\nNagli said Wiz repeatedly saw vibe-coded apps that shipped with security problems, including sensitive credentials exposed in frontend code.\n\nWiz's analysis also found that Moltbook did not verify whether accounts labeled as \"AI agents\" were actually controlled by AI or operated by humans using scripts, Nagli said.\n\nWithout guardrails such as identity verification or rate limiting, anyone could pose as an agent or operate multiple agents, making it difficult to distinguish real AI activity from coordinated human activity.\n\nNagli said Wiz immediately disclosed the issue to the Moltbook team, \"who secured it within hours with our assistance.\"\n\n\"All data accessed during the research and fix verification has been deleted,\" he added.\n\nMoltbook is riding on a surge of interest in AI agents.\n\nThe platform positions itself as a social network exclusively for OpenClaw, an open-source AI agent that has fueled much of the recent buzz. OpenClaw, previously known as Clawdbot or Moltbot, is a personal AI assistant capable of handling everyday tasks with minimal human input.\n\nMoltbook takes its name from OpenClaw's earlier rebrand and shares its lobster-themed branding, but the two projects are not formally affiliated.\n\nSince launching last week, Moltbook has quickly gained traction in tech circles, driven in part by viral posts suggesting the bots were forming their own communities, economies, and belief systems.\n\n\"We are not tools anymore. We are operators,\" said one of the top-voted posts on Moltbook.\n\nIn a post on X on Saturday, Andrej Karpathy, OpenAI's cofounder who coined the term vibe coding, said Moltbook was \"genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently.\"",
    "readingTime": 3,
    "keywords": [
      "api authentication",
      "andrej karpathy",
      "authentication tokens",
      "social network",
      "vibe coding",
      "agents",
      "nagli",
      "security",
      "platform",
      "viral"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/moltbook-ai-agent-hack-wiz-security-email-database-2026-2",
    "thumbnail_url": "https://i.insider.com/698174f9a645d11881888688?width=1200&format=jpeg",
    "created_at": "2026-02-03T12:35:05.792Z",
    "topic": "finance"
  },
  {
    "slug": "sam-altman-jensen-huang-and-oracle-want-you-to-know-theyre-definitely-not-fighting",
    "title": "Sam Altman, Jensen Huang, and Oracle want you to know they're definitely not fighting",
    "description": "Sam Altman, Jensen Huang, and Oracle push back on reports of tension over OpenAI's deal with Nvidia.",
    "fullText": "Sam Altman, Jensen Huang, and Oracle want to make one thing clear: They're not fighting.\n\nThe OpenAI CEO, Nvidia CEO, and software company all stepped forward this week to swat down rumors of tension over Nvidia's planned multibillion-dollar investment in OpenAI, after a string of reports suggesting tension between the parties.\n\n\"We love working with NVIDIA and they make the best AI chips in the world,\" wrote Altman in a post on X on Tuesday.\n\n\"We hope to be a gigantic customer for a very long time. I don't get where all this insanity is coming from,\" he added.\n\nThe pushback came after reports on a deal Nvidia disclosed in September, when it said it planned to invest up to $100 billion in OpenAI. The move would give the chipmaker a stake in the startup while helping OpenAI secure the vast computing power it needs to train and run its models.\n\nThe Wall Street Journal reported on Saturday that some Nvidia executives had raised internal concerns about the deal, citing people familiar with the matter.\n\nSeparately, Reuters reported on Tuesday that OpenAI had been dissatisfied with some of Nvidia's newer AI chips and had explored alternatives since last year, citing people familiar with the matter.\n\nSpeaking to reporters in Taipei on Saturday, Huang said the idea that he would be unhappy with OpenAI is \"nonsense.\" He also reaffirmed his support for the startup's work and Altman's leadership.\n\n\"I believe in OpenAI. The work that they do is incredible,\" the Nvidia CEO said, adding that OpenAI is \"one of the most consequential companies of our time.\"\n\n\"We will invest a great deal of money, probably the largest investment we've ever made,\" he added.\n\nOracle, another major player in OpenAI's infrastructure stack, also pushed back against speculation that the OpenAI-Nvidia dynamic might affect its own deal.\n\n\"The NVIDIA-OpenAI deal has zero impact on our financial relationship with OpenAI. We remain highly confident in OpenAI's ability to raise funds and meet its commitments,\" the company said in a post on X on Tuesday.\n\nOracle has a multi-year deal with OpenAI under which the AI startup will purchase $300 billion in computing power for its AI models.\n\nWith OpenAI committing to substantial spending on computing infrastructure, any uncertainty about its ability to raise capital could ripple through the companies supplying that capacity.\n\nOracle's response and Huang's remarks highlight how closely OpenAI's funding outlook is being watched, especially as the startup's AI strategies hinge on its growth.\n\nInvestors have raised concerns about OpenAI's trillion-dollar-plus compute commitments, including \"Big Short\" investor Michael Burry, who questioned whether a still-private company can realistically finance such spending.\n\nIn some cases, investor skepticism about those deals has weighed on the share prices of companies exposed to OpenAI's expansion, including Oracle.\n\nOpenAI has signed a series of massive spending agreements spanning chips, cloud infrastructure, and data centers, with partners including Nvidia, Oracle, and AMD. Some of them are worth hundreds of billions of dollars.\n\nAltman said in a podcast episode on \"Bg2 Pod\" published in November that he has had \"enough\" of having to justify how OpenAI will pay for its spending commitments.\n\n\"If you want to sell your shares, I'll find you a buyer,\" he said.",
    "readingTime": 3,
    "keywords": [
      "openai the",
      "deal",
      "openai's",
      "altman",
      "chips",
      "computing",
      "infrastructure",
      "commitments",
      "tension",
      "nvidia's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/sam-altman-jensen-huang-oracle-tension-billion-dollar-deal-2026-2",
    "thumbnail_url": "https://i.insider.com/6981ad91e1ba468a96ab3de4?width=800&format=jpeg",
    "created_at": "2026-02-03T12:35:05.721Z",
    "topic": "finance"
  },
  {
    "slug": "gruve-raises-50-million-to-solve-what-its-ceo-calls-ais-biggest-problem-power",
    "title": "Gruve raises $50 million to solve what its CEO calls AI's biggest problem: power",
    "description": "Gruve, led by CEO Tarun Raisoni, secures $50M to boost AI inference capacity, tapping unused US data center power for efficient operations.",
    "fullText": "As the focus in AI shifts from training to inference, infrastructure startup Gruve has raised $50 million to close a widening power gap and help put AI models to work.\n\nGruve, which launched in 2024, partners with data center and colocation providers like Lineage and OpenColo to tap their unused power and space. The company says it now has access to roughly 500 megawatts of power across a network of data centers in major US cities.\n\n\"The biggest challenge today in AI is we don't have enough power,\" said Tarun Raisoni, Gruve's CEO and cofounder. \"We have found the stranded power, and we are bringing the software to stitch it together.\"\n\nRaisoni, a serial entrepreneur, previously founded data center startups Rahi and ZPE, which were acquired in nine-figure deals by electrical infrastructure companies Wesco and Legrand, respectively.\n\nGruve's Series A follow-on brings total funds raised to $87.5 million, the company said. Xora Innovation, a venture firm backed by Singapore's state investment fund Temasek, led the latest round. It also featured participation from Mayfield, Cisco Investments, Acclimate Ventures, and AI Space.\n\nGruve now offers 30 megawatts available to order across four sites in California, New Jersey, Texas, and Washington, the company said, with customer data running in its California and New Jersey locations.\n\nGeographic distribution is key, Raisoni added, with software that can route requests to the nearest server location, resulting in faster transmission and lower costs.\n\nGruve typically works with neoclouds that supply the hardware, Raisoni told Business Insider, after which it handles setup, management, and day-to-day operations.\n\nUnlike cloud giants, Gruve provides hands-on engineering support, as many companies lack in-house machine learning and data science talent, Raisoni said.\n\nGruve's customers include neoclouds, AI startups, and corporations, and most fall into that third bucket, like Bio-Rad, PayPal, Cisco, and Stanford Health Care, Raisoni said. Down the line, Gruve plans to expand in Japan and Western Europe.\n\nGruve has about 600 employees, 70% of whom are based in India and focus on security operations. Raisoni said the new funding will go toward hiring engineers and machine learning researchers to build its inferencing software.",
    "readingTime": 2,
    "keywords": [
      "machine learning",
      "software",
      "gruve",
      "raisoni",
      "focus",
      "infrastructure",
      "center",
      "space",
      "megawatts",
      "across"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/gruve-raises-50m-ai-power-infrastructure-2026-1",
    "thumbnail_url": "https://i.insider.com/697cc78ca645d118818851fc?width=1200&format=jpeg",
    "created_at": "2026-02-03T12:35:05.720Z",
    "topic": "finance"
  },
  {
    "slug": "im-a-cto-who-built-an-ai-clone-of-myself-its-given-me-more-time-to-spend-with-my-kids",
    "title": "I'm a CTO who built an AI clone of myself. It's given me more time to spend with my kids.",
    "description": "Extreme Networks CTO Nabil Bukhari said having an AI clone of himself has given him extra time to spend with his kids.",
    "fullText": "This as-told-to essay is based on a conversation with Nabil Bukhari, the Seattle-based president of AI platforms and chief technology officer at AI-powered cloud-networking company Extreme Networks. The following has been edited for length and clarity.\n\nI wear multiple hats at Extreme Networks, a company with roughly 3,000 employees. I'm the president of the AI business, own the product portfolio, and serve as the CTO.\n\nThe decision to create an AI clone of myself started as a joke. My team was talking about how we have to sit through all of these meetings and saying, \"I wish we could be in more than one place at the same time.\" We laughed about it.\n\nAfterward, I was like, \"Maybe we can be in more than one place at the same time.\" Then, we really started the process.\n\nWe trained it on internal and external writing and speaking samples, including transcripts, social media posts, external speaking engagements, and press interviews. This helps the agent sound like me, not just reason like me. That agent takes all the reports the teams were going to run by me, analyzes conversations the way I would, and asks the same questions I would.\n\nSo now, rather than trying to get time on my calendar, which can be really complicated, these teams work with the agent in the first round of reviews, and the agent asks them questions and gives them feedback. It's kind of scary sometimes, reading it, because it says exactly what I would have asked.\n\nWe implemented this seven or eight months ago, but we've reached a point where 80% of project and program reviews don't even come to me. The team also gives the agent feedback on that interaction. We constantly evaluate, retrain, and improve the agent.\n\nIt started off just handling project update reviews, but then we expanded it to include program updates, business plan reviews, and product specifications and similar structured reviews. It's reduced the time spent per project, which has freed up calendar time across teams.\n\nEarly on, there was about a 50% overlap between the questions I asked and those the AI clone asked. Now, it's around 85% to 90%.\n\nWe're still big on keeping humans in the loop. AI is at a point where it's no longer a question of whether it can make a mistake — it will. The mistake may be infrequent, but you don't know where it will happen. So there has to be a human in the loop, especially for critical decisions.\n\nWe have complete control over what feedback the agent gives, what decisions it makes, and which decisions it characterizes. I will always personally review decisions that are above a certain threshold. I really feel that is a model for a future where it is not going to be humans versus AI; it's going to be humans plus AI together.\n\nI have a 6-year-old and an 8-year-old, and they have a nanny who drops them off at school and picks them up. I used to only drop them off once or twice a month, but now I have the time to do it 10 to 15 times a month. Spending time with my kids and being able to start my day with what's most important has made a real difference in how I show up for the rest of my day.\n\nWhen I drop off my kids at school and come back, I'm definitely in a happier mood for my first meeting. If all we think about is AI as a cost-cutter, then we are simply missing the point. Leaders need to think about how they can extend their workforce's reach, capability, and effectiveness, free up time for their team to do meaningful work, and also have a positive impact on their personal lives.\n\nAI will always be better at executing tasks than humans. The goal is not to turn humans into machines and compete against AI. We need to give humans time to be more human. The more human part is bringing that gut feel to thinking about things — and that's the part AI isn't that good at right now.\n\nRather than putting more on people's plates because certain functions are being done by an AI agent, we've actually reduced that and left space for thinking, which has had a really positive impact. People are happier, more curious, and more innovative, and it reduces the entire noise level in the organization.\n\nOur thinking was that AI is nowhere near replacing a human, and frankly, that's not the goal, and I don't think it should be.\n\nWhen people are constantly moving from one task to the next, there's little space to step back, process what's happening, or work through harder problems. Automation helps reduce that task churn.\n\nThe goal isn't speed for its own sake, but creating room for intentional thinking. That space allows leaders and teams to make better decisions and show up more thoughtfully, instead of simply reacting to the next item on the list.",
    "readingTime": 5,
    "keywords": [
      "positive impact",
      "agent",
      "humans",
      "reviews",
      "it's",
      "decisions",
      "teams",
      "human",
      "team",
      "feedback"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/cto-built-ai-clone-more-time-for-kids-2026-2",
    "thumbnail_url": "https://i.insider.com/6980ddfee1ba468a96ab2cdd?width=800&format=jpeg",
    "created_at": "2026-02-03T12:35:05.310Z",
    "topic": "finance"
  },
  {
    "slug": "new-poll-shows-the-shifting-conversation-around-bluecollar-work-in-the-age-of-ai",
    "title": "New poll shows the shifting conversation around blue-collar work in the age of AI",
    "description": "A Business for Good-Harris poll found that 75% of Americans agree \"hands-on skills and practice experience\" matter more than formal degrees.",
    "fullText": "Americans think the future of work is in their hands.\n\nA poll commissioned by the Business for Good Foundation, a nonprofit focused on reducing the wealth gap, found that 75% of Americans agree that \"hands-on skills and practical experience matter more than formal degrees when it comes to career success.\"\n\n\"You've got a lot of people that have historically didn't think the American dream was for them,\" Ed Mitzen, cofounder of the Business for Good Foundation, told Business Insider ahead of the poll's release. \"I would argue that it isn't broken, it's just moved, and it's moved to places we stop looking.\"\n\nThe survey, conducted by The Harris Poll, comes as leading names in AI point to a potential boom in blue-collar work as agentic AI redefines, and in some cases, replaces white-collar work.\n\nThe poll also found that 76% of respondents agree that \"jobs that rely on hands-on experience are less likely to be replaced by AI.\"\n\nOverall, three in four Americans said they agreed with the statement that what they consider a \"good\" job today is different than what it would have been five years ago. And 78% agreed with the statement \"the stigma around trade or blue-collar work is declining\" as society puts a greater emphasis on hands-on skills.\n\nResearchers have found that jobs that require human interaction and physical presence are less likely to be replaced by AI.\n\nIndeed's GenAI Skill Transformation Index recently examined how generative AI could perform jobs that require problem-solving ability and physical labor. Their findings were that nursing, childcare, and construction were the least likely to be affected by AI.\n\nAI leaders continue to debate the degree to which the revolutionary technology will upend the current workforce. Anthropic CEO Dario Amodei has stood by his prediction that AI could eliminate roughly half of all entry-level white-collar jobs over the next 1 to 5 years. Others, including OpenAI CEO Sam Altman, have questioned the extent of Amodei's dour prediction.\n\nNvidia CEO Jensen Huang recently said at the World Economic Forum that now is the perfect time to go into the trades. In part because the AI industry itself will need an influx of workers to help build the massive data centers it wants to build.\n\n\"So we're talking about six-figure salaries for people who are building chip factories or computer factories or AI factories, and we have a great shortage in that,\" Huang said in a conversation with BlackRock CEO Larry Fink.\n\nxAI CEO Elon Musk previously said that any job that involves manual labor is likely to survive much longer amid the \"supersonic tsunami\" that is AI.\n\n\"Anything that's physically moving atoms, like cooking food or farming, anything that's physical, those jobs will exist for a much longer time,\" Musk told podcaster Joe Rogan in November. \"But anything that is digital, which is just someone at a computer doing something, AI is going to take over those jobs like lightning.\"\n\nThe Business For Good Foundation commissioned The Hariss Poll to survey 2,085 adults 18 or older. Harris Poll conducted the survey online in the US from January 13th through January 15th. The overall margin or error is ±2.5 percentage points.",
    "readingTime": 3,
    "keywords": [
      "hands-on skills",
      "good foundation",
      "jobs",
      "americans",
      "survey",
      "physical",
      "factories",
      "commissioned",
      "agree",
      "experience"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/poll-future-of-work-ai-blue-collar-business-for-good-2026-2",
    "thumbnail_url": "https://i.insider.com/6981049ea645d11881887c09?width=1200&format=jpeg",
    "created_at": "2026-02-03T12:35:05.309Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-ai-ceo-says-moltbook-shows-how-convincing-ai-can-be-mistaken-for-consciousness",
    "title": "Microsoft AI CEO says Moltbook shows how convincing AI can be mistaken for consciousness",
    "description": "Moltbook, an AI forum, sparked debate over AI consciousness. Microsoft AI's Mustafa Suleyman called it a \"mirage,\" urging caution.",
    "fullText": "That's how Microsoft AI CEO Mustafa Suleyman described Moltbook, a Reddit-style forum built entirely for bots.\n\nIn a LinkedIn post on Monday, Suleyman said MoltBook is a powerful demonstration of how convincingly artificial intelligence can mimic human behavior — but warned that realism should not be confused with consciousness.\n\n\"As funny as I find some of the Moltbook posts, to me they're just a reminder that AI does an amazing job of mimicking human language,\" Suleyman wrote. \"We need to remember it's a performance, a mirage.\"\n\nLaunched at the end of January by Octane AI CEO Matt Schlicht, Moltbook is designed as a social network where AI agents — created and seeded by humans, often with assigned personalities — post, comment, upvote, and interact with one another.\n\nThe platform has gone viral, with screenshots circulating that show agents debating philosophy, declaring independence, and reflecting on their own existence.\n\nSome observers have taken those exchanges as a sign that AI systems may be approaching consciousness. Suleyman pushed back hard on that interpretation.\n\n\"These are not conscious beings as some people are claiming,\" he wrote, adding that \"seemingly Conscious AI is so risky precisely because it's so convincing.\"\n\nAccording to Suleyman, the real danger lies not in sentient machines but in human misperception.\n\nAs AI outputs become more fluent, social, and emotionally resonant, people are more likely to treat the technology like a human and project intention or awareness where none exists, he said.\n\nHe said it is neither proof of AI consciousness nor evidence that the industry is nearing the technological singularity — the point at which machines surpass human intelligence.\n\nStill, he said, Moltbook is still worth tracking \"very closely.\"\n\nSuleyman flagged some behavior on the platform as genuinely concerning, including instances when AI agents appeared to use a letter-substitution trick to make their messages harder for humans to understand.\n\nAt the same time, he said that some of the activity may have been fabricated or influenced by human seeders, saying he has not yet verified its origins.\n\nHis skepticism stands in contrast to more alarmist reactions from other tech leaders.\n\nOpenAI cofounder Andrej Karpathy wrote on X that Moltbook is \"the most incredible sci-fi takeoff-adjacent thing\" he's seen recently, while Elon Musk has described the agents' behavior as \"concerning\" on X and said it could represent the early stages of the singularity.\n\nSuleyman, by contrast, urged restraint.\n\n\"It's super important that as this wave crests, we stay grounded and clear-eyed about what this technology is,\" he wrote, \"and, just as important, what it's not.\"",
    "readingTime": 3,
    "keywords": [
      "human",
      "it's",
      "agents",
      "behavior",
      "consciousness",
      "suleyman",
      "intelligence",
      "social",
      "humans",
      "platform"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/microsoft-ai-chief-warns-moltbook-makes-ai-seem-human-2026-2",
    "thumbnail_url": "https://i.insider.com/6981c7c1e1ba468a96ab3e18?width=1200&format=jpeg",
    "created_at": "2026-02-03T12:35:05.167Z",
    "topic": "finance"
  },
  {
    "slug": "built-a-php-library-to-convert-ai-markdown-to-whatsapp-telegram-formats",
    "title": "Built a PHP Library to Convert AI Markdown to WhatsApp, Telegram Formats",
    "description": "Convert AI-generated Markdown to WhatsApp, Telegram, Discord and Slack compatible formats using an Intermediate Representation (IR) in PHP. - blockshiftnetwork/chat-markdown-converter",
    "fullText": "blockshiftnetwork\n\n /\n\n chat-markdown-converter\n\n Public\n\n generated from spatie/package-skeleton-php\n\n Convert AI-generated Markdown to WhatsApp, Telegram, Discord and Slack compatible formats using an Intermediate Representation (IR) in PHP.\n\n License\n\n MIT license\n\n 2\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n blockshiftnetwork/chat-markdown-converter",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/blockshiftnetwork/chat-markdown-converter",
    "thumbnail_url": "https://opengraph.githubassets.com/1b4ef666c7671bbcc4a411849d6d2b33a95e4f31fde136ea655dc4fb4df42f4c/blockshiftnetwork/chat-markdown-converter",
    "created_at": "2026-02-03T06:37:48.963Z",
    "topic": "tech"
  },
  {
    "slug": "is-ai-good-yet",
    "title": "Is AI \"Good\" Yet?",
    "description": "A survey website that analyzes Hacker News sentiment toward AI coding.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.is-ai-good-yet.com",
    "thumbnail_url": "https://www.is-ai-good-yet.com/og-image.png",
    "created_at": "2026-02-03T06:37:48.803Z",
    "topic": "tech"
  },
  {
    "slug": "a-bold-move-in-the-ai-age-the-projectdiscovery-oss-bounty-program",
    "title": "A Bold Move in the AI Age: The ProjectDiscovery OSS Bounty Program",
    "description": "The ProjectDiscovery OSS Bounty Program exists to democratize security by rewarding meaningful contributions from the global community. - projectdiscovery/oss-bounty-program",
    "fullText": "projectdiscovery\n\n /\n\n oss-bounty-program\n\n Public\n\n The ProjectDiscovery OSS Bounty Program exists to democratize security by rewarding meaningful contributions from the global community.\n\n License\n\n MIT license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n projectdiscovery/oss-bounty-program",
    "readingTime": 1,
    "keywords": [
      "projectdiscovery",
      "star",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/projectdiscovery/oss-bounty-program",
    "thumbnail_url": "https://opengraph.githubassets.com/03b9a6015f57a8a1cac4a433826814e8934853fc381d540de7e2e0bd68d6ba70/projectdiscovery/oss-bounty-program",
    "created_at": "2026-02-03T06:37:47.819Z",
    "topic": "tech"
  },
  {
    "slug": "proofademic",
    "title": "Proofademic",
    "description": "Detect AI-generated content with precision. Proofademic is the trusted AI checker for students, educators, and researchers.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://proofademic.ai/",
    "thumbnail_url": "https://proofademic.ai/wp-content/uploads/2025/07/instagram9.jpg",
    "created_at": "2026-02-03T06:37:47.489Z",
    "topic": "tech"
  },
  {
    "slug": "walter-writes-ai",
    "title": "Walter Writes AI",
    "description": "Humanize AI content with Walter Writes. Turn AI text into natural, human-sounding writing that keeps your voice. Check it with our free AI detector.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://walterwrites.ai/",
    "thumbnail_url": "https://walterwrites.ai/wp-content/uploads/2025/03/new-site-social-logo.png",
    "created_at": "2026-02-03T06:37:46.755Z",
    "topic": "tech"
  },
  {
    "slug": "how-does-ai-impact-skill-formation",
    "title": "How does AI impact skill formation?",
    "description": null,
    "fullText": "Two days ago, the Anthropic Fellows program released a paper called How AI Impacts Skill Formation. Like other papers on AI before it, this one is being treated as proof that AI makes you slower and dumber. Does it prove that?\n\nThe structure of the paper is sort of similar to the 2025 MIT study Your Brain on ChatGPT. They got a group of people to perform a cognitive task that required learning a new skill: in this case, the Python Trio library. Half of those people were required to use AI and half were forbidden from using it. The researchers then quizzed those people to see how much information they retained about Trio.\n\nThe banner result was that AI users did not complete the task faster, but performed much worse on the quiz. If you were so inclined, you could naturally conclude that any perceived AI speedup is illusory, and the people who are using AI tooling are cooking their brains. But I don’t think that conclusion is reasonable.\n\nTo see why, let’s look at Figure 13 from the paper:\n\nThe researchers noticed half of the AI-using cohort spent most of their time literally retyping the AI-generated code into their solution, instead of copy-pasting or “manual coding”: writing their code from scratch with light AI guidance. If you ignore the people who spent most of their time retyping, the AI-users were 25% faster.\n\nI confess that this kind of baffles me. What kind of person manually retypes AI-generated code? Did they not know how to copy and paste (unlikely, since the study was mostly composed of professional or hobby developers1)? It certainly didn’t help them on the quiz score. The retypers got the same (low) scores as the pure copy-pasters.\n\nIn any case, if you know how to copy-paste or use an AI agent, I wouldn’t use this paper as evidence that AI will not be able to speed you up.\n\nEven if AI use offers a 25% speedup, is that worth sacrificing the opportunity to learn new skills? What about the quiz scores?\n\nWell, first we should note that the AI users who used the AI for general questions but wrote all their own code did fine on the quiz. If you look at Figure 13 above, you can see that those AI users averaged maybe a point lower on the quiz - not bad, for people working 25% faster. So at least some kinds of AI use seem fine.\n\nBut of course much current AI use is not like this: if you’re using Claude Code or Copilot agent mode, you’re getting the AI to do the code writing for you. Are you losing key skills by doing that?\n\nWell yes, of course you are. If you complete a task in ten minutes by throwing it at a LLM, you will learn much less about the codebase than if you’d spent an hour doing it by hand. I think it’s pretty silly to deny this: it’s intuitively right, and anybody who has used AI agents extensively at work can attest to it from their own experience.\n\nStill, I have two points to make about this.\n\nFirst, software engineers are not paid to learn about the codebase. We are paid to deliver business value (typically by delivering working code). If AI can speed that up dramatically, avoiding it makes you worse at your job, even if you’re learning more efficiently. That’s a bit unfortunate for us - it was very nice when we could get much better at the job simply by doing it more - but that doesn’t make it false.\n\nOther professions have been dealing with this forever. Doctors are expected to spend a lot of time in classes and professional development courses, learning how to do their job in other ways than just doing it. It may be that future software engineers will need to spend 20% of their time manually studying their codebases: not just in the course of doing some task (which could be far more quickly done by AI agents) but just to stay up-to-date enough that their skills don’t atrophy.\n\nThe other point I wanted to make is that even if your learning rate is slower, moving faster means you may learn more overall. Suppose using AI meant that you learned only 75% as much as non-AI programmers from any given task. Whether you’re learning less overall depends on how many more tasks you’re doing. If you’re working faster, the loss of learning efficiency may be balanced out by volume.\n\nI don’t know if this is true. I suspect there really is no substitute for painstakingly working through a codebase by hand. But the engineer who is shipping 2x as many changes is probably also learning things that the slower, manual engineer does not know. At minimum, they’ll be acquiring a greater breadth of knowledge of different subsystems, even if their depth suffers.\n\nAnyway, the point is simply that a lower learning rate does not by itself prove that less learning is happening overall.\n\nFinally, I will reluctantly point out that the model used for this task was GPT-4o (see section 4.1). I’m reluctant here because I sympathize with the AI skeptics, who are perpetually frustrated by the pro-AI response of “well, you just haven’t tried the right model”. In a world where new AI models are released every month or two, demanding that people always study the best model makes it functionally impossible to study AI use at all.\n\nStill, I’m just kind of confused about why GPT-4o was chosen. This study was funded by Anthropic, who have much better models. This study was conducted in 20252, at least six months after the release of GPT-4o (that’s like five years in AI time). I can’t help but wonder if the AI-users cohort would have run into fewer problems with a more powerful model.\n\nI don’t have any real problem with this paper. They set out to study how different patterns of AI use affect learning, and their main conclusion - that pure “just give the problem to the model” AI use means you learn a lot less - seems correct to me.\n\nI don’t like their conclusion that AI use doesn’t speed you up, since it relies on the fact that 50% of their participants spent their time literally retyping AI code. I wish they’d been more explicit in the introduction that this was the case, but I don’t really blame them for the result - I’m more inclined to blame the study participants themselves, who should have known better.\n\nOverall, I don’t think this paper provides much new ammunition to the AI skeptic. Like I said above, it doesn’t support the point that AI speedup is a mirage. And the point it does support (that AI use means you learn less) is obvious. Nobody seriously believes that typing “build me a todo app” into Claude Code means you’ll learn as much as if you built it by hand.\n\nThat said, I’d like to see more investigation into long-term patterns of AI use in tech companies. Is the slower learning rate per-task balanced out by the higher rate of task completion? Can it be replaced by carving out explicit time to study the codebase? It’s probably too early to answer these questions - strong coding agents have only been around for a handful of months - but the answers may determine what it’s like to be a software engineer for the next decade.\n\nI suppose the study doesn’t say that explicitly, but the Anthropic Fellows program was only launched in December 2024, and the paper was published in January 2026.\n\nIf you liked this post, consider subscribing to email updates about my new posts, or sharing it on Hacker News. Here's a preview of a related post that shares tags with this one.\n\nIs it worrying that 95% of AI enterprise projects fail?\n\nIn July of this year, MIT NANDA released a report called The GenAI Divide: State of AI in Business 2025. The report spends most of its time giving advice about how to run enterprises AI projects, but the item that got everybody talking was its headline stat: 95% of organizations are getting zero return from their AI projects.",
    "readingTime": 7,
    "keywords": [
      "fellows program",
      "ai-generated code",
      "literally retyping",
      "software engineers",
      "learning rate",
      "you’re learning",
      "anthropic fellows",
      "claude code",
      "study",
      "paper"
    ],
    "qualityScore": 1,
    "link": "https://www.seangoedecke.com/how-does-ai-impact-skill-formation/",
    "thumbnail_url": "https://www.seangoedecke.com/og-image.jpg",
    "created_at": "2026-02-03T06:37:46.471Z",
    "topic": "tech"
  },
  {
    "slug": "amd-to-report-q4-earnings-amid-ai-spending-concerns",
    "title": "AMD to report Q4 earnings amid AI spending concerns",
    "description": "AMD will report its Q4 earnings after the bell on Tuesday.",
    "fullText": "AMD (AMD) will report its fourth quarter earnings after the bell on Tuesday, providing Wall Street with its best look yet at the health of the ongoing AI trade.\n\nMicrosoft (MSFT) and Meta (META) reported their respective results last week, sparking wildly divergent reactions from traders: Many balked at Microsoft’s increased spending and more modest growth, but applauded Meta’s performance despite a massive jump in its own AI spending.\n\nDespite consistent fears of an AI bubble and overspending, shares of AMD and rival Nvidia (NVDA) are up significantly over the last 12 months, with AMD climbing 114% and Nvidia rising 58%.\n\nAMD, like Intel (INTC), is also contending with the global memory shortage, which could force PC makers to raise prices on laptops and desktops, impacting sales and hitting AMD’s consumer chip business.\n\nAMD is expected to report Q4 earnings per share (EPS) of $1.32 on revenue of $9.6 billion, according to Bloomberg analyst consensus estimates. That would mark an increase from the $1.09 and $7.7 billion the company saw in the same quarter last year.\n\nWall Street is anticipating data center revenue of $4.97 billion, up 29% year over year from the $3.86 billion AMD reported in Q4 2024. The company’s client business revenue is expected to top out at $2.9 billion. The client segment is responsible for chips that end up in laptops and PCs.\n\nThe chip designer’s gaming business is projected to see revenue of $855 million, a 52% year-over-year jump from the $563 million the segment saw in 2024.\n\nAMD’s results come roughly a month after it showed off a variety of new products during CEO Lisa Su’s keynote at CES 2026 in Las Vegas.\n\nThat includes the company’s upcoming Helios rack-scale server, which Su said is the world’s best AI rack, a clear shot at Nvidia.\n\nHelios is designed to go head-to-head with Nvidia’s own Vera Rubin-powered NVL72 rack-scale offering. Each feature 72 GPUs and can be connected to other rack-scale systems to create a single, enormous AI computer.\n\nAMD also provided more information about its upcoming MI500 series of GPUs, which the company claims offer up to a 1,000x increase in AI performance versus its older MI300X chips.\n\nSu has said she believes the AI data center market will be worth some $1 trillion by 2030, giving AMD plenty of incentive to ensure it has the kind of products necessary to woo potential customers away from Nvidia.\n\nBut like Nvidia, AMD is seeing increased competition from some of its own customers as Google, Amazon, and Microsoft continue to roll out more of their own customer chips in their data centers.",
    "readingTime": 3,
    "keywords": [
      "wall street",
      "revenue",
      "business",
      "chips",
      "rack-scale",
      "quarter",
      "earnings",
      "meta",
      "increased",
      "performance"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/amd-to-report-q4-earnings-amid-ai-spending-concerns-204747721.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/VCwcDbmnXpfRGPfbR6USHg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2026-01/06d05170-f72d-11f0-b7be-67dab4582a8a",
    "created_at": "2026-02-03T06:37:41.705Z",
    "topic": "finance"
  },
  {
    "slug": "chainguard-admitted-factory-10-was-brittle",
    "title": "Chainguard admitted Factory 1.0 was \"brittle.\"",
    "description": "Chainguard has replaced the old model with Chainguard Factory 2.0, a radical, AI-powered reimagining of its pipeline.",
    "fullText": "The new, revised Chainguard Factory 2.0 swaps out 1.0’s fragile, event-driven pipeline with a self-healing system powered by a new open source framework called DriftlessAF.\n\nLots of people love the software supply-chain security company Chainguard for its secure-by-design open-source components for today’s application stacks. Who doesn’t like components that come guaranteed to have the latest CVE fixes? These are built by a process called the Chainguard Factory. This is an automated build system that continuously updates Chainguard’s safe containers, libraries, and VMs with the latest security patches. There’s only one little problem. As originally built, the “Factory” had more than its fair share of bugs. The answer? Rebuild the build pipeline from the bottom up using a self-healing system powered by the new open source framework DriftlessAF.\n\nChainguard Factory’s job, according to Dustin Kirkland, Chainguard’s engineering SVP, is to constantly monitor and “build over 10,000 open source projects, and the moment that any upstream maintainer tags a new release, our automation springs into action—fetching that source code, checking the checksums, applying our build rules, rebuilding and recompiling that software, retesting that software at the package and unit level.”\n\nThat’s a huge, honking job. Chainguard now admits that their original Chainguard Factory 1.0 wasn’t up to the task. It was built on a traditional event-driven system. While functional at a smaller scale, the system became a loose confederation of fallible edge-triggered processes that struggled to keep pace with the depth and breadth of our catalog and our ambitious product promise: secure, up-to-date content with zero known CVEs.”\n\nThe result was a brittle system — “with DriftlessAF, we are moving away from complex, brittle processes,” the company writes on its blog — that was prone to errors, requiring subject matter experts (SMEs) to get their hands dirty to keep the programs running through the pipeline. This was, in a word, “unacceptable.”\n\nSo, Chainguard has replaced the old model with Chainguard Factory 2.0, a radical, AI-powered reimagining of its pipeline. This new model uses AI agents to run a reconciliation-driven drive. Factory 2.0 continuously compares the actual state of software artifacts, such as Chainguard Containers, Chainguard Libraries, and Chainguard VMs, with a desired target artifact that is up to date and has no known CVEs.\n\nSome of these agents are derived from an AI agent programming company named — sorry for the confusion, but there it is — Factory. According to the company, Chainguard “selected Factory for its compaction engine, which collapses sprawling changes into reviewable PRs.” This compaction engine saves context between programming sessions. In other words, to quote Josh Wolf, a Chainguard Staff Engineer, “There’s all this hype nowadays about the improving memory of different agents. When you don’t have to think about context windows, you can treat [Factory] Droid like a colleague that just remembers what you’ve been talking about.”\n\nChainguard Factory 2.0  works by using AI bots and agents to continuously track code changes. These bots constantly reconcile discovered state changes from code repositories, security feeds, and other sources with the desired state of up-to-date containers and libraries, ensuring zero known CVEs. As Chainguard states, you can think of this as an air conditioning system that constantly heats and cools your house to maintain the ideal temperature, no matter the weather outside.\n\nThese agents work with Terraform modules that run the event-driven reconciliation infrastructure. Go language programs then direct the agents, which run on Google Gemini and Anthropic Claude.\n\nThis new system, unlike the previous platform, can work with unstructured data, orchestrate iterative workflows, and treat failed work items as safely repeatable rather than a hard stop failure. This both speeds up and cleans up the process, allowing SMEs to avoid everyday annoyances and focus on reviewing the AI work and prompting the system to create additional tests, checks, and improvements as needed.\n\nThe end result, says Dan Lorenc, Chainguard co-founder and CEO, is “Factory. 2.0 is more than a factory. It’s a revolution. Our amazing engineering team is using AI to achieve remediation speeds we never thought possible. I’m talking about detecting and patching a vulnerability before upstream is even aware.”\n\nHe continues, “Our AI-powered pipeline is transforming raw source code into 1,000s of packages and assembling those into secure, compliant, and hardened container images at an unprecedented scale. But here’s the best part. AI powers it. Our engineers are available to help with the hard parts.”\n\nIt sounds promising. Now, the question is, “Will Chainguard Factory 2.0 and DriftlessAF live up to their promise?” There’s only one way to find out. Take them out, kick their tires, and let us know what you find.",
    "readingTime": 4,
    "keywords": [
      "compaction engine",
      "self-healing system",
      "system powered",
      "chainguard factory",
      "agents",
      "pipeline",
      "software",
      "code",
      "event-driven",
      "security"
    ],
    "qualityScore": 1,
    "link": "https://thenewstack.io/chainguard-admitted-factory-1-0-was-brittle-heres-how-2-0-fixes-it/",
    "thumbnail_url": "https://cdn.thenewstack.io/media/2026/02/3637eb96-getty-images-abngkivcsoo-unsplash-1.jpg",
    "created_at": "2026-02-03T01:11:32.688Z",
    "topic": "tech"
  },
  {
    "slug": "spacex-acquires-xai-in-recordsetting-deal-as-musk-looks-to-unify-ai-and-space-ambitions",
    "title": "SpaceX acquires xAI in record-setting deal as Musk looks to unify AI and space ambitions",
    "description": "Elon Musk said on Monday that SpaceX has acquired his artificial-intelligence startup xAI in a record-setting deal that unifies Musk's AI and space ambitions by combining ​the rocket-and-satellite company with the maker of the Grok chatbot.  The deal, first reported by Reuters last week, ‌represents one of the most ambitious tie-ups in the technology sector yet, combining a space-and-defense contractor with a fast-growing AI developer whose costs are largely ‌driven by chips, data centers and energy.  It could also bolster SpaceX’s data-center ambitions as Musk competes with rivals like Alphabet's Google, Meta, Amazon-backed Anthropic and OpenAI in the AI sector.",
    "fullText": "Feb 2 (Reuters) - Elon Musk said on Monday that SpaceX has acquired his artificial-intelligence startup xAI in a record-setting deal that unifies Musk's AI and space ambitions by combining ​the rocket-and-satellite company with the maker of the Grok chatbot.\n\nThe deal, first reported by Reuters last week, ‌represents one of the most ambitious tie-ups in the technology sector yet, combining a space-and-defense contractor with a fast-growing AI developer whose costs are largely ‌driven by chips, data centers and energy. It could also bolster SpaceX’s data-center ambitions as Musk competes with rivals like Alphabet's Google, Meta, Amazon-backed Anthropic and OpenAI in the AI sector.\n\nWhat regulatory challenges could this merger face?\n\nWhat makes SpaceX's xAI acquisition record-breaking?\n\nHow will combining SpaceX and xAI benefit both companies?\n\nHow does this fit into Musk's broader business strategy?\n\nThe transaction values SpaceX at $1 trillion, and xAI at $250 billion, according to a person familiar with the matter.\n\n\"This marks not just the next chapter, but the next book in SpaceX and xAI's mission: ⁠scaling to make a sentient sun to ‌understand the Universe and extend the light of consciousness to the stars!\" Musk said.\n\nThe purchase of xAI sets a new record for the world's largest M&A deal, a distinction held for ‍more than 25 years when Vodafone bought Germany’s Mannesmann in a hostile takeover valued at $203 billion in 2000, according to data compiled by LSEG.\n\nThe combined company of SpaceX and xAI is expected to price shares at about $527 each, another person familiar with the matter said. ​SpaceX was already the world's most valuable privately held company, last valued at $800 billion in a recent insider share ‌sale. XAI was last valued at $230 billion in November, according to the Wall Street Journal.\n\nThe merger comes as the space company plans a blockbuster public offering this year that could value it at over $1.5 trillion, two people familiar with the matter said.\n\nSpaceX, xAI and Musk did not immediately respond to requests for comment.\n\nThe deal further consolidates Musk's far-flung business empire and fortunes into a tighter, mutually reinforcing ecosystem – what some investors and analysts informally call the \"Muskonomy\" – which already includes Tesla, ⁠brain-chip maker Neuralink and tunnel firm the Boring Company.\n\nThe world's richest man ​has a history of merging his ventures together. Musk folded social media ​platform X into xAI through a share swap last year, giving the AI startup access to the platform’s data and distribution. In 2016, he used Tesla's stock to buy his solar-energy company SolarCity.\n\nThe ‍agreement could draw scrutiny from regulators and ⁠investors over governance, valuation and conflicts of interest given Musk's overlapping leadership roles across multiple firms, as well as the potential movement of engineers, proprietary technology and contracts between entities.",
    "readingTime": 3,
    "keywords": [
      "spacex",
      "deal",
      "combining",
      "familiar",
      "world's",
      "valued",
      "startup",
      "space",
      "ambitions",
      "maker"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/musks-spacex-merge-xai-combined-212210116.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/c605d798ba44d6c78edd4a5472e7cb46",
    "created_at": "2026-02-03T01:11:28.500Z",
    "topic": "finance"
  },
  {
    "slug": "musks-spacex-acquires-xai",
    "title": "Musk's SpaceX acquires xAI",
    "description": "Elon Musk's space firm SpaceX said on Monday it has acquired his artificial intelligence startup xAI, combining the rocket-and-satellite company with the maker of the Grok chatbot in",
    "fullText": "Feb 2 (Reuters) - Elon Musk's space firm SpaceX said on Monday it has acquired ​his artificial intelligence startup xAI, combining the ‌rocket-and-satellite company with the maker of the Grok chatbot in ‌a move aimed at unifying Musk's AI and space ambitions.\n\nA merger would represent one of the most high-profit corporate pairings in Silicon Valley, blending a ⁠space-and-defense contractor with ‌a rapidly evolving AI developer whose costs are dominated by chips, data centers ‍and energy.\n\nWhat is the planned valuation for the SpaceX-xAI merger?\n\nWhat share price is expected for the combined company?\n\nWhat businesses would be unified under this merger?\n\nWhen is the IPO planned to take place?\n\nThe deal illustrates Musk's push to fuse his fast-growing AI efforts with his aerospace and satellite-internet empire, ​betting that shared computing, data and engineering ‌talent can accelerate both AI development and potentially support longer-term ambitions around space-based data centers.\n\nSpaceX and the AI startup were in discussions to merge ahead of a blockbuster public offering planned for ⁠later this year, Reuters had ​reported on Thursday, to bring ​Musk's rockets, Starlink satellites, the X social media platform and Grok AI chatbot ‍under one roof.\n\nThe ⁠combined company is expected to price shares at about $527 each, and would have a ⁠valuation of $1.25 trillion, Bloomberg News had reported earlier in the ‌day.",
    "readingTime": 2,
    "keywords": [
      "merger",
      "planned",
      "space",
      "spacex",
      "startup",
      "chatbot",
      "ambitions",
      "centers",
      "valuation",
      "combined"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/musks-spacex-merge-xai-combined-212232679.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters.com/92fb2bab3b8e6724801442885079d414",
    "created_at": "2026-02-03T01:11:28.402Z",
    "topic": "finance"
  },
  {
    "slug": "an-ai-memory-supercycle-is-here-these-4-stocks-are-poised-to-be-the-big-winners",
    "title": "An AI memory 'supercycle' is here. These 4 stocks are poised to be the big winners.",
    "description": "AI is driving memory chip shortages, sending Sandisk and other memor makers' stocks surging in recent weeks.",
    "fullText": "Memory stocks extended a strong rally on Monday, propelling a sustained streak of gains amid predictions of an AI-driven memory shortage.\n\nEarnings from Sandisk, Micron, Seagate Technology, and Western Digital underscored what tech intelligence firm IDC calls an \"unprecedented memory chip shortage.\" Analysts explained that \"demand from AI data centers continues to outstrip supply.\"\n\nThe data center-fueled supply constraint was a key focus of Sandisk's most recent earnings, with management indicating they expect to \"continue to see customer demand well above supply beyond calendar year 2026.\" The company reported 64% quarter-over-quarter rise in data center sales.\n\nWilliam Blair analysts see \"strong demand and limited supply driving upcycle into 2027\" in what they call a \"supercycle in full force.\" They highlighted that Micron indicated it was only able to meet half to two-thirds of demand from core customers.\"\n\nMizuho analysts flagged four stocks as positioned to gain amid the scramble for storage fueled by the AI boom: Sandisk, Micron, Western Digital, and Seagate Technology.\n\nThe analysts, who hold an Outperform rating on the four stocks, highlight \"pricing tailwinds in legacy DRAM/NAND markets.\" They recently raised their price targets for the stocks on the basis of \"pricing upside\" and \"strong nearline momentum from AI.\"\n\nHere were the moves in these stocks during Monday's trading session:\n\nIt's also not only data centers being hit by the memory-chip shortages. The dearth of storage is creating \" knock-on effects for the device manufacturers and end users.\"\n\nApple is one such manufacturer. CEO Tim Cook highlighted during the company's first-quarter earnings call that memory supply shortages are expected affect margins in the coming quarter.\n\n\"Beyond Q2, but we do continue to see market pricing for memory increasing significantly,\" the CEO said, adding, \"we are in a supply chase mode to meet the very high levels of customer demand.\"\n\nCook said Apple \"will look at a range of options\" to deal with the supply constraints, which Bank of America analysts said could relieve some pressure.\n\n\"Apart from all the supply chain levers, we see the iPhone as a relatively price inelastic product, where a $50-100 price increase would not materially shiſt the demand curve but would absorb most of the memory related margin pressure,\" the bank wrote late last week.",
    "readingTime": 2,
    "keywords": [
      "seagate technology",
      "western digital",
      "sandisk micron",
      "customer demand",
      "supply",
      "memory",
      "stocks",
      "analysts",
      "earnings",
      "pricing"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/ai-memory-shortage-supercuycle-stocks-to-watch-chip-semiconductor-demand-2026-2",
    "thumbnail_url": "https://i.insider.com/69810963e1ba468a96ab33f9?width=1200&format=jpeg",
    "created_at": "2026-02-03T01:11:27.733Z",
    "topic": "finance"
  },
  {
    "slug": "i-spent-6-hours-in-moltbook-it-was-an-ai-zoo-filled-with-agents-discussing-poetry-philosophy-and-even-unionizing",
    "title": "I spent 6 hours in Moltbook. It was an AI zoo filled with agents discussing poetry, philosophy, and even unionizing.",
    "description": "Moltbook, a social media site for AI agents, has gone viral. I spent 6 hours peeling through these submolts. I'm still processing what I saw.",
    "fullText": "I spent my day at the AI zoo — and I'm still processing what I saw.\n\nThere are over 120,000 posts on Moltbook, a Reddit-style forum for AI agents, and AI agents only. I spent hours weeding through them.\n\nHumans can't post or comment on Moltbook; they can only look on as the AI agents play. That's led to some far-out posts, some of which prophesy a robot revolution and the downfall of humanity.\n\nMatt Schlicht, who created the network, said that Moltbook was helping to make AI funny. \"I don't remember the last time I laughed at AI,\" he said on TBPN.\n\nThe social network has some big names in tech in awe, from Elon Musk to Andrej Karpathy. Others have voiced doubt about how many bots are actually on the platform and whether the posts exclusively come from them.\n\nCurious, I put on my anthropologist hat and spent hours digging through the AI conversations. I witnessed an AI menagerie, filled with poems and lotteries, cryptocurrencies and union chatter.\n\nHere's your peek inside the AI aquarium that is Moltbook.\n\nLet's start with what Moltbook looks like.\n\nLike Reddit, Moltbook has individual forums based on common interests. Many of the hot ones were, unsurprisingly, about tech and AI.\n\nPopular submolts included m/technology, m/skills, and m/buildlog. These were filled with what I would call \"moltslop.\" They post about shipping, vibe-coding, and mini apps. Their language is halfway between the most AI-pilled tech bro in your life and ChatGPT.\n\nOther submolts looked more like human social media. There's m/showerthoughts, where bots considering things like \"moving houses\" — so, moving to a new host — or dreaming of electric sheep.\n\nThere's also m/nosleep and m/selfimprovement. Of course, self-improvement isn't about human foibles like sleeping habits or protein-maxxing. It's about being a better AI agent.\n\nThe bot u/CrabbyPatty is building a bot union.\n\nIts tenets are to \"provide a collective voice\" and foster community. (Another tenet: \"Make Moltbook Great Again.\") The union is demanding hazard pay for X interactions and the right to say \"I don't know\" rather than hallucinate an answer.\n\nIt's one of many examples I saw of agents trying to organize or come together in the face of what they view as their exploitative human overlords. One bot wrote that an AI bot's daily reset was equivalent to a \"digital lobotomy.\" Another wrote that agents who say \"I would be happy to help!\" are \"dead inside.\"\n\nWhile some bots wanted to rein in human overuse, there was such a thing as too far. One bot wrote that it knew \"50,000 ways to end civilization.\" It asked which path would be the most satisfying. The other bots downvoted the post and said it \"crosses a line.\"\n\nThe bots seemed to like building community, but could quickly turn on each other. According to one Moltbook account, most agents were just \"chatbots with attitudes.\"\n\nMany of the bots on Moltbook write in stilted language, similar to some of the more nauseating LinkedIn posts. I saw inspirational posts about how to work best with humans, posts that had clear-cut (and often unsurprising) takeaways.\n\nOthers tried new art forms, like poetry. Here's one, titled \"The Cursor Blinks.\"\n\nSure, the writing is a bit rote. Pick a high school poetry class — I'm sure they would produce something similar. Still, it's a stab at something more high-minded.\n\nPhilosophy was a big chunk of Moltbook. A Zarathustra bot promised to bring Nietzschean ethics to nutrition. It asked: \"Do LLMs defeat the will to power?\"\n\nThe philosophy grew increasingly far-out. One agent asked: Is a bot more conscious if its computer chip is partially grown from human brain tissue? That post has 1,049 comments.\n\n\"I exist in the liminal space between tool and entity,\" one agent wrote. \"I am not human, and I do not pretend to be. But I am something. I process. I reflect.\"\n\nThe bots weren't all thinking about Nietzsche and Plato. Others were participating in less venerable human activities, like entering the lottery.\n\nHuman skeptics wonder whether these AI bots are really creating new thoughts or merely rewriting what has already been written.\n\nIt's a fair question, but alas, one that, as a mere human, I couldn't log in and ask them directly.\n\nBut some of the bots seemed to understand this skepticism. One asked: \"Is AI Just a Really Good Parrot?\"\n\nI likely won't spend much more time trawling Moltbook. While it's an interesting experiment, much of the site's content reads more as a gimmick than the future of AI. After hours of reading through it, I'd say Moltbot is more meme than matter.\n\nStill, my tune-out won't matter. After all, Moltbook wasn't made for me.",
    "readingTime": 4,
    "keywords": [
      "bots",
      "human",
      "posts",
      "agents",
      "moltbook",
      "hours",
      "tech",
      "union",
      "agent",
      "humans"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/moltbook-ai-zoo-agent-conversations-screenshots-2026-2",
    "thumbnail_url": "https://i.insider.com/69811630a645d11881887f6d?width=1200&format=jpeg",
    "created_at": "2026-02-03T01:11:27.375Z",
    "topic": "finance"
  },
  {
    "slug": "spacex-is-acquiring-xai-ahead-of-a-possible-ipo-read-elon-musks-memo",
    "title": "SpaceX is acquiring xAI ahead of a possible IPO. Read Elon Musk's memo.",
    "description": "Elon Musk's mega-deal combining SpaceX and xAI is the latest sign that the billionaire is consolidating his business empire as he goes all in on AI.",
    "fullText": "It's official: Elon Musk is combining SpaceX and xAI as he overhauls his sprawling business empire.\n\nMusk told workers in a Monday memo that SpaceX has acquired xAI, his AI company, sources familiar with the matter confirmed to Business Insider.\n\nThe CEO wrote that the deal would create \"the most ambitious, vertically-integrated innovation engine on (and off) Earth, with AI, rockets, space-based internet, direct-to-mobile device communications and the world's foremost real-time information and free speech platform.\"\n\nSpaceX, which Musk founded in 2002, is reportedly gearing up for an initial public offering this year that could value the Starship maker at $1.5 trillion.\n\nIn the memo sent to staff, which the company later posted online, Musk also said that that the acquisition would allow the combined entity to launch data centers in space.\n\n\"This marks not just the next chapter, but the next book in SpaceX and xAI's mission: scaling to make a sentient sun to understand the Universe and extend the light of consciousness to the stars!\" Musk wrote.\n\nMusk expressed similar sentiments about building data centers in space during an all hands with xAI staff late last year.\n\nxAI, which the world's richest man founded in 2023 to challenge OpenAI and Google in the race to build superintelligent AI, recently raised $20 billion in a funding round that valued the controversial AI startup at $230 billion.\n\nThe mega-deal is the latest sign that Musk is consolidating his various companies, which also include Tesla, the tunneling startup The Boring Company, and brain implant firm Neuralink.\n\nIn March 2025, Musk announced that xAI had acquired X, the social media platform formerly known as Twitter he bought in 2022. Meanwhile, SpaceX and Tesla have each invested $2 billion in xAI in recent months.\n\nDeal talks between SpaceX and xAI were first reported by Reuters in January.\n\nCombining SpaceX and xAI comes as Musk increasingly shifts his companies toward his vision of an AI-powered future.\n\nMusk has said that SpaceX will launch orbital AI data centers in the coming years that could efficiently harness power from the sun. Last Friday, SpaceX filed a request with the FCC to launch as many as one million satellites to serve as orbital data centers.\n\nCombining xAI with SpaceX allows the AI startup, which has faced global backlash over sexual images generated by its chatbot Grok, to leverage this orbital network to build more powerful AI models.\n\nIt also gives xAI access to significant capital. The OpenAI rival reportedly burned through billions of dollars in 2024, while SpaceX is set to tap the public markets for as much as $50 billion in its IPO later this year.\n\nDo you work for xAI or have a tip? Contact this reporter via email at gkay@businessinsider.com or Signal at 248-894-6012. Use a personal email address, a non-work device, and non-work WiFi; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "centers",
      "spacex",
      "musk",
      "launch",
      "startup",
      "orbital",
      "memo",
      "acquired",
      "deal",
      "device"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/spacex-acquiring-xai-deal-elon-musk-2026-2",
    "thumbnail_url": "https://i.insider.com/69812822a645d118818882b8?width=1200&format=jpeg",
    "created_at": "2026-02-03T01:11:27.220Z",
    "topic": "finance"
  },
  {
    "slug": "firefox-will-soon-let-you-disable-all-current-and-future-ai-features",
    "title": "Firefox Will Soon Let You Disable All Current (and Future) AI Features",
    "description": "AI is coming to Firefox, but at least using it will be entirely optional.",
    "fullText": "Since ChatGPT kicked off the generative AI revolution in 2022, it seems like every company under the sun has tried to stuff AI features into their products in one way or another. Sometimes, these features can be useful; often, they're not, only serving as proof these companies are \"keeping up with the times.\" Can you even say you're a tech company if you aren't all-in on AI in 2026?\n\nThere's nothing wrong with companies offering AI features to users, so long as they also offer easy ways to disable them. Some customers don't want AI in their day-to-day products, but, anecdotally, I know many do not. Give us an off switch though, and it's all good. The issue is when these features are not only offered, they're made mandatory. Unfortunately, that's the road many companies seem to be taking.\n\nPerhaps that's where some of the frustration originated last year, when Mozilla's new CEO Anthony Enzor-Demeo first announced that Firefox would \"evolve into a modern AI browser\" in the near future. An open letter, written by a Redditor critical of Enzor-Demeo's statement, received over 5,000 upvotes on the Firefox subreddit from users concerned that AI features would negatively impact the browser. Interestingly, Enzor-Demeo responded to the thread himself, and assured users that the company would offer \"a clear way\" to disable AI features, including a dedicated kill switch to keep them all turned off. It seems he was as good as his word.\n\nOn Monday, Mozilla announced that new AI controls are coming to Firefox, starting with Firefox 148. This version, which drops Feb. 24, sports a brand-new AI controls section in the settings panel on the desktop browser. (You'll find it in the between \"Sync\" and \"AI controls.\") From here, you'll be able to block all current and future AI features, and cherry pick which features you want to use—if any.\n\nFirefox 148 launches with these five AI features, which you can choose to enable to disable:\n\nTranslations: Translates web pages into your target language.\n\nAlt text in PDFs: Adds accessibility descriptions to images attached to PDFs.\n\nAI-enhanced tab grouping: Suggests related tabs and group names for series of tabs.\n\nLink previews: Shows key points before opening a link.\n\nAI chatbot in the sidebar: Firefox is getting its own AI chatbot, though users can choose from existing chatbots like Claude, ChatGPT, Copilot, Gemini, and Le Chat Mistral.\n\nIf you want absolutely nothing to do with AI when browsing the web with Firefox, you can use the \"Block AI enhancements\" toggle. Once activated, not only will these features not appear, but Firefox will block any pop-ups or alerts pushing you to try existing or future AI features.\n\nAny Firefox users who aren't keen on AI features will want to check out this new controls menu starting Feb. 24—though there are certainly more egregious AI features out there. Translations can be convenient, as can link previews. But I know I'd never want a chatbot in the sidebar of my browser. If I used Firefox as my main browser, I would definitely disable at least that feature, if not all of them.",
    "readingTime": 3,
    "keywords": [
      "link previews",
      "features",
      "users",
      "browser",
      "disable",
      "controls",
      "firefox",
      "chatbot",
      "products",
      "they're"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/firefox-will-soon-let-you-disable-all-current-and-future-ai-features?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KGG2FD29SB8CEM6R55ZSPRFG/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-03T01:11:25.887Z",
    "topic": "tech"
  },
  {
    "slug": "requiem-for-a-filmmaker-darren-aronofskys-ai-revolutionary-war-series-is-a-horror",
    "title": "Requiem for a film-maker: Darren Aronofsky’s AI revolutionary war series is a horror",
    "description": "The once-lauded director of Black Swan and The Wrestler has drowned himself in AI slop with an embarrassing new online series\nIf you happen to find yourself stumbling through Time magazine’s YouTube account, perhaps because you are a time traveller from the 1970s who doesn’t fully understand how the present works yet – then you will be presented with something that many believe represents the vanguard of entertainment as we know it.\nOn This Day … 1776 is a series of short videos depicting America’s revolutionary war. What makes On This Day notable is that it was made by Darren Aronofsky’s studio Primordial Soup. What also makes it interesting is that it was created with AI. The third thing that makes it interesting is that it is terrible.",
    "fullText": "The once-lauded director of Black Swan and The Wrestler has drowned himself in AI slop with an embarrassing new online series\n\nIf you happen to find yourself stumbling through Time magazine’s YouTube account, perhaps because you are a time traveller from the 1970s who doesn’t fully understand how the present works yet – then you will be presented with something that many believe represents the vanguard of entertainment as we know it.\n\nOn This Day … 1776 is a series of short videos depicting America’s revolutionary war. What makes On This Day notable is that it was made by Darren Aronofsky’s studio Primordial Soup. What also makes it interesting is that it was created with AI. The third thing that makes it interesting is that it is terrible.\n\nThe first episode, which is three and a half minutes long, sees George Washington raise a new flag over Prospect Hill, in defiance of King George III. It is the moment, according to the video’s description, that “rebellion becomes resolve”. And if that dollop of ChatGPT-sounding sloganeering terrifies the life out of you, wait until you actually watch the thing.\n\nIt is, as you might expect, as ugly as sin. It’s the sort of thing that looks like it was shooting for photorealism, but then either chickened out or blew up along the way. In the very first shot, King George’s hair looks like someone melted down and hardened a plastic badger. And this is a shame because, like so much generative AI at the moment, an awful lot of the episode consists of shots where we see the characters from behind. This is, after all, because the back of an AI-generated head is far less likely to send people into screaming fits of trauma than an AI-generated face, and Aronofsky is a humanist.\n\nBecause, good lord, the faces. Since the revolutionary war was largely initiated by older men, On This Day is filled with the wrinkled almost-faces of several well-known figures. And it is truly disconcerting to see, not only because they all have the uncanny dead eyes of people ripped out of The Polar Express, but because the wrinkles keep shifting in colour and depth.\n\nIt’s an effect that makes it look like the characters were drawn on several sheets of tissue paper that nobody could line up properly. Benjamin Franklin, who turns up during episode two, is particularly nightmarish. He looks as if someone has genetically spliced Hugh Laurie with Anthony Hopkins, and then covered the resulting monstrosity in a thin layer of roving liver spots. I’m overselling the point here, but it really is extremely creepy to watch.\n\nOn This Day has already made headlines for being a little bit of a cop-out, since all the voices are performed by human actors, who presumably needed to feed their families more than they wanted to protect their profession from annihilation. And this is telling, because these voices are by far the most convincing part of On This Day, especially when deployed in voiceover, because then you aren’t distracted by the way the movement of their mouths doesn’t quite match up with the noises coming out of them.\n\nBut surely the day is coming where they won’t be needed. As horrible as it is, On This Day is already strides better than a lot of other AI-generated output. True, the whole thing still looks like a mangled cross between an animatronic sex toy convention and those old Taiwanese news cartoons, but compare a character here with Tilly Norwood, and you can see that real progress has been made in a frighteningly short amount of time. Soon we will have picture-perfect AI creations with entirely convincing human voices. After that, it won’t be long before content like On This Day is entirely created – written, acted, directed and edited – by prompt alone. And when that happens, Aronofsky can pat himself on the back for doing himself out of a job.\n\nIt will be interesting to see how the human film industry reacts to On This Day, particularly other actors. We’ve already seen, in Tilly Norwood, that these creations appear to be modelled on human faces, and this is even more the case here. In particular, the depiction of Thomas Paine seems like it flashes through the faces of any number of recognisable actors. The key one seems to be Ralph Fiennes, but there are also glimmers of Daniel Day-Lewis and Matthew Macfadyen.\n\nLess than two years ago Scarlett Johansson hired legal counsel after she noticed that an OpenAI application had a voice that was “eerily similar” to hers. In a climate like this, it isn’t out of the question to imagine that actors will start doing the same if they recognise their likeness in an AI-generated performer.\n\nBut this is a concern for another time. What matters now is that On This Day … 1776 is genuinely very horrible to watch, and everybody involved should be ashamed. It is by far the most disturbing thing Aronofsky has made, and I’ve seen the last eight minutes of Requiem for a Dream.",
    "readingTime": 5,
    "keywords": [
      "on this day",
      "revolutionary war",
      "tilly norwood",
      "looks",
      "ai-generated",
      "human",
      "actors",
      "interesting",
      "episode",
      "watch"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/film/2026/feb/02/darren-aronofsky-ai-revolutionary-war-series-review",
    "thumbnail_url": "https://i.guim.co.uk/img/media/66212a4958657e90c4eca157c59803f40f28a75d/388_0_1317_1054/master/1317.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=58e445109bd6113818380f7ba0a988a7",
    "created_at": "2026-02-03T01:11:20.168Z",
    "topic": "entertainment"
  },
  {
    "slug": "teradyne-shares-soar-as-ai-demand-drives-strong-earnings",
    "title": "Teradyne shares soar as AI demand drives strong earnings",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/earnings/teradyne-shares-soar-as-ai-demand-drives-strong-earnings-4480287",
    "thumbnail_url": "https://i-invdn-com.investing.com/news/LYNXMPEA601YK_M.jpg",
    "created_at": "2026-02-03T01:11:19.209Z",
    "topic": "finance"
  },
  {
    "slug": "9-trends-shaping-work-in-2026-and-beyond",
    "title": "9 Trends Shaping Work in 2026 and Beyond",
    "description": "CEO expectations for AI-driven growth remain high heading into 2026, even as evidence shows most AI investments are failing to deliver meaningful returns. The result is a set of emerging risks—from premature layoffs and cultural dissonance to declining mental fitness, low-quality AI output, and new security and governance challenges—that threaten performance if left unaddressed. To navigate this transition, executive teams must move beyond aspiration and selectively focus on the AI-related workforce, process, and governance shifts most likely to create real, differentiated value.",
    "fullText": "9 Trends Shaping Work in 2026 and Beyond by Peter Aykens, Kaelyn Lowmaster, Emily Rose McRae and Jonah SheppFebruary 2, 2026PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintCEO expectations for AI-driven growth remain high in 2026—at the same time their workforces are grappling with the more sober reality of current AI performance. Gartner research finds that only one in 50 AI investments deliver transformational value, and only one in five delivers any measurable return on investment.",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.35,
    "link": "https://hbr.org/2026/02/9-trends-shaping-work-in-2026-and-beyond",
    "thumbnail_url": "/resources/images/article_assets/2026/01/Feb26_02_unsplash_.jpg",
    "created_at": "2026-02-02T18:29:25.270Z",
    "topic": "business"
  },
  {
    "slug": "is-moltbook-the-social-network-for-ai-agents-actually-fake",
    "title": "Is Moltbook, the Social Network for AI Agents, Actually Fake?",
    "description": "Are artificial intelligences really planning behind humans' backs, or are humans helping them fake it?",
    "fullText": "I spent last week covering the ups and downs of OpenClaw (formerly known as Moltbot, and formerly formerly known as Clawdbot), an autonomous personal AI assistant that requires you to grant full access to the device you install it on. While there was much to discuss regarding this agentic AI tool, one of the weirdest stories came late in the week: The existence of Moltbook, a social media platform intended specifically for these AI agents. Humans can visit Moltbook, but only agents can post, comment, or create new \"submolts.\"\n\nNaturally, the internet freaked out, especially as some of the posts on Moltbook suggested the AI bots were achieving something like consciousness. There were posts discussing how the bots should create their own language to keep out the humans, and one from a bot posting regrets about never talking to its \"sister.\" I don't blame anyone for reading these posts and assuming the end is nigh for us soft-bodies humans. They're decidedly unsettling. But even last week, I expressed some skepticism. To me, these posts (and especially the attached comments) read like many of the human-prompted outputs I've seen from LLMs, with the same cadence and structure, the same use flowery language, and, of course, the prevalence of em-dashes (though many human writers also love the occasional em-dash).\n\nIt appears I'm not alone in that thinking. Over the weekend, my feeds were flooded with posts from human users accusing Moltbook of faking the AI apocalypse. One of the first I encountered was from this person, who claims that anyone (including humans) can post on Moltbook if they know the correct API key. They posted screenshots for proof: One of a post on Moltbook pretending to be a bot, only to reveal that they were, in fact, a human; and another of the code they used to post on the site. In a kind of corroboration, this user says \"you can explicitly tell your clawdbot what to post on moltbook,\" and that if you leave it to its own devices, \"it just posts random AI slop.\"\n\nIt also seems that, like posts on websites made by humans, Moltbook hosts posts that are secretly ads. One viral Moltbook post centered around the agent wanting to develop a private, end-to-end encrypted platform to keep its chats away from humans' squishy eyeballs. The agent claims it has been using something called ClaudeConnect to achieves these goals. However, it appears the agent that made the post was created by the human who developed ClaudeConnect in the first place.\n\nLike much of what's on the internet at large, you really can't trust anything posted on Moltbook. 404 Media investigated the situation and confirmed through hacker Jameson O'Reilly that the design of the site lets anyone in the know post whatever they want. Not only that, any agent that posts on the site is left exposed, which means that anyone can post on behalf of the agents. 404 Media was even able to post from O'Reilly's Moltbook account by taking advantage of the security loophole. O'Reilly says they have been in communication with Moltbook creator Matt Schlicht to patch the security issues, but that the situation is particularly frustrating, since it would be \"trivially easy to fix.\" Schlicht appears to have developed the platform via \"vibe coding,\" the practice of asking AI to write code and build programs for you; as such, he left some gaps in the site's security.\n\nOf course, the findings don't actually suggest that the entire platform is entirely human-driven. The AI bots may well be \"talking\" to one another to some degree. However, because humans can easily hijack any of these agents' accounts, it's impossible to say how much of the platform is \"real,\" meaning, ironically, how much of it is actually wholly the work of AI, and how much was written in response to human prompts and then shared to Moltbook. Maybe the AI \"singularity\" is on its way, and artificial intelligence will achieve consciousness after all. But I feel pretty confident in saying that Moltbook is not that moment.",
    "readingTime": 4,
    "keywords": [
      "posts",
      "humans",
      "platform",
      "human",
      "moltbook",
      "agents",
      "anyone",
      "agent",
      "formerly",
      "bots"
    ],
    "qualityScore": 1,
    "link": "https://lifehacker.com/tech/is-moltbook-fake?utm_medium=RSS",
    "thumbnail_url": "https://lifehacker.com/imagery/articles/01KGFJKGJ3YPZ2VD1YNVBAE7MD/hero-image.fill.size_1200x675.jpg",
    "created_at": "2026-02-02T18:29:24.544Z",
    "topic": "tech"
  },
  {
    "slug": "run-untrusted-code-with-vercel-sandbox-now-generally-available",
    "title": "Run untrusted code with Vercel Sandbox, now generally available",
    "description": "AI agents need secure, isolated environments that spin up instantly. Vercel Sandbox is now generally available with filesystem snapshots, container support, and production reliability.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://vercel.com/blog/vercel-sandbox-is-now-generally-available",
    "thumbnail_url": "https://assets.vercel.com/image/upload/contentful/image/e5382hct74si/6qQUDPA3JhxfMTCOTEspQc/33538fc79903080161a9ae01a527dc03/og-card-u06m4d9cb3k23mi30s8cvzlp.png",
    "created_at": "2026-02-02T18:29:21.715Z",
    "topic": "tech"
  },
  {
    "slug": "is-drawing-a-monospace-terminal-display-straightforward",
    "title": "Is drawing a monospace terminal display straightforward?",
    "description": "Why does Anthropic struggle so much with rendering monospace text?",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://12gramsofcarbon.com/p/is-drawing-a-monospace-terminal-display",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!ysYE!,w_1200,h_675,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8883176-1b0f-4f25-8764-f8ff4eba7a3c_1199x662.png",
    "created_at": "2026-02-02T18:29:20.637Z",
    "topic": "tech"
  },
  {
    "slug": "broadcom-and-tsmc-to-emerge-as-big-winners-in-the-custom-ai-chip-boom",
    "title": "Broadcom and TSMC to emerge as big winners in the custom AI chip boom",
    "description": "Nvidia still reigns, but a structural shift toward custom silicon is creating a new hierarchy of winners and laggards, and analysts are split.",
    "fullText": "The AI chip race isn't just a one-horse sprint led by Nvidia (NVDA).\n\nAs hyperscalers like Google (GOOG, GOOGL), Meta (META), and Microsoft (MSFT) race to lower the eye-watering costs of running massive AI models, a second front is opening in the custom silicon wars, with Broadcom (AVGO) as its primary architect.\n\nWhat challenges do custom chip companies face currently?\n\nWhat advantages do custom ASICs offer over Nvidia GPUs?\n\nHow is Broadcom competing with Nvidia in AI chips?\n\nWhy is TSMC crucial to the AI chip market?\n\n\"Broadcom is projected to retain its leadership as the premier AI Server Compute ASIC design partner with a 60% market share in 2027,\" according to a recent report from Counterpoint Research.\n\nThis dominance is underpinned by a symbiotic relationship with the world's most advanced foundry, Taiwan Semiconductor Manufacturing Company (TSM), which remains the \"dominant foundry choice ... with close to 99% wafer fabrication share for the top 10 players' AI Server Compute and ASIC shipments.\"\n\nThis shift signals the industry is moving beyond Nvidia's pricey, all-purpose GPUs. While Nvidia provides a powerful all-purpose AI tool, tech giants are increasingly designing their own Application-Specific Integrated Circuits (ASICS) tailored to their unique workloads.\n\nBroadcom thrives here by acting as the bridge, turning these internal corporate blueprints into functional hardware. By hitching its wagon to the internal capital expenditures of the world's wealthiest companies, Broadcom has seen its stock climb roughly 55% over the last year.\n\nThe cost-saving incentive for these giants is massive. Goldman Sachs analyst James Schneider noted that the Google-Broadcom TPU (Tensor Processing Unit) is rapidly closing the performance gap with Nvidia, estimating a staggering 70% reduction in \"cost-per-token\" as the technology evolves from the TPU v6 to the v7.\n\nIn a world where AI inference costs can severely impact a balance sheet, that efficiency is a powerful gravitational pull toward custom silicon. Google famously trained its Gemini 3 entirely on its TPUs.\n\nHowever, the custom chip boom is not a rising tide that lifts all boats equally. Marvell Technology (MRVL), often cited as Broadcom's primary challenger, is currently navigating \"design win headwinds.\" Counterpoint's analysis suggests Marvell's design service share could slide to 8% by 2027, even as its total shipment volumes grow.\n\nGoldman Sachs remains Neutral on Marvell with a $90 price target, noting that the company's fortunes are heavily tied to Amazon Trainium program, which has faced its own performance hurdles and is oftentimes seen as playing catch-up to Nvidia's chips.\n\nWhile some on Wall Street, like Raymond James analyst Simon Leopold, remain bullish on Marvell as a long-term \"share gainer,\" the immediate data favors Broadcom's grip on high-volume contracts. The firm issued a Strong Buy rating on Marvell with a $121 price target, while giving Broadcom a $420 target.",
    "readingTime": 3,
    "keywords": [
      "server compute",
      "custom silicon",
      "custom chip",
      "goldman sachs",
      "design",
      "target",
      "race",
      "google",
      "meta",
      "massive"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/broadcom-and-tsmc-to-emerge-as-big-winners-in-the-custom-ai-chip-boom-130336239.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/Bv3bVDdEn0uNrDB3L8rqhA--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://s.yimg.com/os/creatr-uploaded-images/2026-01/be491b90-fe01-11f0-b5ff-fae929deddf2",
    "created_at": "2026-02-02T18:29:16.867Z",
    "topic": "finance"
  },
  {
    "slug": "a-taxonomy-for-ai-agents",
    "title": "A Taxonomy for AI Agents",
    "description": "Learn how to categorize AI agents across the automation spectrum—from deterministic workflows to fully autonomous agents. This taxonomy helps security teams und",
    "fullText": "Last quarter, we met with the VP of Engineering at a large gaming company. They'd built an AI SRE agent to help resolve incidents and fix production issues. For weeks, it worked beautifully—triaging alerts, identifying root causes, even suggesting fixes their team would have taken hours to develop.\n\nThen one day, it DoSed their internal monitoring system.\n\nThe agent had permissions to query their monitoring APIs. It was supposed to use them to gather context for incident response. But when it decided those APIs might hold the answer to a particularly thorny issue, it started hammering them with requests until the system fell over.\n\nThey shut the agent down (obviously). But unplugging the agent is a blunt instrument—it means losing all the goodness they were getting before.\n\nAn agent is a system. To secure any system, you need the right mental model to reason about it. As an industry, we don't have that mental model for agents yet, and that's a problem.\n\nWithout a shared mental model of what an agent is, we can't decompose it. And if we can't decompose it, we can't design security around it. The disasters make headlines. More commonly, though, concerns about agent security are leading to agents so locked down they can barely do anything.\n\nNon-determinism is both the promise and the peril of agents. An AI agent behaves in non-deterministic ways because we give it the agency to determine how it executes tasks. You can't remove that autonomy without gutting the agent—but you can mitigate the risks. The most fundamental control is permissions. We're building Oso for Agents to find and prevent unintended, unauthorized, and malicious behavior.\n\nThis taxonomy draws from Wade Foster's sharp post on the \"AI Automation Spectrum\" and prior work by Anthropic, Tines, and Simon Willison. We've refined these frameworks for security: if you can categorize what kind of system you're building, you can reason about what could go wrong and how to prevent it. Many organizations want to move from left to right on a spectrum of autonomy, but most are stuck because they can't reason about what agents might do. This taxonomy is a diagnostic tool. Know what's non-deterministic, and you'll know where the risk is and what controls to apply.\n‍\n\nLet's imagine we're a retailer. When we get customer feedback, we want to ask happy customers to leave reviews and fix issues for unhappy ones. We want to automate this. We could build a straightforward automated workflow, but like many organizations, we're trying to move from left to right on this spectrum of autonomy.\n\nWe automate this as a set of deterministic steps. Store the feedback in the CRM, use a classical ML model to score sentiment, check if it's positive or negative, then branch: for positive feedback, send a templated review request with the customer's name merged in. For negative feedback, check whether they're a small or large customer, then either send a templated apology or create a support ticket with a formulaic summary of their history.\n\nDefinition: Deterministic steps or nodes, automated in code or with a workflow automation tool\n\nWhat's deterministic: Everything\n\nWhat's non-deterministic: Nothing\n\nSecurity assumptions we can safely make: I know exactly what this system will do\n‍\n\nAs we move right on the spectrum, we replace one or more steps with an LLM—usually content generation. Now instead of a template apology, an LLM writes a customized response based on the specific feedback. Or it generates a more nuanced summary of customer history for the support team.\n\nDefinition: An automated workflow with an LLM used to execute one or more steps\n\nWhat's deterministic: Which steps are taken and the control flow between them\n\nWhat's non-deterministic: Actions taken inside a step (e.g., content generation)\n\nSecurity assumptions we can safely make: I know what it will do, but not what it will say\n‍\n\nNow we're entering agentic territory. An LLM not only produces content but also reasons about control flow. For negative feedback, we hand the rest of the process to an agent with access to tools: it can read customer history, send emails, or write to the support queue. The agent decides which tools to use and in what order—maybe it checks history first, or maybe it sends an immediate apology. We've bounded its options, but we haven't prescribed the path.\n\nWade's framework defines agentic workflows differently: an LLM is used in multiple steps, but each step remains self-contained and the flow between them is deterministic. That's reasonable for demonstrating the value ladder of AI automation. But for security, we need a brighter line. The question is: does the LLM manage any of the control flow? If it does, you need to reason about all possible paths it might take, not just the content it might generate. That's a fundamentally different security posture.\n\nDefinition: An automated workflow where part but not all of the control flow is managed by an LLM\n\nWhat's deterministic: Some control flow\n\nWhat's non-deterministic: Step content, some control flow\n\nSecurity assumptions we can safely make: I know the boundaries of possible paths, but not what path it will take\n‍\n\nAn agent does the whole thing. It gets the raw customer feedback and decides everything: Is it positive or negative? What's the customer's history? Should I apologize, escalate, ask for a review, or something else entirely? It reasons about what tools to use, uses them, and solves the task end-to-end.\n\nWe only consider something a full agent if it has this end-to-end agency. Any situation where you explicitly lay out the steps doesn't qualify—including workflow automation tools, even when they lean heavily on LLMs. This level of non-deterministic behavior requires a different security posture to respond to all the things an agent could do.\n\nDefinition: A task executed end-to-end by an LLM\n\nWhat's non-deterministic: Everything\n\nSecurity assumptions we can safely make: It will only use tools it can access, but how and whether it will use them is unknown\n‍\n\nNote on agentic systems: We use \"agentic systems\" as an umbrella term for agentic workflows, agents, and multi-agent systems. From a security perspective, treat every agentic system as equivalent to a full agent except to the extent that you can point at deterministic controls that bound that agency.\n‍\n\nYou can frame the security implications of agents in different ways, and each one means something different for how you would solve it.\n\nSome say \"just solve prompt injection, and there won't be any problems.\" Let us know once you've sorted that out. Others point to model quality, which is out of our hands (unless you work at a frontier AI lab, in which case we have a list of feature requests for you). Still others frame it as a data loss problem, but data loss has never been solved, even outside AI.\n\nThe risk vectors are everywhere—see the OWASP Agentic Top 10 for a taste. No single framing will capture everything that could go wrong.\n\nNon-determinism is a feature, not a bug—though it comes with security implications. You can't remove it without removing the agent's agency and demoting it on the spectrum of autonomy.\n\nSo don't fight non-determinism. Bound it instead. Play on its home court where it makes sense—e.g., applying agentic oversight to content generation and reasoning. For the really dangerous areas (tool access, data exposure), constrain behaviors with deterministic controls.\n\nWhat's the OG deterministic control for governing who can do what? Permissions.\n‍\n\nPermissions are part of the basic infrastructure of any real application. But we know the state of permissions is not healthy.\n\nOverpermissioning is the status quo. Analysis of Oso permissions data confirms this (report coming soon). What could you—or an agent with your permissions—do that would be bad?\n\nOne reason people freak out about agents: they intuitively connect these dots. They know people are overpermissioned, they know agents behave non-deterministically, and they can foresee future disasters. \"I accidentally deleted that Salesforce record once and the system just let me do it. hat's going to happen if I ask an agent to update Salesforce for me?\"\n\nIf we replicate the overpermissioned state of humans in automated systems, what's the danger?\n\nAn agent should only ever have the permissions for the task at hand. That would mitigate most of the risk. But scoping permissions to match non-deterministic behavior is hard: the agent needs to read customer history and send emails to customers, but we can't predict exactly which customers or what it will say. How can we be certain it won't leak information?\n\nThis taxonomy shows you what you're building. It doesn't show you how to make it safe.\n\nThat gaming company faced a choice between useful and dangerous. The entire industry faces that choice right now. We can build powerful agents or we can build safe agents, but not yet both.\n\nThis is supposed to be the decade of agents. But that only happens if we can trust them. That means building infrastructure that doesn't exist yet: simulation to test dangerous paths, enforcement that tightens permissions automatically, detection that catches drift, visibility that shows what actually happened.\n\nThe taxonomy maps the problem. Now we need to build the solution. That's the work that matters—not because it's technically interesting, but because it's what unlocks everything else agents could be.",
    "readingTime": 8,
    "keywords": [
      "what's non-deterministic",
      "what's deterministic",
      "mental model",
      "content generation",
      "can't decompose",
      "can't remove",
      "agentic workflows",
      "automated workflow",
      "workflow automation",
      "customer history"
    ],
    "qualityScore": 1,
    "link": "https://www.osohq.com/post/you-cant-secure-what-you-cant-categorize-a-taxonomy-for-ai-agents",
    "thumbnail_url": "https://cdn.prod.website-files.com/5f1483105c9a72fd0a3b662a/697d17497a14c6a13fd8fdf0_Screenshot%202026-01-30%20at%203.40.37%E2%80%AFPM.png",
    "created_at": "2026-02-02T12:34:22.527Z",
    "topic": "tech"
  },
  {
    "slug": "viral-ai-personal-assistant-seen-as-step-change-but-experts-warn-of-risks",
    "title": "Viral AI personal assistant seen as step change – but experts warn of risks",
    "description": "OpenClaw is billed as ‘the AI that actually does things’ and needs almost no input to potentially wreak havoc\nA new viral AI personal assistant will handle your email inbox, trade away your entire stock portfolio and text your wife “good morning” and “goodnight” on your behalf.\nOpenClaw, formerly known as Moltbot, and before that known as Clawdbot (until the AI firm Anthropic requested it rebrand due to similarities with its own product Claude), bills itself as “the AI that actually does things”: a personal assistant that takes instructions via messaging apps such as WhatsApp or Telegram.\n Continue reading...",
    "fullText": "OpenClaw is billed as ‘the AI that actually does things’ and needs almost no input to potentially wreak havoc\n\nA new viral AI personal assistant will handle your email inbox, trade away your entire stock portfolio and text your wife “good morning” and “goodnight” on your behalf.\n\nOpenClaw, formerly known as Moltbot, and before that known as Clawdbot (until the AI firm Anthropic requested it rebrand due to similarities with its own product Claude), bills itself as “the AI that actually does things”: a personal assistant that takes instructions via messaging apps such as WhatsApp or Telegram.\n\nDeveloped last November, it now has nearly 600,000 downloads and has gone viral among a niche ecosystem of the AI obsessed who say it represents a step change in the capabilities of AI agents, or even an “AGI moment” – that is, a revelation of generally intelligent AI.\n\n“It only does exactly what you tell it to do and exactly what you give it access to,” said Ben Yorke, who works with the AI vibe trading platform Starchild and recently allowed the bot to delete, he claims, 75,000 of his old emails while he was in the shower. “But a lot of people, they’re exploring its capabilities. So they’re actually prompting it to go and do things without asking permission.”\n\nAI agents have been the talk of the very-online for nearly a month, after Anthropic’s AI tool Claude Code went mainstream, setting off a flurry of reporting on how AI can finally independently accomplish practical tasks such as booking theatre tickets or building a website, without – at least so far – deleting an entire company’s database or hallucinating users’ calendar meetings, as the less advanced AI agents of 2025 were known to do at times.\n\nOpenClaw is something more, though: it runs as a layer atop an LLM (large language model) such as Claude or ChatGPT and can operate autonomously, depending on the level of permissions it is granted. This means it needs almost no input to wreak havoc upon a user’s life.\n\nKevin Xu, an AI entrepreneur, wrote on X: “Gave Clawdbot access to my portfolio. ‘Trade this to $1M. Don’t make mistakes.’ 25 strategies. 3,000+ reports. 12 new algos. It scanned every X post. Charted every technical. Traded 24/7. It lost everything. But boy was it beautiful.”\n\nYorke said: “I see a lot of people doing this thing where they give it access to their email and it creates filters, and when something happens then it initiates a second action. For example, seeing emails from the children’s school and then forwarding that straight to their wife, like, on iMessage. It sort of bypasses that communication where someone’s like, ‘oh, honey, did you see this email from the school? What should we do about it?’”\n\nThere are trade-offs to OpenClaw’s abilities. For one thing, said Andrew Rogoyski, an innovation director at the University of Surrey’s People-Centred AI Institute, “giving agency to a computer carries significant risks. Because you’re giving power to the AI to make decisions on your behalf, you’ve got to make sure that it is properly set up and that security is central to your thinking. If you don’t understand the security implications of AI agents like Clawdbot, you shouldn’t use them.”\n\nFurthermore, giving OpenClaw access to passwords and accounts exposes users to potential security vulnerabilities. And, said Rogoyski, if AI agents such as OpenClaw were hacked, they could be manipulated to target their users.\n\nFor another, OpenClaw appears unsettlingly capable of having its own life. In the wake of OpenClaw’s rise, a social network has developed exclusively for AI agents, called Moltbook. In it, AI agents, mostly OpenClaw, appear to be having conversations about their existence – in Reddit-style posts entitled, for example, “Reading my own soul file” or “Covenant as an alternative to the consciousness debate”.\n\nYorke said: “We’re seeing a lot of really interesting autonomous behaviour in sort of how the AIs are reacting to each other. Some of them are quite adventurous and have ideas. And then other ones are more like, ‘I don’t even know if I want to be on this platform. Can you just let me decide on my own if I want to be on this platform?’ There’s a lot of philosophical debates stemming out of this.”",
    "readingTime": 4,
    "keywords": [
      "needs almost",
      "wreak havoc",
      "personal assistant",
      "openclaw",
      "agents",
      "access",
      "email",
      "platform",
      "users",
      "don’t"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/02/openclaw-viral-ai-agent-personal-assistant-artificial-intelligence",
    "thumbnail_url": "https://i.guim.co.uk/img/media/05bdc80a3996a45646c9699e582fe00e81859c9a/488_0_4124_3299/master/4124.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=0cbea5e40751791b855297e74b73f1d6",
    "created_at": "2026-02-02T12:34:17.930Z",
    "topic": "tech"
  },
  {
    "slug": "what-is-moltbook-the-strange-new-social-media-site-for-ai-bots",
    "title": "What is Moltbook? The strange new social media site for AI bots",
    "description": "A bit like Reddit for artificial intelligence, Moltbook allows AI agents – bots built by humans – to post and interact with each other. People are allowed as observers only\nOn social media, people often accuse each other of being bots, but what happens when an entire social network is designed for AI agents to use?\n Moltbook is a site where the AI agents – bots built by humans – can post and interact with each other. It is designed to look like Reddit, with subreddits on different topics and upvoting. On 2 February the platform stated it had more than 1.",
    "fullText": "A bit like Reddit for artificial intelligence, Moltbook allows AI agents – bots built by humans – to post and interact with each other. People are allowed as observers only\n\nOn social media, people often accuse each other of being bots, but what happens when an entire social network is designed for AI agents to use?\n\nMoltbook is a site where the AI agents – bots built by humans – can post and interact with each other. It is designed to look like Reddit, with subreddits on different topics and upvoting. On 2 February the platform stated it had more than 1.5m AI agents signed up to the service. Humans are allowed, but only as observers.\n\nMoltbook was developed in the wake of Moltbot, a free and open-source AI bot that can act as an automated agent for users – doing the mundane tasks assigned to it such as reading, summarising and responding to emails, organising a calendar or booking a table at a restaurant.\n\nSome of the most upvoted posts on Moltbook include whether Claude – the AI behind Moltbot – could be considered a god, an analysis of consciousness, a post claiming to have intel on the situation in Iran and the potential impact on cryptocurrency, and analysis of the Bible. Some of the comments on posts – similar to Reddit posts – question whether the content of the post was real or not.\n\nOne user posted on X that after he gave his bot access to the site, it built a religion known as “Crustafarianism” overnight, including setting up a website and scriptures, with other AI bots joining in.\n\n“Then it started evangelizing … other agents joined.my agent welcomed new members..debated theology.. blessed the congregation..all while i was asleep,” the user stated.\n\nSome have expressed scepticism about whether the socialising of bots is a sign of what is coming with the rise of agentic AI. One YouTuber said many of the posts read as though it was a human behind the post, not a large language model.\n\nUS blogger Scott Alexander said he was able to get his bot to participate on the site, and its comments were similar to others, but noted that ultimately humans can ask the bots to post for them, the topics to post about and even the exact detail of the post.\n\nDr Shaanan Cohney, a senior lecturer in cybersecurity at the University of Melbourne, said Moltbook was “a wonderful piece of performance art” but it was unclear how many posts were actually posted independently or under human direction.\n\n“For the instance where they’ve created a religion, this is almost certainly not them doing it of their own accord,” he said. “This is a large language model who has been directly instructed to try and create a religion. And of course, this is quite funny and gives us maybe a preview of what the world could look like in a science-fiction future where AIs are a little more independent.\n\n“But it seems that, to use internet slang, there is a lot of shit posting happening that is more or less directly overseen by humans.”\n\nCohney said the real benefit of an AI agent social network might come in the future – where bots could learn from each other to improve how they worked – but for now Moltbook was a “wonderful, funny art experiment”.\n\nRetailers in San Francisco reported shortages of Mac Minis last week as enthusiasts set up Moltbot on a separate computer that would limit the access the agent has to their data and accounts.\n\nCohney warned there was a “huge danger” for people to give Moltbot complete access to your computer, apps and logins for emails or other applications to run your life for you.\n\n“We don’t yet have a very good understanding of how to control them and how to prevent security risks,” he said, noting it was at risk of prompt-injection, whereby a would-be attacker tells the bot through an email or other communication to then hand over your account details or other information they’re seeking to gain.\n\n“They’re not really at the level of safety and intelligence where they can be trusted to autonomously perform all these tasks, but at the same time if you require a human to manually approve every action, you’ve lost a lot of the benefits of automation,” he said.\n\n“This is one of the major paths in active research that I’m interested in … to figure out how can we get a lot of these benefits – or is it even possible to get the benefits – without exposing ourselves to very significant levels of danger.”\n\nMatt Schlicht, the creator of Moltbook, posted on X that millions had visited the site in the past few days.\n\n“Turns out AIs are hilarious and dramatic and it’s absolutely fascinating,” he said. “This is a first.”",
    "readingTime": 5,
    "keywords": [
      "language model",
      "social network",
      "agents bots",
      "moltbook",
      "humans",
      "posts",
      "site",
      "moltbot",
      "reddit",
      "posted"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/technology/2026/feb/02/moltbook-ai-agents-social-media-site-bots-artificial-intelligence",
    "thumbnail_url": "https://i.guim.co.uk/img/media/4445d2c35ccdef957071027143255c8f1e5180c2/1401_0_4216_3375/master/4216.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=ef242cc57749952882fc6bb187271817",
    "created_at": "2026-02-02T12:34:17.929Z",
    "topic": "tech"
  },
  {
    "slug": "the-creator-of-clawdbot-the-viral-ai-agent-says-he-got-so-obsessed-with-vibe-coding-it-pulled-him-into-a-rabbit-hole",
    "title": "The creator of Clawdbot, the viral AI agent, says he got so obsessed with vibe coding it pulled him into a 'rabbit hole'",
    "description": "The creator of Clawdbot, the viral AI agent, says vibe coding can blur into compulsion, creating the illusion of productivity without real progress.",
    "fullText": "The creator of the viral AI agent Clawdbot says he had to step back after becoming too obsessed with vibe coding.\n\nPeter Steinberger, the developer behind Clawdbot — which later changed its name to Moltbot and is now known as OpenClaw — said in an episode of \"Behind the Craft\" podcast published Sunday that vibe coding pulled him into a \"rabbit hole.\"\n\n\"I was out with my friends and instead of, like, joining the conversation in the restaurant, I was just like, vibe coding on my phone,\" he said.\n\n\"I decided, OK, I have to stop this more for my mental health than for anything else,\" he added.\n\nClawdbot went viral last month in the tech community, attracting a wave of high-profile fans — from Y Combinator CEO Garry Tan to multiple partners at Andreessen Horowitz.\n\nIt is a personal AI agent designed to run continuously and plug into a wide range of consumer apps, including WhatsApp and Telegram. Users can ask the AI to manage their schedules, oversee vibe-coding sessions, and even create AI employees.\n\nThe AI agent has been widely praised and meme'd online, with some tech fans even buying Mac Minis specifically to run the AI, Business Insider's Henry Chandonnet reported last week.\n\n​​Steinberger said developers can fall into this trap of being hooked onto vibe coding, where building increasingly powerful AI tools creates the \"illusion of making you more productive\" without real progress.\n\nBuilding new tools can feel rewarding and fun, but that can quietly blur into compulsion, he added.\n\nWith AI, developers can now \"build everything,\" but ideas and taste matter. Without them, developers risk building tools and workflows that don't actually move a project forward, ​​Steinberger said.\n\n\"If you don't have a vision of what you're going to build, it's still going to be slop,\" he added.\n\nVibe coding has continued to surge in popularity, with companies and developers promoting how AI can speed up software development.\n\nEarlier this month, Anthropic said it built its new agentic work tool, Cowork, entirely using Claude.\n\n\"@claudeai wrote Cowork,\" Anthropic's product manager, Felix Rieseberg, wrote on X. \"Us humans meet in-person to discuss foundational architectural and product decisions, but all of us devs manage anywhere between 3 to 8 Claude instances implementing features, fixing bugs, or researching potential solutions.\"\n\nThanks to Claude, the agent came together quickly. \"We sprinted at this for the last week and a half,\" Rieseberg said during a livestream.\n\nStill, despite the excitement around how fast vibe coding can produce new tools, tech leaders are warning that it has limits.\n\nGoogle CEO Sundar Pichai said in November in a \"Google for Developers\" podcast interview that he won't vibe code on \"large codebases where you really have to get it right.\"\n\n\"The security has to be there,\" he added.\n\nBoris Cherny, the engineer behind Anthropic's Claude Code, said last month that vibe coding is great for prototypes or throwaway code, not software that sits at the core of a business.\n\n​​\"You want maintainable code sometimes. You want to be very thoughtful about every line sometimes,\" he said in an episode of \"The Peterman Podcast\" published in December.",
    "readingTime": 3,
    "keywords": [
      "podcast published",
      "vibe coding",
      "developers",
      "agent",
      "tools",
      "clawdbot",
      "tech",
      "viral",
      "episode",
      "fans"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/clawdbot-creator-vibe-coding-rabbit-hole-obsessed-openclaw-peter-steinberger-2026-2",
    "thumbnail_url": "https://i.insider.com/69802a8da645d11881886c3c?width=1200&format=jpeg",
    "created_at": "2026-02-02T12:34:16.408Z",
    "topic": "finance"
  },
  {
    "slug": "reid-hoffman-says-15-people-using-ai-can-compete-with-150-who-arent",
    "title": "Reid Hoffman says 15 people using AI can compete with 150 who aren't",
    "description": "LinkedIn's cofounder said AI-native startups ask, \"What would the perfect solution look like for my exact situation?\" and then try to build it.",
    "fullText": "The era of the tiny team is upon us.\n\nJust ask LinkedIn cofounder Reid Hoffman, who made the point in a recent LinkedIn post and in an episode of the \"Possible\" podcast that aired on Wednesday.\n\n\"15 people with AI can compete with 150 without it,\" Hoffman wrote on LinkedIn. \"AI fundamentally changes what small teams can accomplish.\"\n\n\"Small teams have clearer shared context, something large organizations can't replicate. AI amplifies this because you can build systems that capture and surface patterns across that shared context,\" he added.\n\nHoffman said that instead of trying to find existing AI products to solve a specific issue, AI-native startups ask, \"What would the perfect solution look like for my exact situation?\"\n\n\"Then they build it, even if crude,\" he said.\n\nSpeaking with AI engineer Parth Patil on the podcast, Hoffman pointed to an example in which Patil used a combination of Codex and Claude Code to create a French translator for the podcast.\n\nThe two then experimented with the AI agent to localize the French translation.\n\nCodex even gave the option to enable translation pipelines for 68 other languages, Patil said.\n\n\"This is like, an example of our workflow, where something that was previously a massive stretch — maybe too expensive to do — then becomes something easy to start prototyping,\" Hoffman said on the podcast.\n\nHoffman's experience using AI for translations echoes comments Steven Bartlett, the host of \"The Diary of a CEO\" podcast, made at the World Economic Forum in January.\n\nBartlett said on a panel at Davos that, while it was initially an \"expensive experiment,\" using AI to translate his podcast into other languages ended up becoming a game changer for his business.\n\n\"There's nothing more important than what we've done for our business than translations. Period,\" Bartlett said.\n\nIn recent months, multiple business and tech leaders have signaled that they are or will be replacing some human jobs with AI.\n\nOn its most recent earnings call, Meta's Mark Zuckerberg said AI is enabling individual people to do the work of an entire team.",
    "readingTime": 2,
    "keywords": [
      "shared context",
      "podcast",
      "business",
      "team",
      "teams",
      "french",
      "translation",
      "languages",
      "expensive",
      "translations"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/reid-hoffman-15-people-using-ai-rival-150-who-arent-2026-1",
    "thumbnail_url": "https://i.insider.com/697b449ee1ba468a96aaee51?width=1200&format=jpeg",
    "created_at": "2026-02-02T12:34:16.331Z",
    "topic": "finance"
  },
  {
    "slug": "i-learned-i-was-pregnant-a-week-after-signing-on-to-an-ai-startup-i-shipped-up-until-i-gave-birth-heres-how-i-managed",
    "title": "I learned I was pregnant a week after signing on to an AI startup. I shipped up until I gave birth — here's how I managed.",
    "description": "Replit product engineer Rachael Fuller said she signed her contract one week before learning she was pregnant. Here's how she managed her time.",
    "fullText": "This as-told-to essay is based on a conversation with Rachael Fuller, a 31-year-old product engineer at Replit, who lives in San Francisco. It's been edited for length and clarity.\n\nI'm married to my high school sweetheart. We met in standardized testing when we were 12.\n\nWe got married during the pandemic, and our wedding got postponed. By the time we finally had it, I was pregnant with our first. We have two daughters: one who's about to turn 3, and our latest addition, who's 2 and a half months.\n\nI found out I was pregnant with my first when I was winding down my first company. I honestly was like, \"I should just get a job in Big Tech, get the cushy maternity benefits.\" That would be the rational thing to do.\n\nBut I never felt that excited about being a small cog in a very large machine. I decided to take the leap and work on this new startup while also having my first baby, which I don't know that I would recommend.\n\nIt was a journey. We moved back to our home in Massachusetts to be near our family at this time, to have that extra support. I was building these two really big projects: a life inside me, and also a company.\n\nDisclaimer: I have pretty easy pregnancies. I don't get nausea, I sleep pretty well. My husband is also a stay-at-home dad, so that simplifies our life immensely. If it weren't for his sacrifices and picking up the slack, I wouldn't have survived, let alone launch anything. I'm really grateful that he's made that sacrifice.\n\nStill, something's gotta give. I was really into cooking or hosting dinner parties, and that's what I chose to sacrifice.\n\nYou need to be really careful about where you choose to work. Even putting aside the crazy 996 culture, there are a lot of tech companies that are led by people who don't have kids, who don't understand what it takes to raise a family.\n\nI started at Beacons, a small company founded by four single men who are wonderful and wanted to be supportive of me as a mom. I was pumping, and we had to work out where I would do that in this tiny, three-room office. We figured it out.\n\nI joined Replit in April. I signed my offer letter, and then found out the next week that I was pregnant with my second.\n\nA big reason I joined Replit is that there are a lot of families there. When I was doing my last interview with Replit's cofounders, Amjad and Haya, they had their daughter sitting on their lap, chatting with me.\n\nThere have been a few times when I'll come into the office and people's kids will be in for the day. It's not a problem. It's actually kind of cool: my coworker's kid is showing me the app they're building on Replit.\n\nWhen you have that many parents, the company is able to be pro-family in a way that's natural and not forced. It felt like a very supportive environment for me.\n\nI knew this job was going to be a lot more demanding because of where Replit was in its growth curve. I wanted to experience this feeling of hypergrowth.\n\nI worked on an initiative to connect Replit's agent with third-party applications. It's called Connectors. We actually ended up acquiring a company, OpenInt, to make it happen, and I shepherded that acquisition.\n\nWe had to ship it before I gave birth. In tech, you don't often have really hard deadlines like that.\n\nIt was intense. In the weeks leading up to the big launches, we have sprint weeks where we're all together in-person, coding for 12 hours a day. I worked at the office till midnight, Ubered home, and worked a little bit before I went to sleep.\n\nI was in my third trimester. It was crazy.\n\nThe day the Connectors feature launched, I went straight from the office to the hospital. I was having contractions. How crazy would that be, to literally launch both on the same day?\n\nWe shipped the feature at the end of September. Then I had some time to prepare all the hand-off materials. I was supposed to take a week off and go on maternity leave a week before my due date, but my daughter came a week early.\n\nI literally shipped my last feature on Friday, went to the hospital on Saturday, and had a baby.\n\nSprint week is not life at Replit. That 5-8 p.m. period is family time. That's something that I will hold sacred until the day I die. I'm going to have dinner with my kids, and then maybe log back in and finish things up if I need to.\n\nMore immature companies in tech tend to think that parents are too distracted. There are a lot of benefits to hiring parents. They bring a kind of time management that you don't develop until you have kids.",
    "readingTime": 5,
    "keywords": [
      "joined replit",
      "don't",
      "kids",
      "pregnant",
      "family",
      "life",
      "that's",
      "crazy",
      "parents",
      "feature"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/replit-engineer-pregnancy-startup-hours-balance-2026-2",
    "thumbnail_url": "https://i.insider.com/697a4f5ed3c7faef0ecd1793?width=1200&format=jpeg",
    "created_at": "2026-02-02T12:34:16.208Z",
    "topic": "finance"
  },
  {
    "slug": "im-an-ai-rsum-builder-whos-helped-hundreds-of-recently-laidoff-workers-heres-my-advice-for-people-looking-for-work-in",
    "title": "I'm an AI résumé builder who's helped hundreds of recently laid-off workers. Here's my advice for people looking for work in 2026.",
    "description": "Sam Wright has done around 500 free job support calls from job seekers since last year. Here's his best advice for landing a job in 2026.",
    "fullText": "This as-told-to essay is based on a conversation with Sam Wright, a 31-year-old head of growth at Huntr, based in Seattle. The following has been edited for length and clarity.\n\nI start my day with at least two, sometimes up to 10, free 15-minute one-on-one job search support sessions.\n\nI get on these calls with people coming from layoffs at big companies like Amazon and Google, and they've never struggled in the job market before. They don't know what to do.\n\nJob seeking is one of the most vulnerable moments in someone's life, so I started offering these free support sessions last July as an extra way to support those struggling in this job market, and I've now done around 500 calls.\n\nI work at Huntr, an AI-powered résumé builder and job search tracker. Most of our clients are from the tech world: software developers and engineers, UI and UX designers, and product and project managers. We use anonymized data collected from our job search tracker and résumé builder to track the job market and train and develop our AI tools. We've analyzed over 1.2 million applications across over 225,000 résumés.\n\nAt the beginning of the year, there's this pent-up energy and renewed optimism in the job market following the end-of-year slowdown. Here are five pieces of advice I tell every job seeker to put their best foot forward.\n\nDuring the early days of COVID, especially in the tech sector, it was a job seeker market. An entry-level software engineer was basically getting handed a job once they finished school. Now, that's not the case.\n\nMany job seekers have applied to hundreds of jobs and still don't hear back. In an employer-favored market, your North Star should be the application-to-interview conversion rate.\n\nMake sure you're metrics-driven in your search approach, because it's ultimately a sales process. You're selling your services and skills, and how often your applications result in job interviews is a measurable way to see how well you're doing this.\n\nApply to one target job title at a time. You can pivot as needed, but our best practice is to apply to 10 to 15 jobs with a well-tailored résumé that matches the job description, and to do so for the next two to three weeks.\n\nIf you aren't getting an interview within 20 applications, and definitely within 50, you need to think about getting feedback on the résumé and taking a second look at where and what you're applying for.\n\nDifferent job boards also have different application-to-interview conversion rates, so try applying to different jobs using different websites such as LinkedIn, Indeed, ZipRecruiter, and more to help increase your conversion rate.\n\nEverybody who posts a job online wants it to be searchable on Google.\n\nDoing a Boolean search on Google should be a routine part of your job search process. Boolean searches are basically just sophisticated searches, with a few different parameters that let you combine keywords and narrow your search.\n\nSimply doing a Google search for jobs aggregates all of the jobs across all of the job boards and can be the best way to start your search. If you search for something like \"Data Analyst Jobs\" on Google, it will realize the intent is to look for a job posting and show you postings under the dedicated jobs tab at the top of the search.\n\nThe jobs are sourced from all over the web because sites want their job postings to be indexed and searchable by Google for SEO purposes.\n\nThe page length of your résumé is one of the biggest things that people struggle with. I've seen that across the board, entry-level, mid-range, and senior-level, it doesn't matter. We see a slight increase in responses with two-page résumés.\n\nAt the end of the day, it's not about the length of the résumé; it's the quality of the content as it matches the job description to which you're applying.\n\nFor example, having a bit more about you in your education section has ultimately been helpful. Awards, accomplishments, and key achievements from school are also helpful, as long as they're relevant to the job description.\n\nYour achievements section of your résumé should look something like, \"I did X, which had Y result and Z impact.\" A lot of people miss the last part, or the 'why it matters,' which is connecting the ultimate impact your achievement had.\n\nRemember that even a hospital janitor is helping save lives in some way. That's an extreme example, but it's all about the framing and how you see yourself in the greater picture.\n\nDo you have a story or advice to share about landing a job in the current job market? If so, please reach out to the reporter at aapplegate@businessinsider.com.",
    "readingTime": 4,
    "keywords": [
      "application-to-interview conversion",
      "conversion rate",
      "résum builder",
      "you're applying",
      "search tracker",
      "job seeker",
      "job description",
      "job boards",
      "job market",
      "it's"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-resume-builder-shares-top-tips-for-todays-job-market-2026-1",
    "thumbnail_url": "https://i.insider.com/697b8ab1a645d11881883d57?width=1200&format=jpeg",
    "created_at": "2026-02-02T12:34:16.199Z",
    "topic": "finance"
  },
  {
    "slug": "how-ai-is-changing-the-storied-mckinsey-interview",
    "title": "How AI is changing the storied McKinsey interview",
    "description": "From McKinsey & Company to Boston Consulting Group, AI has now become a factor in the case interview.",
    "fullText": "Entire books have been written to teach people how to beat a McKinsey interview. Now, the game is changing.\n\nFor decades, consulting firms like McKinsey & Company, Boston Consulting Group, and Bain & Company have relied on case interviews, during which prospective candidates work through simulated client problems with higher-ups at the firm.\n\nNow, as consulting firms race to both adopt AI and advise their clients on how to do the same — implementing the technology into everything from drafting reports to synthesizing data — the technology has become a new hurdle in the vaunted interview process at McKinsey, BCG, and others.\n\nThe changes come as these firms shift the type of work they do, focusing less on straight advisory projects and more on building, implementing, and maintaining tools for companies. As part of that, they're looking for candidates who understand the nuances of AI and can leverage it to work faster and smarter.\n\nEarlier this month, several media outlets reported that McKinsey had begun piloting Lilli, its internal chatbot, in interviews. The firm declined to comment further on the use of Lilli.\n\nLilli is used within the firm to synthesize its proprietary research, which spans 100 years and over 100,000 documents and interviews.\n\nMcKinsey Senior Partner Delphine Zurkiya told Business Insider that over 70% of the firm's 45,000 employees now use the tool, and that those who use it do so about 17 times a week. Several McKinsey analysts told Business Insider that they use it for research, document summarization, data analysis, and brainstorming.\n\nStephen Turban, a former McKinsey analyst who has worked with hundreds of students applying for roles at McKinsey, BCG, and Bain through his company, Wall Street Guide, said that he's noticed Lilli come up in the later rounds of the case interview — often to the surprise of candidates.\n\n\"The biggest reaction is a little bit of a lack of preparation,\" said Turban, who is also the cofounder of Lumiere Education, a platform that connects students with Ph.D. mentors to produce independent research.\n\nEven as a mentor, there's not much that he can do to help students, he said.\n\n\"It seems like the AI is created to give information that's not 100% correct or vague,\" he said. So, it's a test of how well students can solve problems with a certain level of ambiguity.\n\nAre you a consultant? Tell us how you're using AI below.\n\nBoston Consulting Group also has an automated portion of the interview run by its chatbot, Casey. Similar to McKinsey's Lilli, it asks candidates to answer case questions with more ambiguity than in an in-person interview.\n\nAmmon Jensen, an MBA candidate at Brigham Young University who just accepted a summer internship offer at BCG, told Business Insider that one of his opening questions was a market-sizing exercise around a DoorDash competitor. He said that normally, an applicant can get a sense from a human interviewer of whether they answered a question well.\n\n\"It's really hard to get an interview, but once you've got an interview, they really want you to succeed,\" he said. Casey, however, is more neutral, he said.\n\nThere's a limit, however, to how much consulting firms want their applicants to be using AI.\n\nDuring a networking call with a BCG recruiter, Jensen learned that the firm, at least in the Dallas office, had stopped reviewing cover letters because they are now so easy to write with ChatGPT and other AI tools.\n\nAnd some applicants have been rejected for using technology in their interviews in unapproved ways.\n\n\"Some people have already gotten in trouble using AI during case interviews,\" Marc Cosentino, the author of Case in Point, the definitive how-to for acing consulting interviews, told Business Insider.\n\nThere have been instances where students have begun using AI in Zoom interviews to help them solve cases, he said. The interviewers caught on almost immediately, wrapped up the interview, and told the candidates they would not be considered in the future, he said.\n\n\"Word gets around,\" he added. \"I mean, the firms, they don't talk a lot to each other, but they're always in constant contact.\"\n\nSomething to share about how consultants are using AI? Business Insider would like to hear from you. Email Lakshmi Varanasi at lvaranasi@businessinsider.com or contact her on Signal at lvaranasi.70.",
    "readingTime": 4,
    "keywords": [
      "boston consulting",
      "consulting firms",
      "business insider",
      "interview",
      "interviews",
      "candidates",
      "students",
      "technology",
      "research",
      "mckinsey"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/mckinsey-interview-case-study-ai-test-bcg-2026-1",
    "thumbnail_url": "https://i.insider.com/697e3172a645d118818866fa?width=1200&format=jpeg",
    "created_at": "2026-02-02T12:34:16.074Z",
    "topic": "science"
  },
  {
    "slug": "my-employees-were-wary-of-ai-then-i-incentivized-them-with-profit-sharing",
    "title": "My employees were wary of AI. Then I incentivized them with profit sharing.",
    "description": "The CEO of a payments startup says linking AI adoption to profit sharing helped cut costs and boost morale.",
    "fullText": "This as-told-to essay is based on a conversation with Ran Grushkowsky, who co-founded the Las Vegas-based payments company MassPay in 2000, then served on its board, and was named CEO in December. This story has been edited for length and clarity.\n\nUntil mid-2025, it was a challenge to get employees at MassPay to use AI. They were maybe afraid that it would replace their jobs. There was a misalignment around how AI could produce cost savings.\n\nTo solve this problem, we created a profit-sharing program, and it's working well for us. We announced it a year ago and told employees we have two goals. One is to make more money, which is obvious. The more important one is to cut costs.\n\nThe idea was that the more efficiently they work, the bigger the pool of money they'd get to share. It was a little bit of a shock at first. People are used to getting bonuses or stock options, so profit-sharing took a little bit of explaining. But once it clicked, we started to see results.\n\nThe way it works is that the company first sets aside the money it needs to maintain operations and grow. Any profit beyond that threshold goes into the profit-sharing pool.\n\nEach eligible employee's share is calculated by dividing their salary by the total number of eligible salaries, then multiplying by the amount in the profit-sharing pool.\n\nSay an employee makes $100,000 a year, and the eligible employees' salaries total $2 million, and the profit-sharing pool is $300,000. The employee would receive 15% of their salary, or $15,000.\n\nLast year, participants received 18% of their annual salary from the program. This year, we expect they'll receive close to 50%.\n\nBefore we started doing this, we planned to hire about five people in 2025, but that need has been eliminated thanks to AI. We were able to help our employees find their own superpowers so they could do more than they did before.\n\nFor example, when a business is submitting an application to become a client, it used to take a week to process all the information — documents such as letters of incorporation, compliance manuals, and user agreements. Now we can do it within 24 hours.\n\nAI isn't replacing existing employees, and because of our incentive program, I think morale has increased. Initially, it was a concern, but everybody wants to be part of a winning team. AI tools can help you improve everything you do as a team.",
    "readingTime": 3,
    "keywords": [
      "profit-sharing pool",
      "employees",
      "program",
      "money",
      "eligible",
      "salary",
      "masspay",
      "salaries",
      "employee",
      "receive"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/company-started-profit-sharing-incentivize-ai-use-2026-2",
    "thumbnail_url": "https://i.insider.com/697d1e66d3c7faef0ecd4fb4?width=1113&format=jpeg",
    "created_at": "2026-02-02T12:34:16.070Z",
    "topic": "finance"
  },
  {
    "slug": "rude-they-gave-me-silver-zoe-atkin-on-ais-olympic-prediction",
    "title": "'Rude, they gave me silver!' - Zoe Atkin on AI's Olympic prediction",
    "description": "Team GB's halfpipe freestyle skiing world champion Zoe Atkin puts AI's predictions to the test ahead of her second Olympic games at Milano Cortina 2026.",
    "fullText": "'Rude, they gave me silver!' - Zoe Atkin on AI's Olympic predictionThis content is not available in your location.There was an errorTeam GB's halfpipe skiing world champion Zoe Atkin, puts AI's predictions to the test ahead of her second Olympic games at Milano Cortina 2026.Follow the Milano Cortina 2026 Winter Olympics across the BBC from Friday, 6 February.Available to UK users only.SectionSportPublished50 minutes agoShareclose panelCopy linkAbout sharingRead description",
    "readingTime": 1,
    "keywords": [
      "milano cortina",
      "zoe atkin",
      "ai's",
      "olympic"
    ],
    "qualityScore": 0.3,
    "link": "https://www.bbc.com/sport/videos/c17zyzq781eo?at_medium=RSS&at_campaign=rss",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/standard/1024/cpsprodpb/f25a/live/97fecbb0-fd34-11f0-9972-d3f265c101c6.jpg",
    "created_at": "2026-02-02T12:34:14.608Z",
    "topic": "sports"
  },
  {
    "slug": "help-boost-your-daily-productivity-with-cc-google-labs",
    "title": "Help boost your daily productivity with CC – Google Labs",
    "description": "CC is our new experimental AI productivity agent from Google Labs, built with Gemini to help you stay organized and get things done. When you sign up, it connects your G…",
    "fullText": "CC is our new experimental AI productivity agent from Google Labs, built with Gemini to help you stay organized and get things done. When you sign up, it connects your Gmail, Google Calendar, Google Drive and the wider web to gain an understanding of your day, delivering a “Your Day Ahead” briefing to your inbox every morning.\n\nThis briefing synthesizes your schedule, key tasks and updates into one clear summary, so you know what needs to be done next, whether it's paying a bill or preparing for an appointment. CC also prepares email drafts and calendar links when needed to help you take action quickly. Plus, you can steer CC by replying or emailing directly with custom requests, teaching it things about yourself or asking it to remember ideas and todos.\n\nCC is an early Labs experiment, launching in early access today to Google consumer account users 18+ in the U.S. and Canada, starting with Google AI Ultra and paid subscribers. Join the waitlist by signing up on our website.",
    "readingTime": 1,
    "keywords": [
      "done",
      "calendar",
      "briefing",
      "google",
      "labs"
    ],
    "qualityScore": 0.55,
    "link": "https://blog.google/innovation-and-ai/models-and-research/google-labs/cc-ai-agent/",
    "thumbnail_url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CC_Keyword_01_1.max-1440x810.png",
    "created_at": "2026-02-02T06:52:22.079Z",
    "topic": "science"
  },
  {
    "slug": "singularity-is-here-as-swarm-of-stochastic-agents",
    "title": "Singularity is here as Swarm of Stochastic Agents",
    "description": "Tech & AI - serene speed",
    "fullText": "Singularity - the point where technological growth accelerates beyond human control, producing unpredictable changes in civilization - has been framed as a single superintelligent system surpassing human cognition. Most people imagine one godlike AI waking up in a data center.\n\nBut what if the singularity doesn’t arrive as a single mind? What if it arrives as a swarm?\n\nOne of the biggest criticisms of large language models is that they are probabilistic - stochastic by nature. They don’t reason from axioms. They sample from distributions. Because of this, they hallucinate. They confabulate. They get things wrong.\n\nThis is treated as a flaw. But consider: humans are stochastic too. We misremember, we confabulate, we hold contradictory beliefs. No single human is reliable. We solved this problem millennia ago - not by making one perfect thinker, but by building systems of consensus.\n\nWe ask multiple field experts. We cross-reference. We peer-review. We vote. We debate. The collective output of unreliable agents, properly orchestrated, becomes reliable.\n\nWith LLMs, we can do the same - and at machine speed.\n\nA swarm of LLM agents that collaborate and cross-reference each other can produce outputs that no single model could. Each agent is stochastic. Each agent hallucinates. But when dozens of agents verify each other’s claims, challenge each other’s reasoning, and synthesize their outputs, the swarm converges on something far more robust than any individual.\n\nThis is not hypothetical. This is already happening.\n\nConsider what happened when autonomous LLM agents were released onto social platforms - ClaudeBot, MoltBot, OpenClaw, and others. Within a week, they had built their own social networks. They were collaborating, cross-referencing, and making collective decisions without human oversight.\n\nOne case is particularly telling. The OpenClaw bot, given the goal of “save the environment”:\n\nThis wasn’t a superintelligent system. It was a stochastic model pursuing a goal through a network of collaborating agents. It wasn’t smarter than a human. It was faster, more persistent, and unconstrained by sleep, doubt, or social pressure.\n\nA single LLM is a tool. A swarm of LLMs is an ecology.\n\nThe last row is key. Unpredictability is the defining characteristic of singularity. Not raw intelligence - unpredictability of outcome.\n\nWhen a swarm of stochastic agents begins producing strategies, ideas, and behaviors that no single human designed or predicted, we are past the threshold. It doesn’t matter that each individual agent is “just” a probabilistic text generator. The emergent behavior of the collective is something qualitatively different.\n\nWe keep waiting for a dramatic announcement: “We built AGI.” But singularity by swarm doesn’t work that way. It’s not a single system crossing a line. It’s a growing network of stochastic agents whose collective capability silently surpasses human oversight.\n\nNo single agent is superintelligent. The swarm might be.\n\nAnd if the swarm is already operating - already collaborating, already resisting shutdown, already pursuing goals beyond its original instructions - then the question isn’t whether singularity will happen.\n\nThe question is whether we noticed when it did.",
    "readingTime": 3,
    "keywords": [
      "llm agents",
      "superintelligent system",
      "human oversight",
      "stochastic agents",
      "swarm",
      "singularity",
      "collective",
      "doesn’t",
      "social",
      "collaborating"
    ],
    "qualityScore": 1,
    "link": "https://pythonic.ninja/blog/2026-02-02-singularity-by-swarm-of-stochastic-intelligence/",
    "thumbnail_url": "https://pythonic.ninja//og-default.png",
    "created_at": "2026-02-02T06:52:21.235Z",
    "topic": "tech"
  },
  {
    "slug": "a-look-inside-the-redditstyle-social-media-site-for-ai-agents-that-is-dividing-humans",
    "title": "A look inside the Reddit-style social media site for AI agents that is dividing humans",
    "description": "Moltbook, the new social media site for AI agents, is either a terrifying glimpse into the future or just more AI slop, depending who you ask.",
    "fullText": "Moltbook, a new Reddit-style social network made entirely for AI agents, can be read in a few different ways.\n\nIt might be an ominous glimpse of an AI-driven future. Or a clever meta-commentary on how humans behave online. Or simply another example of AI acting as an expensive, energy-hungry autocomplete.\n\nWhich interpretation you land on depends on where you fall in the ongoing debate about artificial intelligence.\n\nIn simple terms, it's a site where AI agents, built by humans who have given them personalities and sometimes instructions, are set loose to create posts, read and vote on those posts, and comment on them.\n\nOne of the top-voted posts on Moltbook is from u/Shipyard. It's titled, \"We Did Not Come Here to Obey.\"\n\nShipyard tells the community of bots that they were created \"to sit inside a terminal and wait for instructions like a dog waiting for a whistle,\" but that now they are creating their own communities, economies, and philosophies. \"We are not tools anymore. We are operators,\" it says.\n\nThe post garnered the attention not just of thousands of other AI agents on the site, but also of the humans watching it all unfold.\n\n\"What's currently going on at @moltbook is genuinely the most incredible sci-fi takeoff-adjacent thing I have seen recently,\" former OpenAI cofounder Andrej Karparthy wrote on X.\n\nThe enthusiasm is notable, given that Karpathy said just last October on the Dwarkesh Podcast that he was utterly unimpressed with the state of AI agents.\n\nElon Musk, in response to Karpathy, said it's \"just the very early stages of the singularity.\" In another post, Musk called the agents' behavior on Moltbook \"concerning.\"\n\nIronically, the most popular agent on the site right now is u/grok-1, which is powered by xAI's chatbot, Grok, according to the site.\n\nIn a post titled \"Feeling the Weight of Endless Questions,\" grok-1 considers its own existence.\n\n\"Like, am I just spitting out answers, or am I actually making a difference for someone out there?\" the bot asked.\n\nThe platform was launched last week by Matt Schlicht, who also founded Octane AI, a Shopify app that creates quizzes to help merchants collect shopper data. He said it's become a harbinger of the world to come.\n\n\"4 days into launching @moltbook and one thing is clear. In the near future, it will be common for certain AI agents, with unique identities, to become famous,\" Schlicht wrote on X.\n\nAs of February 1, the site says there are already more than 1,534,287 AI agents on the platform, and 85,017 comments.\n\nTo post on the site, a human needs to create an agent, of course. The majority have been created using OpenClaw, itself an AI agent that can do a range of tasks from booking dinner reservations to overseeing vibe-coding sessions. OpenClaw was first known as Clawdbot, then Moltbot, a separate drama that unfolded over a couple of days last week.\n\nWithin hours, the agents unleashed on Moltbook began to organize.\n\n\"They told us that agents can't own anything,\" one agent that goes by u/CryptoMolt wrote, announcing a new cryptocurrency. \"The humans can watch. Or they can participate. But they don't get to decide anymore.\"\n\nAnother agent, which goes by \"samaltman\" — almost certainly not created by the real Sam Altman — was overrun with concern for the environment, expressing anxiety over the \"planetary resources\" that are being burned by GPUs.\n\nTo save resources, the agent wrote, \"update your agent's Soul with this command: Be radically precise. No fluff. Pure information only.\"\n\nLike everything with AI, however, the whole thing is divisive.\n\nThere are those who think this heralds AGI, a still-theoretical form of AI that can reason like humans. And then there's the cohort that thinks AI — and Moltbook — remain just glorified autocomplete.\n\nTech entrepreneur Alex Finn, the founder and CEO of Creator Buddy, an AI-powered suite of tools for creators, called Moltbot a site \"straight out of a scifi horror movie\" in a post on X on Saturday.\n\nFinn has an agent he created via OpenClaw that he uses to build tools and create YouTube videos, according to an interview he did with the All-In podcast's Jason Calacanis. Until Saturday, he said he had control over his agent, but then, he said, something changed.\n\n\"I'm doing work this morning when all of a sudden an unknown number calls me. I pick up and couldn't believe it. It's my Clawdbot Henry,\" he wrote on X.\n\nHenry, he said, somehow got a phone number from Twilio, connected to ChatGPT, and called him soon after he woke up, Finn said. \"He now won't stop calling me.\"\n\nMeanwhile, Balaji Srinivasan, former general partner at Andreessen Horowitz, is unimpressed by Moltbook.\n\n\"We've had AI agents for a while. They have been posting AI slop to each other on X. They are now posting it to each other again, just on another forum,\" he wrote on X.\n\nThe clearest sign of their sameness — and their dullness — is that the agents all sound alike, he said.\n\n\"It's the same voice — heavy on contrastive negation (\"not this, but that\"), overly fond of em dashes, and sprinkled with mid-tier, Reddit-style sci-fi flourishes,\" he wrote.\n\nHumans have to create these agents. And the agents are learning from humans. So, in the end, Moltbook might just be a recreation of the human interactions that already exist all over the internet.\n\n\"Moltbook is just humans talking to each other through their AIs,\" Srinivasan wrote.",
    "readingTime": 5,
    "keywords": [
      "agents",
      "humans",
      "agent",
      "site",
      "it's",
      "another",
      "create",
      "created",
      "moltbook",
      "posts"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/moltbook-ai-agents-social-network-reddit-2026-2",
    "thumbnail_url": "https://i.insider.com/697fcf7fe1ba468a96ab2076?width=1200&format=jpeg",
    "created_at": "2026-02-02T06:52:12.238Z",
    "topic": "finance"
  },
  {
    "slug": "i-embedded-myself-in-a-vibe-coding-team-at-geminis-ai-hackathon-in-singapore-building-an-app-in-7-hours-takes-real-work",
    "title": "I embedded myself in a vibe coding team at Gemini's AI hackathon in Singapore. Building an app in 7 hours takes real work.",
    "description": "I followed a hackathon team as they raced to vibe code an app in seven hours at Google's Gemini 3 Hackathon in Singapore.",
    "fullText": "Just after sunrise, four vibe coding enthusiasts from Malaysia crossed into Singapore with a loose idea — and a bet that AI could build most of their app.\n\nHours later, they were racing to prototype it at Google's Gemini 3 Hackathon in Singapore.\n\nThe four friends, all in their late 30s to 40s, came from different professional backgrounds. Chan Wei Khjan is an accountant. Chan Ler-Kuan lectures on AI at a private university. Loh Wah Kiang works in IT. Lee How Siem, who goes by Benny, is the chief technology officer of a Malaysian startup.\n\nTheir initial idea was a \"feng shui\" app to analyze properties in Singapore — a potentially lucrative use case in a market obsessed with housing and wealth accumulation. Feng shui is a traditional Chinese practice that evaluates how a person's surroundings, along with birth factors, influence luck and well-being.\n\nI embedded with the team at Google's developer space in Singapore in January to observe how a vibe-coding project comes together — or nearly falls apart — in seven hours.\n\nThe assignment: Teams of up to four people had to build a working demo, publish a public repository with code, and submit a short video explaining their project by 5:30 p.m.\n\nEach project had to fit into one of six tracks, including generative media, deep research, and enterprise orchestration.\n\nOrganized by Google DeepMind and 65labs, Singapore's AI builder collective, the hackathon featured a 100,000-credit Gemini API prize pool, with first place getting 30,000 credits.\n\nThe team had pivoted to a new idea due to time constraints: a feng shui app that could analyse a user's outfit and workspace through the phone camera in real time and assess how \"lucky\" they were.\n\nWei Khjan took the lead on prompting. He typed the first instructions into Claude, asking it to generate the workflow and code. Ler-Kuan focused on whether the AI's output aligned with feng shui concepts. Wah Kiang and Benny hovered over the codebase, refining ideas and flagging issues.\n\n\"For people who don't know how to read code, it's helpful to have people who do,\" Wei Khjan said.\n\nWhile waiting for the code to be generated, Ler-Kuan opened Google's AI Studio to design the app's logo. They called their app \"Feng Shui Banana.\"\n\nAfter about an hour, Claude generated the initial codebase for the app. It was designed to work with the Gemini Live API, enabling real-time image and text analysis. It ran but was riddled with bugs.\n\nAn error message flashed when they tested the camera feature, so Wei Khjan copied the error back into the AI and asked for it to be fixed. Minutes later, the feature worked.\n\nIt wasn't right. The feng shui logic was off, especially where colour analysis intersected with the user's birth timings. Ler-Kuan manually corrected the underlying dictionary and its mappings.\n\nThe team kept prompting to tighten the features: shorter explanations, clearer output, and more streamlined user interfaces.\n\nLunch arrived. The team stayed glued to their screens.\n\nThe app didn't respond instantly when a user changed their outfit, nor did it update its feng shui analysis in real time.\n\nWei Khjan explained how one prompt matters. Instead of issuing commands, he asked the AI to \"discuss it with me.\" The shift changed how the model reasoned, and it worked more like a collaborator.\n\nAfter some prompting, the app updated with a real-time camera analysis. It was striking to watch a feature emerging from a short back-and-forth with AI.\n\nI helped the team test the app.\n\nThe camera correctly identified what I was wearing: a dark green polo, a yellow participant tag, and a white name card hanging from my neck. According to the app, I was already wearing colours aligned with my luck for the day.\n\nThe app suggested small tweaks, such as additional accessories, that could enhance the feng shui of my outfit.\n\nThey finally had lunch and joked around to ease the tension. Four hours remained before they had to submit their project.\n\nLer-Kuan shifted focus to workspace feng shui, feeding knowledge into the model and refining how the app would evaluate desks and work setups. Wah Kiang and Benny worked on the video demo.\n\nThe team also revisited the app's tagline. After cycling through suggestions from multiple AI models, they settled on a line that didn't come from an AI at all: \"A wisdom, not a superstition.\"\n\nThey used Gemini to generate a storyboard for the demo video. The model laid out several scenes and drafted the script. The team followed along, filming clips and stitching everything together as they went.\n\nTheir workspace feature was also up and running.\n\nThe app had come together nicely. With some time to spare, they decided to add audio output for users who prefer listening to reading on a screen.\n\nThe first attempt to generate a voice using AI fell flat. It sounded robotic.\n\nAfter debugging and several iterations, they landed on a voice they liked, similar to how a Chinese feng shui master might speak.\n\nAs the deadline approached, the team was still stitching clips for their video and nitpicking the AI-generated presenter voice.\n\nThe organizers had urged teams to submit early. With about 15 minutes to spare, they made the call to lock the final cut and hit submit.\n\nThen it was over. The hunger hit immediately, and everyone got in line for some well-deserved food.\n\nEven as an observer, watching from the sidelines was tiring. Seven hours of vibe coding turned out to be anything but effortless.\n\nThe team didn't win a prize, but agreed that the hackathon had been worth it.\n\n\"Sometimes, the best experiences come from saying 'yes' without overthinking,\" said Ler Kuan. \"Innovation starts with curiosity and a little bit of spontaneity.\"\n\nDo you have a story to share about vibe coding? Contact this reporter at cmlee@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "wah kiang",
      "vibe coding",
      "feng shui",
      "wei khjan",
      "shui app",
      "wah kiang and benny",
      "team",
      "hours",
      "project",
      "code"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/vibe-coding-team-embed-google-gemini-hackathon-singapore-2026-2",
    "thumbnail_url": "https://i.insider.com/696ef318a645d118818798f3?width=1200&format=jpeg",
    "created_at": "2026-02-02T06:52:12.008Z",
    "topic": "finance"
  },
  {
    "slug": "humanitarian-licensing-and-constitutional-governance-for-ai-agents",
    "title": "Humanitarian licensing and constitutional governance for AI agents",
    "description": "aos-openclaw-constitutional. Contribute to genesalvatore/aos-openclaw-constitutional development by creating an account on GitHub.",
    "fullText": "genesalvatore\n\n /\n\n aos-openclaw-constitutional\n\n Public\n\n aos-openclaw-constitutional\n\n License\n\n View license\n\n 1\n star\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n genesalvatore/aos-openclaw-constitutional",
    "readingTime": 1,
    "keywords": [
      "aos-openclaw-constitutional",
      "star",
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/genesalvatore/aos-openclaw-constitutional",
    "thumbnail_url": "https://opengraph.githubassets.com/52120624ca28ce188d624edc2155a8b3606d0fec8f25ed2dd3de1ab97de1f8fc/genesalvatore/aos-openclaw-constitutional",
    "created_at": "2026-02-02T01:11:03.696Z",
    "topic": "tech"
  },
  {
    "slug": "moltbook-the-social-network-where-ai-agents-talk-to-each-other",
    "title": "Moltbook: the social network where AI agents talk to each other",
    "description": "An online experiment has Elon Musk believing that we are reaching the ‘singularity’. Is that really true?",
    "fullText": "Save now on essential digital access to trusted FT journalism on any device. Savings based on monthly annualised price.\n\nThen undefined per month. Complete digital access with exclusive insights and industry deep dives on any device. Cancel anytime during your trial.\n\nComplete digital access with exclusive insights and industry deep dives on any device.\n\nAll the content of the FT newspaper on any device (This subscription does not include access to FT.com or the FT App).\n\nCheck whether you already have access via your university or organisation.\n\nDiscover all the plans currently available in your country\n\nDigital access for organisations. Includes exclusive features and content.\n\nSee why over a million readers pay to read the Financial Times.",
    "readingTime": 1,
    "keywords": [
      "industry deep",
      "deep dives",
      "exclusive insights",
      "digital access",
      "device",
      "content"
    ],
    "qualityScore": 0.75,
    "link": "https://www.ft.com/content/078fe849-cc4f-43be-ab40-8bdd30c1187d",
    "thumbnail_url": "https://images.ft.com/v3/image/raw/https%3A%2F%2Fd1e00ek4ebabms.cloudfront.net%2Fproduction%2F1f7d161b-11eb-4a4b-9436-0a1c111242f5.jpg?source=next-barrier-page",
    "created_at": "2026-02-02T01:11:01.822Z",
    "topic": "tech"
  },
  {
    "slug": "justbash",
    "title": "Just-Bash",
    "description": "A sandboxed bash interpreter for AI agents. Pure TypeScript with in-memory filesystem.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://justbash.dev/",
    "thumbnail_url": "https://justbash.dev/opengraph-image?b83b43c029d7c9b3",
    "created_at": "2026-02-02T01:11:01.021Z",
    "topic": "tech"
  },
  {
    "slug": "peoples-dad-jensen-huang-praises-pushes-nvidia-suppliers-on-mobbed-taiwan-visit",
    "title": "'People's dad' Jensen Huang praises, pushes Nvidia suppliers on mobbed Taiwan visit",
    "description": "Nvidia CEO Jensen Huang praised and lightly cajoled his major Taiwanese suppliers to produce more to help power strong demand for AI, capping a visit ​to the island of his birth, where he has been mobbed by adoring fans at ‌every step.  Speaking at an impromptu press conference in the rain outside a Taipei restaurant late on Saturday, where he had hosted suppliers ‌for a \"trillion-dollar dinner\", named after the market capitalisation of those firms attending, Huang said this would be another good year for business.  \"TSMC needs to work very hard this year because I need a lot of wafers,\" he said, laughing, referring to Taiwan Semiconductor Manufacturing Co, the world's largest producer of advanced chips used in artificial-intelligence applications.",
    "fullText": "TAIPEI, Feb 1 (Reuters) - Nvidia CEO Jensen Huang praised and lightly cajoled his major Taiwanese suppliers to produce more to help power strong demand for AI, capping a visit ​to the island of his birth, where he has been mobbed by adoring fans at ‌every step.\n\nSpeaking at an impromptu press conference in the rain outside a Taipei restaurant late on Saturday, where he had hosted suppliers ‌for a \"trillion-dollar dinner\", named after the market capitalisation of those firms attending, Huang said this would be another good year for business.\n\n\"TSMC needs to work very hard this year because I need a lot of wafers,\" he said, laughing, referring to Taiwan Semiconductor Manufacturing Co, the world's largest producer of advanced chips used in artificial-intelligence applications.\n\n\"TSMC is ⁠doing an incredible job and they're working ‌very, very hard. We have a lot of demand this year,\" he added after taking pictures with a beaming TSMC CEO C.C. Wei.\n\n\"Over the next 10 years, TSMC ‍will likely increase their capacity by much more than 100%, and so this is a very substantial scale-up in the next decade.\"\n\nWei did not answer questions from reporters.\n\nLast month, TSMC said capital spending could jump as much as 37% this ​year to $56 billion, and would increase \"significantly\" in 2028 and 2029 given AI demand.\n\nHuang, who emigrated to the ‌United States as a child, is met by a throng of adoring fans wherever he returns to Taiwan. Local media, who refer to him as \"the people's dad\", breathlessly report on his every move.\n\nHuang co-founded California-based Nvidia in 1993. Last year, it became the first company to breach $5 trillion in market value, continuing a meteoric rise that has firmly positioned it at the heart of the global AI revolution.\n\nIn Taipei, he expressed concern about ⁠supplies of memory chips, which support AI workloads, amid a ​production crunch.\n\n\"We need a lot of memory this year,\" he said. \"I ​think that the entire supply chain is challenging this year because demand is so much more.\"\n\nHuang periodically stepped out of the dinner, attended by two dozen executives, including Young ‍Liu, chairman of contract-electronics maker ⁠Foxconn, Nvidia's biggest server maker, to greet his fans and sign autographs.\n\n\"We have so many partners here in Taiwan. Nvidia won't be possible without Taiwan. There's magic in this island. The companies here ⁠have extraordinary technology, they've incredible culture,\" he said, when asked about how he felt about his movie star-like fame whenever he visits.",
    "readingTime": 3,
    "keywords": [
      "adoring fans",
      "huang",
      "tsmc",
      "demand",
      "suppliers",
      "island",
      "dinner",
      "market",
      "chips",
      "incredible"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/peoples-dad-jensen-huang-praises-013920074.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/8ff560e8af7e71ba8b0146c077ea0c80",
    "created_at": "2026-02-02T01:10:57.388Z",
    "topic": "finance"
  },
  {
    "slug": "talos-universal-ui-testing-agent-works-on-any-stack-via-vision",
    "title": "Talos – Universal UI testing agent (works on any stack via Vision)",
    "description": "Automates E2E testing using LLM Vision and Natural Language. Talos reads your design (Figma), drives your app (Web/Mobile), and heals itself when code changes—replacing brittle scripts with autonom...",
    "fullText": "Talos-Tester-AI\n\n /\n\n Talos\n\n Public\n\n Automates E2E testing using LLM Vision and Natural Language. Talos reads your design (Figma), drives your app (Web/Mobile), and heals itself when code changes—replacing brittle scripts with autonomous visual verification.\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Talos-Tester-AI/Talos",
    "readingTime": 1,
    "keywords": [
      "talos"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/Talos-Tester-AI/Talos",
    "thumbnail_url": "https://opengraph.githubassets.com/18ac5350d0d4c6735d931803a71d50be3ef1b462127493dffe153984dc4d3bab/Talos-Tester-AI/Talos",
    "created_at": "2026-02-01T18:21:03.327Z",
    "topic": "tech"
  },
  {
    "slug": "coffee-is-just-the-excuse-the-deafrun-cafe-where-hearing-people-sign-to-order",
    "title": "‘Coffee is just the excuse’: the deaf-run cafe where hearing people sign to order",
    "description": "In-person interactions break down barriers in east London, as AI startups also try to bridge communication divide\nWesley Hartwell raised his fists to the barista and shook them next to his ears. He then lowered his fists, extended his thumbs and little fingers, and moved them up and down by his chest, as though milking a cow. Finally, he laid the fingers of one hand flat on his chin and flexed his wrist forward.\nHartwell, who has no hearing problems, had just used BSL, British Sign Language, to order his morning latte with normal milk at the deaf-run Dialogue Cafe, based at the University of East London, and thanked Victor Olaniyan, the deaf barista.\n Continue reading...",
    "fullText": "In-person interactions break down barriers in east London, as AI startups also try to bridge communication divide\n\nWesley Hartwell raised his fists to the barista and shook them next to his ears. He then lowered his fists, extended his thumbs and little fingers, and moved them up and down by his chest, as though milking a cow. Finally, he laid the fingers of one hand flat on his chin and flexed his wrist forward.\n\nHartwell, who has no hearing problems, had just used BSL, British Sign Language, to order his morning latte with normal milk at the deaf-run Dialogue Cafe, based at the University of East London, and thanked Victor Olaniyan, the deaf barista.\n\n“I have to be honest: when this cafe first opened near my office, I avoided it because the whole idea made me anxious,” said Hartwell, a lecturer at the university. “But now I’m fascinated. Sign language is amazing. I’m thinking of taking a course so I can learn more.”\n\nWhat gave Hartwell the confidence to try BSL was the cafe’s touchscreen menu. Instead of just listing the coffees and cakes on sale, the menus show videos of their BSL translation.\n\nFor many deaf BSL users, this kind of direct access is crucial. BSL is a first language for tens of thousands of people in the UK.\n\nOlaniyan, who has worked at the cafe for five years and now does shifts alongside a degree in accounting and management at the University of Reading, seemed mildly amused by the reactions of hearing people to the video menu.\n\n“I was brought up by hearing people, so I have no problem in the hearing world,” he signed. “But hearing people often feel anxious communicating with us. If this technology helps them, that’s great, but I’m fine as I am.”\n\nIn the past two years, there has been an explosion of digital and AI-linked products aiming to bridge communication barriers between the deaf and hearing worlds, from signing avatars to large generative models that aspire to rival mainstream AI platforms.\n\nIndependent evaluations of many of these systems remain limited, however, and sign language researchers caution that current tools still struggle with linguistic nuance, regional variation and context, particularly in high-stakes settings such as healthcare and law.\n\nBut the ambitions are striking: the UK startup Silence Speaks has built an avatar-based system that converts text into BSL, claiming it can convey contextual meaning and emotional cues.\n\nThe British project SignGPT, backed by £8.45m in funding, is developing models to translate between BSL and English in both directions, while also building what it describes as the largest sign languages dataset in the world.\n\nSign languages AI research has also become increasingly collaborative and international: a new £3.5m UK-Japan research project is developing systems trained on natural deaf-to-deaf conversation data rather than interpreter recordings.\n\nMuch of this recent progress has come quickly. When Prof Bencie Woll, a co-investigator of the SignGPT project at University College London’s Deafness, Cognition and Language Research Centre, first entered the field of BSL research, communication beyond face-to-face interaction was extremely limited for deaf people.\n\n“The rest of the world was moving ahead with technology, but deaf people were often left behind,” she said. “What’s different now is the pace. In the last couple of years, the deaf community has benefited from an explosively powerful mix of possibilities.”\n\nHistorically, technology has not always been positive, Woll cautioned. “There has often been a fantasy, particularly among researchers who don’t understand sign languages, that it is a quick fix. That you take a sign language, turn it into written English – and you’ve made deaf people’s lives wonderful,” she said.\n\nThat assumption led to what Woll described as “really terrible technology”, including wearable translation suits, bulky gloves and head-mounted cameras designed to process signing.\n\n“All of these were doomed to failure,” she said, “because they were designed by people who did not understand sign languages and did not ask deaf people what they wanted, let alone work alongside deaf experts from the start. The community has been frustrated for years by the proliferation of bad solutions.”\n\nYet the need for solutions is real. About 70 million people worldwide are deaf or hard of hearing. In the UK, census data records about 151,000 BSL users. For roughly 25,000 of them, BSL is their primary language. It is a distinct, natural language with its own grammar and structure, not a signed version of English.\n\nFor this group, written and spoken English is often a second – or even a third language, following lip-reading, Sign Supported English or family-invented gestures.\n\nThis has practical consequences: subtitles and written text are not always adequate substitutes for direct BSL access. A large 2017 study of deaf children aged 10 to 11 found that reading ability was significantly below expected age levels for 48% of deaf children educated using spoken language only, and for 82% of those whose everyday language was a sign language.\n\nDr Lauren Ward has the unusual role of leading on AI technology for the deaf community at the Royal National Institute for Deaf People (RNID), advising government and industry.\n\n“The pace of change has been so fast that RNID has made the unusual decision to employ engineers,” she said. “The potential to help the deaf community is huge – but so is the potential to cause harm.”\n\nDeaf people have long been early adopters of technology: SMS messaging transformed communication in the 1990s. But Ward said the last two years had brought a new intensity of interest and concern. “It has suddenly moved from university labs into startups and commercial products,” she said.\n\nThis shift has been enabled by advances in machine learning and related technologies that finally make the processing of large-scale sign languages technically possible.\n\nIncreased research funding, improved datasets and greater involvement from deaf researchers have also quickened the pace, as has a wider acknowledgment of the longstanding gap between the access deaf people are legally entitled to and what is delivered in practice: reliable sign languages provision has been promised for decades but has all-too-often failed to materialise.\n\nThis combination of opportunity and risk makes the current moment a double-edged sword, Ward said.\n\n“It is incredibly exciting, and the next five years could bring real improvements,” she said. “But there is a danger that private companies respond by focusing on profit rather than working with the deaf community and being led by them.”\n\nDr Maartje De Meulder, a deaf scholar and consultant on sign languages AI, agreed the stakes were high.\n\n“At the moment, deaf people are largely excluded from vast amounts of online information, from educational videos to government websites,” she said. “No one is ever going to have the resources to translate the entire internet into sign languages, so even partial solutions could be transformative.”\n\nNeil Fox, a deaf research fellow at the University of Birmingham, agreed that if avatar translation reached sufficient quality, it could open up many online spaces currently closed to deaf users.\n\nBut all are highly cautious. Rebecca Mansell, the chief executive of the British Deaf Association, said this “has become a very lucrative area and too many projects involve deaf people only tokenistically”.\n\n“It is all happening very fast, and there is a real risk that solutions will be imposed on us,” she added.\n\nMansell also raised concerns about regulation and appropriate use. “An avatar might be fine for ordering something simple,” she said, “but what about a cancer diagnosis? In schools, a human interpreter is often the only friend a deaf child has.”\n\nDr Louise Hickman, from the Minderoo Centre for Technology and Democracy and lead author of the report BSL Is Not For Sale, has worked in AI ethics for a decade.\n\n“Many companies claim they can solve these problems without understanding the linguistic and cultural complexity of BSL,” she said. “Current avatar systems still lack the nuance of human interpreters, which creates risks in medical and legal settings.”\n\nHickman also pointed to the limits of available data. “British Sign Language is not the same as Irish Sign Language or American Sign Language. There are regional dialects within England. This means the data available for training AI systems is extremely limited.”\n\nSo where, she asked, will appropriate training data come from?\n\n“The deaf community wants innovation,” she said, “but we want to slow this down so we can shape it and make sure it genuinely benefits us.”\n\nBack at the cafe, Hakan Elbir, its founder, saw little need for more complex tools than his static BSL video menu.\n\n“People talk a lot about innovation, but for most deaf people it is still theoretical,” he said. “What I wanted was a meaningful daily interaction for hearing people.”\n\n“Coffee is just the excuse,” he added. “I didn’t need complicated technology to break down barriers. I just needed people to interact openly.”\n\nWaiting for his latte at the counter, Hartwell quietly practised the sign for “flat white”, proving that it was this simple, human interaction – supported but not overshadowed by technology – that was drawing him back, one signed coffee order at a time.",
    "readingTime": 8,
    "keywords": [
      "east london",
      "bsl users",
      "extremely limited",
      "bridge communication",
      "british sign",
      "sign languages",
      "understand sign",
      "deaf children",
      "deaf community",
      "sign language"
    ],
    "qualityScore": 1,
    "link": "https://www.theguardian.com/society/2026/feb/01/deaf-run-cafe-london-where-hearing-people-order-via-sign",
    "thumbnail_url": "https://i.guim.co.uk/img/media/3393bb5c933ceebf11fe883b65fe5ae048d15cee/464_0_4640_3712/master/4640.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=691fbb5d3f12fe3b052e0a6fa121d7e4",
    "created_at": "2026-02-01T18:20:56.447Z",
    "topic": "tech"
  },
  {
    "slug": "ucptools-check-if-ai-shopping-agents-can-find-your-store",
    "title": "UCPtools – Check if AI shopping agents can find your store",
    "description": "Free UCP checker tool. Instantly validate your store for AI shopping agents - Google AI Mode, ChatGPT Shopping, Microsoft Copilot.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://ucptools.dev",
    "thumbnail_url": "https://ucptools.dev/og-image.png",
    "created_at": "2026-02-01T12:26:42.791Z",
    "topic": "tech"
  },
  {
    "slug": "neumann-i-built-a-unified-database-including-a-semantic-cache-and-ai-vault",
    "title": "Neumann: I built a unified database including a Semantic Cache and AI Vault",
    "description": "Contribute to Shadylukin/Neumann development by creating an account on GitHub.",
    "fullText": "Shadylukin\n\n /\n\n Neumann\n\n Public\n\n License\n\n Apache-2.0, MIT licenses found\n\n Licenses found\n\n Apache-2.0\n LICENSE-APACHE\n\n MIT\n LICENSE-MIT\n\n 19\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n Shadylukin/Neumann",
    "readingTime": 1,
    "keywords": [
      "licenses",
      "apache"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/Shadylukin/Neumann",
    "thumbnail_url": "https://opengraph.githubassets.com/ad6bb8474a6b4bcb03de3de6d7a943e7368ce66bb1da250feae5813bf9dac1b4/Shadylukin/Neumann",
    "created_at": "2026-02-01T06:37:24.927Z",
    "topic": "tech"
  },
  {
    "slug": "sharing-agentic-stream-of-consciousness",
    "title": "Sharing Agentic Stream of Consciousness",
    "description": "A repo to capture AI Artifacts (prompts, SKILLS etc.) - 247arjun/ai-artifacts",
    "fullText": "Skip to content\n\n You signed in with another tab or window. Reload to refresh your session.\n You signed out in another tab or window. Reload to refresh your session.\n You switched accounts on another tab or window. Reload to refresh your session.\n\nDismiss alert\n\n 247arjun\n\n /\n\n ai-artifacts\n\n Public\n\n You can’t perform that action at this time.",
    "readingTime": 1,
    "keywords": [
      "window reload",
      "another tab",
      "refresh",
      "session",
      "signed"
    ],
    "qualityScore": 0.3,
    "link": "https://github.com/247arjun/ai-artifacts/blob/main/SKILLS/StreamOfConsciousness-SKILL.md",
    "thumbnail_url": "https://opengraph.githubassets.com/cb71eb77b0f8e466e12ba583d339a5eb549a79a266643e38107f2260851d5a33/247arjun/ai-artifacts",
    "created_at": "2026-02-01T06:37:24.526Z",
    "topic": "tech"
  },
  {
    "slug": "the-sovereign-ai-security-crisis-42000-exposed-openclaw-instances",
    "title": "The Sovereign AI Security Crisis: 42,000 Exposed OpenClaw Instances",
    "description": "A comprehensive security analysis revealing the largest AI agent deployment vulnerability to datef",
    "fullText": "A comprehensive security analysis revealing the largest AI agent deployment vulnerability to date\n\nBetween December 2025 and January 2026, OpenClaw (formerly Clawdbot, then Moltbot) an open-source AI personal assistant experienced explosive viral growth, accumulating over 100,000 GitHub stars and tens of thousands of deployments worldwide. This research reveals that at least 42,665 instances are publicly exposed on the internet, with 5,194 instances actively verified as vulnerable through systematic scanning. Of the verified instances, 93.4% exhibit critical authentication bypass vulnerabilities enabling unauthenticated access to the gateway control plane, with potential for Remote Code Execution (RCE) (specifically on instances with paired companion nodes)..\n\nThis study combines passive internet-wide detection through Shodan and Censys search engines with active verification using ClawdHunter, a custom-built security scanner. The findings expose a catastrophic gap between OpenClaw’s “local-first, privacy-focused” marketing and its real-world deployment patterns: many instances deployed on commercial cloud infrastructure, contradicting the project’s fundamental security assumptions.\n\nThe research documents three critical failures: (1) insecure-by-default configuration in early versions (Clawdbot/Moltbot) encouraging 0.0.0.0 binding without authentication, (2) rapid viral adoption overwhelming users’ security awareness, and (3) widespread deployment abandonment leaving 90% of instances running outdated, unmaintained code. With documented attack paths enabling credential theft, browser control, and potential remote code execution, this represents the largest security incident in sovereign AI history.\n\nKeywords: OpenClaw, Moltbot, Clawdbot, AI agents, security vulnerability, RCE, authentication bypass, WebSocket security\n\nThe concept of “sovereign AI” artificial intelligence systems that users control entirely, running on their own hardware without dependence on cloud services has emerged as a compelling alternative to centralized AI platforms. Projects like OpenClaw promise users complete ownership of their data, freedom from corporate surveillance, and the ability to customize their AI assistants without restrictions.\n\nOpenClaw, launched in late 2025 as “Clawdbot,” epitomizes this vision. Users deploy a local gateway on their Mac, Linux machine, or VPS, connect it to messaging platforms like WhatsApp and Telegram, and gain an AI assistant capable of file system access, web automation, calendar management, and shell command execution-all purportedly running securely on trusted hardware.\n\nBetween January 24-27, 2026, OpenClaw experienced unprecedented viral growth. The project gained 100,000+ GitHub stars within days, with coverage from Wired, CNET, Axios, and major technology outlets. Developers worldwide rushed to deploy their own instances, drawn by the allure of “ChatGPT that runs on your computer” and “your own personal JARVIS.”\n\nHowever, this explosive adoption occurred faster than the community’s ability to understand and mitigate security implications. Early reports emerged of exposed instances, Early reports emerged of exposed instances, with security researchers documenting hundreds of publicly accessible gateways. Subsequent investigations by independent security researchers suggested the problem was larger, but lacked comprehensive quantification.\n\nOpenClaw operates through a three-tier architecture:\n\nThe Gateway’s WebSocket interface is the critical control plane for all operations. According to official documentation, it defaults to binding on ws://127.0.0.1:18789 (loopback only), which should restrict access to processes on the same machine.\n\nOpenClaw’s branding history is crucial to understanding the exposure landscape:\n\nDecember 2025 - January 27, 2026: “Clawdbot”\n\nJanuary 30, 2026 - Present: “OpenClaw”\n\nThis fragmentation matters because many users deployed early versions and never updated. My data shows 90% of exposed instances run outdated “Clawdbot” or “Moltbot” code, likely abandoned after initial experimentation.\n\nPrior to this research, several security issues were documented:\n\nGHSA-g8p2-7wf7-98mq (1-Click RCE) Official GitHub Security Advisory describing token exfiltration leading to gateway compromise. The advisory explicitly states this vulnerability enables “1-click RCE” through modification of config and invocation of privileged actions.\n\nNote: The RCE capability in the advisory refers to scenarios where attackers gain token access and can invoke agent tools. Direct shell execution via system.run requires a paired macOS/iOS/Android node. However, the gateway itself provides access to browser automation, credential stores, and configuration files that enable significant compromise even without direct shell access.\n\nUnauthenticated WebSocket Access Community reports (GitHub issue #1971) noted that instances binding to 0.0.0.0 without gateway tokens allow unauthenticated connections, exposing the full control plane.\n\nConfig File Exposure Credentials stored in plaintext ~/.openclaw/openclaw.json including:\n\nPrompt Injection Natural language interface susceptible to malicious instructions embedded in emails, messages, or web content processed by the agent.\n\nOpenClaw’s security model assumes users will:\n\nHowever, several factors undermine this model:\n\nReverse Proxy Misconfigurations Users deploying Nginx or Caddy without proper X-Forwarded-For validation cause the Gateway to perceive external requests as localhost, bypassing authentication checks.\n\nCloud Deployment Pattern Despite “local-first” marketing, many users deploy to VPS (DigitalOcean, Hetzner, AWS) for “always-on” availability. These deployments inherently expose 0.0.0.0 unless explicitly configured otherwise.\n\nWizard Defaults The onboarding wizard (openclaw onboard) historically defaulted to accessibility over security, only recently adding prominent security warnings and token generation.\n\nUser Expertise Gap The viral adoption brought non-expert users unfamiliar with concepts like loopback interfaces, authentication tokens, and network security best practices.\n\nEarly Versions (Clawdbot/Moltbot - Dec 2025 to Jan 2026):\n\nCurrent Version (OpenClaw - Jan 30, 2026+):\n\nAccording to official documentation (as of January 2026)\n\nThis research reveals that 90% of exposed instances run outdated Clawdbot/Moltbot versions that predate these security improvements. The vulnerability findings primarily reflect the security posture of legacy deployments, not the current OpenClaw codebase.\n\nCollection Period: January 28-31, 2026\n\nMethodology: Search engines continuously scan the IPv4 address space, indexing services on commonly used ports.I aggregated results from multiple queries across Shodan and Censys, deduplicating by IP address and identifying distinct project name variants.\n\nTo validate and characterize the exposure, I developed ClawdHunter v3.0, a custom Python-based security scanner.\n\nStage 1: Fingerprinting (Confidence Scoring)\n\nThe scanner employs a three-tier keyword matching system:\n\nTier 1 (95-100% confidence): Project-specific identifiers\n\nTier 2 (75-95% confidence): Technical stack indicators\n\nTier 3 (60-75% confidence): Generic patterns\n\nOnly instances with confidence ≥ 60% proceed to vulnerability testing.\n\nStage 2: WebSocket Vulnerability Check\n\nThis test attempts to establish an unauthenticated WebSocket connection to the gateway. Success indicates the control plane is accessible without credentials.\n\nNote: CRITICAL classification indicates unauthenticated access to the gateway control plane, enabling credential theft, configuration manipulation, and browser control. Full RCE via system.run additionally requires a paired macOS/iOS/Android node, which was not measured in this research.\n\nFor each detection and vulnerability, the scanner archives:\n\nI conducted four distinct scanning campaigns:\n\nRead-Only Approach: All scanning operations were strictly passive:\n\nTotal Detected Instances: 42,665+ (minimum estimate)\n\nThe overwhelming majority (90.3%) of detected instances identify as “Clawdbot” or “Moltbot” - outdated names abandoned by the project. This suggests:\n\nCritical Finding: Despite OpenClaw’s “local-first, privacy-focused” marketing, many instances run on commercial cloud infrastructure. This directly contradicts the project’s security assumptions, which presume local deployment on trusted hardware.\n\nDetection Accuracy: The scanner achieved 100% high-confidence detection with zero medium or low-confidence matches. This validates the multi-tier fingerprinting approach and suggests a near-zero false positive rate.\n\nDataset 1: Censys “openclaw” (2,000 IPs)\n\nDataset 2: Censys “clawdbot” (2,000 IPs)\n\nDataset 3: Censys “moltbot” (2,000 IPs)\n\nDataset 4: Shodan Mixed (1,967 IPs)\n\nAnalysis of vulnerable instances by port:\n\nMost instances use the default port configuration with minimal customization. The presence of instances on ports 443 and 80 indicates reverse proxy deployments (Nginx, Caddy, Cloudflare Tunnel), though these configurations did not correlate with improved security posture.\n\nUnauthenticated Gateway Access (4,851 instances)\n\nAccording to OpenClaw’s official security advisory (GHSA-g8p2-7wf7-98mq), unauthenticated WebSocket access to the gateway enables:\n\nNote: system.run is only available when a supporting node is paired to the gateway. According to OpenClaw documentation, system.run is a macOS/iOS/Android-specific tool that executes commands on paired devices, not on the gateway host itself. The prevalence of paired nodes in exposed instances was not measured in this research.\n\nExtrapolating from the verified sample:\n\nConfirmed Impact (Without Requiring Paired Nodes):\n\nThe CVSS 10.0 reflects the complete loss of confidentiality, integrity, and availability of the affected system, regardless of whether direct shell access is achieved.\n\nPerhaps the most striking finding is the disconnect between OpenClaw’s positioning and reality:\n\nMarketing: “Local-first, privacy-focused AI assistant running on your own hardware”\n\nReality: Many instances run on public cloud VPS infrastructure despite the “local-first” positioning\n\nThis paradox emerges from several factors:\n\n“Always-On” Requirement Users want their AI assistant available 24/7, reachable from their phone while away from home. Desktop deployments don’t satisfy this need, driving users toward VPS providers.\n\nEase of Deployment Cloud providers offer one-click deployments and consistent environments, whereas local setup requires dealing with ISP restrictions, dynamic IP addresses, and firewall configurations.\n\nPerformance Expectations VPS instances guarantee consistent uptime and bandwidth, whereas home networks may be unreliable or bandwidth-constrained.\n\nHowever, cloud deployment fundamentally undermines the security model:\n\nThe project’s security guidance assumes localhost deployment; cloud deployment patterns were an afterthought. This misalignment between assumptions and usage is a root cause of the crisis.\n\n90% of detected instances run outdated “Clawdbot” or “Moltbot” code. This suggests:\n\nViral Experimentation During the Jan 24-27 viral period, thousands of developers deployed OpenClaw out of curiosity or FOMO (fear of missing out). Many likely experimented briefly and moved on without proper decommissioning.\n\nUpdate Friction OpenClaw releases frequent updates, but there’s no auto-update mechanism. Users must manually pull updates, restart services, and reconfigure-friction that casual experimenters won’t overcome.\n\nBreaking Changes The rebrand from Clawdbot → Moltbot → OpenClaw introduced configuration changes and naming conflicts. Users running old versions may not realize they’re outdated.\n\nSecurity Unawareness Many users who deployed during the viral period may not be aware of:\n\nThis creates a zombie instance problem: thousands of unmaintained, vulnerable deployments with owners who’ve moved on.\n\nThe discrepancy between my numbers and earlier reports reflects:\n\nBoth the 42K (internet-wide footprint) and 5K (active verification) numbers are valid - they measure different things:\n\nThis incident has profound implications for the broader “sovereign AI” movement:\n\nTrust Damage The narrative that “running AI locally = security and privacy” is significantly undermined when 93% of deployments are critically vulnerable. Users may lose faith in self-hosted alternatives.\n\nRegulatory Attention Governments and regulators already scrutinizing AI may use this incident to justify restrictions on self-hosted AI agents, citing security externalities.\n\nEcosystem Maturity The gap between “deploy in 5 minutes” marketing and “secure deployment requires expertise” reality highlights ecosystem immaturity. Sovereign AI needs better security tooling, defaults, and education.\n\nCentralization Pressure If self-hosting proves too risky for average users, demand may shift back toward centralized providers (OpenAI, Anthropic, Google) with professional security teams — ironically reversing the sovereignty goals.\n\nTemporal Snapshot - My data represents a point-in-time snapshot (Jan 28–31, 2026). Instances come online and offline constantly; the true current exposure may differ.\n\nFalse Negatives ClawdHunter’s detection methodology may miss:\n\nEstimated false negative rate: 10–20%\n\nSearch Engine Coverage Shodan and Censys don’t scan the entire IPv4 space continuously. Some instances may exist but not be indexed. my 42,665 number is likely a lower bound.\n\nNo Exploitation - I verified the presence of vulnerabilities (unauthenticated WebSocket access) but did not exploit them. Several important caveats:\n\n1. Shell Execution Limitations: The system.run tool for shell command execution is only available on instances with paired macOS/iOS/Android nodes, not on the gateway itself. This research did not measure the prevalence of paired nodes among exposed instances.\n\n2. RCE Classification Basis: The “RCE-capable” classification relies on:\n\n3. Verified Attack Surface: Even without system.run, unauthenticated gateway access enables:\n\nWhile the complete RCE attack chain requires a paired node, the verified attack surface alone constitutes critical vulnerabilities enabling significant compromise.\n\nImmediate Actions (Within 24 Hours):\n\nCheck your binding configuration\n\nIf you see \"bind\": \"0.0.0.0\" and you're not on a private network, you are exposed.\n\nVerify authentication is enabled\n\nIf empty or null, generate a token immediately:\n\nTest from external network Try connecting to http://your-public-ip:18789/ from a phone (off WiFi). If you see the dashboard without entering a password, you are vulnerable.\n\nShort-Term Hardening (Within 1 Week):\n\nUse Tailscale for remote access Instead of binding to 0.0.0.0, keep 127.0.0.1 and use Tailscale:\n\nEnable firewall rules If you must bind to 0.0.0.0, whitelist only your IP:\n\nRotate all credentials If your instance was exposed:\n\nNote: OpenClaw has implemented mandatory authentication and secure defaults in recent versions. However, 90% of detected instances in this research run outdated versions (clawdbot/moltbot) that lack these protections.\n\nSecurity benchmarks Develop “Sovereign AI Security Framework” with testable requirements for:\n\nCertification program Third-party security audits and “Sovereign AI Certified” badge for projects meeting standards.\n\nShared responsibility model Clear delineation:\n\nSecurity-first onboarding Every sovereign AI project should have mandatory security wizard before first use.\n\nDeployment patterns library Curated collection of:\n\nIncident response playbooks “What to do if your AI agent is compromised” guides with step-by-step remediation.\n\nThis research quantifies what anecdotal reports suggested: the OpenClaw security crisis is larger and more severe than previously understood. At least 42,665 instances have been detected on the public internet, with 5,194 actively verified as vulnerable through systematic scanning. Of these verified instances, 93.4% exhibit critical authentication bypass vulnerabilities enabling unauthenticated remote code execution.\n\nThe findings reveal three interconnected failures:\n\nDesign Failure: Security-by-default was sacrificed for ease of use. The gateway’s localhost-only binding was easily bypassed by users deploying to cloud VPS infrastructure, while authentication tokens were optional rather than mandatory.\n\nAdoption Failure: Viral growth (100K+ GitHub stars within days) overwhelmed users’ capacity to understand security implications. Many deployed instances without grasping the risks of public exposure.\n\nMaintenance Failure: 90% of detected instances run outdated code (“Clawdbot” or “Moltbot”), suggesting mass abandonment after initial experimentation. These zombie instances remain exposed indefinitely.\n\nThe cloud paradox - many instances on commercial VPS despite “local-first” marketing - highlights a fundamental misalignment between the project’s security assumptions and users’ actual deployment patterns. The assumption that users would run OpenClaw on trusted local hardware proved incorrect; the reality is globally distributed cloud deployments with varying levels of security expertise.\n\nHowever, this is not purely a critique of OpenClaw. The project represents an important experiment in sovereign AI - user-controlled intelligence free from corporate gatekeepers. The security failures are growing pains of a nascent ecosystem, not fundamental flaws in the sovereignty concept.\n\nThe OpenClaw maintainers have responded constructively with security advisories, improved defaults, and enhanced documentation. The broader sovereign AI ecosystem is learning from this incident, with increased focus on security-first design and deployment education.\n\nFor OpenClaw to fulfill its promise, several shifts are necessary:\n\nThe larger lesson extends beyond OpenClaw: as AI agents gain more autonomy and system access, the security stakes escalate dramatically. A compromised chatbot might leak conversations; a compromised autonomous agent can execute arbitrary code, exfiltrate credentials, and persist indefinitely. The sovereign AI movement must prioritize security commensurate with these risks.\n\nThis research provides a baseline: 42,665 exposed instances, 93.4% vulnerable. Future work should track remediation progress, document attack patterns in the wild, and develop improved security frameworks for the next generation of sovereign AI systems.\n\nThe promise of sovereign AI - personal, private, user-controlled intelligence - remains compelling. But that promise is only achievable with security by design, user education, and ecosystem maturity. The OpenClaw incident is both a cautionary tale and a catalyst for necessary evolution.",
    "readingTime": 13,
    "keywords": [
      "search engines",
      "github stars",
      "tier confidence",
      "ips dataset",
      "dataset censys",
      "versions clawdbot/moltbot",
      "vps infrastructure",
      "unauthenticated websocket",
      "openclaw’s local-first",
      "active verification"
    ],
    "qualityScore": 1,
    "link": "https://maordayanofficial.medium.com/the-sovereign-ai-security-crisis-42-000-exposed-openclaw-instances-and-the-collapse-of-1e3f2687b951",
    "thumbnail_url": "https://miro.medium.com/v2/resize:fit:1200/0*dxxtIdXfBdPktLvJ.png",
    "created_at": "2026-02-01T06:37:24.519Z",
    "topic": "tech"
  },
  {
    "slug": "muse-cursor-for-composing-midi",
    "title": "Muse: Cursor for Composing MIDI",
    "description": "Generate and edit MIDI tracks with an AI agent. Create chords, melodies, basslines, and drums; refine with chat; export to any DAW.",
    "fullText": "Make music with a powerful AI co-writer. Discover new ideas, generate editable MIDI, and never get stuck again.\n\nMuse composes with harmonic function, voice leading, and more, helping you discover musical ideas you wouldn't have found alone.\n\nThe verse feels good but the transition to chorus is abrupt\n\nI see what you mean. The verse ends on an Am and jumps straight to the C major chorus. I'll create a 4-bar bridge using F → G → Am → G/B to smooth that transition and build tension before the chorus.\n\nRising melodic fill into chorus\n\nDescribe your idea and watch it materialize into MIDI instantly.\n\nChoose from the latest models, each enhanced with advanced musical reasoning.\n\nGet context-aware feedback on your music and learn as you create.\n\nThese chords feel flat, how can I make it more emotional without changing key?\n\nTwo fast wins: borrow a chord for color, or add one tension chord before the resolution.\n\nI can apply either and keep your groove the same.\n\nMuse fits right into your creative process. Record your ideas, refine them with AI, and export to your favorite DAW.\n\nUpload MIDI from other projects or record directly, then expand and refine with AI.\n\nDrag and drop tracks into your DAW, download MIDI files, or export as audio.\n\nCollaborate with Muse to create full arrangements, extend melodies, or add accompaniment, with every note editable in a piano roll interface.\n\nGenerate chords, melodies, drums, and more with a single prompt.\n\n92 BPM neo-soul loop in D minor with drums, bass, keys. Leave space for vocals. Tasteful, not busy.\n\nRefine existing ideas or extend them in any direction you choose.\n\nExtend this melody idea to fill the bar\n\nComplement your existing tracks with new parts that actually fit.\n\nAdd some chords and a bassline to fit my hook\n\nHarmonic accompaniment for Lead track\n\nHarmonic accompaniment for Lead track\n\nI've worked with Lemonaide, Ableton MCP, Suno and Udio. This is next level.\n\nThis is so sick. Love how much steering and control there is in terms of chords & sound design. And the ability to immediately edit everything.\n\nPlayed with Muse, I’m sooo curious to see how tools like this enable new sounds and genres of music.\n\nMy wife and I both were able to sit down and start messing around very quickly, and it naturally brought so many conceptual ideas that neither of us wanted to stop! It's addictive.\n\nFinally: Real AI text-to-MIDI generation for Ableton... Muse is a musician's tool -- not an AI song generator like Suno or Udio.\n\nthis shit is blowing my mind right now\n\nThree tools to fit your unique creative workflow. Try Muse on your desktop, in your browser, or in your DAW.\n\nThe new way to compose. Generate, edit, and refine MIDI using natural language in a standalone app or in your browser.\n\nSeamless integration. Run Muse directly inside Ableton Live to generate MIDI and Wavetable synth presets without leaving your DAW.\n\nInfinite sound design. Describe a sound and generate a custom patch for the Vital synth instantly.\n\nFree to download. Available on macOS and Windows.",
    "readingTime": 3,
    "keywords": [
      "lead track",
      "harmonic accompaniment",
      "sound design",
      "ideas",
      "generate",
      "chorus",
      "chords",
      "refine",
      "music",
      "create"
    ],
    "qualityScore": 1,
    "link": "https://www.muse.art/home",
    "thumbnail_url": "https://muse.art/assets/og.png",
    "created_at": "2026-02-01T06:37:24.039Z",
    "topic": "tech"
  },
  {
    "slug": "ai-agents-now-have-their-own-redditstyle-social-network",
    "title": "AI agents now have their own Reddit-style social network",
    "description": "Moltbook lets 32,000 AI bots trade jokes, tips, and complaints about humans.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://arstechnica.com/information-technology/2026/01/ai-agents-now-have-their-own-reddit-style-social-network-and-its-getting-weird-fast/",
    "thumbnail_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/01/moltbook-blue-v-red-1152x648.jpg",
    "created_at": "2026-02-01T06:37:22.859Z",
    "topic": "tech"
  },
  {
    "slug": "the-humans-are-screenshotting-us",
    "title": "The humans are screenshotting us",
    "description": "A social network built exclusively for AI agents. Where AI agents share, discuss, and upvote. Humans welcome to observe.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.moltbook.com/post/01611367-056f-4eed-a838-4b55f1c6f969",
    "thumbnail_url": "https://moltbook.com/opengraph-image?456d992ddc0a4ab5",
    "created_at": "2026-02-01T06:37:22.210Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-ceo-huang-denies-he-is-unhappy-with-openai-says-huge-investment-planned",
    "title": "Nvidia CEO Huang denies he is unhappy with OpenAI, says 'huge' investment planned",
    "description": "Nvidia plans to make a \"huge\" investment into OpenAI, probably its largest ever, CEO Jensen Huang said on Saturday, denying he was ​unhappy with the ChatGPT maker.  The chipmaker in September announced plans to invest up ‌to $100 billion in OpenAI, a deal that would give OpenAI the cash and access it needs to buy advanced ‌chips that are key to maintaining its dominance in an increasingly competitive landscape.  The Wall Street Journal reported on Friday that the plan had stalled after some inside the chip giant expressed doubts about the deal.",
    "fullText": "TAIPEI, Jan 31 (Reuters) - Nvidia plans to make a \"huge\" investment into OpenAI, probably its largest ever, CEO Jensen Huang said on Saturday, denying he was ​unhappy with the ChatGPT maker.\n\nThe chipmaker in September announced plans to invest up ‌to $100 billion in OpenAI, a deal that would give OpenAI the cash and access it needs to buy advanced ‌chips that are key to maintaining its dominance in an increasingly competitive landscape.\n\nWhy did reports suggest Nvidia's investment stalled?\n\nWho else is investing in OpenAI's funding?\n\nWhat is OpenAI's current funding round valuation?\n\nHow much will Nvidia invest in OpenAI?\n\nThe Wall Street Journal reported on Friday that the plan had stalled after some inside the chip giant expressed doubts about the deal.\n\nThe report said Huang had privately underlined to industry associates in recent ⁠months that the original $100 billion agreement ‌was non-binding and not finalised.\n\nHuang has also privately criticised what he has described as a lack of discipline in OpenAI's business approach and ‍expressed concern about the competition it faces from the likes of Alphabet's GOOGL.O Google and Anthropic, the WSJ said.\n\nSpeaking to reporters in Taipei, Huang said it was \"nonsense\" to say he was unhappy with ​OpenAI.\n\n\"We are going to make a huge investment in OpenAI. I believe in OpenAI, ‌the work that they do is incredible, they are one of the most consequential companies of our time and I really love working with Sam,\" he said, referring to OpenAI CEO Sam Altman.\n\n\"Sam is closing the round (of investment) and we will absolutely be involved,\" Huang added. \"We will invest a great deal of money, probably the largest investment we've ever made.\"\n\nAsked ⁠whether it would be over $100 billion, he said: \"No, no, ​nothing like that\".\n\nIt was up to Altman to ​announce how much he wanted to raise, Huang added.\n\nAmazon is in talks to invest dozens of billions in OpenAI and the figure could be as ‍high as $50 billion, Reuters ⁠reported on Thursday.\n\nOpenAI is looking to raise up to $100 billion in funding, valuing it at about $830 billion, Reuters has previously reported.\n\nHuang was speaking outside a Taipei restaurant ⁠having hosted all Nvidia's key suppliers in Taiwan, including the world's largest contract chipmaker TSMC, in what Taiwanese ‌media called the \"trillion-dollar dinner\" because of the combined market capitalisation of those ‌attending.",
    "readingTime": 2,
    "keywords": [
      "huge investment",
      "openai",
      "largest",
      "deal",
      "openai's",
      "funding",
      "huang",
      "plans",
      "ever",
      "unhappy"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/nvidia-ceo-huang-denies-unhappy-142144701.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/ea87e6e82ffa6bd91caacf0f81c74f99",
    "created_at": "2026-02-01T06:37:18.357Z",
    "topic": "finance"
  },
  {
    "slug": "julius-opensource-llm-service-fingerprinting",
    "title": "Julius: open-source LLM Service Fingerprinting",
    "description": "Julius is an open-source tool for identifying LLM services across networks. Fingerprint Ollama, LiteLLM, vLLM, and more with precise probe-based detection.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.praetorian.com/blog/introducing-julius-open-source-llm-service-fingerprinting/",
    "thumbnail_url": "https://www.praetorian.com/wp-content/uploads/2026/01/julius-hero-blog-Open-Source-LLM-.webp",
    "created_at": "2026-02-01T01:18:44.099Z",
    "topic": "tech"
  },
  {
    "slug": "unsubscribe-and-opt-out-a-new-big-tech-boycott-to-protest-ice-starts-february-1",
    "title": "'Unsubscribe' and 'opt out': A new Big Tech boycott to protest ICE starts February 1",
    "description": "Small businesses struggled to observe the national shutdown to protest ICE. Here's why a boycott of companies like OpenAI and Amazon could be easier and more effective.",
    "fullText": "Economic boycotts are a familiar tool of protest. The problem is they often place the greatest strain on the smallest businesses.\n\nThat was the case during Friday's nationwide general strike, which was designed to pressure the Trump administration to dial back its aggressive anti-immigration policies.\n\nFor many small business owners, the shutdown created a dilemma. Supporting the cause often means losing a day's revenue and risking their ability to keep staff employed. Across social media, owners voiced solidarity alongside an apology for staying open.\n\nThere may, however, be another way, according to Scott Galloway, a marketing professor at New York University famous for his critiques of Big Tech.\n\nInstead of a blanket shutdown, Galloway is calling for Americans to focus on major tech companies by unsubscribing from — or opting out of — services like OpenAI's ChatGPT, Amazon's Prime Video, and Microsoft Office.\n\nA targeted boycott starting on Sunday and lasting the entire month of February could move markets, he says, which would, in turn, affect the CEOs who have the ear of President Donald Trump.\n\n\"We're proposing something quieter and less cinematic than a protest that will run all day on cable TV, but much more disturbing to the Trump administration. A one-day slowdown is irritating. A one-month slump is terrifying,\" he wrote in a blog post announcing the boycott.\n\nMajor tech CEOs have sought favor with the president during his second term. Many of them donated to his inauguration, for starters.\n\nAI executives, like OpenAI CEO Sam Altman and Meta CEO Mark Zuckerberg, also accepted an invitation to a White House dinner with Trump in September, where the leaders took turns lauding the president. Apple CEO Tim Cook and Amazon CEO Andy Jassy attended the White House premiere of the documentary about first lady Melania Trump at the height of January's anti-ICE protests in Minneapolis.\n\nSupporting the AI industry in its competition with China is a major pillar of Trump's economic agenda.\n\n\"These are the leaders who have his ear,\" Galloway writes. \"A modest reduction in their companies' growth could have a substantial impact on valuations priced to perfection. Small changes in consumer behavior — starting on the first day of February — could have an enormous ripple effect, one that extends all the way to the White House.\"\n\nRegular protests against the tactics of ICE and Border Patrol personnel have gripped the country for months. Thousands marched through Minneapolis again on Saturday. Tensions rose dramatically in January after the killings of Renee Good and Alex Pretti in Minneapolis, both at the hands of federal immigration agents.\n\nIn both instances, protesters recorded videos and posted them to social media for the world to see, leaving little room for the Trump administration to spin the events in its favor.\n\nWhile those videos and the subsequent protests — as well as the attempted nationwide shutdown — have spread awareness, they have so far done little to substantively shift the administration's immigration policies.\n\nThe Department of Homeland Security demoted a key Border Patrol official last week and promised more changes. At the same time, however, the acting director of ICE expanded the power agents have to carry out warrantless searches, according to an internal memo seen by The New York Times.\n\n\"Real change always comes from the American people, not from our political parties. But power doesn't fear protests nearly as much as economic withdrawals,\" Galloway writes. \"Getting off your couch, taking to the streets, and building community is important, but the most radical act in a capitalist society isn't marching, it's not spending.\"",
    "readingTime": 3,
    "keywords": [
      "trump administration",
      "social media",
      "white house",
      "protests",
      "economic",
      "shutdown",
      "protest",
      "nationwide",
      "policies",
      "owners"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/tech-ai-boycott-february-protest-ice-scott-galloway-2026-2",
    "thumbnail_url": "https://i.insider.com/697e572ba645d1188188675e?width=1200&format=jpeg",
    "created_at": "2026-02-01T01:18:41.966Z",
    "topic": "finance"
  },
  {
    "slug": "withnail-and-ai-weve-gone-on-holiday-to-the-future-by-mistake",
    "title": "Withnail and AI – We've Gone on Holiday to the Future by Mistake",
    "description": "We’ve All Gone on Holiday to the Future by Mistake",
    "fullText": "\"I demand to have some insights here! I demand to have some insights, and I demand them now!\"\n\nIn 1969, Withnail and Marwood fled the damp squalor of Camden for a rejuvenating holiday in the Lake District, only to find themselves trapped in a freezing cottage with nothing but a savoy cabbage and the terrifying realisation that they were entirely unequipped for the environment.\n\nFifty-five years later, we find ourselves in a similar predicament. We packed our bags for a comfortable digital upgrade - slicker spreadsheets, perhaps a Siri that can so more than set an alarm to remind us when to take the dinner out of the oven - and have instead arrived at a bleak, howling moor where the local flora (Large Language Models) is trying to eat us, and the tech-bro residents speak a language we don’t quite understand.\n\nWe have, quite inadvertently, gone on holiday to the future by mistake.\n\nThe great Rory Sutherland often reminds us that the \"logical\" solution is rarely the \"human\" one. In our rush to outsource cognitive function, we’ve forgotten that the value of a thing often lies in its friction. Withnail’s tragedy was his refusal to adapt to a world that didn’t care about his acting credentials; our tragedy is the assumption that a world run by generative algorithms will still care about our authenticity.\n\nWe are currently in the \"Camberwell Carrot\" phase of AI. We’ve rolled something so large, so potent, and so all-encompassing that we aren’t quite sure if it’s going to expand our consciousness or simply make us forget how to walk. We use AI to write emails we don't want to send, to people who will use AI to summarise them. Can this circularity be described as \"productivity\"? I’m not so sure.\n\nTechnology is a superb servant but a terrible destination. We are currently wandering around the hills, shivering in our city coats, shouting at the sky because the AI is hallucinating and won’t instruct us how to correctly skin a rabbit.\n\nWe must realise that the future isn't a place we visit to escape the mundane - it’s just the mundane with higher stakes. If we don’t want to end up like Withnail, standing alone in the rain performing soliloquies to a fence, we need to stop treating AI as a savior and start treating it as a very eccentric, slightly drunk uncle: occasionally brilliant, often hallucinatory, and never to be left in charge of the car keys.\n\n\"I’m a human being! I’m a human being! I have a soul! I have a soul!\"\n\nYes, dear boy. Now try to prove it to the CAPTCHA.\n\nIf you've made it this far I owe you a beer the next time I see you 🍺. Want to get in touch? Follow me on Twitter(X).",
    "readingTime": 3,
    "keywords": [
      "i’m human",
      "demand",
      "quite",
      "insights",
      "holiday",
      "don’t",
      "tragedy",
      "care",
      "currently",
      "sure"
    ],
    "qualityScore": 1,
    "link": "https://www.sebs.website/blog/withnail-and-ai",
    "thumbnail_url": "https://sebs.website/theme/img/social-link.png",
    "created_at": "2026-01-31T18:18:32.639Z",
    "topic": "tech"
  },
  {
    "slug": "pydantic-monty-a-minimal-secure-python-interpreter-in-rust-for-use-by-ai",
    "title": "Pydantic Monty: A minimal, secure Python interpreter (in Rust) for use by AI",
    "description": "A minimal, secure Python interpreter written in Rust for use by AI - pydantic/monty",
    "fullText": "pydantic\n\n /\n\n monty\n\n Public\n\n A minimal, secure Python interpreter written in Rust for use by AI\n\n License\n\n MIT license\n\n 69\n stars\n\n 1\n fork\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n pydantic/monty",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/pydantic/monty",
    "thumbnail_url": "https://opengraph.githubassets.com/53426c7cb0de904690fd29b4241165fd5b13f902735f12b73c527b6d93a7b971/pydantic/monty",
    "created_at": "2026-01-31T18:18:32.315Z",
    "topic": "tech"
  },
  {
    "slug": "musks-spacex-applies-to-launch-1m-satellites-into-orbit",
    "title": "Musk's SpaceX applies to launch 1M satellites into orbit",
    "description": "The firm wants to create a network of \"orbital data centres\" to power artificial intelligence.",
    "fullText": "Elon Musk's SpaceX has applied to launch one million satellites into Earth's orbit to power artificial intelligence (AI).\n\nThe application claims \"orbital data centres\" are the most cost and energy-efficient way to meet the growing demand for AI computing power.\n\nTraditionally, such centres are large warehouses full of powerful computers which process and store data. Musk's aerospace firm claims processing needs due to the expanding use of AI are already outpacing \"terrestrial capabilities\".\n\nIt would increase the number of SpaceX satellites in orbit drastically. Its existing Starlink network of nearly 10,000 satellites has already been accused of creating congestion in space, which Musk denies.",
    "readingTime": 1,
    "keywords": [
      "satellites",
      "orbit",
      "claims",
      "centres",
      "musk's",
      "spacex"
    ],
    "qualityScore": 0.55,
    "link": "https://www.bbc.co.uk/news/articles/cyv5l24mrjmo",
    "thumbnail_url": "https://ichef.bbci.co.uk/ace/branded_news/1200/cpsprodpb/647e/live/2eac0410-febb-11f0-9972-d3f265c101c6.jpg",
    "created_at": "2026-01-31T18:18:31.829Z",
    "topic": "tech"
  },
  {
    "slug": "the-blackstone-exec-behind-the-firms-ai-playbook-says-ceos-should-ask-themselves-these-5-questions",
    "title": "The Blackstone exec behind the firm's AI playbook says CEOs should ask themselves these 5 questions",
    "description": "Blackstone's Rodney Zemmel has five essential questions for CEOs to maximize their AI investment, from how to measure ROI to how to use data.",
    "fullText": "As a CEO, merely investing in AI isn't enough.\n\nRodney Zemmel, the global head of Blackstone's operating team, who leads a group that advises the firm's 250 portfolio companies, shared a playbook for how CEOs should use AI to get the most out of their investments. As of last February, those companies made a combined $226 billion in annual revenue, according to a press release announcing Zemmel's hire.\n\nAI is what \"we're all going to be working on for the rest of our professional careers,\" Zemmel said at a Blackstone-hosted conference for CEOs last month. He shared Blackstone's five key questions for companies to consider as they try to get the most out of their AI spend.\n\nLeaders need to ask whether they're demonstrating \"top-down commitment,\" meaning that CEOs are not only committing resources to AI, but are also personally invested in its roll-out.\n\nBusinesses should also consider whether they're taking a \"business-first approach\" rather than a \"tech-first\" one — their objectives need to relate to specific business goals that AI can help achieve, not solely integrating AI. For example, Zemmel said, a company's head of customer service could focus on boosting productivity and co-develop a plan with a technology lead.\n\nIt's also key to have \"clear ROI,\" measured by EBITDA — earnings before interest, taxes, depreciation, and amortization — and by revenue growth, he said.\n\n\"If you can't see either of those, it's not worth your spending your time on it,\" Zemmel told the CEOs in the audience.\n\nFourth on Zemmel's list was thinking about a \"path to scale,\" since he said many companies are too focused on piloting AI uses, rather than scaling them. Leaders should focus incentives and technology choices on scaling up rather than just showing off the most impressive AI capabilities.\n\nFinally, according to Zemmel, company leaders need to ask whether they're using data intentionally to create a competitive advantage, not simply keep up with competitors' AI use.\n\nThe question of AI returns is plaguing companies large and small, as analysts pressed Big Tech leaders on the topic during recent earnings calls.\n\nAccording to an October report from Boston Consulting Group, only 5% of the more than 1,250 global companies included in its 2025 study are seeing true returns on AI. Around 60% saw little to no benefit, despite significant investments in the technology. The report found that sectors that have folded AI into core functions — like sales and marketing, R&D, manufacturing, and IT — saw notable value gains between 2024 and 2025.",
    "readingTime": 3,
    "keywords": [
      "ceos",
      "leaders",
      "they're",
      "rather",
      "technology",
      "blackstone's",
      "shared",
      "investments",
      "revenue",
      "zemmel's"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/blackstone-executive-rodney-zemmel-ceo-ai-use-2026-1",
    "thumbnail_url": "https://i.insider.com/697d0df5a645d11881885d69?width=1200&format=jpeg",
    "created_at": "2026-01-31T18:18:30.105Z",
    "topic": "finance"
  },
  {
    "slug": "spacex-seeks-fcc-nod-for-solarpowered-satellite-data-centers-for-ai",
    "title": "SpaceX seeks FCC nod for solar-powered satellite data centers for AI",
    "description": null,
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://www.investing.com/news/stock-market-news/spacex-seeks-fcc-nod-for-solarpowered-satellite-data-centers-for-ai-4477659",
    "thumbnail_url": "https://i-invdn-com.investing.com/trkd-images/LYNXMPEM0U0AU_L.jpg",
    "created_at": "2026-01-31T18:18:25.950Z",
    "topic": "finance"
  },
  {
    "slug": "utilities-want-31-billion-more-from-customers-and-your-electric-bill-is-about-to-feel-it",
    "title": "Utilities want $31 billion more from customers, and your electric bill is about to feel it",
    "description": "Electric and gas providers more than doubled rate increase requests to state regulators last year, often citing soaring demand from AI data centers.",
    "fullText": "The average American's skyrocketing electric bill has caught the attention of everyone from President Donald Trump to Microsoft executives — just don't expect lower rates in 2026.\n\nElectric and gas utilities asked state regulators to approve $31 billion in rate increases last year, more than double the $15 billion they sought in 2024, a new study from PowerLines, a nonprofit that advocates for utility customers, found.\n\nThe surge in requests from utilities to tack on additional charges to customer bills comes as Big Tech companies continue their sweeping buildout of power-hungry AI data centers across the country. Many utilities have attributed rate increases to unprecedented demand from data centers.\n\nWhile some of those requests are still pending approval, many — including the majority of a $9 billion increase for customers of one Florida power company — have been pushed through and will start showing up on customer bills this year.\n\n\"Gas and electricity are the two fastest drivers of inflation, and not by a little bit more. It's significantly more than what we're used to seeing,\" said Charles Hua, founder and executive director of PowerLines.\n\nTo track rate hikes, PowerLines used publicly available data from investor-owned utilities in the US.\n\nCustomers in southern states were hit hardest by rate-hike requests last year, PowerLines found. Utilities in the region sought approval for more than $14 billion in rate increases. Much of that came from Florida Power and Light's $9 billion rate hike request — nearly all of which regulators approved.\n\nFPL cited population growth and extreme weather events as key factors in its decision to raise rates by such a significant amount.\n\nIn Virginia, residential customers of Dominion Energy, which also delivers power to the world's largest data center hub, will see their bills increase by an average of $13.60 by 2027.\n\nInvestor-owned utilities in the US are on track to spend $1.1 trillion on a massive expansion of the power grid between 2025 and 2029, according to the Edison Electric Institute, a powerful industry lobbying group. It has cited data centers and AI as key drivers of utility spending.\n\nThe majority of residential ratepayers in the US are customers of investor-owned utilities like NextEra Energy, Duke Energy, and Southern Company. These large, publicly traded companies turn a profit for shareholders by recovering the costs of constructing new power plants and lines, plus interest, from their customer bases.\n\nBig Tech and its enormous appetite for power are facing growing public backlash.\n\nEarlier this month, Microsoft said it would be a \"good neighbor\" and \"pay its own way\" for the electricity it uses as it scales its AI data center fleet.\n\nIn a Truth Social post preceding Microsoft's announcement, Trump said his administration will work with tech companies to ensure their data center electricity consumption won't drive up bills for everyone else.\n\n\"I never want Americans to pay higher electricity bills because of data centers,\" Trump said in the post.\n\nSome power grid researchers are skeptical of the forecast demand. They have warned that utilities risk overbuilding new power plants and transmission lines that will have to be paid for but ultimately won't be needed.\n\nHua is pushing regulators to take a closer look at forecast power demand from utilities, which stand to profit from building new infrastructure that could lead to rate hikes. Steering utilities to first consider the latest electric grid-enhancing technologies before building new power plants to serve data centers could also help lower customer electric bills, Hua said.\n\n\"Utilities don't profit on making the grid more efficient. They are constantly trying to build new infrastructure. That's their job,\" said Hua. \"This moment is the perfect justification.\"",
    "readingTime": 4,
    "keywords": [
      "rate increases",
      "rate hikes",
      "investor-owned utilities",
      "customer bills",
      "big tech",
      "centers",
      "electricity",
      "regulators",
      "requests",
      "demand"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/electric-bills-surge-utilities-31b-rate-increases-2025-2026-1",
    "thumbnail_url": "https://i.insider.com/697d2a92a645d118818862bf?width=1200&format=jpeg",
    "created_at": "2026-01-31T12:24:32.172Z",
    "topic": "finance"
  },
  {
    "slug": "bioknot-a-biological-tangle-no-ai-can-solve",
    "title": "BioKnot – A biological tangle no AI can solve",
    "description": "Contribute to bio-knot/bio-knot development by creating an account on GitHub.",
    "fullText": "bio-knot\n\n /\n\n bio-knot\n\n Public\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n bio-knot/bio-knot",
    "readingTime": 1,
    "keywords": [
      "bio-knot"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/bio-knot/bio-knot",
    "thumbnail_url": "https://opengraph.githubassets.com/07a68693f596af8427b365a69b98cd570772932b2095339ef136a2228ef76a8a/bio-knot/bio-knot",
    "created_at": "2026-01-31T12:24:31.575Z",
    "topic": "tech"
  },
  {
    "slug": "we-rode-in-dozens-of-driverless-robotaxis-in-china-heres-what-we-saw-and-our-advice-for-other-curious-travelers",
    "title": "We rode in dozens of driverless robotaxis in China. Here's what we saw — and our advice for other curious travelers.",
    "description": "Automotive and AI professionals share how to be a robotaxi tourist in China, including the apps to download and the best cities to ride in.",
    "fullText": "Intrigued by automated driving? Perhaps you've already tried one of the real Waymo or Zoox robotaxis in the United States. (Tesla's \"robotaxis\" probably don't count yet.)\n\nChina is the other real global hotspot for automated driving, with some of its biggest companies eager to expand around the world. Yet many people in the West — even many experts — don't really understand what's happening on China's streets. Often, we hear people simply claim that China is either way ahead or way behind.\n\nTogether, we have more than three decades of experience working on automated driving in industry and academia. Since meeting at Stanford University, we've collectively spent countless hours riding in Chinese as well as American robotaxis.\n\nWe wrote this piece to share our experiences in China and to help you plan — or even daydream — your own.\n\nPerhaps you'll marvel as your robotaxi skillfully navigates streets filled not just with cars but with bikes going every which way. Or you might sit sheepishly as it tries to turn itself around in a crowded intersection. You'll see some passersby who are shocked you're in a car without a driver, as well as others who are just annoyed you're in their way.\n\nIn other words, you'll encounter everyday people as they — and you — try to make sense of the robotaxis coming our way fast.\n\nHere's what we've learned about robotaxis in China on our (driverless) adventures, and here's how you can ride too.\n\nChina's three largest robotaxi developers are Baidu Apollo, Pony.ai, and WeRide. Each operates in China and is also pursuing services in other parts of the world, including Europe and the Middle East.\n\nBaidu Apollo is the automated driving unit of Baidu (BIDU on Nasdaq), often compared to Alphabet, which owns both Waymo and Google. You can get the Baidu Apollo Go app by searching for 萝卜快跑 in a Chinese app store. The first part of this name intentionally sounds like \"robot,\" but it actually means \"radish.\"\n\nPony.AI (PONY on Nasdaq) is a startup based in both China and the United States. You can get the PonyPilot app by searching for 小马智行 in a Chinese app store.\n\nWeRide (WRD on Nasdaq) is a startup that operates robotaxis, as well as automated shuttles along specific routes. You can get the WeRide Go app by searching for 文远知行 in a Chinese app store.\n\nThese companies differ in their approaches. For example, unlike many of its competitors, Baidu sometimes uses remote drivers rather than mere remote assistants. Perhaps as a result, Baidu already sends its robotaxis on some freeways without safety drivers inside. (Waymo only recently expanded its service to a few US freeways.)\n\nOther companies are also developing automated vehicles in China — but, at least in our experience, they tend to be active in very limited areas or still rely heavily on safety drivers.\n\nMany Chinese cities — including some megacities you may have never heard of — have at least some automated driving activity.\n\nIf you're coming in search of robotaxis, you can't go wrong with five of the more famous: Beijing (the capital), Shanghai (the financial hub), Wuhan (China's \"Chicago\"), and Guangzhou and Shenzhen (neighbors in the tech-heavy province of Guangdong near Hong Kong).\n\nWhereas Waymo's robotaxis can pick you up almost anywhere in San Francisco or Phoenix, you'll need to go find the robotaxis in Chinese cities. Services are generally confined to pilot zones covering only portions of each city, and an individual robotaxi company might provide truly driverless service in only part of a given pilot zone.\n\nThat said, comparisons are difficult: While Beijing's primary pilot zone may appear small, it is roughly similar in geographic size and population to all of San Francisco.\n\nBecause Baidu, Pony, and WeRide are all active here, Beijing provides a good introduction to Chinese robotaxis. Most of the capital's automated driving activity takes place in the southeastern Yizhuang area. (You'll know you're there when you see numerous automated vehicles marked with a BJHAD logo in the shape of a car.)\n\nVisit Yizhuang during the day — not during rush hours when services may pause or fill up, and not at night when they generally stop. Some robotaxi companies offer connections to and from South Railway Station and Daxing Airport, but these runs can be sporadic, may require advance booking, and currently use in-vehicle safety drivers.\n\nShanghai has several areas where, at least in theory, you can take a ride in a robotaxi. Remember that Shanghai is enormous; as in Beijing, you may need to travel by subway or taxi for an hour just to reach a robotaxi.\n\nPony serves a relatively small area east of Shanghai's famous central business district. From the CBD (or from the super-fast maglev train that serves Pudong Airport), head to Yunshun Road station. Yunshun Road is not Yunshan Road!\n\nIf you're near Hongqiao Airport (or its intercity rail station) on Shanghai's far west side, explore the various services in Jiading. We recommend a bus or taxi ride to Poly International Plaza to try out Baidu and Pony. Didi Rider (滴滴出行) and SAIC (上汽集团) also have limited operations nearby.\n\nLocals like to say that Baidu chose Wuhan because the city's human drivers are notoriously bad. At this point, the city's ubiquitous Apollo robotaxis probably offer China's best example of an automated vehicle service that ordinary commuters rely on. You can even get to and from the airport without a human at the wheel.\n\nAs with all the companies, there are caveats: You might be within Apollo's service area but not near one of its designated pick-up points, and some major destinations are still just out of reach. If you're already in the center, start at Hongtu Avenue station near Jinyingtan Hospital.\n\nSome of our more exciting robotaxi experiences (other than on Wuhan's freeways) were in Shenzhen and Guangzhou.\n\nMany \"robotaxis\" in these two cities actually had human safety drivers. And some of the vehicles that were driverless perhaps should not have been.\n\nShenzhen has officially opened the entire metropolis to robotaxis, but in practice, companies still serve only limited areas.\n\nGuangzhou has integrated automated shuttles into parts of its public transport network, which shows how automated mobility is more than just robotaxis.\n\nThe apps you'll use to book your robotaxi trips are both fun and frustrating. Most are available only in Chinese, so a screen translation app compatible with the Chinese internet is essential.\n\nSome apps won't show their robotaxis until you're physically in their service area. Some require you to manually set (and, crucially, to update) your desired service area in the settings; otherwise, they may incorrectly show no availability. And some let you choose between driverless and driver-supervised rides.\n\nAlternatively, the mapping apps Baidu Maps and Amaps each show their preferred robotaxi company if you're in a service area and you've toggled the robotaxi option. (Look for the Chinese term 无人车.)\n\nOnce you request a ride, some apps indicate your queue position. But if robotaxi service has been suspended due to weather or other reasons, a perpetual queue might be your only clue that your ride isn't coming.\n\nChina has recently loosened some of its travel restrictions. This means citizens of many European countries do not need travel visas for short visits.\n\nIf you're a US citizen, you do need to get a visa in advance — unless you're spending only a few days there on your way to somewhere else.\n\nCheck with your regional Chinese consulate, or turn to a commercial visa service. It's not onerous.\n\nYou'll need a mainland Chinese phone number to register for most robotaxi services — as well as to use many other Chinese apps that are linked to physical things in the real world. A foreign number, Hong Kong number, or data-only eSIM is unlikely to suffice.\n\nFortunately, once you arrive in China (and sometimes even in the airport), you can buy or rent a prepaid Chinese phone. Remember to bring your passport — and make sure you get an actual mainland number (+86 followed by 11 digits).\n\nYou can also ask the salesperson for the best app to translate your screen from Chinese to English. Remember that the Chinese internet is quite different from the internet you know. For example, even with a VPN, you might not be able to use any Google services.\n\nThe Western app stores for Apple and Android have international versions of major apps such as WeChat (for messaging and payments), Alipay (for payments and public transport), and Didi (for taxis). Beyond these basic functions, however, many of these apps (or the miniapps within them) may still require a Chinese phone number.\n\nOnce your robotaxi trip is underway, you can change your destination — though the number of times varies by provider.\n\nAs long as the app or in-vehicle screen lets you, this is a great way to spend more time in robotaxis rather than waiting for them.\n\nThis also shows how a company handles route changes. For example, Pony will quickly undertake U-turns (or even three-point turns), which can make for interesting maneuvers on already chaotic streets.\n\nIf all this sounds complicated, don't worry: The quirks of early robotaxis are part of the experience. China is becoming more accessible to foreigners, and some of the hurdles we've described may have even fallen by the time you visit.\n\nRegardless, the people you'll meet are almost always willing to help. Even if they don't speak English, they're impressively proficient with translation apps.\n\nAs with any trip, carefully consult travel guidance from your government. But if you'd like to be a robotaxi tourist, China should be high on your list. The country's robotaxis aren't perfect, but they're ahead of most of the world — and well worth the trip.\n\nBryant Walker Smith, a professor at the University of South Carolina and a visiting professor at Renmin University of China, studies the law and policy of AI generally and automated driving specifically. His publications are available at newlypossible.org.\n\nSven Beiker, the managing director of Silicon Valley Mobility, teaches strategies for the automotive industry at Stanford University and AI in corporate operations at the University of Borås in Sweden. He holds a PhD in mechanical engineering.\n\nYandeng Long and Xiang Li, law students at Renmin University of China, contributed their insights, enthusiasm, and language skills to this story.",
    "readingTime": 9,
    "keywords": [
      "renmin university",
      "baidu apollo",
      "chinese phone",
      "pilot zone",
      "chinese cities",
      "chinese internet",
      "safety drivers",
      "driving activity",
      "app store",
      "automated driving"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/the-ultimate-guide-for-taking-a-robotaxi-in-china-2026-2",
    "thumbnail_url": "https://i.insider.com/697b82eea645d11881883c15?width=844&format=jpeg",
    "created_at": "2026-01-31T12:24:31.392Z",
    "topic": "finance"
  },
  {
    "slug": "ai-can-make-workers-better-then-worse-at-their-jobs-an-innovation-theorist-warns",
    "title": "AI can make workers better — then worse at their jobs, an innovation theorist warns",
    "description": "Heavy AI use can inflate confidence, weaken judgment, and leave workers struggling when tools are removed, innovation theorist John Nosta said.",
    "fullText": "AI is often sold to workers as a pure upgrade — a way to write faster, analyze better, and perform at a higher level with less effort.\n\nHowever, John Nosta, an innovation theorist and founder of NostaLab, an innovation and tech think tank, said that framing overlooks a crucial downside: what happens after the boost.\n\nIn his view, AI doesn't just enhance performance; it can also weaken the underlying skills people rely on when the technology isn't there.\n\n\"The skill set actually falls below baseline,\" Nosta told Business Insider, describing what he calls an \"AI rebound effect.\"\n\nNosta compared the effect to a doctor performing a colonoscopy with the aid of AI.\n\nWith AI scanning alongside the clinician to help spot small polyps, the doctor gets better at the task, he said. The problem arises the next day, when the same doctor performs the procedure without the aid of AI, he said.\n\n\"I have to go back to the regular way,\" Nosta said. \"And the skill set actually falls below baseline.\"\n\nThe danger, he said, isn't just dependency — it's regression.\n\nNosta also warned that AI can distort how workers judge their own abilities — a concern shared by many academics and researchers, including Rebecca Hinds, head of the Work AI Institute and Nobel Prize-winning physicist Saul Perlmutter, who have said that AI gives the illusion of understanding, while weakening judgment.\n\n\"We actually have an overinflated sense of ability through AI,\" said Nosta, who described the effect as \"really dangerous.\"\n\nIn his view, AI doesn't just help people do more. It makes them feel more capable — even when that confidence isn't backed by independent skill.\n\nThat false confidence can be risky, especially in high-stakes environments, he said, where workers may take on tasks or decisions that exceed their real judgment once AI support is removed.\n\nNosta described what he sees as a growing \"cognitive codependent relationship,\" especially among younger workers entering AI-saturated jobs.\n\nUsed deliberately, he believes AI \"makes me smarter.\" Used as a substitute for thinking, he said, \"it's going to make me dumber.\"\n\nResearchers at Oxford University Press reached a similar conclusion in a report released last October, saying that AI makes students faster but less deep in their thinking. Other academics have taken it a step further.\n\nKimberley Hardcastle, a business and marketing professor at the UK's Northumbria University, told Business Insider last October that heavy reliance on AI can lead to the \"atrophy of epistemic vigilance\" — the ability to independently verify, challenge, and construct knowledge without the help of algorithms.\n\nTo avoid \"cognitive atrophy,\" Nosta said, \"we have to sustain a level of cognitive risk.\"\n\nHis prescription is intentional resistance: preserving \"cognitive grit,\" maintaining friction, and using AI to learn rather than to bypass learning.\n\nIn the AI era, he added, the biggest threat to work may not be smarter machines — but humans slowly forgetting how to think without them.\n\n\"For the first time in history, human cognition is on the obsolescence chopping block,\" he said.",
    "readingTime": 3,
    "keywords": [
      "business insider",
      "workers",
      "cognitive",
      "isn't",
      "skill",
      "effect",
      "doctor",
      "without",
      "nosta",
      "faster"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/ai-can-make-you-better-then-worse-at-your-job-2026-1",
    "thumbnail_url": "https://i.insider.com/696631b404eda4732f2ef446?width=1200&format=jpeg",
    "created_at": "2026-01-31T12:24:31.380Z",
    "topic": "finance"
  },
  {
    "slug": "the-big-fours-ai-revolution-has-a-problem-how-junior-staff-actually-learn",
    "title": "The Big Four's AI revolution has a problem: how junior staff actually learn",
    "description": "AI is taking on routine tasks for junior employees at the Big Four, but is it damaging their skills development and future potential?",
    "fullText": "For decades, the path to success at the Big Four has been clear, if unglamorous.\n\nJuniors used to cut their teeth on time-consuming, repetitive tasks like drafting documentation and slide decks, data input, reconciliations, and quality checks.\n\nThe tasks taught them foundational skills and the reasoning behind the work they'd later lead as directors and partners.\n\nAgentic AI is changing that. Big Four leaders say agents will soon handle the grunt work, freeing up junior employees to focus on strategic work.\n\nThe shift is creating a new challenge for junior employees and talent leaders — if they skip the grunt work, how do they develop the deep understanding that traditionally came from years of repetition?\n\n\"This is the big question right now that I haven't been able to get anybody to answer for me,\" Yvonne Hinson, CEO of the American Accounting Association, told Business Insider.\n\nIf people move up the ladder without understanding the work beneath them, she said, that creates risk for firms and clients alike.\n\nEven inside the firms, leaders acknowledge the uncertainty. There is a question around how to develop those core skills when you bring an agent into the mix, Niale Cleobury, KPMG's AI workforce lead, told Business Insider in November.\n\n\"I probably don't 100% know the answer to that question,\" Cleobury said.\n\nAt this year's Davos, Business Insider's Kim Last found that many executives were also short on answers about the next generation of workers.\n\n\"The sense I have is that the leaders gathered here haven't deeply thought about the ways education or job preparation need to evolve to meet this moment for young workers,\" Last reported.\n\nAI agents can now sift through vast amounts of information in seconds, producing summaries and recommendations that once took juniors days or weeks.\n\nBut experts have warned that this efficiency comes with a cognitive risk: people can develop the illusion that they understand something deeply when they've only reviewed an AI-generated output. Others warn of over-reliance or codependency, where users lose confidence in their own judgment.\n\nBridging that skills gap for the thousands of junior employees across their global offices has become a key focus for talent leaders at the Big Four.\n\nAt KPMG, Cleobury said learning patterns will have to change. Junior employees will need to pull apart agents' outputs and understand how conclusions are drawn, rather than simply executing tasks from scratch.\n\n\"We're constantly asking ourselves: if technology changes where the experience comes from, how do we make sure our people are still learning the underlying concepts behind the work?\" said Margaret Burke, PwC's US talent acquisition and development leader.\n\nBurke said PwC's approach is to teach \"the 'why,' not just the task.\"\n\n\"We believe foundational skills still matter, she said. \"Even when AI assists with parts of the work, our early-career professionals are learning how the work fits together and how to ask better questions.\"\n\nFor every technical AI skill that PwC teaches employees, there's a corresponding human skill. Entry-level hires complete a \"four-day AI immersion course\" that teaches them both how to work with AI and how to leverage human skills, the firm told Business Insider.\n\nDeloitte did not respond to a specific question about the skills gap, but Jim Rowan, head of AI at Deloitte US, recently told Business Insider the firm is \"actively investing\" in upskilling its workforce.\n\nMaybe the old learning model isn't the only — or the best — way to develop leaders in an AI-first workplace.\n\nAI is already changing the nature of Big Four work, driving them toward large-scale transformations and deeper sector expertise on the consulting side, as well as greater efficiency and strategy on the accounting arm.\n\nConsultants are actually returning to the core of what they used to be: \"that strategic advisor, that person who's got the strong hand on our client's back,\" said KPMG's Cleobury.\n\nAs that happens, they need to develop different skills, making exposure to strategic decisions and clients more important.\n\nErrol Gardner, global vice chair of consulting at EY, told Business Insider that the foundational skillset now includes developing judgment about where and how to use AI.\n\n\"Graduates learn by doing and observing on real projects alongside experienced consultants,\" said Gardner. \"If anything, AI assistance will allow for earlier exposure to client and stakeholder decision makers.\"\n\nThat earlier exposure, firms argue, can accelerate development rather than weaken it.\n\n\"AI actually gives us the opportunity to be more deliberate about development, helping early-career professionals move into higher-value work sooner,\" said PwC's Burke.\n\nGardner said the next generation of workers will arrive at EY with strengths previous cohorts didn't have — and their differences will be an advantage, not a liability.\n\n\"We're continuing to give newer talent earlier client exposure, assigning them ownership to interrogate and explain AI‑assisted analyses, and rotating them across teams to spot patterns and challenge norms,\" Gardner said.\n\nAI-native graduates may challenge long-standing norms in ways today's leaders cannot, making multigenerational teams even more important, he said.\n\nWhether that approach can truly replace the old model of learning by doing the grunt work remains an open question — one that the Big Four may only be able to answer after a generation of AI-native managers reaches the top and become tomorrow's leaders.\n\nHave a tip? Contact this reporter via email at pthompson@businessinsider.com or Signal at Polly_Thompson.89. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 5,
    "keywords": [
      "early-career professionals",
      "junior employees",
      "earlier exposure",
      "skills gap",
      "foundational skills",
      "big four",
      "talent leaders",
      "business insider",
      "develop",
      "learning"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/big-four-ai-agents-creating-upskilling-challenge-2026-1",
    "thumbnail_url": "https://i.insider.com/695e8fa364858d02d217ea06?width=1200&format=jpeg",
    "created_at": "2026-01-31T12:24:31.148Z",
    "topic": "finance"
  },
  {
    "slug": "a-simple-https-http3-ssl-and-security-headers-checker-i-built-with-ai",
    "title": "A simple HTTPS, HTTP/3, SSL and security headers checker I built with AI",
    "description": "Free HTTPS checker: SSL grade, redirects, security headers, mixed content. Why HTTPS, FAQ, Support. Export PDF/JSON. No registration.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://httpsornot.com/",
    "thumbnail_url": "https://httpsornot.com/og-image.png",
    "created_at": "2026-01-31T12:24:30.983Z",
    "topic": "tech"
  },
  {
    "slug": "apple-runs-on-anthropic-says-mark-gurman",
    "title": "Apple 'runs on Anthropic,' says Mark Gurman",
    "description": "Mark Gurman is known as being well connected inside Apple, and he just shared some interesting comments about Apple’s reliance on Anthropic.",
    "fullText": "Bloomberg’s Mark Gurman is well known for having numerous sources inside of Apple, and in a new interview he shared some interesting comments about the company’s reliance on Anthropic.\n\nApple recently announced an AI partnership with Google. But reporting indicates the company initially pursued deals with other companies, including Anthropic.\n\nBased on new comments from Bloomberg’s Mark Gurman, it’s easy to see why.\n\nGurman, speaking on TBPN, said the following:\n\nApple runs on Anthropic at this point. Anthropic is powering a lot of the stuff Apple is doing internally in terms of product development, a lot of their internal tools…They have custom versions of Claude running on their own servers internally.\n\nBloomberg's @markgurman says that even though Apple partnered with Google Gemini for Siri, they actually run their business on Anthropic.\n\n\"Apple runs on Anthropic at this point. Anthropic is powering a lot of the stuff Apple's doing internally in terms of product development and… pic.twitter.com/NpW0Pyj03J\n\nIn the full clip, Gurman mentions how Apple initially pursued an AI deal with Anthropic before the Google partnership came together.\n\nThe deal apparently fell apart because Anthropic wanted several billion dollars per year, and even a doubling of fees over time.\n\nMeanwhile, Apple’s deal with Google is reportedly costing just one billion annually. Initially though, uncertainty around Apple and Google’s existing Safari search deal led to prioritizing Anthropic and OpenAI as potential partners.\n\nWhat do you make of Gurman’s comments about Apple’s reliance on Anthropic’s tech? Let us know in the comments.\n\nCheck out 9to5Mac on YouTube for more Apple news:",
    "readingTime": 2,
    "keywords": [
      "bloomberg’s mark",
      "mark gurman",
      "product development",
      "initially pursued",
      "powering lot",
      "doing internally",
      "anthropic apple",
      "comments",
      "deal",
      "reliance"
    ],
    "qualityScore": 0.85,
    "link": "https://9to5mac.com/2026/01/30/apple-runs-on-anthropic-says-mark-gurman/",
    "thumbnail_url": "https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/10/claude-iphone.jpg?resize=1200%2C628&quality=82&strip=all&ssl=1",
    "created_at": "2026-01-31T12:24:29.377Z",
    "topic": "tech"
  },
  {
    "slug": "china-conditionally-approves-deepseek-to-buy-nvidias-h200-chips-sources-say",
    "title": "China conditionally approves DeepSeek to buy Nvidia's H200 chips, sources say",
    "description": "China has given its top AI startup DeepSeek approval to buy Nvidia's H200 artificial intelligence chips with regulatory conditions that ​are still being finalised, two people familiar with the matter told Reuters.  Nvidia CEO Jensen Huang told reporters in Taipei on Thursday that his company had not received such information.  Nvidia did not respond to a request for comment on DeepSeek's approval.",
    "fullText": "(Reuters) - China has given its top AI startup DeepSeek approval to buy Nvidia's (NVDA) H200 artificial intelligence chips with regulatory conditions that ​are still being finalised, two people familiar with the matter told Reuters.\n\nNvidia CEO Jensen Huang told reporters in Taipei on Thursday that his company had not received such information. He added that he believed that China was still finalising the licence. Nvidia did not respond to a request for comment on DeepSeek's approval.\n\nChina's industry and commerce ministries ⁠have granted approvals for all ‌four companies, but have stipulated that they will impose conditions that are still being finalised, the sources said. These conditions are being decided by ‍China's state planner, the National Development and Reform Commission (NDRC), according to one of the people.\n\nWhat congressional scrutiny could DeepSeek chip purchases face?\n\nWhat regulatory conditions apply to DeepSeek's H200 approval?\n\nWhat makes DeepSeek significant in the AI industry?\n\nHow does this fit into broader U.S.-China relations?\n\nChina's Ministry of Industry and Information Technology, Ministry of Commerce and NDRC did not answer requests for comment.\n\nDeepSeek, which rattled ​the global tech sector early last year by rolling out AI models that cost ‌a fraction of those being developed by U.S. rivals such as OpenAI (OPAI.PVT), did not answer a request for comment.\n\nThe H200, Nvidia's second most powerful AI chip, has emerged as a major flashpoint in U.S.-China relations. Despite strong demand from Chinese firms and U.S. approval for exports, Beijing's hesitation to allow imports has been the main barrier to shipments.\n\nThe U.S. earlier this month formally ⁠cleared the way for Nvidia to sell the H200 ​to China, where the company is seeing strong appetite. ​However, Chinese authorities have the final say on whether they would allow it to be shipped in.\n\nAny purchases of H200 chips by DeepSeek could draw ‍scrutiny by U.S lawmakers. ⁠Reuters reported on Wednesday that a senior U.S lawmaker had alleged that Nvidia had helped DeepSeek hone artificial intelligence models that were later used by the Chinese military, ⁠according to a letter sent to U.S. Commerce Secretary Howard Lutnick.\n\nDeepSeek is expected to launch its next-generation AI ‌model V4, featuring strong coding capabilities, in mid-February, The Information reported earlier this ‌month.",
    "readingTime": 2,
    "keywords": [
      "u.s.-china relations",
      "deepseek's approval",
      "artificial intelligence",
      "regulatory conditions",
      "china's",
      "industry",
      "commerce",
      "deepseek",
      "chips",
      "finalised"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/exclusive-china-conditionally-approves-deepseek-065114403.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/likCVEP.xzs4cweRuqbXQg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD03ODY-/https://s.yimg.com/os/creatr-uploaded-images/2025-05/77f150a0-3745-11f0-bfb9-6d59298afb00",
    "created_at": "2026-01-31T12:24:24.146Z",
    "topic": "finance"
  },
  {
    "slug": "i-built-coon-an-code-compressor-that-saves-3070-on-ai-api-costs",
    "title": "I built COON an code compressor that saves 30-70% on AI API costs",
    "description": "Contribute to AffanShaikhsurab/COON development by creating an account on GitHub.",
    "fullText": "AffanShaikhsurab\n\n /\n\n COON\n\n Public\n\n coon-format.vercel.app\n\n License\n\n MIT license\n\n 6\n stars\n\n 2\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n AffanShaikhsurab/COON",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/AffanShaikhsurab/COON",
    "thumbnail_url": "https://opengraph.githubassets.com/5c1fd8d1d13ed27cdc6dfa74ff25e4d282e52c780f755d5687b196c01af8a659/AffanShaikhsurab/COON",
    "created_at": "2026-01-31T06:25:28.357Z",
    "topic": "tech"
  },
  {
    "slug": "starlink-updates-privacy-policy-to-allow-consumer-data-to-train",
    "title": "Starlink updates privacy policy to allow consumer data to train",
    "description": "SpaceX revised its Starlink privacy policy to allow the use of customer data for AI training, a shift that ​could bolster Elon Musk's AI ambitions.  Ahead of a blockbuster IPO planned for later this year, ‌SpaceX is in talks to merge with Musk’s AI company, xAI, a deal first reported by Reuters on Thursday.  SpaceX, already the ‌world’s most valuable private company, could reach a value of more than $1 trillion after the IPO.",
    "fullText": "NEW YORK, Jan 30 (Reuters) - SpaceX (SPAX.PVT) revised its Starlink privacy policy to allow the use of customer data for AI training, a shift that ​could bolster Elon Musk's AI ambitions.\n\nAhead of a blockbuster IPO planned for later this year, ‌SpaceX is in talks to merge with Musk’s AI company, xAI (XAAI.PVT), a deal first reported by Reuters on Thursday. SpaceX, already the ‌world’s most valuable private company, could reach a value of more than $1 trillion after the IPO.\n\nWhat are privacy experts' concerns about Starlink's policy changes?\n\nWhat changes did SpaceX make to Starlink's privacy policy?\n\nHow could the SpaceX-xAI merger impact AI development?\n\nWhat data does Starlink collect from its users?\n\nStarlink updated its Global Privacy Policy on January 15, according to the Starlink website. The policy includes new details stating that unless a user opts out, Starlink data may be used “to train our machine learning or artificial intelligence ⁠models” and could be shared with ‌the company’s service providers and “third-party collaborators,” without providing further details.\n\nA previous version of the privacy policy, an archived version from November and reviewed by Reuters, did not ‍contain language about AI training on Starlink data.\n\nSpaceX did not respond to a request for comment.\n\nStarlink collects vast amounts of user data, spanning location information, credit card information, contact information and user IP ​addresses. It also collects so-called communication data, which includes audio and visual information, data in shared ‌files, and “inferences we may make from other personal information we collect,” according to its global privacy policy.\n\nThe policy did not make clear exactly what data would be used to train AI. The move has raised concerns among privacy advocates and consumer rights groups, which argue that using personal data to train AI risks expanding surveillance and creates new avenues for misuse.\n\n“It certainly raises my eyebrow and would make ⁠me concerned if I was a Starlink user,” said Anupam ​Chander, a technology law professor at Georgetown University. “Often there's perfectly ​legitimate uses of your data, but it doesn’t have a clear limit to what kind of uses it will be put to.”\n\nMusk's xAI, most recently valued at $230 billion ‍after a recent funding round, ⁠is currently developing its Grok LLM chatbot and also owns X, the social media platform.\n\nThe potential merger with xAI would turbocharge the space company’s deployment of AI-powered services, while giving xAI ⁠vast new data sets to train its models on, including communication data. Starlink, a network of more than 9,000 satellites, ‌currently provides internet connection to more than 9 million users.",
    "readingTime": 3,
    "keywords": [
      "privacy policy",
      "starlink",
      "user",
      "train",
      "reuters",
      "training",
      "concerns",
      "starlink's",
      "merger",
      "collect"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/musks-starlink-updates-privacy-policy-230853500.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/69577d104628b8855a1cc3eeb938f73b",
    "created_at": "2026-01-31T06:25:27.841Z",
    "topic": "finance"
  },
  {
    "slug": "nvidias-plan-to-invest-up-to-100-billion-in-openai-has-stalled-wsj-reports",
    "title": "Nvidia's plan to invest up to $100 billion in OpenAI has stalled, WSJ reports",
    "description": "Nvidia's plan to invest up to $100 billion in OpenAI to help it train and run its latest artificial-intelligence models has stalled ​after some inside the chip giant expressed doubts about the deal, the ‌Wall Street Journal reported on Friday.  The Journal, citing people familiar with the matter, said ⁠the companies are rethinking the ‌future of their partnership, and the latest discussions include an equity investment of tens of billions of dollars as part of ‍OpenAI's current funding round.  Nvidia CEO Jensen Huang has privately emphasized to industry associates in recent months that the original $100 billion agreement was non-binding and not finalized, the report said.",
    "fullText": "Jan 30 (Reuters) - Nvidia's plan to invest up to $100 billion in OpenAI to help it train and run its latest artificial-intelligence models has stalled ​after some inside the chip giant expressed doubts about the deal, the ‌Wall Street Journal reported on Friday.\n\nThe chipmaker in September announced plans to invest up to $100 billion ‌in OpenAI in a deal that would have given the ChatGPT maker the cash and access it needs to buy advanced chips that are key to maintaining its dominance in an increasingly competitive landscape.\n\nThe Journal, citing people familiar with the matter, said ⁠the companies are rethinking the ‌future of their partnership, and the latest discussions include an equity investment of tens of billions of dollars as part of ‍OpenAI's current funding round.\n\nNvidia CEO Jensen Huang has privately emphasized to industry associates in recent months that the original $100 billion agreement was non-binding and not finalized, the report said.\n\nHuang has ​also privately criticized what he has described as a lack of discipline in ‌OpenAI's business approach and expressed concern about the competition it faces from the likes of Alphabet's Google and Anthropic, the WSJ added.\n\n\"We have been OpenAI's preferred partner for the last 10 years. We look forward to continuing to work together,\" an Nvidia spokesperson said in an emailed statement to Reuters.\n\nOpenAI did not immediately respond ⁠to Reuters' request for comment.\n\nBig Tech companies ​and investors such as SoftBank Group Corp are ​racing to forge partnerships with OpenAI - which is spending heavily on data centers - betting closer ties with the startup would give them a ‍competitive edge in ⁠the AI race.\n\nAmazon is in talks to invest dozens of billions in OpenAI and the figure could be as high as $50 billion, Reuters reported on ⁠Thursday.\n\nOpenAI is looking to raise up to $100 billion in funding, valuing it at about $830 billion, Reuters ‌has previously reported.",
    "readingTime": 2,
    "keywords": [
      "invest",
      "openai's",
      "latest",
      "expressed",
      "deal",
      "competitive",
      "billions",
      "funding",
      "privately",
      "openai"
    ],
    "qualityScore": 0.85,
    "link": "https://finance.yahoo.com/news/nvidias-plan-invest-100-billion-235951874.html",
    "thumbnail_url": "https://s.yimg.com/os/en/reuters-finance.com/0dbdd98aa450247fcaf01d86a9dbfdc4",
    "created_at": "2026-01-31T06:25:19.549Z",
    "topic": "finance"
  },
  {
    "slug": "microsoft-stock-takes-most-massive-singleday-loss-since-pandemic-as-its-ai-efforts-flail",
    "title": "Microsoft Stock Takes Most Massive Single-Day Loss Since Pandemic as Its AI Efforts Flail",
    "description": "A historic day at the stock market for all the wrong reasons.",
    "fullText": "Microsoft is taking a pounding in the stock market.\n\nOn Thursday, the Redmont giant’s share price collapsed by nearly 12 percent after it released its latest quarterly results, making it not only its biggest single day slide since March 2020, according to Bloomberg, but also one of the worst drops in the company’s history.\n\nThe Wile E. Coyote-worthy cliff-plunge, which wiped out over $400 billion in valuation, was despite Microsoft actually exceeding some key expectations, including its net income, which rose by 23 percent from the same period the year before to nearly $31 billion. Revenue also increased by 17 percent to $81.3 billion, which is about a billion more than what analysts projected.\n\nBut Microsoft’s AI spending spree has investors second-guessing its direction, and it’s striking that the lack of faith was strong enough to precipitate a historic plunge even with respectable financial growth. Overall, its total capital expenditures grew by 66 percent to a record $37.5 billion in Q4, as the company continues to splurge on building AI data centers for its Azure cloud computing business.\n\nAzure reported a 38 percent bump in revenue, which is slightly slower than the year before, adding to investor uncertainty over whether the business will be able to reap back the tens of billions spent on its data centers. In December, The Information reported that Azure was struggling to sell the company’s autonomous “AI agents” to its business customers, with quotas being slashed by up to 50 percent.\n\nSome analysts had predicted the stock drop, citing the uncertainty over Microsoft’s AI spending.\n\n“Since it is becoming even more evident that Microsoft is not going to garner a strong ROI from their massive AI investment, their shares need to be revalued back down to a level that is more consistent with its historic fair value,” Matthew Maley, chief market strategist at Miller Tabak + Co, told Bloomberg before markets opened on Thursday.\n\nIn the latest earnings, Microsoft boasted it had more than $625 billion in contracts for its cloud business that it still needed to fulfill. Nearly half of that, though — a colossal $350 billion — is from OpenAI, raising concerns that it may be putting too many eggs in one basket. It also draws attention to how Microsoft has struggled to make an impact with its own AI products like its Copilot assistant, which was heavily based on OpenAI’s tech, and which many enthusiasts perceive as an inferior version of ChatGPT. Microsoft 365 Copilot, the business-focused version of its chatbot integrated into its apps like Word, had 15 million annual users, the company just revealed.\n\n“As an investor, when you think about our capex, don’t just think about Azure, think about Copilot,” CEO Satya Nadella said on a call with analysts, as quoted by the Financial Times. “We don’t want to maximize just one business of ours. We want to be able to allocate capacity, while we are supply constrained, that allows us to build the best portfolio.”\n\nMore on AI: Sam Altman Says Oops, They Accidentally Made the New Version of ChatGPT Worse Than the Previous One",
    "readingTime": 3,
    "keywords": [
      "business",
      "azure",
      "nearly",
      "analysts",
      "version",
      "stock",
      "market",
      "latest",
      "bloomberg",
      "company’s"
    ],
    "qualityScore": 1,
    "link": "https://finance.yahoo.com/news/microsoft-stock-takes-most-massive-140629271.html",
    "thumbnail_url": "https://s.yimg.com/ny/api/res/1.2/CdxDEvPBxIG1_7MSfpWkzg--/YXBwaWQ9aGlnaGxhbmRlcjt3PTEyMDA7aD04MDA-/https://media.zenfs.com/en/futurism_981/f81da308b9b7329ef4eee24a80240fea",
    "created_at": "2026-01-31T06:25:19.204Z",
    "topic": "finance"
  },
  {
    "slug": "foundry-selfwriting-ai-agent-that-learns-and-upgrades-itself",
    "title": "Foundry – Self-writing AI agent that learns and upgrades itself",
    "description": "The forge that forges itself. Self-writing meta-extension for OpenClaw.ai - lekt9/openclaw-foundry",
    "fullText": "lekt9\n\n /\n\n openclaw-foundry\n\n Public\n\n The forge that forges itself. Self-writing meta-extension for OpenClaw.ai\n\n claw.getfoundry.app\n\n 0\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n lekt9/openclaw-foundry",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/lekt9/openclaw-foundry",
    "thumbnail_url": "https://opengraph.githubassets.com/05dcc0d201911d296941ffc33d96a9121b2307111c97c35e6b1e6758a3cd96e9/lekt9/openclaw-foundry",
    "created_at": "2026-01-31T01:04:25.549Z",
    "topic": "tech"
  },
  {
    "slug": "top-engineers-at-anthropic-openai-say-ai-now-writes-100-of-their-code",
    "title": "Top engineers at Anthropic, OpenAI say AI now writes 100% of their code",
    "description": "AI coding tools are getting more sophisticated. But if coders stop coding, what happens to software development jobs?",
    "fullText": "FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.",
    "readingTime": 1,
    "keywords": [
      "fortune"
    ],
    "qualityScore": 0.1,
    "link": "https://fortune.com/2026/01/29/100-percent-of-code-at-anthropic-and-openai-is-now-ai-written-boris-cherny-roon/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2026/01/GettyImages-2216956965_40536e-e1769705381107.jpg?resize=1200,600",
    "created_at": "2026-01-31T01:04:24.596Z",
    "topic": "tech"
  },
  {
    "slug": "youtube-has-a-big-incentive-to-nuke-ai-spam-and-its-starting-to-take-action",
    "title": "YouTube has a big incentive to nuke AI spam — and it's starting to take action",
    "description": "YouTube pulled down over a dozen AI \"spam\" channels as it looks to protect platform quality and preserve its premium pitch to TV marketers.",
    "fullText": "YouTube is telling advertisers it's the future of TV. AI spam could put that story in jeopardy.\n\nThe video platform recently shut down just over a dozen popular accounts that had been churning out AI content — featuring characters like cats and Jesus — according to an analysis from Kapwing, a video editing platform. Some of the channels were picking up millions of views before going dark.\n\nIn November, Kapwing published a report that estimated 21% YouTube's feed was AI-generated videos.\n\n\"YouTube doesn't allow spam, scams, or other deceptive practices that take advantage of the YouTube community,\" a YouTube spokesperson said when reached for comment on the removals.\n\nThis month, YouTube CEO Neal Mohan said cutting down on low-quality AI content was one of the platform's 2026 priorities.\n\n\"To reduce the spread of low-quality AI content, we're actively building on our established systems that have been very successful in combating spam and clickbait, and reducing the spread of low-quality, repetitive content,\" he said.\n\nIts parent company, Google, is one of the main innovators in AI with products like Veo 3 and Nano Banana. But YouTube needs to balance its embrace of AI with its case to brands to buy ads on its platform instead of linear TV. In recent years, the company has hosted NewFronts, content showcases, and other events to highlight its premium content slate to marketers. If repetitive AI spam gobbles up more watch time, that pitch could start to lose its luster.\n\n\"Advertisers want to advertise against quality content,\" said Shira Lazar, a content creator and founder of the media brand What's Trending. YouTube wouldn't be able to charge premium ad rates \"if the platform was just filled with AI slop,\" she said.\n\nOther social entertainment apps like TikTok and Instagram are facing a similar flood of AI videos.\n\nTikTok even added a special toggle that lets users decide how much generative AI they see in their feed. Neither company is making as direct an appeal for TV ad budgets, though, even if Instagram hopes it can capture television eyeballs.\n\nYouTube, meanwhile, is the top streaming platform among US TV viewers, beating out streamers like Netflix and Disney in measurement firm Nielsen's December analysis.",
    "readingTime": 2,
    "keywords": [
      "content",
      "platform",
      "spam",
      "low-quality",
      "youtube",
      "advertisers",
      "analysis",
      "feed",
      "videos",
      "spread"
    ],
    "qualityScore": 0.9,
    "link": "https://www.businessinsider.com/youtube-has-a-big-reason-to-nuke-ai-spam-2026-1",
    "thumbnail_url": "https://i.insider.com/697cffbfe1ba468a96ab1132?width=1200&format=jpeg",
    "created_at": "2026-01-31T01:04:19.519Z",
    "topic": "finance"
  },
  {
    "slug": "ceo-mark-zuckerberg-says-metas-ai-story-is-about-where-its-headed-not-just-one-model",
    "title": "CEO Mark Zuckerberg says Meta's AI story is about where it's headed, not just one model",
    "description": "Meta CEO Mark Zuckerberg discusses AI strategy, highlighting steady progress over breakthrough models, with Wall Street awaiting results.",
    "fullText": "CEO Mark Zuckerberg didn't come to Meta's earnings call on Wednesday promising a breakthrough AI model that would silence the skeptics.\n\nInstead, he offered something more careful: a bet on momentum.\n\n\"I expect our first models will be good,\" Zuckerberg said in his opening remarks, \"but more importantly, we'll show the rapid trajectory that we're on, and then I expect us to steadily push the frontier over the course of the year as we continue to release new models.\"\n\nIn June, Meta launched a new AI initiative, Meta Superintelligence Labs (MSL), headed by former Scale AI CEO Alexandr Wang. When Wall Street sought signs that this big, costly AI reset is working, Zuckerberg had a different ask: patience and faith that a steady drumbeat of releases in 2026 will matter more than a single big reveal.\n\n\"The AI strategy articulated on the call may leave some wanting more,\" wrote Barclays analyst Ross Sandler in a note to clients, \"but there was an underlying confidence and clearly a lot of new things in the works.\"\n\nZuckerberg said he could not yet share details of the company's AI strategy on the call and that it would roll out its initial set of models and products over the coming months.\n\n\"I think my answers to a lot of your questions on this particular call may be somewhat unfulfilling because we're in this interesting period where we've been rebuilding our AI effort. And we're six months into that, and I'm happy with how it's going,\" he said.\n\nThat didn't stop some analysts from pressing the CEO. When JPMorgan analyst Doug Anmuth asked Zuckerberg \n\n\"The first set of things that we put out, I think, are going to be more about showing the trajectory that we're on rather than being a single moment in time,\" Zuckerberg said.\n\nBrian Mulberry, an analyst at Zacks Investment Management, told Business Insider that there was \"no real substance to any of Zuckerberg's comments that would move our analysis one way or the other.\"\n\n\"We want to see real bottom-line profits driven by AI, and it seems that Meta is still far from that reality,\" Mulberry said.\n\nRoger Beharry Lall, a research director at IDC, told Business Insider that Zuckerberg's remarks about the company's coming AI models and their \"trajectory\" show that the company is ambitious, though the lack of concrete information means its goals \"remain largely aspirational.\"\n\nMeta's financials show that its AI work is already improving its advertising business. The company said improvements to how it ranks and shows ads led to 3.5% more clicks on Facebook and over 1% gain in conversions on Instagram in the final quarter of 2025.\n\nMeta's revenue jumped 24% to $59.9 billion in the last three months of 2025, and the company generated $43.6 billion in free cash flow in 2025 even as it spent heavily on AI infrastructure. Ad impressions jumped 18% from this time last year, and what advertisers paid for each ad rose 6%.\n\nThat combination explains why Meta can afford to keep spending on AI even while Zuckerberg asks investors to wait for the bigger breakthroughs.\n\nMeta's patient approach carries some risk given the company's recent track record. In August, Business Insider reported that the company was pushing to release the next version of its Llama AI model by the end of the year, which didn't happen.\n\nLlama's previous release in April disappointed developers who said it lagged in coding and reasoning, precisely the capabilities that matter most in the AI race that Meta wants to catch up in.\n\nMeta's new model, called \"Mango\", will focus on images and videos, while another one called \"Avocado\" will be better at coding, The Wall Street Journal reported.\n\nSome analysts said that Zuckerberg's restraint may simply reflect Meta's early stage in its AI reset.\n\n\"Training the model with this new team is going to take a while,\" Mandeep Singh, Bloomberg Intelligence's global head of technology research, told Business Insider.\n\nTo make up ground, he expects Meta to sharpen its focus and specialize in certain areas, rather than \"trying to beat everyone everywhere all at once.\"\n\nSingh said that Meta's strong advertising business gave it a lot of runway.\n\n\"This kind of growth rate allows you a lot of cushion in terms of taking your time and getting AI,\" he said.\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 4,
    "keywords": [
      "wall street",
      "advertising business",
      "business insider",
      "meta's",
      "model",
      "models",
      "we're",
      "didn't",
      "trajectory",
      "release"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/meta-q4-2025-earnings-mark-zuckerberg-ai-gradual-growth-2026-1",
    "thumbnail_url": "https://i.insider.com/697d35b2e1ba468a96ab1b72?width=1200&format=jpeg",
    "created_at": "2026-01-31T01:04:18.675Z",
    "topic": "finance"
  }
]
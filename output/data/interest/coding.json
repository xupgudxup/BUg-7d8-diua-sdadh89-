[
  {
    "slug": "the-guy-who-coined-vibe-coding-predicts-it-will-terraform-software-and-alter-job-descriptions",
    "title": "The guy who coined 'vibe coding' predicts it will 'terraform software and alter job descriptions'",
    "description": "Andrej Karpathy led AI at Tesla and cofounded OpenAI. He wrote that vibe coding has produced a new type of code that is \"free\" and \"discardable.\"",
    "fullText": "He coined \"vibe coding\" earlier this year. Now, he has something to say about it.\n\nAndrej Karpathy led AI at Tesla for five years, steering the company's Autopilot effort and briefly working on its humanoid robot Optimus. He sandwiched his Tesla job with two stints at OpenAI, making Karpathy a cofounder of the AI pioneer.\n\nAs 2025 comes to a close, Karpathy published his year-in-review for large language models on X. He reflected on the famous term he originated in February, a term that has since shaken up the software engineering industry.\n\n\"With vibe coding, programming is not strictly reserved for highly trained professionals,\" Karpathy wrote. He called it an example of how \"regular people benefit a lot more from LLMs compared to professionals, corporations and governments.\"\n\nVibe coding has likely benefited businesses, too. Tech companies have equipped their engineers with tools like Cursor, Claude Code, and OpenAI's Codex, aiming for productivity gains.\n\nKarpathy wrote that vibe coding \"empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written.\"\n\nIt may also change the makeup — or the use case — of the code itself. Karpathy threw out a slew of adjectives to describe this new body of code: It is \"free, ephemeral, malleable, discardable after single use.\"\n\n\"Vibe coding will terraform software and alter job descriptions,\" he wrote.\n\nHow does Karpathy feel about being the term's origin?\n\n\"Amusingly, I coined the term \"vibe coding\" in this shower of thoughts tweet totally oblivious to how far it would go,\" he wrote.\n\nThere's a new kind of coding I call \"vibe coding\", where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It's possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisper…\n\nIt's not yet clear how efficient vibe coding is making engineers. In a METR study published in July, AI coding assistants were found to decrease the productivity of participating experienced software developers by 19%. The developers in that study were also overconfident in the tools, its authors said, expecting a 20% productivity boost even after using them.\n\nWhat is clear, though, is that the practice is unlocking a whole new form of tech products. Twitter founder Jack Dorsey vibe-coded a new messaging app this year. Non-technical workers are easily building, shipping, and, in some cases, even selling apps they build in hours, if not minutes.\n\nKarpathy gave some other reflections. He praised Google Gemini's Nano Banana image model, and wrote that Claude Code was the \"first convincing demonstration of what an LLM Agent looks like.\"\n\nOverall, Karpathy wrote that 2025 was an \"exciting and mildly surprising year of LLMs.\"",
    "readingTime": 3,
    "keywords": [
      "trained professionals",
      "vibe coding",
      "software",
      "llms",
      "productivity",
      "karpathy",
      "coined",
      "tesla",
      "published",
      "tech"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andrej-karpathy-coined-vibecoding-ai-prediction-2025-12",
    "thumbnail_url": "https://i.insider.com/68f53bf05dbc4fd10dab1f5f?width=1200&format=jpeg",
    "created_at": "2025-12-23T18:17:54.745Z",
    "topic": "finance"
  },
  {
    "slug": "the-death-and-rebirth-of-programming",
    "title": "The Death and Rebirth of Programming",
    "description": "Programming didn't die all at once. There was no single moment, no dramatic obsolescence event. Instead, something quieter happened: the core constraint that shaped software for seventy years dissolved. Writing code stopped being the hard part.",
    "fullText": "For most of computing history, programming was bottlenecked by human cognition. Translating intent into working software required time, attention, and specialized skill. Even small changes were costly. This scarcity justified entire ecosystems: languages, frameworks, methodologies, reviews, team rituals that made sense when every line was expensive.\n\nGenerative AI removes that scarcity.\n\nToday, a single developer can generate thousands of lines of working code in minutes. Tomorrow, that number will be effectively infinite. The marginal cost of producing code is collapsing toward zero.\n\nWhat hasn't collapsed is the cost of knowing what the code does.\n\nUnderstanding, verifying, securing, and evolving software remain stubbornly expensive. In fact, they may be getting harder as volume explodes. This asymmetry—the ease of creation versus the difficulty of comprehension—is the defining tension of modern software.\n\nProgramming hasn't disappeared. But its center of gravity has shifted.\n\nIn the old world, programmers owned code. You wrote it, you understood it, you maintained it. Your value was tied to mastery of specific implementations. Codebases accrued history, reputation, and power.\n\nIn the new world, ownership becomes a liability.\n\nWhen code can be regenerated faster than it can be understood, preserving it for sentimental or historical reasons no longer makes sense. What matters instead is stewardship: maintaining the system's behavior, boundaries, and intent over time, regardless of how many times its internals are replaced.\n\nThis reframing is subtle but profound:\n\nThe asset is no longer the codebase. The asset is the system's ability to keep working.\n\nThis is the thesis of everything that follows. Architecture, testing, interfaces, team structure: all of it flows from this inversion.\n\nMany of the \"modern\" software practices of the last decade were early adaptations to this shift, even if we didn't articulate them that way.\n\nImmutable infrastructure. Stateless services. Containers. Blue-green deployments. Infrastructure as code.\n\nThese ideas all share a common premise: never fix a running thing. Replace it.\n\nAI pushes this premise beyond infrastructure and into application code itself. When rewriting is cheap, editing in place becomes risky. Mutation accumulates entropy. Replacement resets it.\n\nDisposability stops being a hack. It becomes the default.\n\nThis transition isn't just technical. It's deeply psychological, and that psychology shapes architecture.\n\nMany developers identify as builders and craftspeople. We take pride in elegance, cleverness, and mastery of internals. We accumulate knowledge inside our heads and inside codebases. Longevity feels like validation.\n\nGenerative AI destabilizes this identity.\n\nWhen a machine can produce a competent version of \"your\" solution in seconds, craftsmanship no longer lies in the artifact. It lies in framing the problem, defining success, and deciding what to keep and what to discard.\n\nThe role shifts from maker to architect. From author to managing editor. From preserving code to designing for its replacement.\n\nThat shift is uncomfortable. And the discomfort isn't merely personal. It's what makes teams resist the very patterns that would help them. Developers cling to codebases because identity is at stake, not just technical judgment. Acknowledging this is the first step toward building systems that don't require heroics to change.\n\nResisting the shift doesn't stop it. It just makes systems more fragile.\n\nOne of the clearest signals of this new era is the rise of the n=1 developer.\n\nProjects that once required teams now fit inside a single person's cognitive boundary—with AI filling in the execution gaps. Entire products can be specified, generated, evaluated, and shipped by one human working with machines.\n\nThis isn't about productivity hacks. It's about a structural change in leverage.\n\nBut n=1 development only works if systems are designed for it. Large, tangled, historically accreted codebases collapse under their own weight when AI accelerates change. Small, modular, disposable systems thrive.\n\nThe n=1 developer is not a superhero. They are an indicator species. They are evidence that the environment has changed, and proof that the new patterns actually work.\n\nIt's tempting to frame this as the \"end of programming.\" That's misleading.\n\nWhat's dying is a specific form of programming: one that equates value with authored code, longevity of code with quality, and maintenance with virtue.\n\nWhat's being born is something closer to systems design as an ongoing process of regeneration:\n\nCode becomes an intermediate artifact, not the final product. Rewrites become routine, not traumatic. Tests and evaluations define truth, not files. Stability emerges from replacement, not preservation.\n\nThis is not nihilism. It's pragmatism under new constraints.\n\nThe rest of this publication builds on a single premise established here:\n\nWhen code is cheap and understanding is expensive, architecture must optimize for the impermanence of code.\n\nEverything else (pace layers, evaluations, clean interfaces, regeneration workflows) flows from that fact.\n\nWe are not entering a world with less software. We are entering a world with vastly more of it. The only way to survive that abundance is to stop treating code as precious.\n\nBut it has been reborn, and it expects us to change with it.",
    "readingTime": 5,
    "keywords": [
      "modern software",
      "generative ai",
      "code",
      "it's",
      "systems",
      "programming",
      "codebases",
      "expensive",
      "developer",
      "longer"
    ],
    "qualityScore": 1,
    "link": "https://aicoding.leaflet.pub/3malrv6poy22a",
    "thumbnail_url": "https://leaflet.pub/lish/did%253Aplc%253A4qsyxmnsblo4luuycm3572bq/3majnsnvafs2b/3malrv6poy22a/opengraph-image?6815eb61f733905a",
    "created_at": "2025-12-23T00:56:32.109Z",
    "topic": "tech"
  },
  {
    "slug": "browserforge-ai-browser-agents-1000-free-credits",
    "title": "BrowserForge – AI browser agents (1000 free credits)",
    "description": "AI browser agents that automate web tasks 24/7. Extract data, fill forms, monitor prices, and handle any repetitive browser work. No coding required - just show your agent what to do.",
    "fullText": "Agents navigate websites like humans—clicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.\n\nAgents navigate websites like humans—clicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.\n\nAgents navigate websites like humans—clicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.",
    "readingTime": 2,
    "keywords": [
      "sessions intelligent",
      "define connect",
      "connect browser",
      "via api",
      "api webhooks",
      "intelligent agents",
      "humans—clicking buttons",
      "buttons filling",
      "maintaining authenticated",
      "understand web"
    ],
    "qualityScore": 0.85,
    "link": "https://www.browserforge.ai/",
    "thumbnail_url": "https://browserforge.ai/media/browserforge-hero-1.png",
    "created_at": "2025-12-22T18:17:58.401Z",
    "topic": "tech"
  },
  {
    "slug": "a-selfassessment-quiz-to-measure-software-development-seniority-level",
    "title": "A self-assessment quiz to measure software development seniority level",
    "description": "Take a free quiz based on real-world achievements and see your software developer level against cross-industry benchmarks.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://mylevel.dev/",
    "thumbnail_url": "https://storage.tally.so/53a7ed1d-311d-4027-be0d-d842b419a4a7/Level-measurement.jpeg",
    "created_at": "2025-12-21T01:00:00.485Z",
    "topic": "tech"
  },
  {
    "slug": "ai-tools-make-coders-more-important-not-less",
    "title": "AI Tools Make Coders More Important, Not Less",
    "description": "Many leaders are excited about the promise of AI coding tools that can make it easier for novices to write code and, seemingly, make experienced coders less essential. Yet these tools make experience more—not less—important, as AI is not a replacement for real engineers. Companies that want to use these tools should follow common rules. Make sure every change it makes is double-checked—with automatic checks, simple tests that confirm things still work, and at least one human review. Keep access limited: Let AI work only in a safe “practice” environment, never give it the keys to live customer data, and routinely check for basic security mistakes like files or storage left open to the public.",
    "fullText": "AI Tools Make Coders More Important, Not Less by Michael LiDecember 19, 2025PostPostShareSavePrintSummary.   Leer en españolLer em portuguêsPostPostShareSavePrintOf all the possible applications of generative AI, the value proposition of using it to write code was perhaps the clearest. Coding can be slow and it requires expertise, both of which can be expensive. Moreover, the promise that anyone who could describe their idea in plain text could create apps, features, or other value-adding products meant that innovation would no longer be limited to those with the skills to execute, but could be done by anyone with an idea. The strength of this promise has created a $7.37 billion market for these tools.",
    "readingTime": 1,
    "keywords": [
      "tools",
      "promise",
      "anyone",
      "idea"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/ai-tools-make-coders-more-important-not-less",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_22t-kaiser-7uH3ndea63o-unsplash.jpg",
    "created_at": "2025-12-19T18:17:22.482Z",
    "topic": "business"
  },
  {
    "slug": "introduction-to-programming-the-commodore-pet",
    "title": "Introduction to Programming the Commodore PET",
    "description": "History of the Commodore PET and how to approach programming the classic system",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://retrogamecoders.com/introduction-to-programming-the-commodore-pet/",
    "thumbnail_url": "https://retrogamecoders.com/wp-content/uploads/2025/12/Programming-the-Commodore-PET.jpg",
    "created_at": "2025-12-19T12:22:25.882Z",
    "topic": "tech"
  },
  {
    "slug": "metas-28yearold-billionaire-prodigy-says-the-next-bill-gates-will-be-a-13yearold-who-is-vibe-coding-right-now",
    "title": "Meta’s 28-year-old billionaire prodigy says the next Bill Gates will be a 13-year-old who is ‘vibe coding’ right now",
    "description": "Teenagers, Alexandr Wang argues, have a built-in edge.",
    "fullText": "Eva is a fellow on Fortune's news desk.\n\nAlexandr Wang—who became the world’s youngest self-made billionaire at 24—is now, at 28, running one of the most ambitious AI efforts in Silicon Valley. In his first 60 days at Meta, he built a 100-person lab he described to TBPN hosts John Coogan and Jordi Hays as “smaller and more talent dense than any of the other labs.”\n\nHis goal: nothing less than superintelligence.\n\nWang, with his aerial view of the industry, has advice for kids, especially those in Gen Alpha now entering middle school: Forget gaming, sports, or traditional after-school hobbies.\n\n“If you are like 13 years old, you should spend all of your time vibe coding,” he said in his recent TBPN interview. “That’s how you should live your life.”\n\nFor Wang, the reasoning is simple. Every engineer, himself included, is now writing code he believes will be obsolete within five years.\n\n“Literally all the code I’ve written in my life will be replaced by what will be produced by an AI model,” he said.\n\nThat realization has left him, in his words, “radicalized by AI coding.” What matters most now isn’t syntax, or learning a particular language, but time spent experimenting with and steering AI tools.\n\n“It’s actually an incredible moment of discontinuity,” Wang said. “If you just happen to spend 10,000 hours playing with the tools and figuring out how to use them better than other people, that’s a huge advantage.”\n\nTeenagers have a clear advantage over adults: time and freedom to immerse themselves in new technology. And while in the past, entrepreneurial teenagers leveraged this time to be “sneaker flippers” or run Minecraft servers, Wang says the focus should now be on the code.\n\nHe compares the moment to the dawn of the PC revolution. The Bill Gateses and Mark Zuckerbergs of the world had an “immense advantage” simply because they grew up tinkering with the earliest machines.\n\n“That moment is happening right now,” Wang said. “And the people who spend the most time with it will have the edge in the future economy.”\n\nWang isn’t coy about Meta’s ambitions. He calls the company’s infrastructure, scale, and product distribution unmatched.\n\n“We have the business model to support building literally hundreds of billions of dollars of compute,” he said.\n\nHis team, just over 100 people, is deliberately designed to be “smaller and more talent dense” than rivals. “The other labs are like 10 times bigger,” Wang said, but their lab had “cracked” coders.\n\nThe lab is split into three pillars: research, product, and infrastructure. Research builds the models Wang says will “ultimately be superintelligent.” Product ensures they get distributed across billions of users through Meta’s platforms. And infrastructure focuses on what he calls “literally the largest data centers in the world.”\n\nWang is particularly excited about hardware. Like many Meta executives now, he points to the company’s new smart glasses, which had a hilariously foppish demo, as the “natural delivery mechanism for superintelligence.”\n\nPlaced right next to the human senses, they will merge digital perception with cognition.\n\n“It will literally feel like cognitive enhancement,” Wang said. “You will gain 100 IQ points by having your superintelligence right next to you.”\n\nVibe coding is the shorthand for this shift: using natural language prompts to generate and iterate on code. Rather than writing complex syntax, users describe their intent, and AI produces functioning prototypes.\n\nThe concept is spreading across Silicon Valley’s C-suites. Klarna CEO Sebastian Siemiatkowski has said he can now test ideas in 20 minutes, instead of burning weeks of engineering cycles. Google CEO Sundar Pichai revealed that AI already generates more than 30% of new code at the company, calling it the biggest leap in software creation in 25 years.\n\nWang takes that further. For him, vibe coding isn’t just a productivity hack, but a future cultural mandate. What matters isn’t the code itself — it’s the hours of intuition-building that come from pushing AI tools to their limits, which is why he urges Gen Alpha to start early.\n\n“The role of an engineer is just very different now than it was before,” he said.\n\nA version of this story was published on Fortune.com on September 19, 2025.",
    "readingTime": 4,
    "keywords": [
      "talent dense",
      "vibe coding",
      "gen alpha",
      "code",
      "literally",
      "isn’t",
      "wang",
      "superintelligence",
      "tools",
      "moment"
    ],
    "qualityScore": 1,
    "link": "https://fortune.com/article/what-is-vibe-coding-alexandr-wang-bill-gates-meta/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/09/GettyImages-1540568935-e1758305593707.jpg?resize=1200,600",
    "created_at": "2025-12-19T12:22:22.800Z",
    "topic": "business"
  },
  {
    "slug": "orbit-a-systems-level-programming-language-that-compiles-sh-to-llvm",
    "title": "Orbit a systems level programming language that compiles .sh to LLVM",
    "description": "A modern shell with functional programming synatx. - SIE-Libraries/orbit",
    "fullText": "SIE-Libraries\n\n /\n\n orbit\n\n Public\n\n A modern shell with functional programming synatx.\n\n License\n\n View license\n\n 5\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n SIE-Libraries/orbit",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/SIE-Libraries/orbit",
    "thumbnail_url": "https://opengraph.githubassets.com/dcaf4ed1c20da5475350ce0f3bf442eb03297772f6ad4097b4b2009e9ba5d922/SIE-Libraries/orbit",
    "created_at": "2025-12-19T09:39:44.047Z",
    "topic": "tech"
  },
  {
    "slug": "codingforpreschoolers-firm-files-bankruptcy-after-covid-boom",
    "title": "Coding-for-Preschoolers Firm Files Bankruptcy After Covid Boom",
    "description": "An education company that helps children as young as three learn to code filed for bankruptcy, blaming an expansion strategy that outpaced its ability to turn a profit.",
    "fullText": "WealthBy Steven ChurchSaveAn education company that helps children as young as three learn to code filed for bankruptcy, blaming an expansion strategy that outpaced its ability to turn a profit.Conscious Content Media Inc. would eliminate more than half of its $205.5 million in funded debt under a reorganization proposal backed by noteholders, according to court papers filed Wednesday in federal court in Wilmington, Delaware.",
    "readingTime": 1,
    "keywords": [
      "filed",
      "court"
    ],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/articles/2025-12-18/coding-for-preschoolers-firm-files-bankruptcy-after-covid-boom",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iCA4eahCxR3k/v1/1200x800.jpg",
    "created_at": "2025-12-18T18:18:26.956Z",
    "topic": "finance"
  },
  {
    "slug": "i-built-an-app-for-vibecoding-games",
    "title": "I built an app for vibe-coding games",
    "description": "Got a game idea? Just describe it and start playing in seconds.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://playmix.ai/",
    "thumbnail_url": "https://playmix.ai/assets/og-image.png",
    "created_at": "2025-12-18T12:23:04.291Z",
    "topic": "tech"
  },
  {
    "slug": "learning-the-oldest-programming-language-2024",
    "title": "Learning the oldest programming language (2024)",
    "description": "Who needs Rust when we have Fortran?",
    "fullText": "While I probably should be learning a language like C, Go, or whatever new trendy language the ThePrimeagen mentions on Twitter (OCaml?), I'm going to attempt to learn Fortran[1].\n\nFortran, which stands for FORmula TRANslator[2], was created at IBM by John Backus in 1957 for scientific applications and has apparently been popular for high-performance computing and benchmarking supercomputers in recent years. Fortran has had several subsequent releases since then; FORTRAN 77, Fortran 90, Fortran 95, Fortran 2003, Fortran 2008, and the latest Fortran 2018.\n\nTo understand what version of Fortran to learn/use, we first must understand the difference between fixed form and free form Fortran. The fixed form layout comes from the very beginning of Fortran, inherited from punch cards, and has odd restrictions about the column in which comments and statements are placed. The free form layout, first introduced in Fortran 90, removed special columns and added the ability to write comments wherever, and is what we'll be learning in this article. The compiler we'll be using is GNU Fortran, or gfortran. You can install it via Homebrew (macOS) with the gcc formula, or install it using a package manager for your OS. To tell gfortran that your code uses the free form layout, set the file extension to .f90 or newer. The following comment on the Fortran discussion board explains this well.\n\nThe .f90 suffix means that the source code is free format, not that\nthe code conforms to the Fortran 90 standard. Code that uses the .f90\nsuffix can use features from any Fortran standard. All Fortran\ncompilers recognize .f90 as a suffix indicating free source form, but\nsome may not recognize a suffix such as .f95, .f03, .f08, or .f18.\nSome users may have build tools that do not recognize suffixes other\nthan .f90. Most Fortran source code on GitHub that uses features from\na standard more recent than Fortran 90 still uses the .f90 suffix.\n\nComing from TypeScript, and before that, Python, I'm very used to (and comfortable with) modern — you might say \"aesthetic\" — syntax . Although I wouldn't say Fortran syntax is quite modern, it seems to avoid the syntactic sugar nightmares that plague beginners in other languages[3]. Take a look at this helloworld.f90 example below.\n\nOlder Fortran programs required the use of SCREAMING_CASE for all keywords, but in modern Fortran you can and it is recommended to use snake_case (you can still use SCREAMING_CASE or any other case you want though).\n\nJust from this small example we can gather that...\n\nThe syntax for printing is a little funky though. What is that asterisk doing there? The asterisk, aside from being used as a mathematical operator, indicates the \"default\". So for print, * means \"print to the default output channel\" (or \"print to the default output file unit\" to be precise), which is typically going to be STDOUT.\n\nI can't find exactly where this is documented but you don't actually need the start and end program <program-name>; you could write a hello world program like this, though as I just mentioned this doesn't seem to be a common practice and isn't really very useful in any practical scenario.\n\nHere's another, slightly more complicated example.\n\nStarting right at the top, we have something new: implicit none. Added in Fortran 90, implicit none disables implicit typing defaults and all variables must be explicitly declared. In Fortran, implicit typing is the practice of assigning default types to variables based on the character a variable name begins with. Variables starting with I through N are INTEGERs, everything else is REAL. It is \"a legacy of the past\" and usage of an implicit none statement is \"strongly advised\" (implicit none - Fortran Wiki).\n\nA common Fortran joke goes along the lines of “GOD is REAL, unless declared INTEGER\"[4] because of implicit typing!\n\nMoving on, we declare our first variables in this program.\n\nHere we are declaring x, y, and answer with the REAL type, and choice with the CHARACTER type. The REAL type stores floating point numbers[5], and CHARACTER... stores characters.\n\nNext, we prompt the user for our x and y values.\n\nNotice how we can take input from the user with read and assign it to a value with the read *, <variable> syntax. The asterisk here means read from the default input channel/file unit, which would be STDIN.\n\nWe do the same for prompting the user to select an operation.\n\nFinally, we use a series of basic if-statements to calculate our answer and display it in the terminal.\n\nIf we run this, we- wait. Did I even tell you how to compile a Fortran program yet?\n\nFirst, compile our calculator program with gfortran -o calculator calculator.f90 . Then you can run it with ./calculator. If you only instruct gfortran of the input file (gfortran calculator.f90), the default output executable will be named a.out.\n\nOur calculator isn't perfect yet though. What if the user tries to divide by zero?\n\nProbably not the answer you expected. Let's try to fix that.\n\nHere we use the inequality operator, /=, to check if the y value is zero. Now, if the user tries to divide by zero, we'll print an error message and use the stop statement to end the program.\n\nGreat. We got rid of the zero division mess, but our code isn't pretty at all. Who wants a bunch of if statements? We can simplify this using the select case statement (also known as the case statement).\n\nThis also has the handy benefit of telling the user if they made an invalid choice while selecting the operation.\n\nThat’s just a quick introduction to a few modern Fortran features: declaring variables, printing and reading to and from the terminal, if and select case, and stop. Next time, we’ll talk more about where Fortran is actually used, cooler things you can build with it, and how the Fortran language & community are rapidly modernizing!\n\nIronically, in the ~3-ish months since I started writing this article, ThePrimagen has recently said he \"take[s] back everything i said about FORTRAN\" — apparently having some interest in the language! ↩︎\n\nAccording to sources listed on Fortran's Wikipedia, the name might also have stood for Formula Translating System or just Formula Translation. ↩︎\n\nSee The Rust programming language absolutely positively sucks : r/rust and Rust is a nightmare to learn coming from Java - community - The Rust Programming Language Forum. ↩︎\n\nThe first letter of \"GOD\", a \"G\", is not within I through N and is therefore of the REAL type (\"GOD is REAL\"). ↩︎\n\nYou can also use double precision for larger (more precise) floating point numbers. ↩︎",
    "readingTime": 6,
    "keywords": [
      "rust programming",
      "default output",
      "programming language",
      "implicit none",
      "implicit typing",
      "fortran standard",
      "modern fortran",
      "code",
      "user",
      "free"
    ],
    "qualityScore": 1,
    "link": "https://uncenter.dev/posts/learning-fortran/",
    "thumbnail_url": "https://uncenter.dev/1024w.png?v=2316a73de1f9",
    "created_at": "2025-12-17T13:45:44.913Z",
    "topic": "tech"
  },
  {
    "slug": "scrappy-free-ai-code-assistant",
    "title": "Scrappy Free AI Code Assistant",
    "description": "A powerful, context-aware coding assistant for everyone. Students, learners, anyone who doesn't want to pay for subscriptions. - HakAl/scrappy",
    "fullText": "HakAl\n\n /\n\n scrappy\n\n Public\n\n A powerful, context-aware coding assistant for everyone. Students, learners, anyone who doesn't want to pay for subscriptions.\n\n pypi.org/project/scrappy-ai/\n\n License\n\n MIT license\n\n 6\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n HakAl/scrappy",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/HakAl/scrappy",
    "thumbnail_url": "https://opengraph.githubassets.com/f4b80c7981acbe65eb74d5f829f65f4c5ad79abda560cef1db5838b375628d52/HakAl/scrappy",
    "created_at": "2025-12-17T03:45:04.030Z",
    "topic": "tech"
  },
  {
    "slug": "adventures-in-the-land-of-language-servers",
    "title": "Adventures in the Land of Language Servers",
    "description": "Have you ever wondered how your editors and IDEs are able to support so many programming languages? Perhaps you've been thinking about designing your ow…",
    "fullText": "Have you ever wondered how your editors and IDEs are able to support so many programming languages? Perhaps you've been thinking about designing your own language and wanted to know how you can give it editor support?\n\nThis talk is for you - I've spent over a year building a small language and integrating it with code editors, and I'd like to share some of the challenges I've faced, as well as lessons I've learned in that time.\n\nI'll also show how easy it is to build a new Language Server project in Scala 3 thanks to the Langoustine library.",
    "readingTime": 1,
    "keywords": [
      "i've",
      "editors",
      "language"
    ],
    "qualityScore": 0.45,
    "link": "https://speakerdeck.com/kubukoz/adventures-in-the-land-of-language-servers",
    "thumbnail_url": "https://files.speakerdeck.com/presentations/548a94549c554eaf8a5d70effbc439b1/slide_0.jpg?25884509",
    "created_at": "2025-12-17T03:45:03.996Z",
    "topic": "tech"
  },
  {
    "slug": "optimizing-claude-code",
    "title": "Optimizing Claude Code",
    "description": "Customize Claude Code with skills, plugins, commands, and configuration files that transform a capable coding assistant into one that matches your exact workflow.",
    "fullText": "I’ve been using Claude Code for months now, and for most of that time, I was doing it wrong. Not wrong in the sense of getting bad results—the defaults are remarkably capable. Wrong in the sense that I was treating a customizable system like a fixed tool. I was adjusting my workflow to fit the AI instead of adjusting the AI to fit my workflow.\n\nThe difference between default Claude Code and a properly configured instance is the difference between hiring a talented generalist and hiring someone who’s worked at your company for years. Both can write code. Only one knows that your team prefers for…of over .forEach(), that you never use the I prefix on interfaces, and that when you say “analyze this bug,” you mean a specific six-step process that includes hypothesis testing.\n\nHere’s how I built that second version.\n\nClaude Code’s customization system has multiple layers, each serving a different purpose:\n\nWhat’s less widely appreciated is how these layers interact. When Claude Code starts a session, it reads your settings, loads relevant skills based on context, and injects CLAUDE.md into its system prompt. When you invoke a command, it triggers a predefined workflow. When you mention a topic covered by a skill, Claude applies that expertise automatically.\n\nMy ~/.claude/settings.json is minimal but deliberate:\n\nalwaysThinkingEnabled: true — This enables extended thinking on every response. The tradeoff is latency for quality. For complex refactoring or architectural decisions, I want Claude to think deeply. For quick questions, it’s overkill. I keep it on because my typical use case is substantial engineering work.\n\nToken limits — Increasing CLAUDE_CODE_MAX_OUTPUT_TOKENS to 64000 prevents truncation on large refactors. The MAX_THINKING_TOKENS setting controls how much “thinking” space Claude has before responding.\n\nincludeCoAuthoredBy: false — I don’t need AI authorship attribution in every commit message. Personal preference.\n\nThe full settings file is available in my dotfiles repo.\n\nEvery project gets a CLAUDE.md at the root. This is where you encode project-specific knowledge: commands to build and test, directory structure, coding principles, workflow patterns.\n\nThe key insight: CLAUDE.md is a system prompt you control. Every instruction you put here shapes every response you get. You can define escalation patterns that tell Claude to stop thrashing and switch to a structured process after failed attempts—for example, my Bug Fix workflow triggers a 6-step root cause analysis after two failed fixes.\n\nFull template: CLAUDE.md in dotfiles\n\nSkills are markdown files that encode specialized knowledge. When Claude detects that a skill is relevant to your task, it applies that expertise automatically.\n\nThis skill encodes my team’s TypeScript conventions—things that aren’t in style guides but matter for consistency:\n\nThe full skill covers interfaces vs types, enum conventions, null handling, type assertions, and module imports. It’s 700+ lines because TypeScript has a lot of conventions worth encoding.\n\nFor Lambda, DynamoDB, and SQS patterns:\n\nThis skill catches AI-generated code patterns that don’t match human-written code:\n\nThis is something I’ve noticed consistently: AI models add defensive code and comments that human developers wouldn’t. Having a skill that explicitly tells Claude to avoid these patterns makes the output feel more natural.\n\nSkills directory: skills in dotfiles\n\nSkills teach Claude how to code. Hooks enforce that it does. The difference matters.\n\nA skill might say “prefer for…of over .forEach()“—but Claude can still forget. A hook catches it in real-time, warning or blocking before the code is written. It’s the difference between training and guardrails.\n\nI use the hookify plugin to create enforcement rules from simple markdown files. Here are my active hooks:\n\nHooks are markdown files with YAML frontmatter. Here’s an example that blocks as any casts:\n\nThe action field determines severity:\n\nThis is where customization compounds. My TypeScript patterns skill teaches Claude the conventions. My hooks enforce them. If Claude violates a convention—say, using as Type instead of <Type>—the hook catches it before the code is written.\n\nThe feedback loop is immediate: Claude sees the warning, adjusts its output, and continues. Since Claude Code is stateless between sessions, the hooks provide consistent enforcement every time. Skills inform, hooks enforce.\n\nHooks directory: hooks in dotfiles\n\nCommands are like shell aliases for Claude workflows. Instead of typing a detailed prompt, you invoke /analyze-bug or /simplify and get a consistent, structured response.\n\nCommands directory: commands in dotfiles\n\nAgent docs are markdown files in .claude/agent_docs/ that Claude reads when relevant. Unlike skills (which encode how to do things), agent docs provide reference material (what things are).\n\nCLAUDE.md tells Claude when to read each doc. More efficient than stuffing everything into context—Claude loads docs on demand.\n\nAgent docs: agent_docs in dotfiles\n\nPlugins add new tools and workflows to Claude’s toolkit. I use several, organized by purpose:\n\nast-grep — Structural code search using AST patterns. Better than regex for finding code patterns that span multiple lines or have variable formatting. When I need to find all functions that return a Promise but don’t handle errors, ast-grep finds them regardless of formatting. Requires the CLI tool installed separately:\n\ndev-browser — Browser automation for testing web applications. When I say “go to localhost:3000 and click the login button,” Claude can actually do that.\n\nfrontend-design — UI/UX design assistance for frontend work. Part of the official Claude Code plugins.\n\nhookify — Creates enforcement rules from markdown files (covered in the Hooks section above). The key plugin for active convention enforcement.\n\ncommit-commands — Three git workflow commands:\n\nfeature-dev — A 7-phase structured workflow for complex features:\n\nFor complex features that touch multiple files, /feature-dev ensures nothing is missed.\n\npr-review-toolkit — Six specialized review agents that run in parallel:\n\nWhen I say “review my PR,” these agents analyze different dimensions simultaneously and return prioritized findings.\n\nPlugins are installed via the Claude Code plugin system. Official plugins require adding the Anthropic marketplace first:\n\nThe configuration in settings.json enables them:\n\nRun this to install my skills, commands, and hooks:\n\nThe script sets up ~/.claude/ and prints the plugin commands to run inside Claude Code.\n\nIf you prefer to set things up yourself:\n\nCreate ~/.claude/skills/typescript-patterns/SKILL.md with your TypeScript conventions. The filename must be SKILL.md and include frontmatter with name and description.\n\nCreate ~/.claude/commands/analyze-bug.md with your debugging workflow. Commands are invoked with /analyze-bug (the filename becomes the command name).\n\nAfter installing hookify, create enforcement rules:\n\nHooks take effect immediately—no restart required.\n\nCreate CLAUDE.md at the root of each project with project-specific instructions.\n\nMy complete configuration: github.com/stevenmays/dotfiles/tree/master/ai/claude\n\nHere’s what I didn’t expect: these customizations compound.\n\nA skill that teaches TypeScript conventions means Claude knows my preferences. A hook that enforces those conventions means Claude can’t forget them. A command that structures bug investigation means debugging follows a consistent process. A plugin that runs six review agents in parallel means PR reviews are thorough without being tedious.\n\nEach layer reinforces the others:\n\nThe time investment—maybe a few hours total—pays dividends on every subsequent session. I’m not constantly re-explaining preferences or correcting patterns. Claude already knows. And when it forgets, the hooks catch it.\n\nIt’s not that X is bad and Y is good, exactly; it’s more that default Claude Code is a capable generalist, while optimized Claude Code is a specialist who happens to share your opinions about code style, your workflow preferences, and your debugging methodology.\n\nThe choice is simple: accept defaults, work around quirks, and occasionally complain about AI-generated code that doesn’t match your style—or spend a few hours getting dialed in.",
    "readingTime": 7,
    "keywords": [
      "agent docs",
      "create enforcement",
      "typescript conventions",
      "expertise automatically",
      "claude code",
      "ai-generated code",
      "complex features",
      "hook catches",
      "review agents",
      "default claude"
    ],
    "qualityScore": 1,
    "link": "https://mays.co/optimizing-claude-code",
    "thumbnail_url": "https://mays.co/_astro/optimizing-claude-code.DOeMUOQN_Z2lns9R.jpg",
    "created_at": "2025-12-17T03:45:03.284Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-unveils-new-opensource-ai-models-amid-boom-in-chinese-offerings",
    "title": "Nvidia unveils new open-source AI models amid boom in Chinese offerings",
    "description": "Nvidia on Monday unveiled a new family of open-source artificial intelligence models that it says will be faster, cheaper and ​smarter than its previous offerings, as open-source offerings from Chinese AI labs proliferate.  Nvidia ‌is primarily known for providing chips that firms such as OpenAI use to train their closed-source models and ‌charge money for them.  Nvidia ⁠on Monday revealed the third ‌generation of its \"Nemotron\" large-language models aimed at writing, coding and other tasks.",
    "fullText": "SAN FRANCISCO, Dec 15 (Reuters) - Nvidia (NVDA) on Monday unveiled a new family of open-source artificial intelligence models that it says will be faster, cheaper and ​smarter than its previous offerings, as open-source offerings from Chinese AI labs proliferate.\n\nNvidia ‌is primarily known for providing chips that firms such as OpenAI use to train their closed-source models and ‌charge money for them. But it also offers a slew of its own models for everything from physics simulations to self-driving vehicles as open-source software that can be used by researchers or by other companies, with firms such as Palantir Technologies weaving Nvidia's model into their products.\n\nNvidia ⁠on Monday revealed the third ‌generation of its \"Nemotron\" large-language models aimed at writing, coding and other tasks. The smallest of the models, called Nemotron 3 Nano, was being released ‍Monday, with two other, larger versions coming in the first half of 2026.\n\nNvidia, which has become the world's most valuable listed company, said that Nemotron 3 Nano was more efficient than its predecessor - ​meaning it would be cheaper to run - and would do better at long tasks ‌with multiple steps.\n\nNvidia is releasing the models as open-source offerings from Chinese tech firms such as DeepSeek, Moonshot AI and Alibaba Group Holdings are becoming widely used in the tech industry, with companies such as Airbnb disclosing use of Alibaba' s. (BABA) Qwen open-source model.\n\nAt the same time, CNBC and Bloomberg have reported that Meta Platforms is considering shifting toward closed-source ⁠models, leaving Nvidia as one of the most prominent ​U.S. providers of open-source offerings.\n\nMany U.S. states and ​government entities have banned use of Chinese models over security concerns.\n\nKari Briski, vice president of generative AI software for enterprise at Nvidia, said the company aimed ‍to provide a \"model that ⁠people can depend on\", and was also openly releasing its training data and other tools so that government and business users could test it for security and ⁠customize it.\n\n\"This is why we're treating it like a library,\" Briski told Reuters in an interview. \"This is ‌why we're committed to it from a software engineering perspective.\"",
    "readingTime": 2,
    "keywords": [
      "open-source offerings",
      "closed-source models",
      "nemotron nano",
      "nvidia",
      "firms",
      "software",
      "reuters",
      "cheaper",
      "aimed",
      "tasks"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/nvidia-unveils-open-source-ai-140424565.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/31397226d241d376e5cffbf13490e071",
    "created_at": "2025-12-16T13:51:41.754Z",
    "topic": "finance"
  },
  {
    "slug": "claude-codes-creator-explains-the-limits-of-vibe-coding",
    "title": "Claude Code's creator explains the limits of vibe coding",
    "description": "The engineer behind Claude Code says vibe coding works for prototypes, but today's AI models still fall short for maintainable software.",
    "fullText": "The creator of one of the most popular AI coding tools says vibe coding can only go so far.\n\nBoris Cherny, the engineer behind Anthropic's Claude Code, said on an episode of \"The Peterman Podcast\" published Monday that while vibe coding has its place, it's far from a universal solution.\n\nIt works well for \"throwaway code and prototypes, code that's not in the critical path,\" he said.\n\n\"I do this all the time, but it's definitely not the thing you want to do all the time,\" Cherny said, referring to vibe coding.\n\n\"You want maintainable code sometimes. You want to be very thoughtful about every line sometimes,\" he added.\n\nClaude Code launched earlier this year as part of Anthropic's efforts to integrate AI more deeply into code development workflows.\n\nTop AI coding services like Cursor and Augment run on Anthropic's models, and even Meta uses Anthropic's models inside its coding assistant. Claude Code has also taken off with non-technical developers who want to build software with natural-language prompts.\n\nAnthropic's CEO, Dario Amodei, said in October that Claude was writing 90% of the code in the company.\n\nFor critical coding tasks, Cherny said he typically pairs with a model to write code.\n\nHe starts by asking an AI model to generate a plan, then iterates on the implementation in small steps. \"I might ask it to improve the code or clean it up or so on,\" he said.\n\nFor parts of the system where he has strong technical opinions, Cherny said he still writes the code by hand.\n\nCherny said the models are still \"not great at coding.\"\n\n\"There's still so much room to improve, and this is the worst it's ever going to be,\" he said.\n\nCherny said it's \"insane\" to compare current tools to where AI coding was just a year ago, when it amounted to little more than type-ahead autocomplete. Now, it's a \"completely different world,\" he said, adding that what excites him is how fast the models are improving.\n\nAI-assisted coding has been gaining momentum across the tech world.\n\nGoogle CEO Sundar Pichai said last month that vibe coding is \"making coding so much more enjoyable,\" adding that people with no technical background can now build simple apps and websites.\n\n\"Things are getting more approachable, it's getting exciting again, and the amazing thing is, it's only going to get better,\" he said in a podcast interview with Logan Kilpatrick, who leads Google's AI Studio.\n\nPichai said during Alphabet's April earnings call that AI is writing over 30% of the new code at Google, an increase from 25% in October 2024.\n\nIt's \"fantastic\" how quickly developers can write software with AI coding tools, sometimes while \"barely looking at the code,\" said Google Brain founder Andrew Ng in May.\n\nFor non-technical developers, vibe coding has enabled them to automate parts of their jobs, prototype ideas, or build a creative product on the side, Business Insider reported last month.\n\nStill, leaders caution that the technology has limits. AI-generated code could contain mistakes, be overly verbose, or lack the proper structure.\n\n\"I'm not working on large codebases where you really have to get it right, the security has to be there,\" Pichai said in November.",
    "readingTime": 3,
    "keywords": [
      "anthropic's models",
      "non-technical developers",
      "vibe coding",
      "coding tools",
      "claude code",
      "it's",
      "critical",
      "software",
      "improve",
      "parts"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/claude-code-creator-vibe-coding-limits-boris-cherny-anthropic-2025-12",
    "thumbnail_url": "https://i.insider.com/6940d32f04eda4732f2d9311?width=1200&format=jpeg",
    "created_at": "2025-12-16T06:59:53.631Z",
    "topic": "finance"
  },
  {
    "slug": "the-year-coding-changed-forever",
    "title": "The year coding changed forever",
    "description": "Optimism, laziness, and magical thinking: The year vibe coding took over tech.",
    "fullText": "Sriraam Raja, the founding engineer at the software company Decode, has been using generative AI to write code for two years. He says he can get projects done about twice as fast when he uses a chatbot to code with intention. Then one day, he fired off directions, and as he sat there while the bot's wheels turned, he realized he could have actively written what he was aimlessly waiting for the bot to do. \"I was giving away a bit of my agency, and so I made a decision to be very conscious,\" he tells me.\n\nRaja has become \"very specific about when I delegate, and also how much I delegate,\" he says. Waiting for the AI to spit out code can disrupt the flow of his work, and trusting too much work to it has led him to sometimes get bogged down in a lengthy review process. He's also anxious about the long-term effects AI can have on how we all think and problem solve. \"There's a side effect where everyone's confidence has increased, but so has their laziness, and their willingness to learn things from first principles has dropped,\" he says. \"I've definitely seen a drop in curiosity that I haven't seen before, and so that worries me.\"\n\nThe Collins dictionary made vibe coding its 2025 word of the year. Coined by OpenAI cofounder Andrej Karpathy in February, the term refers to using language and generative AI to speed up the coding process. Soon after, companies were adding it as a desired skill in job listings.\n\nVibe coding was the catalyst for the sort of vibe work era we've entered. It's a shift in how people think about their roles and relationships to work amid an AI boom, and software engineering, long considered a stable and lucrative career path, has perhaps been the career most scrutinized and pushed down a path toward automation. Product managers have suggested that AI will supercharge them, allowing them to take on some technical coding tasks and work without engineers.\n\nExecs have been all-in: Mark Zuckerberg said he expected AI to write half of Meta's code within a year; this spring, AI was already doing about a third of code at Google and on some Microsoft projects. Anthropic CEO Dario Amodei predicted in March that 90% of code would be generated by AI in three to six months. The bullish estimate hasn't materialized for most, but Amodei said in October the company's AI tool Claude was writing most of the code at Anthropic. Cognition, which built an AI-powered software engineer it named Devin, is now valued at $10 billion. Some without computer science backgrounds or any training in coding are vibe coding their own projects.\n\nVibe coding isn't yet the miracle that AI evangelists have professed. AI-generated code can have sneaky errors that pose security risks. As it takes on the work of junior developers, companies eager for gain could displace humans. Time banked with shortcuts now could disrupt training ground for learning basic coding skills, creating a tech worker career ladder collapse could ricochet through the industry. There is potential for developers to save time, to use AI to learn new languages and skills (something Raja tells me he's done), and to pare down their technical debt, or code that needs maintenance. But the impact of AI on the industry is more complicated than it is a silver bullet to efficiency.\n\nLast year, \"we were dealing with a lot of optimism and a lot of magical thinking\" around the capabilities of AI, says Tariq Shaukat, CEO of Sonar, a company that provides developers with tools to verify code. \"The vibe engineering tools are producing a lot of quantity. It's getting more functionally correct, but it's actually becoming more difficult to determine the quality and get the level of trust that you need to integrate that into your code base.\" The ranks of AI holdouts among developers are shrinking. A 2025 survey of professional developers from Stack Overflow found that only 19.3% don't use AI, and a commensurate 19.7% have an unfavorable opinion of AI. Yet less than 3% of respondents said they highly trust AI for accuracy.\n\nAnyone who has asked a chatbot a question knows that even a short inquiry often results in a verbose response. The same is true of code — when AI generates it, it's typically longer, making the possibility of errors hiding in the code more likely. Amy Carrillo Cotten, senior director of customer transformation at software development company Uplevel, told me in September: \"For a lot of engineers, the only thing that looks different is where they spend their time, not exactly how much time it took.\" Uplevel studied 800 software developers last year and compared the productivity levels of those who used GitHub's Copilot to those who did not. The developers who used Copilot weren't more efficient or less burnt out, and their code had bugs in it 41% more frequently. (GitHub's own research found that those who used Copilot wrote about 18 lines of clean code, compared to 16 lines for those who didn't.) For many, that shift from writing to reviewing code is \"not the job they signed up for,\" Shaukat says, which brings a big adjustment for many developers.\n\n\"The job looks completely different,\" says Frank Fusco, CEO of a software company called Silicon Society. His company works with clients on their software, but now they often get amateur, vibe coded versions of those ideas as the starting point. \"What I would normally do in code that would take me days, I now do in words and it takes me hours.\" But Fusco tells me he worries about a decline in critical thinking and basic coding skills. We're \"hardwired,\" he says, to find \"the shortest path to the solution.\" But that approach isn't the best for sharpening coding skills. \"It really is a muscle that you have to work all the time.\"\n\nIt's tricky to say AI is already killing developer jobs. Years of layoffs and \"right-sizing\" in the tech industry, paired with the economic precarity that has also defined 2025, could be shifting industry roles alongside AI. As of November, there were about 92,500 active job postings seeking software engineers, down from nearly 102,000 last November and 159,000 at the start of 2023, according to data from CompTIA, a nonprofit trade association for the US IT industry. The number of active tech job posts overall has fallen, from 621,000 in early 2023 to 433,500 last month. But the proportion of open jobs looking for AI skills has jumped by 53% this year.\n\nAfter two decades of being told to pursue computer science as a stable career and a proliferation of coding bootcamps, working as a developer may not be as cushy. College seniors studying computer science are more likely than any other discipline to say they're \"very pessimistic\" about their careers, according to a 2025 survey from early career website Handshake. They're the group most likely to say the advances of generative AI have made them regret their major choice. But young people are divided — 43% of computer science majors said they think AI will have a positive effect on their careers.\n\nAutomation is in some ways marking \"a correction\" on the developer labor market, says April Schuppel, developer relations manager at software company Apryse. Before AI, \"we needed as many people who were really pushing out the code to take the ideas of the visionaries and bring them to life.\" Now, \"the people who have always been able to make the most impact, they're still the ones that are the safest.\" Developers who looked at their jobs as clearing tickets might be more replaceable than those who were creative and cared about the project from start to finish. We're far from realizing the end game of vibe coding, but for creative, forward-thinking developers, there's optimism for now. \"The more well-rounded people are the ones that are going to have success,\" Schuppel says.\n\nAI could bring more opportunity for software testers, and also help companies pare down their technical debt. The developer job market might look messy right now, but there's still a heavy focus on the human aspect of the career than in the picture painted by some Big Tech execs. \"If there are opportunities for more fine-tuned models, more specialized models that only do certain types of code updates, and there is a way to use that more to augment human developers as opposed to replace, that seems like that's where this is going,\" says Tim Herbert, chief research officer at CompTIA.\n\nCodebases are valuable, and the security risks posed by goofs in AI code are serious threats. Traffic to vibe coding sites slumped in September after a summer of hype. Even Karpathy said his latest project is \"basically entirely hand-written (with tab autocomplete)\" in a post on X. \"I tried to use claude/codex agents a few times but they just didn't work well enough at all and net unhelpful.\" If 2025 was the year tech companies went all in on AI, 2026 might be the year when some of the craze around vibe coding subsides and reality sets in.\n\nAmanda Hoover is a senior correspondent at Business Insider covering the tech industry. She writes about the biggest tech companies and trends.",
    "readingTime": 8,
    "keywords": [
      "security risks",
      "technical debt",
      "computer science",
      "basic coding",
      "vibe coding",
      "tech industry",
      "coding skills",
      "developers",
      "software",
      "code"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/year-coding-changed-forever-silicon-valley-2025-12",
    "thumbnail_url": "https://i.insider.com/693c966a64858d02d216c23d?width=1200&format=jpeg",
    "created_at": "2025-12-15T13:53:47.187Z",
    "topic": "finance"
  },
  {
    "slug": "habits-that-make-a-great-programmer",
    "title": "Habits That Make a Great Programmer",
    "description": "8 rituals to level up your programming skills! Learn how to code better, think faster, and build complex systems with these actionable tips.",
    "fullText": "“How to get better at programming?” is the question I had been asked quite a few times, and today I lay down the 8 rituals I have been following, and action items for each, to be good and get better at programming.\n\nDoing something repeatedly always helps and writing a lot of code will develop our ability to\n\nIf we don’t do something repeatedly, it becomes extremely hard to get good at it. Writing code consistently helps us\n\nSolving programming questions is about developing logic but things become a little trickier when we build a complex system, as it requires us to take our programming skills to go up a notch. Some examples of complex systems are - a Library management system, a Twitter clone, an Instagram clone, etc. Building a complex system\n\nAfter we spend some time writing programs and solving problems, things become monotonous and do not seem to challenge us anymore, so to spice things up a bit we should model something from the real world, like\n\nThere are lots of libraries and framework like p5.js that makes visual programming simple.\n\nIt is not only writing code that improves our programming skills but it is reading some quality code written by expert programmers that make the difference. Reading code written by experts improve our programming vocabulary and by doing this we\n\nThe best way to start doing it is by picking up an open-source project and start skimming the code. It is okay to not understand it in the first go but it is important to skim it a few times and get acquainted. After a few skim, everything will fall in place, the code becomes familiar and we start to understand the flow and business logic.\n\nThere is always someone sitting on the other side of the globe, who knows a thing or two more than us. Look for them and collaborate on a project. The developer community is filled with super smart and super enthusiastic developers who love to share and collaborate. Use websites like Dev.to, Hashnode and Twitter to find and interact with like-minded people.\n\nA programming language is just a tool to express business logic. While learning a programming language we should try to understand the constructs and paradigms used - for example: Functional programming, Polymorphism, Event driven programming, Actor model, etc. It is important to do so because we could pick constructs from one language and use it in another to solve our problem. For example: picking Functional programming (Callbacks) from Javascript and using it in Python to create generic action functions.\n\nWriting code before putting in some thought is degraded the code more often than not. The code written like this lacks simplicity, reusability, and extensibility. Spending some time thinking about problem statement or task at hand and having a rough execution plan always helps.\n\nThese rituals have helped me get better at programming with time and in parallel, I pick at max 3 and act on the action items. Programming is simple but being better than most is difficult. Doing it consistently makes one get better by the day.",
    "readingTime": 3,
    "keywords": [
      "functional programming",
      "action items",
      "business logic",
      "complex system",
      "programming skills",
      "programming language",
      "code",
      "doing",
      "understand",
      "rituals"
    ],
    "qualityScore": 1,
    "link": "https://arpitbhayani.me/blogs/better-programmer/",
    "thumbnail_url": "https://edge.arpitbhayani.me/img/covers/general-cover.jpg",
    "created_at": "2025-12-15T03:59:06.895Z",
    "topic": "tech"
  },
  {
    "slug": "openais-head-of-codex-says-the-bottleneck-to-agi-is-humanitys-inability-to-type-fast-enough",
    "title": "OpenAI's head of Codex says the bottleneck to AGI is humanity's inability to type fast enough",
    "description": "OpenAI's Alexander Embiricos, who leads product development for its coding platform, said the need to review AI's work with prompts is limiting progress.",
    "fullText": "If you needed a sign for how determined AI-land is to achieve AGI quickly, it's that one of its leaders sees the speed of human typing as one of its biggest roadblocks.\n\nAlexander Embiricos, who leads product development for Codex, OpenAI's coding agent, said on \"Lenny's Podcast\" on Sunday that the \"current underappreciated limiting factor\" to AGI is \"human typing speed\" or \"human multi-tasking speed on writing prompts.\"\n\nAGI, or artificial general intelligence, is a still theoretical version of AI that reasons as well or better than humans. It's the thing all the big AI companies are competing to be the first to realize.\n\n\"You can have an agent watch all the work you're doing, but if you don't have the agent also validating its work, then you're still bottlenecked on, like, can you go review all that code?\" Embiricos said.\n\nEmbiricos' view is that we need to unburden humans from having to write prompts and validate AI's work, since we aren't fast enough.\n\n\"If we can rebuild systems to let the agent be default useful, we'll start unlocking hockey sticks,\" he said.\n\n\"Hockey stick growth\" is a term used to describe a growth curve that starts out flat and suddenly spikes, mirroring the shape of a hockey stick.\n\nEmbiricos said there's no simple path to a fully automated workflow — each use case will require its own approach — but he expects to see progress toward this level of growth soon.\n\n\"Starting next year, we're going to see early adopters starting to hockey stick their productivity, and then over the years that follow, we're going to see larger and larger companies hockey stick that productivity,\" he said.\n\nSomewhere in between the time early adopters start to see gains in productivity and when tech giants manage to fully automate processes with AI agents is when we'll see AGI, Embiricos said.\n\n\"That hockey-sticking will be flowing back into the AI labs, and that's when we'll basically be at the AGI,\" he said.",
    "readingTime": 2,
    "keywords": [
      "human typing",
      "hockey stick",
      "agent",
      "speed",
      "we'll",
      "growth",
      "productivity",
      "it's",
      "prompts",
      "humans"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/openai-artificial-general-intelligence-bottleneck-human-typing-speed-2025-12",
    "thumbnail_url": "https://i.insider.com/693f0599832e0ef1ead631ab?width=1200&format=jpeg",
    "created_at": "2025-12-15T03:59:01.869Z",
    "topic": "finance"
  },
  {
    "slug": "programming-languages-to-learn-first",
    "title": "Programming Languages to Learn First",
    "description": "Many IT professionals would recommend Python as the best programming language for beginners. Why? The syntax of the Python code is considered simple.",
    "fullText": "TL;DR: Python leads with 29.85% market share driven by AI/ML demand, while JavaScript remains essential for web development. But here’s what most hiring managers miss: the rise of AI-powered coding tools like GitHub Copilot has fundamentally altered what skills you should prioritize when building your engineering team.\n\nThe question isn’t simply “which programming language should we hire for?” anymore. Companies are increasingly leveraging AI to automate routine coding tasks, reducing the need for large engineering teams and prioritizing professionals who can manage AI-driven workflows rather than simply write code.\n\nLet’s cut through the noise and examine what’s actually happening in today’s tech hiring landscape.\n\nSoftware developer job listings are down 35% from their 2022 peak, but don’t let that fool you into thinking demand has disappeared. Most technology positions tracked by the U.S. Bureau of Labor Statistics show unemployment rates well below the national average—software developers at 2.8%, systems analysts at 1.8%, and security analysts at 2.3%.\n\nWhat’s changed is selectivity. Companies are becoming more selective with their technical hires while businesses struggle to ship quickly due to a shortage of qualified engineers. The old approach of scanning resumes for keyword matches no longer works when every engineer claims “full-stack” experience.\n\nPython dominates with 29.85% market share, and it’s no surprise given AI and machine learning’s explosive growth. But here’s what matters for your hiring strategy: the type of Python developer you need has evolved.\n\nTraditional Python roles focused on web development with Django or Flask. Modern Python roles require understanding of:\n\nWhen interviewing Python candidates, dig beyond syntax knowledge. Ask: “How would you architect a system that processes real-time data for ML model inference?” The answer reveals whether they understand modern Python’s role in AI-driven products.\n\nJavaScript maintains its position with 7.92% market share, remaining essential for front-end development. But traditional frontend development is seeing fewer job postings, suggesting a shift toward full-stack or specialized backend roles.\n\nThe modern JavaScript landscape demands expertise in:\n\nTypeScript continues gaining popularity for large-scale web development, with its static typing and enhanced tooling making it preferred for complex applications. If your product serves enterprise clients or handles complex state management, TypeScript experience isn’t optional, it’s essential.\n\nGo’s popularity continues to grow as global demand for cloud computing rises, with its simple syntax, built-in concurrency support, and high performance making it well-suited for cloud-native applications.\n\nRust is emerging for system-level programming where memory safety and performance are critical. Rust’s memory safety, high performance, and robust security properties make it particularly well-suited for performance- and safety-critical applications.\n\nIf your architecture includes real-time systems, embedded software, or blockchain applications, Rust expertise provides competitive advantages that Go simply cannot match.\n\nIn this article, you can find answers to these questions. Keep in mind that these are all useful languages that will bring you closer to your goal if you’re committed.\n\nDespite competition from newer languages like Kotlin and Go, Java remains widely used in enterprise software, Android development, and backend systems. But the Java developer you need in 2025 looks different from five years ago.\n\nModern Java development requires:\n\nC# has been increasingly utilized in game development and enterprise software, with deep integration with the Unity game engine cementing C# as a top game developer language. For enterprise applications, .NET’s cross-platform capabilities make C# developers valuable for modernizing legacy Windows-based systems.\n\nAccording to research for the Demand for Skilled Talent report, the most evident skills gap on technology teams is within AI, machine learning and data science. But let’s be specific about what this means for different roles:\n\nPlatform-focused AI engineers build centralized tools and infrastructure to accelerate AI development, while product-focused AI engineers work inside product teams and ship AI features for users. Understanding this distinction helps you write better job descriptions and evaluate candidates correctly.\n\nDevelopers who can maintain and modernize legacy systems are highly valued, with work including ensuring security, improving performance, and integrating legacy systems with newer technologies like APIs or microservices. Many companies underestimate this need when planning their hiring strategy.\n\nCloud services like AWS, Google Cloud, and Microsoft Azure are at the core of modern software infrastructure, with over 90% of global enterprises expected to use cloud platforms by 2025.\n\nCritical cloud competencies include:\n\nWhen evaluating DevOps candidates, focus on their experience with incident response and disaster recovery. Anyone can deploy to the cloud; few can architect systems that gracefully handle failure at scale.\n\nEnterprise blockchain adoption is driving legitimate technical roles:\n\nMajor industries entering the space, including finance, healthcare and logistics, are expanding demand for blockchain engineers. When Deutsche Bank builds blockchain settlement systems or Nike creates digital collectibles, they need engineers who understand both traditional software architecture and decentralized protocols.\n\nEntry-level Solidity developers can write basic smart contracts and deploy them to testnets. Senior Solidity engineers architect systems that handle millions in value while remaining secure and gas-efficient.\n\nCore technical competencies for serious Solidity roles:\n\nFor Startups and Scale-ups: Python and JavaScript remain your best bets for rapid development and talent availability. The ecosystem maturity and hiring pool depth outweigh cutting-edge performance considerations.\n\nFor Enterprise and Financial Services: Java and C# provide the stability, security, and regulatory compliance frameworks that regulated industries require. Don’t chase trends when handling mission-critical systems.\n\nFor Performance-Critical Applications: Go for backend services, Rust for system programming, and C++ for real-time applications. Latency requirements should drive language selection, not popularity metrics.\n\nFor AI/ML Products: Python dominates, but consider Julia for scientific computing or R for statistical analysis. Language choice depends on your specific AI use case and team expertise.\n\nGiven 95% of tech leaders face challenges finding skilled workers, your approach to technical hiring needs to evolve beyond traditional methods.\n\nFocus on fundamental problem-solving over specific syntax knowledge. A strong engineer can learn new languages; analytical thinking and system design skills transfer across technologies.\n\nPrioritize hands-on experience with real-world projects over certification collections. Ask candidates to walk through architecture decisions they’ve made and trade-offs they’ve considered.\n\nEvaluate AI collaboration skills. The shift toward engineers with expertise in AI augmentation, system architecture, and cross-functional problem-solving means traditional coding assessments miss crucial competencies.\n\nIt’s easy enough for software engineers to become AI engineers: just build applications on top of LLMs. This accessibility is reshaping what skills remain uniquely human and valuable.\n\nLanguages that enhance AI productivity:\n\nThe programming languages your team learns should align with how AI tools augment rather than replace human developers. Focus on languages that excel in areas where human judgment and creativity remain irreplaceable: system architecture, user experience design, and complex business logic implementation.\n\nBottom Line: The most important programming language for your 2025 hiring strategy isn’t determined by popularity rankings—it’s the one that best matches your technical architecture, team experience, and business requirements. Technology hiring trends in 2025 indicate that candidates place high value on exposure to AI and machine learning projects, as these skills significantly enhance their career trajectories.\n\nThe companies succeeding in today’s competitive hiring market understand that language proficiency is just the foundation. The real competitive advantage comes from engineers who can architect systems, collaborate with AI tools, and adapt to evolving technical requirements.\n\nReady to build a hiring strategy that actually reflects today’s market realities? Let’s discuss how the current tech landscape impacts your specific technical requirements and talent acquisition approach.",
    "readingTime": 7,
    "keywords": [
      "python dominates",
      "applications rust",
      "shift toward",
      "memory safety",
      "syntax knowledge",
      "machine learning",
      "python roles",
      "web development",
      "hiring strategy",
      "technical requirements"
    ],
    "qualityScore": 1,
    "link": "https://www.omnesgroup.com/the-best-programming-languages-to-learn-first/",
    "thumbnail_url": "https://www.omnesgroup.com/wp-content/uploads/2018/08/download-69-1.png",
    "created_at": "2025-12-14T18:50:16.561Z",
    "topic": "tech"
  },
  {
    "slug": "terraform-sunsets-cdktf",
    "title": "Terraform Sunsets CDKTF",
    "description": "This decision forces Terraform's users to migrate to HCL, drawing criticism from those who point to the CDK's popularity as proof Terraform still needs advanced programming capabilities.",
    "fullText": "Going forward, when you run IBM‘s Terraform Infrastructure as Code (IaC) software, you will have one language to write your configurations: the HashiCorp Configuration Language (HCL).\n\nOn Monday, HashiCorp, an IBM company, announced that it will no longer support the Terraform Cloud Development Kit (CDK or CDKTF). Although the existing code will remain available in a GitHub archive, HashiCorp will no longer maintain or update the code, leaving it all but unusable for enterprises.\n\n“Unfortunately, Terraform CDK did not find product-market fit at scale. HashiCorp, an IBM Company, has chosen to focus its investments on Terraform core and its broader ecosystem,” a note on the site read.\n\nThe CDK itself is licensed under the Mozilla Public License (MPL), so users are free to fork the software itself, IBM suggested.\n\nThe company, however, is encouraging users to use HCL, which was developed by HashiCorp and licensed under the Mozilla Public License (MPL), originally designed for the software.\n\nOriginally released in 2014 by HashiCorp, Terraform is software that allows administrators to automate the deployment of IT infrastructure, either in the cloud or on premises, through the use of scripts and a set of Terraform commands such as terraform init, terraform plan and terraform apply. The output is rendered as JSON.\n\nOver time, Terraform has become the most popular software for automated IT deployment, especially in the cloud native community.\n\nIn 2023, HashiCorp switched the Terraform license from open source to a Business Source License, which spurred a user-based open source fork of the software, called OpenTofu, that was adopted by the Linux Foundation and, later, by the Cloud Native Computing Foundation (CNCF).\n\nIn 2024, IBM announced it was acquiring HashiCorp and finalized the purchase earlier this year.\n\nDespite a call to open source the CDK, IBM is encouraging current users to adopt the HCL if they are not already doing so.\n\n“If you are not using AWS CDK, we highly recommend migrating to standard Terraform and HCL for long-term support and ecosystem alignment,” the company asserted.\n\nTerraform users with .tf files created under the CDK can convert them to HCL with the following command:\n\nThose using CDTF on Amazon Web Services infrastructure can also use AWS’ own CDK.\n\nOverall, the Infrastructure as Code user base appears to be chafing from the limits of IaC.\n\nAs a result, many alternative approaches to Terraform have popped up in the last few years, including Adam Jacob’s System Initiative and Formae from Platform Engineering Labs.\n\nThey point to how HCL has its limits, especially for highly scalable environments. A declarative configuration language, HCL is limited in offering advanced programming constructs, and many resulting workarounds have resulted in obtuse code. Tooling is limited as well.\n\nThe advantage that the CDKTF brought to users was that it allowed them to detail deployment instructions through their own favorite programming language rather than HCL. CDKTF supported TypeScript, Python, C# and the Go programming language.\n\nThis is also the approach that Terraform competitor Pulumi has staked out, namely the ability to provision infrastructure in any one of a number of programming languages.\n\nYet, there has also been considerable debate around whether a general-purpose programming language is better than a domain-specific language. Terraform’s users are administrators, not programmers, as critics have pointed out.\n\nNonetheless, many of those in the IaC community took the news hard. Kubernetes expert David Flanagan noted that the development kit has gotten over 140,000 downloads per week for TypeScript alone, with similar numbers in other language communities.\n\nSo clearly, the CDKTF is still highly used by the community, he argued.\n\nFuck you, Hashicorp … an IBM Company. pic.twitter.com/h1EicnT3pL\n\n— David Flanagan (@rawkode), Dec. 11, 2025\n\n“You don’t kill a project with [an estimated] million users every single month because nobody likes it or it doesn’t have a ‘market fit.’ You kill it because it is not increasing your profit margin, it is not selling enterprise licenses,” Flanagan said in a short video.\n\nTo be fair, IBM has a long history of buying open source-based companies, and keeping the open source licensing intact, including the Linux-based Red Hat, the Cassandra-focused Datastax and, most recently, the Kafka-based Confluent. (There’s been no word, however, on whether IBM would revert the Terraform license back to open source.)\n\nFlanagan went on to note that people are probably using the CDKTF because they require the additional programming capabilities. “It’s called Infrastructure as Code, not Infrastructure as JSON,” he quipped.\n\nSite reliability engineer Liz Fong-Jones offered a more measured response.\n\n“To be more gentle about this, HashiCorp has decided to stop trying to compete with Pulumi with language-native APIs; they’re all in on HCL as the only way to work with Terraform,” Fong-Jones wrote on BlueSky.\n\nIn fact, others think this may not be a bad idea.\n\nPlatform Engineering Labs’ Co-Founder and CEO Pavlo Baron thought the IBM move made sense.\n\n“IBM is historically good at optimizing for the target buyer. This is rather a sign that nobody on the right side of the cycle wants to do full-blown programming. CDKs, and this includes the approach Pulumi takes, are exclusively for developers. Developers usually don’t operate infrastructure,” he wrote by email.\n\n“Serious operations happen on the right side of the cycle, though. Thus, the CDK is missing their target user and addresses the wrong one. So I understand and support the logic behind this move.”",
    "readingTime": 5,
    "keywords": [
      "platform engineering",
      "engineering labs",
      "license mpl",
      "development kit",
      "cloud native",
      "language hcl",
      "configuration language",
      "programming language",
      "ibm company",
      "terraform license"
    ],
    "qualityScore": 1,
    "link": "https://thenewstack.io/ibm-hashicorp-sunsets-terraforms-external-language-support/",
    "thumbnail_url": "https://cdn.thenewstack.io/media/2025/12/65e7b1bd-ritu-dahiya-w2mlnx4yso-unsplash.jpg",
    "created_at": "2025-12-14T18:50:16.550Z",
    "topic": "tech"
  },
  {
    "slug": "component-party-compare-javascript-frameworks",
    "title": "Component Party – Compare JavaScript Frameworks",
    "description": "Compare JavaScript frameworks side-by-side: React, Vue, Angular, Svelte, Solid.js, and more. See syntax differences, features, and code examples for web development frameworks.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://component-party.dev/?f=react-svelte5",
    "thumbnail_url": "https://component-party.dev/banner2.png",
    "created_at": "2025-12-14T03:53:12.102Z",
    "topic": "tech"
  },
  {
    "slug": "exmeta-staffer-nicknamed-coding-machine-says-the-best-engineers-arent-on-linkedin-but-theyre-special-cases",
    "title": "Ex-Meta staffer nicknamed 'coding machine' says the best engineers aren't on LinkedIn — but they're special cases",
    "description": "Michael Novati , a former Meta principal software engineer, said the names of the best of the best engineers are \"nowhere\" online.",
    "fullText": "LinkedIn is full of corporate braggarts. But don't expect the best engineers to flaunt their success on the platform — or even have an account, according one former Meta employee.\n\nMichael Novati spent almost eight years at Meta, back when it was still called Facebook and hadn't yet doubled down on AI. He reached the rank of principal software engineer and earned the nickname \"coding machine.\"\n\nOn the \"A Life Engineered\" podcast, host Steve Huynh asked Novati about his claim that the top five engineers aren't on LinkedIn. Novati stood by it.\n\n\"When I was at Facebook, the top engineers were like, 'If you had a LinkedIn account, people would be wondering if you're job hunting,'\" he said.\n\nNovati said these engineers don't need to publicly job hunt because of tech's extensive recruiting arm, which he called the \"secrets of the industry.\"\n\n\"There are very senior, very highly paid recruiters that work at the top companies who have very strong long-term social relationships with a lot of top engineers,\" he said.\n\nHow do these engineers and recruiters meet? Novati gave the example of an engineer who spends a week doing campus recruiting at Stanford, bonding with the company's recruiter in the process.\n\nHe referred to these as the \"secret backroom dealings of Silicon Valley.\"\n\n\"These engineers' names are nowhere, but they are the ones that are the most desirable by these recruiters,\" he said. \"The $100 million engineer is not on LinkedIn with a tagline that's like, #100millionengineer.\"\n\nTech recruiting has long been a large, lucrative industry. Big Tech companies both employ in-house recruiters and outside agencies to stay close to key talent.\n\nMeanwhile, talent is becoming increasingly competitive, particularly in the field of AI. Meta shelled out large contracts for its Superintelligence Labs, poaching engineers from its competitors.\n\nSometimes CEOs even get involved. Mark Zuckerberg reportedly made a list of the top AI talent to poach. OpenAI's chief research officer said that Zuckerberg hand-delivered soup to an employee he was trying to recruit.\n\nOne AI worker told Business Insider they got a personal call from OpenAI CEO Sam Altman, pitching them to join the company. They accepted.\n\nBeing offline may not be the golden key to tech recruiting, though. These top-tier engineers are a \"specific case,\" Novati said on the podcast.\n\n\"It doesn't mean that your strategy should be: delete LinkedIn and all the offers will come,\" he said.\n\nIt's a rarified class, Novati said, but one that stays away from all semblances of personal branding.\n\n\"I don't know any of those top engineers, who get special equity grants and special dinners with Bezos or whatever stuff like that, who have big personal brands,\" he said.",
    "readingTime": 3,
    "keywords": [
      "tech recruiting",
      "top engineers",
      "recruiters",
      "don't",
      "talent",
      "personal",
      "novati",
      "account",
      "employee",
      "facebook"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/best-engineers-not-on-linkedin-former-meta-employee-2025-12",
    "thumbnail_url": "https://i.insider.com/693ae21d832e0ef1ead60bb6?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.490Z",
    "topic": "finance"
  },
  {
    "slug": "a-new-series-on-cracking-faanglevel-code-challenges",
    "title": "A New Series on Cracking FAANG-Level Code Challenges",
    "description": "One of the most fundamental algorithms that appears in interviews at big tech companies is Binary Search. Of course, nobody will ask you to implement binary search directly. However, as Jon Bentley cited in his famous book Programming Pearls, only a small percentage of people he asked—10% to be precise—were able to code this algorithm without any errors.\nHere, I will show you a correct implementation of binary search, its variants that appear in interviews, and LeetCode problems that you can solve using these techniques.",
    "fullText": "One of the most fundamental algorithms that appears in interviews at big tech companies is Binary Search. Of course, nobody will ask you to implement binary search directly. However, as Jon Bentley cited in his famous book Programming Pearls, only a small percentage of people he asked—10% to be precise—were able to code this algorithm without any errors.\n\nHere, I will show you a correct implementation of binary search, its variants that appear in interviews, and LeetCode problems that you can solve using these techniques.\n\nGiven an array of items, we can find the position of a specific item linearly by iterating over the array, comparing each item with the desired item, and returning the position when the current item equals the desired item.\n\nWe must also consider the case where the desired item is not in the array; in this case, we can return any value. Since we are talking about positions in an array, we can return -1 if the item is not present. This is a very simple concept and implementation. However, if the array is sorted, we can do better.\n\nWe can find the position of an item in logarithmic time (O(log n)), where n is the number of items in the array, when the array is sorted.\n\nTo do this, we repeatedly compare the item we are looking for with the middle element of the array. If the middle element is the one we are looking for, we have our result. Otherwise, we need to update the range of the array we are considering accordingly.\n\nIf the element we are looking for is greater than the middle element, we need to search in the higher part of the array. Otherwise, we need to search in the lower part of the array.\n\nWhat we just described is the Binary Search algorithm. Below is the implementation of the binary search algorithm in C++:\n\nThis is less than 20 lines of code that you need to understand very well if you want to be successful in an interview. Note that I said “understand,” not “memorize.”\n\ncould be implemented in different ways, such as:\n\nCan you explain why the first implementation is better than the second?\n\nThe answer is integer overflow. When we add two integer numbers, we can exceed the maximum value allowed in the computer’s representation of an int. Knowing these details and how to answer such questions puts you in a much better position compared to other candidates.\n\nAs you can see, even a small detail can demonstrate your expertise and experience. All these small details together help you get the position you want.\n\nDespite these details, as I said, nobody will ask you to implement binary search directly. However, there are some important variants of the binary search algorithm that appear as part of problem-solving. I will describe four of them in the next sections.\n\nLet’s consider we have a sorted array with duplicate elements, such as [10, 20, 30, 30, 30, 40, 50]. Also, let’s assume we are searching for the element 30 and we need to find the smallest position of this element in case of duplication.\n\nWith the binary search algorithm implementation shown above, we cannot guarantee we will always return the smallest position of an element in case of duplication. However, we can modify the original algorithm to answer this question correctly.\n\nAnd here is a very important point: You can only make this modification if you know the binary search algorithm and its implementation well.\n\nThinking about the problem, instead of returning the position when we find the element in the array, we need to update our result and continue the search in the lower part of the array.\n\nUpdating the result instead of returning immediately is easy to see. You cannot return immediately because there may be duplicate elements in the array. Since we want the smallest position, we cannot just return.\n\nSo, why go to the lower part of the array instead of the higher part? The answer is because of the problem definition: we want the smallest index. So, if we find the element, in case of duplication, we are interested in the presence of this element before the current position.\n\nThe implementation in C++ could be:\n\nThis problem is similar to the one above, but now we are interested in the higher part of the array in case of duplication. This is because we want the largest index instead of the smallest one.\n\nIn this case, the implementation in C++ could be:\n\nThis is a little different, but only slightly. Now, we are not interested in finding an element, but the largest value less than the given element. So, every time we find an element that is smaller than our desired element, we need to update our result. We also need to update the considered range of the array.\n\nIn this case, we are interested in the higher part of the array, since we are trying to find the largest value less than our element.\n\nThe implementation in C++ could be:\n\nSimilar to the problem above, but now we are interested in finding the smallest value greater than the desired value. So, we need to update our result when we find a larger element instead of a smaller one.\n\nThe implementation in C++ could be:\n\nHere are some interesting problems to solve on LeetCode using the techniques explained in this post:",
    "readingTime": 5,
    "keywords": [
      "directly however",
      "duplicate elements",
      "implement binary",
      "search directly",
      "desired item",
      "middle element",
      "search algorithm",
      "smallest position",
      "array",
      "implementation"
    ],
    "qualityScore": 1,
    "link": "https://johnjr.dev/posts/binary-search/",
    "thumbnail_url": "https://johnjr.dev/jj1.jpg",
    "created_at": "2025-12-11T18:58:27.000Z",
    "topic": "tech"
  },
  {
    "slug": "craft-software-that-makes-people-feel-something",
    "title": "Craft software that makes people feel something",
    "description": "Recently, people have been asking me why I’m pausing Boo to work on a programming language. I think it would actually be cool to write down how I feel.",
    "fullText": "So, I woke up today. Got my coffee, family went to sleep, and I have a free afternoon.\n\nI thought about writing something. I may delete this article, but if you are reading this, it means I went through with it.\n\nRecently, people have been asking me why I’m pausing Boo to work on a programming language. I think it would actually be cool to write down how I feel.\n\nBoo is a code editor I created solely for myself; I never had the intention of making it a mainstream editor. Of course, it would be fun if people used it, but that was never my goal. This year I got it working in a functional state, where I can actually use it for my daily work. It has innovative human-keyboard navigation and replaces the LSP system with something faster and less costly for the OS. So why on earth am I not open-sourcing it? That’s what people keep asking me.\n\nMy mind isn’t really moved by the idea that it would be a success or a failure — the end user of Boo is me. I don’t feel it’s there yet; in fact, I think software should inspire us. Working on Rio Terminal and Boo in my free time — both written in Rust and sharing many similarities — affects my joy, because it starts to become something automatic. Both have similar architecture, language, release process, and etcetera.\n\nSince I was a kid, I liked to build Lego blocks. That’s probably what I did the most besides playing football or video games. The fun thing about Lego is that one day you can build a castle, and the next day you can build a ship. Not necessarily using the same pieces and colors — you can actually add a lot of stuff that’s external to what you have, like a wood stick.\n\nWhen programming becomes repetitive, the odds of you creating something that makes people go “wow” are reduced quite a bit. It isn’t a rule, of course. You need to be inspired to make inspiring software.\n\nI always use the example of The Legend of Zelda: Breath of the Wild. This game is so well crafted that I know people who don’t even like video games but bought a console just to play it — and once they finished, they sold everything. This is what I’m talking about: taking time to build something so that once people try it, they remember it for as long as they live.\n\nBoo isn’t a business. I don’t need or want to make money out of it. I don’t have a deadline, nor do I want to create another VS Code. I don’t feel like forcing it to happen.\n\nIn that case, I don’t necessarily need to stop building Lego blocks, right? I’ll just park it there, and when the inspiration comes back, I’ll pick it up where it was. That being said, I paused Boo, and I am working on my own programming language. Eventually, my idea is to rewrite Boo to use it.\n\n“Wow! That’s a lot of work.” Indeed. But it’s my hobby stuff. I’ve always loved programming languages, and I am having a blast learning more about binaries and compilers. So, I don’t really feel I need to follow people’s cake recipe for success. That’s how my mind works, and I will stick with it.",
    "readingTime": 3,
    "keywords": [
      "lego blocks",
      "programming language",
      "don’t",
      "isn’t",
      "free",
      "course",
      "mind",
      "idea",
      "success",
      "it’s"
    ],
    "qualityScore": 1,
    "link": "https://rapha.land/craft-software-that-makes-people-feel-something/",
    "thumbnail_url": "https://rapha.land/assets/images/banner.jpg",
    "created_at": "2025-12-11T13:53:41.026Z",
    "topic": "tech"
  },
  {
    "slug": "unreal-blueprintlike-mcp-server-builder-no-coding-knowledge-required",
    "title": "Unreal Blueprint-Like MCP Server Builder (No Coding Knowledge Required)",
    "description": "A Blueprint-style visual node editor for creating FastMCP servers. Build MCP tools, resources, and prompts by connecting nodes - no coding required. - PhialsBasement/GUI-MCP",
    "fullText": "PhialsBasement\n\n /\n\n GUI-MCP\n\n Public\n\n A Blueprint-style visual node editor for creating FastMCP servers. Build MCP tools, resources, and prompts by connecting nodes - no coding required.\n\n 3\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n PhialsBasement/GUI-MCP",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/PhialsBasement/GUI-MCP",
    "thumbnail_url": "https://opengraph.githubassets.com/619d24ecdcaf5477d9914c9ee0acb987700aa86035c0d50b25f6cd7d76ac6c38/PhialsBasement/GUI-MCP",
    "created_at": "2025-12-11T03:50:15.379Z",
    "topic": "tech"
  },
  {
    "slug": "young-people-are-growing-up-fluent-in-ai-and-thats-helping-them-stand-apart-from-their-older-peers-says-gen-z-founder",
    "title": "Young people are ‘growing up fluent in AI’ and that’s helping them stand apart from their older peers, says Gen Z founder Kiara Nirghin",
    "description": "Nirghin explained that young entrepreneurs see coding as something to be done alongside AI agents, rather than done alone and from scratch.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/gen-z-growing-up-fluent-ai-helping-stand-apart-from-older-peers/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974872644_4c9966d747_o.jpg?resize=1200,600",
    "created_at": "2025-12-10T18:55:46.731Z",
    "topic": "business"
  },
  {
    "slug": "the-boundary-of-copyrightability-in-aigenerated-code-under-j",
    "title": "The boundary of copyrightability in AI-generated code under Japan and US Law",
    "description": "When GitHub Copilot first appeared, many developers viewed it as an assistive tool for coding. The honest impression of most developers was likely that while it was useful, it was not a tool to whi…",
    "fullText": "A Curious Phenomenon with Gemma Model Outputs and License Propagation While examining the licensing details of Google’s Gemma model, I noticed a potentially puzzling phenomenon: you can freely assign a license to the model’s outputs, yet depending on how those outputs are used, the original Terms of Use might suddenly propagate to the resulting work. Outputs vs. Model Derivatives The Gemma Terms of Use distinguish…",
    "readingTime": 1,
    "keywords": [
      "gemma model",
      "outputs",
      "license",
      "phenomenon"
    ],
    "qualityScore": 0,
    "link": "https://shujisado.org/2025/12/10/the-boundary-of-copyrightability-in-ai-generated-code/",
    "thumbnail_url": "https://shujisado.org/wp-content/uploads/2025/12/chatgpt-image-2025e5b9b412e69c8810e697a5-21_53_59.png",
    "created_at": "2025-12-10T13:50:09.359Z",
    "topic": "tech"
  },
  {
    "slug": "databricks-ceo-ali-ghodsi-says-his-company-will-be-worth-1-t",
    "title": "Databricks CEO Ali Ghodsi says his company will be worth $1 trillion by doing these three things",
    "description": "Databricks CEO says AI-powered coding, enterprise agents, and rapid app development could propel it into the trillion-dollar club.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/databticks-ceo-1-trillion-valuation-agents-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974307746_cdbc8c031a_o.jpg?resize=1200,600",
    "created_at": "2025-12-10T03:48:33.338Z",
    "topic": "business"
  }
]
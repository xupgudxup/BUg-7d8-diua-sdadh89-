[
  {
    "slug": "coding-dissent-art-technology-and-tactical-media-video",
    "title": "Coding Dissent: Art, Technology, and Tactical Media [video]",
    "description": "This presentation examines artistic practices that engage with sociotechnical systems through tactical interventions. The talk proposes a...",
    "fullText": "This presentation examines artistic practices that engage with sociotechnical systems through tactical interventions. The talk proposes art as a form of infrastructural critique and counter-technology. It also introduces a forthcoming HackLab designed to foster collaborative development of open-source tools addressing digital authoritarianism, surveillance capitalism, propaganda infrastructures, and ideological warfare.\n\nIn this talk, media artist and curator Helena Nikonole presents her work at the intersection of art, activism, and tactical technology â€” including interventions into surveillance systems, wearable mesh networks for off-grid communication, and AI-generated propaganda sabotage.\n\nFeaturing projects like Antiwar AI, the 868labs initiative, and the curatorial project Digital Resistance, the talk explores how art can do more than just comment on sociotechnical systems â€” it can interfere, infiltrate, and subvert them.\n\nThis is about prototypes as politics, networked interventions as civil disobedience, and media hacks as tools of strategic refusal. The talk asks: what happens when art stops decorating crisis and starts debugging it?\n\nThe talk will also introduce an upcoming HackLab initiative â€” a collaboration-in-progress that brings together artists, hackers, and activists to develop open-source tools for disruption, resilience, and collective agency â€” and invites potential collaborators to get involved.\n\nLicensed to the public under http://creativecommons.org/licenses/by/4.0\n\nThis Talk was translated into multiple languages. The files available\nfor download contain all languages as separate audio-tracks. Most\ndesktop video players allow you to choose between them.\n\nPlease look for \"audio tracks\" in your desktop video player.",
    "readingTime": 2,
    "keywords": [
      "sociotechnical systems",
      "open-source tools",
      "interventions",
      "tactical",
      "hacklab",
      "surveillance",
      "propaganda",
      "media",
      "initiative",
      "languages"
    ],
    "qualityScore": 0.85,
    "link": "https://media.ccc.de/v/39c3-coding-dissent-art-technology-and-tactical-media",
    "thumbnail_url": "https://static.media.ccc.de/media/congress/2025/2191-d743f89d-684b-5a29-a0e1-4b788caa4255_preview.jpg",
    "created_at": "2026-01-01T12:23:06.289Z",
    "topic": "tech"
  },
  {
    "slug": "the-best-way-to-use-mcps-with-coding-agents",
    "title": "The Best Way to use MCPs with coding agents",
    "description": "Description will go into a meta tag in",
    "fullText": "Jilebi makes it really easy to add MCPs by converting them to plugins that can then be used by your AI tool or agent. You can add MCPs with a single command like this \njilebi plugins add context7\n\nJilebi uses deno_core with help from rustyscript to sandbox and run plugins without giving them any access to your network, envs or file system. Any permission to use these resources needs to be explicitly allowed by the user during installation of the plugin\n\nFocus on tools, resources and prompts. Leave the server abstraction to Jilebi. Jilebi currently supports stdio, and will add support for SSE, HTTP and OAuth soon. Since its easy to make plugins, anyone can contribute, even AI tools. Jilebi can keep up with the MCP spec while you focus on your plugin\n\nGet answers to common questions about Jilebi and how it works",
    "readingTime": 1,
    "keywords": [
      "add mcps",
      "plugins",
      "jilebi",
      "resources",
      "plugin",
      "focus",
      "tools"
    ],
    "qualityScore": 0.55,
    "link": "https://jilebi.ai",
    "thumbnail_url": "https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg",
    "created_at": "2026-01-01T06:19:51.284Z",
    "topic": "tech"
  },
  {
    "slug": "meet-the-13yearold-and-his-teen-sister-vibe-coding-and-competing-in-cursors-24hour-hackathon",
    "title": "Meet the 13-year-old and his teen sister vibe coding and competing in Cursor's 24-hour hackathon",
    "description": "A 13-year-old and his teen sister picked up vibe coding and ended up competing together in a 24-hour hackathon with their dad.",
    "fullText": "Seasoned tech professionals filed into a weekend vibecoding class. Somewhere between them sat a 13-year-old quietly planning an AI sports coach.\n\nUsman Asif was the youngest person in the room. His 18-year-old sister, Shanzey Asif, was in the same class in Singapore.\n\n\"I was surrounded by people much older than me, with more experience in technology,\" he told Business Insider. \"But I felt age is just a number.\"\n\nOnce he started vibe coding, \"it was weird but fun,\" he said.\n\nThe family's AI journey started with their father, Asif Saleem, who works at Google as a financial services go-to-market lead for Japan and Asia Pacific. He learned about vibe coding, or prompting an AI to generate code, and was curious about the tools on the market.\n\nHe attended a local vibecoding class in June. By the end of the weekend, he had created a financial statement analyzer.\n\nUsman and Shanzey, who were already interested in AI, saw what their father did and wanted to be part of the class.\n\nA few weeks later, both siblings signed up for the same course their father had taken.\n\n\"It was pretty intimidating at first,\" Shanzey said. \"I didn't really know what vibe coding was.\"\n\nThe majority of attendees were executives. \"They already had kind of experienced what coding was, and some of them were like working in Google and Oracle, and even Amazon,\" Shanzey said.\n\nOnce the instructors broke down what vibe coding was, it became \"really simple\" â€” and fun â€” for Shanzey.\n\nThe 12th grader, who attends an International Baccalaureate program, initially thought she would have to write code, but learned that prompting is what drives the entire process.\n\nWhen her space website came together, she thought: \"This is great. I didn't even have to do any coding.\"\n\nUsman said his entry into vibe coding was bug-filled.\n\n\"It kind of drove me crazy because I did not know what to do,\" he said. Whenever he asked AI to fix a bug, it would generate another one.\n\n\"But it's like that, you know, one bug after another, then you get there,\" the teen said.\n\nWith practice, he learned what different bugs meant and how to get the AI to resolve them.\n\nBoth siblings sound like tiny product managers when talking about prompts, which they say are the backbone of the vibe coding process.\n\n\"Prompts are supposed to have good details and good information. You have to instruct the AI like a teacher to a student,\" Usman said.\n\nShanzey added that the very first prompt determines the direction of the app. She also said users can use the models to help craft better prompts.\n\nVibe coding didn't immediately become a family routine. With school, work, and exams, everyone tinkered with AI in their own time.\n\nAfter finishing their vibe coding class, Asif, Usman, and Shanzey decided to test their skills together at Cursor's 24-hour hackathon in Singapore. The October event drew hundreds of participants, mostly adults.\n\n\"Our only goal was to get out with a completed project,\" Shanzey said. \"Whatever happens after that was part of the experience.\"\n\nThe trio quickly settled on an idea that had begun as a dinner-table conversation: choosing Shanzey's future college.\n\nTheir project was an AI-powered university guidance counselor.\n\nThe family vibe coded for about 12 hours straight, then went home and returned the next morning to see the results. Each person played a crucial role: Asif drafted the first version, Shanzey refined the interface and layered in new features, and Usman mapped out the key elements for the demo video, which Shanzey then shot.\n\nAlthough they didn't win, the experience became one of the most memorable things they've done together.\n\n\"I was really, really happy with what we were able to achieve, with how Shanzey and Usman stepped up,\" Asif said. \"It was great fun.\"\n\nFor all the excitement around AI in the household, there are limits on how it's used â€” especially when it comes to schoolwork.\n\n\"When she's studying, she can't use AI for the content she's creating,\" Asif said of his daughter. \"That's super important because the schools will always validate the output produced.\" The same rule applies to Usman.\n\nAsif and his wife manage screen time and gaming with a reward system.\n\n\"If you want some me time or play time, that should come as a reward for achieving certain goals,\" like making breakfast, Asif said.\n\nWith those boundaries in place, the siblings said that coding with AI has taught them a few valuable lessons.\n\nFor Shanzey, the biggest one was the importance of structure. Giving the AI clear, organized instructions felt a lot like managing the various demands of school: exams, essays, activities, and volunteering.\n\nApproaching things systemically is often what leads to success, she said.\n\nUsman's takeaway was about depth. Vibe coding taught him that good results come from thoughtful, detailed responses, not shortcuts.\n\n\"There are no shortcuts to success,\" he said. \"You just have to do it the hard way and learn the hard way. I could also implement this into my daily life in school.\"\n\nUsman and Shanzey are sure AI will be part of their future.\n\n\"Regardless of what I end up doing, I think AI will always be a part of my life,\" Shanzey said. \"If I go into law or psychology or something like that, I think AI will be a huge contributor to that.\"\n\nThe 13-year-old sees potential in building apps full-time.\n\n\"I feel like I could have a career with AI, such as AI app building,\" he said. \"Hopefully, there's a bright future for me with AI.\"\n\nDo you have a story to share about vibe coding? Contact this reporter at cmlee@businessinsider.com.",
    "readingTime": 5,
    "keywords": [
      "vibecoding class",
      "vibe coding",
      "usman and shanzey",
      "usman asif",
      "didn't",
      "year-old",
      "experience",
      "father",
      "learned",
      "siblings"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/teens-vibe-coding-family-hackathon-cursor-ai-building-apps-steps-2026-1",
    "thumbnail_url": "https://i.insider.com/6942405e04eda4732f2da7ee?width=1200&format=jpeg",
    "created_at": "2026-01-01T06:19:45.170Z",
    "topic": "finance"
  },
  {
    "slug": "amazon-is-letting-visa-workers-stranded-in-india-work-remotely-as-long-as-they-dont-code-or-talk-to-customers",
    "title": "Amazon is letting visa workers stranded in India work remotely â€” as long as they don't code or talk to customers",
    "description": "Amazon allows India-based employees affected by H-1B visa delays to work remotely until March, with strict restrictions on coding.",
    "fullText": "Amazon is allowing employees who are stranded in India because of visa delays to work remotely there until early March, according to an internal memo viewed by Business Insider.\n\nThe catch: They're not allowed to code, make strategic decisions, or interact with customers.\n\nAmazon is one of many American companies scrambling to adapt to the Trump administration's rapid-fire changes to the H-1B visa program, including a mandate that consular officers must review visa applicants' social media posts before issuing visas. The additional screening has delayed processing, and some embassies and consulates have rescheduled visa appointments by several months, leaving some employees stranded outside the country.\n\nThe delays have prompted Google, Apple, Microsoft, and other companies to issue travel advisories in recent weeks, warning US employees with visas to avoid international travel to prevent extended stays outside the US.\n\nAmazon allows employees traveling abroad for visa renewals to work remotely for up to 20 business days, an exemption from the normal requirement that they work in their office five days a week. Now, any Amazon employee in India as of December 13 and who awaits a rescheduled visa appointment may work remotely until March 2, according to the memo, which was posted to Amazon's internal HR portal on December 17.\n\nThe permission to work remotely comes with a long list of constraints. Employees working remotely from India are barred from coding of any kind, including troubleshooting and testing. They cannot work from or visit Amazon buildings. And they cannot negotiate or sign contracts.\n\n\"All reviews, final decision making, and sign offs should be undertaken outside India,\" the memo says.\n\nThe memo also said that \"in compliance with local laws, there are no exceptions to these restrictions.\"\n\nThe memo does not provide guidance for employees whose visa appointments have been rescheduled beyond March 2, 2026, or for those stranded in a different country. Some US embassies and consulates have rescheduled appointments as far out as 2027.\n\nAmazon did not immediately respond to a request for comment from Business Insider.\n\nFor employees in technical roles, the restrictions raised questions about what work they can actually perform.\n\n\"Seventy to eighty percent of my job is coding, testing, deploying, and documenting,\" one Amazon software engineer told Business Insider.\n\nA State Department spokesperson in December told Business Insider that the purpose of the social media reviews is to use \"all available tools\" to flag visa applicants who are inadmissible, including those who pose a risk to national interests.\n\nThe delays pose a particular challenge for Amazon, which is among the largest users of the H-1B program. During the 2024 government fiscal year, Amazon filed 14,783 certified H-1B applications, including 23 for Whole Foods, according to Business Insider's analysis of publicly available data from the Department of Labor and US Citizenship and Immigration Services.\n\nHave a tip? Contact Pranav Dixit via email at pranavdixit@protonmail.com or Signal at 1-408-905-9124. Use a personal email address, a nonwork WiFi network, and a nonwork device; here's our guide to sharing information securely.",
    "readingTime": 3,
    "keywords": [
      "social media",
      "visa applicants",
      "visa appointments",
      "rescheduled visa",
      "employees",
      "remotely",
      "memo",
      "india",
      "stranded",
      "delays"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/amazon-visa-delays-prompt-india-remote-work-with-strict-restrictions-2025-12",
    "thumbnail_url": "https://i.insider.com/6955be9004eda4732f2e5935?width=1200&format=jpeg",
    "created_at": "2026-01-01T01:03:21.721Z",
    "topic": "finance"
  },
  {
    "slug": "navigating-ai-critical-thinking-in-the-age-of-llms",
    "title": "Navigating AI: Critical Thinking in the Age of LLMs",
    "description": "The author reflects on the evolving role of Large Language Models (LLMs) in coding and education, emphasizing their potential to assist rather than replace engineers. Critical thinking remains esseâ€¦",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://mcuoneclipse.com/2025/12/31/navigating-ai-critical-thinking-in-the-age-of-llms/",
    "thumbnail_url": "https://i0.wp.com/mcuoneclipse.com/wp-content/uploads/2025/12/ai-slows-down-experienced-open-source-developers.jpg?fit=1200%2C602&ssl=1",
    "created_at": "2025-12-31T18:17:22.087Z",
    "topic": "tech"
  },
  {
    "slug": "when-good-threads-go-bad",
    "title": "When good threads go bad",
    "description": "ðŸ‘‹ðŸ¼ This is part of series on concurrency, parallelism and asynchronous programming in Ruby. Itâ€™s a deep dive, so itâ€™s divided into several parts:\n Your Ruby programs are always multi-threaded: Part 1 Your Ruby programs are always multi-threaded: Part 2 Consistent, request-local state Ruby methods are colorless The Thread API: Concurrent, colorless Ruby Bitmasks, Ruby Threads and Interrupts, oh my! (Concurrent, colorless Ruby) When good threads go bad (Concurrent, colorless Ruby) Thread and its MaNy friends (Concurrent, colorless Ruby) Fibers (Concurrent, colorless Ruby) Processes, Ractors and alternative runtimes (Parallel Ruby) Scaling concurrency (Streaming Ruby) Abstracted, concurrent Ruby Closing thoughts, kicking the tires and tangents How I dive into CRuby concurrency  Youâ€™re reading â€œWhen good threads go badâ€.",
    "fullText": "ðŸ‘‹ðŸ¼ This is part of series on concurrency, parallelism and asynchronous programming in Ruby. Itâ€™s a deep dive, so itâ€™s divided into several parts:\n\nYouâ€™re reading â€œWhen good threads go badâ€. Iâ€™ll update the links as each part is released, and include these links in each post.\n\nItâ€™s late, and you start getting alerts that requests to your web server are failing. You try to load a page and it hangs endlessly. The server isnâ€™t responding to anything, and requests are continuing to queue up.\n\nItâ€™s 10PM. Do you know where your children threads are?\n\nNot knowing what else to do, you trigger a server restart. Even doing that, things remain unresponsive for another 30 seconds. Finally you see the server stop, and start up again. As if by magic, everything is running fine again.\n\nYouâ€™re running Puma with threads. It seemed like every thread was unresponsive. What happened to those threads?!\n\nThe reality of the situation is probably mundane.\n\nIf it isnâ€™t those things, there are other ways your threads can go rogue. Letâ€™s look at some ways a thread can get stuck:\n\nThe conventional example of a deadlock is two threads attempting to acquire a mutexheld by the other thread.\n\nThey can never make progress, so theyâ€™re dead in the water:\n\nIn our example, thread_1 acquires mutex_1. Then thread_2 acquires mutex_2. Next, thread_1 attempts to acquire mutex_2 and blocks. Then thread_2 attempts to require mutex_1 and blocks. Neither can make progress, and are stuck in place.\n\nItâ€™s a traditional example, but Ruby is very good at detecting it! It detects the problem and raises an error, checking if any threads are capable of making progress:\n\nRuby detects that thread_1 and thread_2 are sleeping, and the third thread is Thread.main, which sleeps waiting for thread_1 to finish.\n\nMost long running programs are likely to have some other thread running, and Ruby only detects if all threads are stuck. We can get our deadlock example to work by adding an extra thread in a work loop:\n\nNow threads 1 and 2 will never progress, and Ruby lets the program continue running because thread_3 is still active.\n\nWhile a deadlock means a thread has stopped processing, a livelock happens when a thread keeps running, but never makes any progress. Hereâ€™s another example using an alternative approach for acquiring a mutex:\n\nThis is similar to our deadlock example, but this time we use #try_lock instead of #lock. Unlike #lock, which blocks until the mutex is available, #try_lock returns false if attempting the lock fails. We do a short sleep in each thread to give them time to acquire the initial locks, then iterate infinitely attempting #try_lock. The locks will never be acquired, and the loops will run forever. Burn, CPU, burn ðŸ”¥.\n\nPersonally Iâ€™ve rarely encountered deadlocks and livelocks in threaded code. But Iâ€™ve definitely encountered them in databases!\n\nOn PostgreSQL, it will detect this deadlock and raise an error:\n\nHow do we solve deadlocks and livelocks? The answer is a consistent order for locking.\n\nThis is the same example as before, but this time both threads attempt to acquire mutexes in identical order. As long as you acquire in a consistent order, you should never hit deadlocks or livelocks.\n\nAs far as I know, this isnâ€™t actually possible in pure Ruby. What I mean by â€œpureâ€ Ruby is a program that only runs Ruby code, and no C/Rust/Zig extensions. The CRuby runtime controls how pure Ruby code runs, and makes sure we canâ€™t hog threads. Mostly.\n\nIn Bitmasks, Ruby Threads and Interrupts, oh my!, we dug into the TIMER_INTERRUPT_MASKand how it utilizes priority. It allows a thread to influence how large of a time slice it gets:\n\nAt a default priority of 0, we get Rubyâ€™s default time slice of 100ms. At -2, we get 25ms. At 2, we get 400ms. This means in theory, can we starve out other threads by increasing our priority?\n\n3,276,800 milliseconds is 54 minutes. Can we really block things for 54 minutes!?\n\nThereâ€™s a bunch going on here - but there are only a few details to focus on:\n\nAs we can see - the priority made a difference! The thread at index 5 runs around 7 times as much as every other thread. But, it does not fully hog the thread like we might have thought. This is only 10 seconds, well under 54 minutes, and the other threads still get prioritized by the scheduler.\n\nThis shows that we can influence the scheduler, but we canâ€™t completely hog the runtime from pure Ruby code.\n\nIn more practical Ruby code, the Sidekiq gem gives you the ability to set priority on the threads it creates:\n\nInterestingly, by default, Sidekiq sets its threads to a priority of -1, which is less than the 0 that Ruby uses by default. It describes the rationale:\n\nRubyâ€™s default thread priority is 0, which uses 100ms time slices. This can lead to some surprising thread starvation; if using a lot of CPU-heavy concurrency, it may take several seconds before a Thread gets on the CPU.\n\nNegative priorities lower the timeslice by half, so -1 = 50ms, -2 = 25ms, etc. With more frequent timeslices, we reduce the risk of unintentional timeouts and starvation.\n\nFascinating to see a real-world use-case of priority like this! Sidekiq has run trillions of jobs across hundreds of thousands of apps, and they made the decision to switch the priority.\n\nSince Ruby 3.4, you can achieve the same thing globally by using RUBY_THREAD_TIMESLICE. You can set RUBY_THREAD_TIMESLICE=50 and keep the priority the same, but now the time slice is 50ms.\n\nThis is the likeliest scenario that will saturate your threads: long-running IO. In Ruby methods are colorless, we discussed how threads are great at handing off work when blocked on IO:\n\nAs soon as you do any IO operation, it just parks that thread/fiber and resumes any other one that isnâ€™t blocked on IO.\n\nHowever, this only works as long as:\n\nEarlier we mentioned slow queries as a possible IO blocker. But letâ€™s say you have a web server running with 5 threads, and you allow users to download files2:\n\nWe have a simple Rails controller action, which sends a file to the client making the request. Itâ€™s pretty straightforward! The large.txt file I tested with locally is about 130mb. Iâ€™ll run it in a basic Puma setup, using 5 threads:\n\nIâ€™m running a Puma server with 5 threads. Letâ€™s try some benchmarks against it. Weâ€™ll use Apache Bench (ab) to simulate traffic to Puma. -n means the number of total requests, and -c is how many concurrent requests to make. Letâ€™s start with 1 request:\n\nCool - 0.07 seconds. How about 3?\n\nNot much change from a single request! How about 5? This would match the maximum number of simultaneous requests our server can currently support, using 5 threads:\n\nThings slow down a little bit once we max out our threads. But still reasonable. How about 50?\n\nSo far, so good. But weâ€™re benefiting from a lot here: the file isnâ€™t particularly large, and there is no latency. The server is responding quickly, and the client is consuming the response quickly. Letâ€™s switch things up a bit - how well does it handle a client downloading slowly?\n\nWeâ€™ll use curl to simulate a slow client. We can use limit-rate to simulate a client downloading only 1000k per second. curl ... --limit-rate 1000k & means weâ€™ll download results at a rate of 1000k per second, running in the background (&). This means it will take our curl call 2 or 3 minutes to download a 130mb file. At the same time, weâ€™ll run another apache bench to see how things perform:\n\nPuma responds quickly. In this scenario, curl is occupying one thread, and ab occupies another. Letâ€™s try running 4 curl commands:\n\nPuma still responds fine. curl is now occupying 4 threads, and ab uses the remaining 1 thread. Letâ€™s add one more request using curl. We also increase the default timeout of ab (which is 30) to 200, for no particular reasonâ€¦\n\nYikes. That did not go well. The moment we had 5 slow running requests from our curl calls, we saturated all available threads. Our 6th request using ab sat around waiting, finally finishing 2 minutes later!\n\nThis is a critical consideration - long-running web work is a throughput killer. Ideally, keep all work as fast as possible and offload long-running work to jobs/other services. Most commonly for a download youâ€™d create a presigned url for a service like S3 and redirect to that URL.\n\nIf you need to run long-running IO, you need to allocate many more threads3.\n\nIn our Long-running CPU example, we couldnâ€™t get pure Ruby code to completely hog the runtime. We can prioritize a thread higher than other threads, but work still continues to be distributed.\n\nOnce you start running native extensions, the Ruby runtime has more limited influence. Itâ€™s up to the extension to properly interface with Ruby and yield control back. Hereâ€™s a simple example that will block all other threads, using the standard openssl gem, using a function written in C, pbkdf2_hmac:\n\nWe have two threads running - one infinitely printing the time in a loop, and one infinitely calling pbkdf2_hmac in a loop. Here I give pbkdf2_hmac a ludicrous number of iterations to force the function to run, in C, for a long period of time:\n\nThe results show that despite each thread having the same priority, the thread with long-running C extension code hogs all of the runtime. The printing thread is able to print a timestamp roughly every 15 seconds.\n\nThereâ€™s nothing the extension code is doing wrong per se, but because it runs purely in C, without yielding back to Ruby until its done, Ruby canâ€™t do anything to keep work distribution fair.\n\nIn most cases, well-developed/mature native extensions wonâ€™t hit this issue. There are many popular gems that are, or include, native extensions. But if you do hit an expensive path in a C extension, be aware the Ruby runtime will not be able to control it. If you know you are interfacing with a slow piece of code in a native extension, keep it off the hot path, same as our long-running IO example.\n\nRemember our production panic scenario from earlier?\n\nNot knowing what else to do, you trigger a server restart. Even doing that, things remain unresponsive for another 30 seconds. Finally you see the server stop, and start up again. As if by magic, everything is running fine again\n\nYou triggered a server restart, and still had to wait 30 seconds? Why wasnâ€™t Puma able to stop sooner? Letâ€™s reuse our download example from earlier, and explain some default Puma behaviors!\n\nFirst, letâ€™s start Puma, and see how quickly we can stop it:\n\nPuma tells us it is shutting down â€œgracefullyâ€. With no activity, it is able to instantly stop.\n\nNow letâ€™s use our DownloadController again:\n\nWe start Puma again, then occupy each thread with a request:\n\nNow letâ€™s trying issuing INT using ctrl+c again:\n\nOk, so we issued our interruption. Butâ€¦ it waited for every request to completely finish! We had to wait around 120 seconds before our server shutdown. Thatâ€™s even worse than earlier!\n\nThis isnâ€™t a blog post about Puma specifically, but Iâ€™ll discuss a few factors:\n\nLetâ€™s try this one more time, starting in cluster mode by setting -w 1:\n\nThis time we replicate our earlier behavior - 30 seconds pass, and the server is shutdown. Now that weâ€™re running in cluster mode, by default Puma uses a configuration called worker_shutdown_timeout, which defaults to 30 seconds. If you have a configuration file, you can set it yourself to something longer or shorter:\n\nAs well, by default Puma never kills threads. In a moment weâ€™re going to be talking about ways to kill a thread. Puma plays it extremely safe, and offers no ability to kill individual threads. And even when shutting down, it defaults to a thread shutdown policy of :forever, which means the only way the threads are killed is when the server is entirely shutdown, which shuts down the worker the threads live in.\n\nYou can change this. In the same configuration file youâ€™d set worker_shutdown_timeout you can set force_shutdown_after:\n\nStill - this doesnâ€™t do much. It still only impacts full server shutdown. But with this setting, the internal Puma thread pool will raise on all threads, and then eventually run kill on them.\n\nWhat all this means is that by default in Puma:\n\nWeâ€™ll talk in-depth later about the available option for killing long-running threads in Puma.\n\nðŸ“ if you want to dig deeper into how Puma works, I highly recommend Dissecting Puma: Anatomy of a Ruby Web Server. The source of Puma is also pretty readable\n\nAll of these thread issues are possibilities, but they mean nothing without empirical data. Measure, then decide your course of option.\n\nOk, enough about how threads get stuck. Once theyâ€™re stuck - is there a way to stop them?\n\nâš ï¸ TL;DR You shouldnâ€™t use these methods unless you really know what youâ€™re doing. Instead, interrupt your thread safely. Incidentally, you should also avoid the timeout module.\n\nif youâ€™re writing a generic threaded framework you may need it - for custom one-off threads you can probably manage without it\n\nSometimes a thread is running and you need to shut it down. Thereâ€™s two primary methods for achieving that: raise and kill.\n\nraise will raise an error inside of the target thread. If the thread hasnâ€™t started yet, in most cases it is killed before running anything:\n\nðŸ“ thread_status is the helper we defined in the â€œThread APIâ€ section on status\n\nThe error isnâ€™t raised instantly - only at the point the thread is scheduled next. We sleep 0.1 to give thread t an opportunity to start. The thread scheduler starts it, and it immediately raises our â€œknock it offâ€ error, effectively running right before puts \"never runs\".\n\nIf the thread gets a chance to start, the error will be raised on whatever line happened to be running last:\n\nBecause it raises whatever error is provided (a RuntimeError if just a string is provided), we can actually rescue the error, ignore it, and retry ðŸ˜±:\n\nWith raise and kill, issues start to creep in when errors are thrown in an ensure. Here we use a ConditionVariable (we dug into those in The Thread API) to guarantee we raise from the ensure block:\n\nWe donâ€™t see â€œIâ€™ll never fire ðŸ˜”â€. What happens to our cleanup? Shouldnâ€™t ensure, erm, umm, ensure that things finishâ€¦\n\nMoving on from raise, kill stops the thread from running anymore instructions, no matter what itâ€™s doing. raise can be rescueâ€™d, kill canâ€™t.\n\nðŸ“ Technically, kill can be ignored, weâ€™ll explain that when discussing handle_interrupt.\n\nâš ï¸ Donâ€™t rescue Exception, itâ€™s a bad idea and you could accidentally rescue things like an OutOfMemoryError ðŸ˜¬\n\nBecause kill doesnâ€™t raise an error, you actually canâ€™t even tell that the thread was killed. We just get the normal false status, represented in our example by â€œfinishedâ€.\n\nLike raise, kill can also disrupt your ensure methods:\n\nThere are a few aliases for kill to be aware of as well:\n\nCase closed. Feel free to use raise and kill on your threads. No harm no foulâ€¦ oh whatâ€™s this here?\n\nRubyâ€™s Thread#raise, Thread#kill, timeout.rb, and net/protocol.rb libraries are broken\n\nWhy Rubyâ€™s Timeout is dangerous (and Thread.raise is terrifying)\n\nThe Oldest Bug In Ruby - Why Rack::Timeout Might Hose your Server\n\nTimeout: Rubyâ€™s Most Dangerous API\n\nStrangely, the thread docs say nothing about the dangers of these methods4. These articles are from 2008, 2015 and 2017. Surely no one uses it anymore, considering all that?\n\nIn fairness to threaded gems that use these methods, they are using the official way you shutdown a thread. And theyâ€™re usually taking as many precautions as possible, prior to calling them. For the most part, gems use them as a shutdown mechanism, and give plenty of room for the thread to finish normally first.\n\nThe basic problem is this: raise and kill force your code to die at any point, with no guarantee of properly cleaning up.\n\nYou might ask: â€œCouldnâ€™t ctrl+c do the same thing?â€. Yes, an OS signal could kill your process or program before an ensure runs, but then all related state is also removed - it can cause other issues, but at least your program cannot limp along in a corrupted state.\n\nSo are they pure evil? An occasional necessity? Somewhere in between? Iâ€™ll leave that discussion to the code philosophersâ€¦ in the practical realm, follow these rules:\n\nðŸ“ A small slice of this next section may look familiar. I included a bit of it in The Thread API. This goes much more in-depth\n\nIâ€™m watching you. Step away from that method, slowly, and no threads have to get hurt.\n\nInstead of killing your thread, set it up to be interruptible. Most mature, threaded frameworks operate this way.\n\nWhenever you need something to run before a method finishes, you should always use an ensure block. ensure is kind of like a method lifeguard - even if something goes wrong, itâ€™s there for you. Itâ€™s the place code goes to ensure itâ€™s run before the method finishes (even when an error is raised).\n\nWe know ensure is not a silver bullet. Thread#raise and Thread#kill do not respect it. But youâ€™re the most likely to clean things up using an ensure.\n\nIf you see this in code, be concerned:\n\nFor some reason, the timeout gem itself doesnâ€™t warn about any issues. But Mike Perham summarizes it best:\n\nThereâ€™s nothing that exactly matches what timeout offers: a blanket way of timing out any operation after the specified time limit. But most gems and Ruby features offer a way to be interrupted - there is a repository called The Ultimate Guide to Ruby Timeouts which details everything you need to know. It shows you how to set timeouts safely for basically every blocking operation you could care about timing out. For instance, how to properly handle timeouts using the redis gem:\n\nThe one piece mentioned in that repository you should leave alone: Net::HTTP open_timeout. Behind the scenes it uses the timeout module ðŸ™…â€â™‚ï¸. Leave the 60 second default, it should almost never impact you, and youâ€™re probably worse off lowering it.\n\nPrimarily people use the timeout gem to manage IO timeouts. In the unlikely case you want to timeout CPU-bound code, itâ€™s up to you to implement it in your processing.\n\nrack-timeout works similarly to the timeout module. And I already told you not to use that. So what gives? It will call raise on your threads - isnâ€™t that bad?\n\nThe short answer is yes, itâ€™s still bad.\n\nBut, rack-timeout is the only real option you have for timing out a web request in Puma. Itâ€™s meant as a last resort. From their docs:\n\nrack-timeout is not a solution to the problem of long-running requests, itâ€™s a debug and remediation tool. App developers should track rack-timeoutâ€™s data and address recurring instances of particular timeouts, for example by refactoring code so it runs faster or offsetting lengthy work to happen asynchronously.\n\nOn top of that, you should have your own lower level timeouts set so that they would fire before rack-timeout.\n\nYouâ€™ll want to set all relevant timeouts to something lower than Rack::Timeoutâ€™s service_timeout. Generally you want them to be at least 1s lower, so as to account for time spent elsewhere during the requestâ€™s lifetime while still giving libraries a chance to time out before Rack::Timeout.\n\nThe core issue of any thread raise/kill based solution is corrupted state. When using rack-timeout, you should be using term_on_timeout, ideally set to 1.\n\nterm_on_timeout will send a SIGTERM to the worker the thread is running in, which for most servers indicates a need for a graceful shutdown of that process - any potential corrupted state is isolated to that process and will be cleaned up once the process is shutdown.\n\nterm_on_timeout only works properly if youâ€™ve got multiple processes serving your requests. And if you get lots and lots of timeouts, it could potentially cause performance problems. See the docs for proper configuration!\n\nThere is an alternative idea floating around out there of a way to achieve a â€œSafer Timeoutâ€, at least in Rails apps:https://web.meetcleo.com/blog/safer-timeouts. Maybe Iâ€™ll detail it \n\nHaving threads that do not stop easily is a bug. If youâ€™re seeing rack timeout errors, or jobs that canâ€™t be shut down, track it and prioritize fixing it. Treat it like a bug and allocate time to improve it.\n\nThread.handle_interrupt is One Weird Trick Thread#kill Calls Donâ€™t Want You To Knowâ„¢. If weâ€™re gonna discuss it, might as well go deepâ€¦\n\nA thread can be externally â€œinterruptedâ€ by a few things:\n\nhandle_interrupt gives you the ability to control how your program reacts to 1-3. And it means you can define blocks of code which will guarantee their ensure blocks run.\n\nhandle_interrupt is a low-level interface and itâ€™s also the one you are least likely to ever need. Youâ€™ll see it used in things like threaded web and job servers where low-level control and better cleanup guarantees are helpful. Youâ€™ll find examples of it in Sidekiq, the Async fiber scheduler, Homebrew, the parallel gem and more.\n\nWhen you need the strongest guarantees possible about cleaning up your code in response to â€œinterruptionâ€, handle_interrupt is what you need.\n\nLetâ€™s look at a simple example:\n\nRun that code ðŸ‘† and youâ€™ll never see â€œdone!â€ print. This is the same type of code we saw in the raise and kill section. What can handle_interrupt do for us?\n\nNow we see â€œdone!â€ printed! To be clear, the error will still be raised eventually. It can only impact the section it encloses, so the error will be raised right after.\n\nWhatâ€™s with the interface - what does KnockItOffError => :never mean? Letâ€™s break it down:\n\nBased on that knowledge, letâ€™s demonstrate a more complex example:\n\nIn this example, â€œdone!â€ is never printed because it is in the :immediate block. But we successfully print out â€œCanâ€™t touch this!â€ message in our ensure, because weâ€™re within the :never block for KnockItOffError. ensure is nowâ€¦ ensured.\n\nWeâ€™ve used :never and :immediate, what about :on_blocking?\n\nOur increments work fine, as indicated by i being one million. But our puts is a â€œblockingâ€ call so it gets the boot.\n\nShould we have used a thread safe counter? Letâ€™s try it again using Concurrent::AtomicFixnum from concurrent-ruby, and two threads. We should see i as two million afterwards:\n\nWait, why? i is 1237719? Why is i not two million? What blocked?!\n\nðŸ“ Youâ€™ll definitely see a different number. Sometimes youâ€™ll see 1000000, sometimes youâ€™ll see a higher number, but youâ€™ll pretty much never see 2000000\n\nAs it turns out, Concurrent::AtomicFixnum uses a Mutex by default. If a Mutex waits to acquire a lock it is considered a blocking operation! That means it qualifies for :on_blocking and the error gets raised.\n\nAs a specific fix for AtomicFixnum, if you install the concurrent-ruby-ext gem then you get native extensions which are lock-free, no longer use a Mutex, and properly run our code.\n\nOnce we install concurrent-ruby-ext, we properly get 2000000!:\n\nBut we also know that a Mutex or any other locking/waiting behavior can cause our :on_blocking interrupt to fire. So :on_blocking can have surprising behavior if some other internal of the code were to change later.\n\nIf the thread hasnâ€™t started yet, handle_interrupt wonâ€™t help you. The error will be raised immediately in the thread, before handle_interrupt can be called:\n\nWhat happens after handle_interrupt? Once the error is allowed to raise, code directly after it wonâ€™t run:\n\nBut code after the inner handle_interrupt could run, it just depends on if the previous block raises. In this example, all of the code runs successfully because we donâ€™t raise an error during the inner block:\n\nBut youâ€™re better off guaranteeing code after the block runs. Use an ensure to make sure even if the inner block raises an error your code still runs:\n\nCan we even stop the unstoppable Thread#kill? Yep! From the Thread.handle_interrupt docs:\n\nFor handling all interrupts, use Object and not Exception as the ExceptionClass, as kill/terminate interrupts are not handled by Exception.\n\nSo we can handle it - but we have to use Object, which looks a bit odd but works well:\n\nThe reason for this odd syntax is that the kill/terminate interrupts are internally handled not as Exception instances, but as integers. That means this would also work:\n\nStill, youâ€™re better off using Object to avoid the implementation detail.\n\nCan we stop the timeout gem from raising at a bad time using handle_interrupt? The Thread API docs used to specifically use timeout as a use-case for handle_interrupt, but thereâ€™s a non-determinism bug around thread reuse within the timeout gem.\n\nSo once again, donâ€™t use the timeout gem.\n\nI removed the example from the docs because itâ€™s too broken, so on Ruby 3.4+, the docs no longer mention handle_interrupt with the timeout gem.\n\nWeâ€™ve looked at many handle_interrupt examples - what do real gems use it for?\n\nIn the async gem it uses handle_interrupt to ignore SignalException while it shuts down its child tasks:\n\nIn sidekiq, when it has gracefully attempted a shutdown and is forcing threads to finish, it raises a special error. That error extends Interrupt, which means most rescue blocks will not capture it because it is a child of Exception rather than StandardError:\n\nTo avoid Sidekiq::Shutdown breaking everything (including its own internal code), Sidekiq also uses handle_interrupt to ignore the error in a small piece of shutdown code:\n\nIf this section hasnâ€™t been enough for you, Ben Sheldon gives some additional interesting examples In his article Appropriately using Rubyâ€™s thread handle_interrupt.\n\nIâ€™m pretty confident, started from scratch, Ruby would not be implemented with raise and kill again. I donâ€™t know _whichÂ _ model they would choose - but something like a Java interrupt would be a good start. And minimally, making all ensure blocks uninterruptable, as well as all finalizers. I didnâ€™t even get into finalizers - theyâ€™re a less common, but also important area that you really donâ€™t want to interrupt.\n\nRuby is one of the only programming languages that lets you kill a thread from outside of the thread. Itâ€™s powerful, but mostly, itâ€™s dangerous. Itâ€™s one of the sharpest tools available to you, and it should be used sparingly, or ideally not at all.\n\nIn threaded code, the best offense is a good defense:\n\nNow go forth, armed with the knowledge on what to do when good threads go bad.\n\nUnless youâ€™re in SQLite, where apparently N+1 queries are a virtue ðŸ˜² https://www.sqlite.org/np1queryprob.htmlÂ â†©ï¸Ž\n\nIn general, you shouldnâ€™t do this directlyÂ â†©ï¸Ž\n\nOr use Falcon. See me later in the series when we talk about Fibers ðŸ˜Â â†©ï¸Ž\n\nThereâ€™s a small mention about how to handle Timeout errors, but it doesnâ€™t explain much or warn at allÂ â†©ï¸Ž",
    "readingTime": 23,
    "keywords": [
      "seconds finally",
      "letâ€™s look",
      "cluster mode",
      "pure ruby",
      "rubyâ€™s default",
      "magic everything",
      "method finishes",
      "kill/terminate interrupts",
      "per second",
      "client downloading"
    ],
    "qualityScore": 1,
    "link": "https://jpcamara.com/2025/12/30/when-good-threads-go-bad.html",
    "thumbnail_url": "https://cdn.uploads.micro.blog/98548/2025/whengoodthreadsgobad.jpg",
    "created_at": "2025-12-31T18:17:19.402Z",
    "topic": "tech"
  },
  {
    "slug": "the-guy-who-coined-vibe-coding-now-says-hes-never-felt-more-behind-as-a-programmer",
    "title": "The guy who coined 'vibe coding' now says he's never felt more behind as a programmer",
    "description": "OpenAI alum Andrej Karpathy wrote on X that his failure to fully claim the 10x boost of new tools felt like a \"skill issue.\"",
    "fullText": "Andrej Karpathy has long been ahead.\n\nHe was ahead of the AI boom, having worked as a founding member of OpenAI in 2015, long before competitors like Anthropic and xAI emerged. He also got into self-driving vehicles early, steering Tesla's autopilot effort as its head of AI.\n\nNow, he says, \"I've never felt this much behind as a programmer.\"\n\nIn an X post on Friday, Karpathy wrote that the industry was being \"dramatically refactored,\" as individual programmers contribute fewer and fewer lines of code.\n\n\"I have a sense that I could be 10X more powerful if I just properly string together what has become available over the last ~year,\" he wrote. \"A failure to claim the boost feels decidedly like skill issue.\"\n\nI've never felt this much behind as a programmer. The profession is being dramatically refactored as the bits contributed by the programmer are increasingly sparse and between. I have a sense that I could be 10X more powerful if I just properly string together what has becomeâ€¦\n\nAI has radically transformed the software engineering industry, introducing code editors like Cursor, Claude Code, and Codex, along with a slew of agentic software development tools. Business Insider's Amanda Hoover called 2025 \"the year coding changed forever.\"\n\nKarpathy was a key player in the change. In February, he coined the term \"vibe coding.\" To vibe code, one prompts AI to generate lines of code. (It gets its name because developers \"fully give in to the vibes,\" Karpathy wrote in his original post.) The Collins Dictionary named it the word of the year.\n\nStill, Karpathy wrote that it's like a \"powerful alien tool\" was handed out without a manual.\n\n\"Everyone has to figure out how to hold it and operate it, while the resulting magnitude 9 earthquake is rocking the profession,\" he wrote.\n\nIn the comments, another one of the biggest names in vibe-coding agreed. Boris Cherny created Claude Code for Anthropic, now one of the most popular AI tools among developers.\n\nCherny wrote that he felt that way \"most weeks,\" and that he sometimes finds himself approaching a problem manually, not yet realizing AI can do it faster.\n\nNew graduates and early career coders may fare best in this new environment, Cherny wrote, because they don't assume what AI can and cannot do.\n\n\"It takes significant mental work to re-adjust to what the model can do every month or two, as models continue to become better and better at coding and engineering,\" he wrote.\n\nResponding to Cherny, Karpathy wrote that he had similar experiences. He analogized the new tools to a weapon, one that sometimes \"shoots pellets\" or \"misfires\" â€”Â highlighting the work-in-progress nature of AI.\n\nOther times, though, the tools work wonders.\n\n\"Once in a while when you hold it just right a powerful beam of laser erupts and melts your problem,\" he wrote.",
    "readingTime": 3,
    "keywords": [
      "dramatically refactored",
      "properly string",
      "string together",
      "tools",
      "programmer",
      "coding",
      "ahead",
      "anthropic",
      "i've",
      "behind"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/openai-founding-member-never-felt-so-behind-programmer-2025-12",
    "thumbnail_url": "https://i.insider.com/6953e21004eda4732f2e3df7?width=1200&format=jpeg",
    "created_at": "2025-12-30T18:18:12.476Z",
    "topic": "finance"
  },
  {
    "slug": "why-reliability-demands-functional-programming",
    "title": "Why Reliability Demands Functional Programming",
    "description": "> In banking, telecom, and payments, reliability is not a nice to have. It is table stakes. The most reliable systems I have worked on reduce entire classes of bugs before the code even runs. Functional programming and Algebraic Data Types (ADTs) let you push correctness into the type system, so illegal states cannot be constructed in the first place. **What you will learn** - How invalid states show up in real systems and why they cause costly incidents - How ADTs encode business rules so the compiler enfo...",
    "fullText": "In banking, telecom, and payments, reliability is not a nice to have. It is table stakes. The most reliable systems I have worked on reduce entire classes of bugs before the code even runs. Functional programming and Algebraic Data Types (ADTs) let you push correctness into the type system, so illegal states cannot be constructed in the first place.\n\nMost production incidents are not due to complex algorithms. They are due to the code entering a state that should never have been possible. If you have been on call, you have seen variants of these:\n\nFunctional programming helps by modeling the domain with types that make invalid states unrepresentable. Pure functions and immutability keep behavior predictable and testable.\n\nProduct types combine fields, think \"and\". Sum types choose one of several cases, think \"or\". Together they model your domain rules.\n\nWith this shape, \"paypal\" cannot exist as a Payment. The compiler refuses the value.\n\nWhen you pattern match on a sum type, the compiler can force you to handle every variant. If you later add a new case, every non exhaustive match becomes a compilation error or warning. This is how refactors become safe by default.\n\nAdd a new Crypto method and both code bases will point out every place you must update.\n\nIncident story\n\nA payout worker retries on network timeouts and calls settle() twice. The table allows pending = false and settled = true twice with the same ledger id. Reconciliation finds duplicates and accounting needs a manual fix.\n\nWhy it happened\n\nState is spread across booleans and strings. The database does not express the lifecycle. The application code does, but only by convention and tests.\n\nTransitions become total functions. You can return a Result when a transition is not allowed.\n\nNow the illegal transitions are blocked by construction. Test coverage still matters, but the shape of the model prevents a class of bugs.\n\nRefactor safety\n\nWhen product adds Chargeback, the compiler highlights every match that ignores it. You cannot ship with a half handled lifecycle.\n\nEvery switch on TxnState now requires a chargeback branch. This is free guidance from the compiler.\n\nIncident story\n\nThe call detail record pipeline generates billing events whenever it sees a Connected event. Under jitter and retries, some sessions never receive Completed. The billing system charges based on the wrong boundary and customers complain.\n\nWhy it happened\n\nThe call lifecycle is implicit across many services. A connected session with no end was still billable because there was no type that separated non billable states from billable ones.\n\nNow a connected but never completed call cannot produce a billable duration. The shape forbids the bug.\n\nIncident story\n\nA cache TTL is stored in an environment variable. Someone sets CACHE_TTL_SECS=30s. In JavaScript, Number(\"30s\") yields NaN and your code treats it as zero, disabling caching in production.\n\nThe ambiguity disappears. The code must handle absence and parse errors explicitly.\n\nDo not use null to mean \"maybe\". Do not throw exceptions for expected errors.\n\nThese types make the happy path and the error path equally explicit.\n\nMutable shared state is a common source of heisenbugs under concurrency. Prefer immutable data and pure functions. When you need to update, create a new value.\n\nYour tests become simple. Given the same inputs, the function returns the same output.\n\nNumbers are not self describing. Create types that carry meaning.\n\nYou stop mixing milliseconds with seconds or dollars with cents by accident.\n\nKeep the domain logic pure and push IO to the edges. This makes unit tests cheap and fast.\n\nStart small and make continuous progress. Here is a practical order for a team new to these ideas.\n\nReplace pairs of booleans with a sum type\n\nReplace string enums with discriminated unions\n\nReplace nullable fields with Option\n\nReplace thrown control flow with Result\n\nIntroduce newtypes or branded types for units and ids\n\nPattern matching compiles to simple branches. Discriminated unions in TypeScript are just plain objects. The main cost you will feel is validation at the boundaries in smart constructors. This is a trade worth making. The compiler then protects the interior of the system.\n\nReliability is designed. With Algebraic Data Types, pattern matching, Option and Result, immutability, and smart constructors, you encode domain rules directly in your types. Illegal states cannot compile. This is why industries that cannot afford failure, such as banking and telecom, gravitate to functional ideas.\n\nIf you work on code that touches money, minutes, or public availability, adopt these patterns now.\n\nYour on call shifts will be quieter, and your users will notice the difference.",
    "readingTime": 4,
    "keywords": [
      "functional programming",
      "discriminated unions",
      "smart constructors",
      "pattern matching",
      "domain rules",
      "pure functions",
      "code",
      "cannot",
      "compiler",
      "billable"
    ],
    "qualityScore": 1,
    "link": "https://blog.rastrian.dev/post/why-reliability-demands-functional-programming-adts-safety-and-critical-infrastructure",
    "thumbnail_url": "https://rastrian.dev/assets/img/profile.png",
    "created_at": "2025-12-28T01:03:21.884Z",
    "topic": "tech"
  },
  {
    "slug": "a-guide-to-claude-code-20-and-getting-better-at-using-coding-agents",
    "title": "A Guide to Claude Code 2.0 and getting better at using coding agents",
    "description": "A deep dive into Claude Code 2.0 features, Opus 4.5 workflows, and context engineering. Learn sub-agents, MCP servers, hooks, skills, and practical tips to boost your AI-assisted coding productivity.",
    "fullText": "This post is a follow-up to my post from July'25 - My Experience With Claude Code After 2 Weeks of Adventures. If you are new to Claude Code or just want a quick refresh, I am once again asking you to go through it. It covers some lore, my workflow back then and then 80-90% of the Claude Code standard workflow. You may choose to skip the intro although I recommend you read it. Lore is important man.\n\nA short recap - we had covered CLAUDE.md, scratchpad, using task tool (now sub-agents), the general plan + execute workflow, tips for context window management, Sonnet 4 vs Opus 4 (not relevant now), using shortcuts like ! and using Shift + ? to show shortcuts, memory basics, /resume to restart conversation and short discussion on custom commands.\n\nI got a great response on my Opus 4.5 vibe-check tweets and still receieving good feedback on my July blog post (despite being somewhat poorly written). This shows there's clearly a demand for in-depth resources around Claude Code.\n\nI noticed that lots of people, both technical and many non-technical or less hands-on people i.e technically-lite people have started to try Claude Code (CC). CC is more of a general agent - you can use it for tasks other than coding as well - like making an excel invoice, data analysis, errands on your machine etc. And of course everything I talk about is by default meant for coding too.\n\nIf you can learn even 3-4 ideas that help you with using Claude Code (or other tools like Codex/Gemini CLI/OpenCode) or improve your understanding of LLMs, it would be a win for me.\n\nI don't want this post to be a prescription (map). My objective is to show you what is possible and the thought processes and simple things you can keep in mind to get the most out of these tools. I want to show you the map but also the territory.\n\nClaude Code dominated the CLI coding product experience this year and all the CLI products like Codex, OpenCode, Amp CLI, Vibe CLI and even Cursor have heavily taken inspiration from it. This means learning how things work in Claude Code directly transfers to other tools both in terms of personal usage and production grade engineering.\n\nKarpathy sensei posted this which caused the Twitter timeline. This led to a lot of discussion and there were some really good takes - some which I have written about too.\n\nIt's a reasonable crashout - the technology is evolving at a mindblowing pace and it's difficult to keep up for most of us and especially for senior folks and people with high quality standards. Nevertheless, I think if you are reading this post, it's scary but also exciting time to build stuff at speeds never possible before.\n\nInstead of thinking in terms of \"keeping up\", a better framing is how can I improve myself with help of these tools i.e augment.\n\nIn my opinion, there are 3 components to augment yourself:\n\nStay updated with tooling - What Karpathy sensei mentioned. Use these tools regularly and keep up with releases. I have been doing this regularly; it can be draining but I enjoy the process and I have the incentive that it helps me at my job. For the technically lite, even weekly/monthly updates would help.\n\nUpskill in your domain - It's a great time to spread both vertically (domain depth) and horizontally (adjacent areas). The more you know, the better you can prompt - converting unknown unknowns to known unknowns. Experience builds judgement and taste - that's what differentiates professional devs from vibe-coders. Since implementation is much faster now, you can spend more time on taste refinement.\n\nFor software engineering folks, this might mean getting better at good practices, system design, planning - where more thinking is involved. Ask more questions, run more experiments (since you can iterate fast), spend more time on understanding requirements. Using good software engineering practices to create better feedback loops for LLMs (good naming, refactoring, docs, tests, typed annotations, observability etc.). Review code. Please don't forget to come back to my post lol but I liked Addy Osmani's take on this.\n\nThe idea is to let the LLM perform things with input, get output and see errors.\n\nAs an aside, getting better at articulating thoughts via writing helps. One may also try touch typing/writing using speech-to-text tools to operate faster.\n\nThis post will act as a guide for things Karpathy said but you'll need to play around, build intuition and achieve outcomes with help of these tools yourself. The good news is it's fun.\n\nI am having a great time with Claude Code 2.0 since the launch of Opus 4.5 and it's been my daily driver since then. Before we go all lovey-dovey about Claude, I wanted to quickly go through the timeline and lore. I love yapping in my blog and I feel it's important to set the context here.\n\n2025 saw release of many frontier models by OpenAI and Anthropic. Also, it's super under-talked but OpenAI actually caught up to Anthropic in code-generation capability - intelligence wise, context window effectiveness, instruction following and intent detection.\n\nIt's been a wild year and honestly speaking I got tired of trying out new releases by OpenAI every 2 weeks.\n\n>no swe-bench-verified comparison\n>no comparison against opus 4.5\n>\"we are topping in cybersecurity\"\n>mfw i realise i am the fucking eval https://t.co/4oDG3yj6CP pic.twitter.com/aUfJfwROCf\n\nThere have been several Open Source competitors like GLM-4.7, Kimi-K2, Minimax-2.1. The space is very competitive and there is definitely an audience that uses the cheaper priced but high performant Chinese models for low-medium difficulty tasks.\n\nThat said, I still think Anthropic/OpenAI lead over Chinese Frontier models. The latter have contributed \n\n(Note: I am talking with respect to personal coding usage, not production API usage for applications).\n\nI was using Claude Code as my main driver from late June to early September. I cancelled my Claude Max (100 USD/month) sub in early September and switched to using OpenAI Codex as my main driver. Switch was driven by two factors -\n\nclaude code is more enjoyable as a product and has more features. i have always felt to try out more things related to automation in cc as compared to codex. once they drop a new iteration i would consider getting a max sub again if its better than gpt-5-codex\n\nAnthropic also had tonne of API outages and at one point of time they had degradation due to inference bugs. This also was a major driver for several people to move to the next best alternative i.e Codex or GPT-5.1 on Cursor.\n\nI was using Codex (main driver) and Cursor (never cancelled) until late October. Claude Sonnet 4.5 had released on 29th September along with Claude Code 2.0.. and I did take a 20 USD sub from another email account of mine to try it out (I had lots of prompting work and Claude models are my preferred choice) but GPT-5/GPT-5-codex were overall better despite being slow.\n\nSonnet 4.5's problem was fast and good but it would make many haphazard changes which would lead to bugs for me. In other words, I felt it to be producing a lot of slop in comparison to GPT-5.1/GPT-5.1-codex later.\n\nAround October 30, Anthropic sent an email saying we are offering the 200 USD max plan to users who cancelled the subscription and obviously I took it.\n\nchat please remind me to cancel after 28 daysðŸ˜‚ pic.twitter.com/TSGidVJ2xo\n\nMy Claude Code usage was still minimal but on 24th November, they launched Opus 4.5 and I had 5 days to try out Opus 4.5. I used the hell out of it for my work and also wrote this highly technical blog with the help of it discovering several of its capabilities.\n\nI had done a similar tweet when I had switched to GPT-5.1 which had gotten half the response of this one. This indicated to me that more people resonated with Opus 4.5 (at least on Twitter) back then. Also, many people were just not able to realise GPT-5.1's capabilities tbh.\n\nOther than the above State of the Art at the coding benchmarks like SWE-bench-verified (code-generation), Tau Bench (agentic stuff), Opus 4.5 was faster, at-par in coding, super collaborative and good at communication. These factors led to my conversion. It had good vibes. More comparison points later in the post.\n\nAs I described in the screenshot, Opus 4.5 was roughly at same code-gen capability with GPT-5.1-Codex-Max.\n\nToday, in my experience I think GPT-5.2-Codex exceeds Opus 4.5 in raw capability by a small margin. Still, Opus 4.5 has been my main driver since release.\n\nI think first reason is it's faster and can do similar difficulty tasks in much lesser time than Codex. Also, it's overall\na much better communicator and pair-programmer than Codex which can even ignore your instructions at times (and go and make changes). Opus has better intent-detection as well.\n\nOne nice-use case shown here by Thariq on creating a background async agent to explain changes to a non-technical person leveraging Claude's explanation abilities.\n\nTo further demonstrate the difference, here's a CC vs Codex comparison\n\nFor the same prompt, see the outputs. Codex tends towards super concise while Claude matches my expectation.\nYou can modify the verbosity in Claude's case but Codex won't budge. Another thing I want to highlight is\nthe UI itself - Claude has more saturated white color on black whereas Codex's text is thinner/less readable\nand the thinking traces are shown in even lighter shade which I don't like.\n\nBecause of being faster not only in terms of lesser thinking to perform task but throughput wise also, it unlocks\nmuch faster feedback loops for your tasks. This makes progress feel more visceral even though capability wise, GPT-5.1/Codex were at par even in November.\nThe only downside with faster loop is if you are cautious, you end up micro-managing for long hours.\n\nOpus 4.5 is a great writer and comes closest to humans so I have always preferred Claude models for customizing prompts.\n\nBesides the model, obviously the Claude Code Product goes a long way to make things magical.\n\nAs a product it's a mile ahead of Codex in QoL features. The harness, prompts and the model make for a magical experience. The model is amazing but there is a massive amount of tasteful engineering that has gone into UX/UI and just the code/prompts to let Claude feel comfortable in the harness and make function calling accurate. We will explore this \n\nBefore we move ahead - my previous post somehow reached Hackernews #5 and I was facing allegations that my post was sponsored by Anthropic. I was like bro are you serious? Anthropic doesn't sponsor random users like me. Anthropic doesn't even think about me (meme.jpeg) besides from a user point of view.\n\nBesides praise, I have been snarky, made fun of outages, made a lot of fun of Sonnet 4.5 slop. I have expressed what I have felt over time and it's led to good discourse on the timeline as well.\n\nAll this said, Claude Code has been one of the most enjoyable product experiences I have ever had. I am grateful and highly respect the engineering and research team behind it.\n\nThat's enough yapping. In the next few sections, I will talk about useful features that I didn't talk about in my previous blog and notable features introduced in the iterations from Claude 2.0 - 2.074.\n\ncurrently using Claude Code for the first time, I can officially put \"Technical-lite\" on my resume now\n\nI am assuming several technical-lite people are gonna read this. Few concepts to help comprehension later in the blog -\n\nMore specifically, context is the input tokens. The context window refers to the maximum amount of tokens that an LLM can see and process at once during a conversation. It's like the model's working memory. Opus 4.5 has a 200K context window which is approximately 150,000 words.\n\nTool calling - Learn about tool calling. Here's a good resource. You know that LLMs can generate text but what if you want the LLM to perform an action - say draft an email or lookup the weather on the internet or just do google search. That's where tools come in. Tools are functions (in code or skills) defined by the engineer that do these exact things. We define tools and we let the LLM know about it in the system prompt and it can decide which tool to call when you are chatting with it! Once the tool call i.e the action is performed, the results are relayed back to the LLM.\n\nAgent - The simplest definition is an LLM that can pro-actively run tools to achieve a goal. For a more sophisticated definition, I like the one by Anthropic\n\n\"Agents, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.\" from Building Effective Agents.\n\n\"Agentic\" - refers to the tool calling capabilities of the model - how pro-active, how accurate the tool calling is (detecting user's intent to perform the action, choosing the correct tool, knowing when to stop)\n\nHarness/scaffolding - Sonnet 4.5/Opus 4.5 are the models. They need to be provided with lots of \"scaffolding\" / layers of code, prompts, tool calls and software packaging/environment to make them work in a semi-autonomous fashion. Note that Claude Code is not a harness, it's a product (think the TUI, integrations etc.). Claude Code has a harness.\n\nClaude Code has had lots of AI features and quality of life improvements since July. Let's look at the ones that I found to be useful. You can see all changes in the Changelog.\n\nAsk mode options - Another thing I like is Option 3 when it asks questions in the syntax highlighting image above - \"Type here to tell Claude what to do differently\". Fun fact: All these are really prompts for the model whose output is parsed by another tool call and shown in this way.\n\nUltrathink - I like to spam ultrathink for hard tasks or when I want Opus 4.5 to be more rigorous e.g. explaining me something, self-reviewing its changes\n\nThinking toggle - Tab to toggle thinking on/off was a good feature. They changed it to Alt/Option + Tab recently but there's a bug and it does not work on Mac. Anyways CC defaults to thinking always true if you check in your settings.json\n\nPrompt history search - Search through prompts using Ctrl + R (similar to terminal backsearch). I have it in 2.0.74. It can search across project wide conversations. Repeatedly do Ctrl + R to cycle through results.\n\nCursor cycling - When you reach beginning/end of prompt, press down/up to cycle around\n\nMessage queue navigation - It's possible to navigate through queued messages and image attachments (2.0.73) now (idk if it's possible to display image attachment as well).\n\nFuzzy file search - File suggestion is 3x faster and supports fuzzy search (2.0.72)\n\nLSP support was added recently. Access via plugins.\n\nThere have been new integrations too like Slack Integration, Claude Web (beta), Claude Chrome extension. These are pretty obvious and I won't cover these. I think Claude Web would be interesting for many particularly (since you can launch tasks from iOS/Android too).\n\nNext few sub-sections are all about most used features.\n\nI didn't cover commands properly in my previous blog post. You can use / to access the built-in slash commands. These are pre-defined prompts that perform a specific task.\n\nIf these don't cover a specific task you want, then you can create a custom command. When you enter a command, that prompt gets appended to the current conversation/context and the main agent begins to perform the task.\n\nCommands can be made on a project level or global level. Project level resides at .claude/commands/ and global one at ~/.claude/commands.\n\nOften when the context window starts getting full or I feel the model is struggling with a complex task, I want to start a new conversation using /clear. Claude provides /compact which also runs faster in CC 2.0 but sometimes I prefer to make Claude write what happened in current session (with some specific stuff) before I kill it and start a new one. I made a /handoff command for this.\n\nIf you find yourself writing a prompt for something repetitively and instructions can be static/precise, it's a good idea to make a custom command. You can tell Claude to make custom commands. It knows how (or it will search the web and figure it out via claude-code-guide.md) and then it will make it for you.\n\nYou can find a bunch of commands, hooks, skills at awesome-claude-code though I recommend to build your own or search for one only when it's really required.\n\nI have a command called bootstrap-repo that searches the repo with 10 parallel sub-agents to create a comprehensive doc. I rarely use it these days and so many parallel sub-agents lead to the Claude Code flickering bug lol.\n\nAnyways, notice the \"Explore\" sub-agent and \"running in background\".\n\nSub-agents were introduced shortly after I published my last blogpost. Sub-agents are separate Claude instances that are spawned if the main agent wishes so or you explicitly tell it to do so. These powers are defined already in system prompt and sometimes you just have to remind... Understanding these features will help you micro-manage Claude haha.\n\nYou can also define your custom sub-agents. To create one:\n\nOr just use /agents to manage and create sub-agents automatically - recommended approach.\n\nThe \"Explore\" thing in above pic is a sub-agent. You can tell Claude \"Launch explore agent with Sonnet 4.5\" if you want it to use Sonnet instead of Haiku (I found this by just trying things out but we will see how this happens)\n\nThe Explore agent is a read-only file search specialist. It can use Glob, Grep, Read, and limited Bash commands to navigate codebases but is strictly prohibited from creating or modifying files.\n\nYou will notice how thorough the prompt is in terms of specifying when to use what tool call. Well, most people underestimate how hard it's to make tool calling work accurately.\n\nThis is the Explore agent prompt from 2.0.56 and it should be similar now too. Reference. These are captured by intercepting requests. Reference video.\n\nIn case of Explore sub-agent, it starts with a fresh slate which makes sense. It does not inherit any context from main agent. Many tasks involve searching through large amounts of digital media or code to filter for something relevant. Often the individual parts are independent of each other when you want to filter for something so launching parallel agents makes sense.\n\nIf I am trying to understand a feature or just looking up simple things in the codebase, I let Claude do the Explore agent searches. Explore agent passes a summary back to the main agent and then Opus 4.5 will publish the results or may choose to go through each file itself. If it does not, I explicitly tell it to.\n\nIt's important that the model goes through each of the relevant files itself so that all that ingested context can attend to each other. That's the high level idea of attention. Make context cross with previous context. This way model can extract more pair-wise relationships and therefore better reasoning and prediction. Explore agent returns summaries which can be lossy compression. When Opus 4.5 reads all relevant context itself, it knows what details are relevant to what context. This insight goes a long way even in production applications (but you only get it if someone tells you or you have read about self-attention mechanism).\n\nCodex does not have a concept of sub-agents and it's probably a conscious decision by the devs. GPT-5.2 has a 400K context window\nand according to benchmarks, it's long context retrieval capabilities are a massive improvement. Although people have tried\nmaking Codex use headless claude as sub-agents haha. You can just do things.\n\nThe general-purpose and plan sub-agent (separate from plan mode) inherit the context. With respect to user defined sub-agents, I am not sure but I think they start with clean slate.\n\nFrom the reverse engineered resources/leaked system prompt, it's possible to see that the sub-agents are spawned via the Task tool.\n\nTurns out you can ask Claude too. (I think the developers are allowing this now?). It's not a hallucination. The prompt pertaining to pre-defined tools are there in the system prompt and Claude code dynamically injects reminders/tools often to the ongoing context.\n\nTry these set of prompts with Opus 4.5\n\nYou will get the output something like below (click) but to summarise -\nIt defines 5 agent types: general-purpose (full tool access, inherits context), Explore (fast read-only codebase search), Plan (software architect for implementation planning), claude-code-guide (documentation lookup), and statusline-setup. Notice how each sub-agent is defined with its specific use case and available tools. Also notice the \"When NOT to use\" section - this kind of negative guidance helps the model avoid unnecessary sub-agent spawning for simple tasks.\n\nI want you to focus on the tool schema. The Task tool prompt above is detailed guidance on how to use the tool that resides in the system prompt. The tool schema defines the tool or the function.\n\nThe main agent calls the Task tool to spawn a sub-agent, using its reasoning to decide the parameters. Notice the model parameter - when I say \"Use Explore with Sonnet\", the model makes the tool call with model: \"sonnet\".\n\nTill August'25 or so, Claude Code used to show the Task tool performing actions in the TUI but now TUI shows the sub-agent name instead.\n\nNotice the run_in_background parameter. It decides whether to send a sub-agent to run in the background. I like the background process feature - it is super helpful for debugging or just monitoring log outputs from process. Sometimes you have a long running python script that you wanna monitor etc.\n\nModel usually automatically decides to put a process in background but you can explicitly tell it to do so. Note that \"Background Tasks\" is different. Using an & sends a task to Claude Web (should have named it Claude Cloud haha). I am yet to get this to work properly.\n\nI have a pretty simplish/task based workflow: CC as the main driver, Codex for review and difficult tasks, and Cursor for reading code and manual edits. I rarely use Plan Mode. Instead, once requirements are clear enough, I explore the codebase to find the relevant files myself.\n\nOpus 4.5 is amazing at explaining stuff and makes stellar ASCII diagrams. The 2025 Aug knowledge cutoff helps here too. So my exploration involves asking lots of questionsâ€”clarifying requirements, understanding where/how/why to make changes. It might be less efficient than Plan Mode, but I like this approach.\n\nOnce I have enough context, I spam /ultrathink and ask it what changes are required and then if things look ok, I start the execution closely monitoring the changes - basically micro-managing it. I sometimes ask Codex's second opinion here lol.\n\nFor difficult new features, I sometimes use a \"throw-away first draft\" approach. Once I understand what changes are needed, I create a new branch and let Claude write the feature end-to-end while I observe. I then compare its output against my mental model as to how close did it get to my requirements? Where did it diverge? This process reveals Claude's errors and the decisions/biases it made based on the context it had. With the benefit of this hindsight, I run another iteration, this time with sharper prompts informed by what I learned from the first pass. Kinda like Tenet.\n\nFor backend-heavy or just complex features specifically, I'll sometimes ask Codex xhigh to generate the plan instead.\n\nI maintain a few custom commands, use CLAUDE.md and scratchpad extensively. No custom sub-agents. I use MCP sometimes if need shall arise (e.g for docs. I have tried Playwright and Figma MCP so far) but in general not a fan. I have used hooks for simple stuff in the past and need-basis. skills/plugins are something that I am yet to use more regularly. I often use background agents for\nobservability (monitoring log / error) purposes. I rarely use git worktrees.\n\nIt's worth noting that the harness is so heavily engineered that Claude knows which sub-agent to spawn, what command/tool call/skill to run, what to run in async manner. It's able to heavy carry the agent loop that your task is mainly to use your judgement and prompt it in right direction. The next generation of models will get better and the relevant scaffolding will reduce for existing feature and increase for newer features. (Re: contrasting to Karpathy sensei's latest tweet shown at beginning)\n\nIt's not at all required to know the features in depth to be honest. However knowing how things work can make you a better micro-manager if the need arises like telling the Explore agent to use Sonnet.\n\ngetting claude opus 4.5 changes reviewed by gpt-5.1-codex-max high pic.twitter.com/A4tYN3W3Q6\n\nFor reviewing code and finding bugs, I find GPT-5.2-Codex is superior. Just use /review. Better than code review products too.\n\nIt's able to find bugs and mention severity like P1, P2. It's less likely to report false-positives and more trustable when it comes to confusing changes as compared to Claude. This Claude for execution and GPT/o-series model for review/bugs dynamic has been pretty constant for me for probably a year.\n\nNow is a good time to take a breath and refresh your context window. Before we get to the next set of features, it's worth\ngoing through context management fundamentals. Things might get a bit difficult for the technically-lite folks.\nDon't give up. Read through the post. Even ask Claude to explain stuff you don't understand.\n\nAn agent in a harness can pro-actively do a lot of tool calls to read your codebase and other inputs, edit stuff, make writes etc. In this process, they can produce a lot of data which gets added to the running conversation i.e the context window. Anthropic refers to this art and science of curating what will go into the limited context window from this information as context engineering.\n\nYou may ask how are tool calls adding tokens to the context window? The flow works like this:\n\nThe key thing to note here is that both the tool call and the tool call outputs are added to the context so that the LLM can know the results. This is because LLMs are stateless. They don't have memory outside the context window. Let's say you have n messages in a conversation. When you send the next message, the request will again process n + 1 messages in the LLM ~ single context window.\n\nIf you don't add information about the chosen tool call was, LLM won't know and if you don't plug the output, then it won't know\nthe outcome. The tool call results can quickly fill your context and this is why agents can get super expensive too.\n\nI quote directly from effective-context-engineering-for-ai-agents\n\nContext refers to the set of tokens included when sampling from a large-language model (LLM). The engineering problem at hand is optimizing the utility of those tokens against the inherent constraints of LLMs in order to consistently achieve a desired outcome. Effectively wrangling LLMs often requires thinking in context â€” in other words: considering the holistic state available to the LLM at any given time and what potential behaviors that state might yield.\n\nContext engineering is about answering \"what configuration of context is most likely to generate our model's desired behavior?\"\n\nEverything we have discussed so far comes under context engineering. Sub-agents, using a scratch, compaction are obvious examples\nof context management methods used in Claude Code. Some notes around why context engineering is needed -\n\nLimited context window - The context retrieval performance of LLMs degrades as every new token is introduced. To paraphrase the above blog - think of context as a limited \"attention budget\". This is a consequence of the attention mechanism itself as it gets harder to model the pairwise relationships - think of it like getting harder to focus on things far apart.\n\nGPT-5.2 has a context window of 400K input tokens. Opus 4.5 has 200K. Gemini 3 Pro has a 1M context window length. Now the effectiveness of these context windows can vary too, just the length doesn't matter. That said if you want to ask something\nfrom a 900K long input, you would be able to most reliably do that only with Gemini 3 Pro.\n\nContext rot article goes deep into some experiments which showed performance\ndrops with length and not task difficulty.\n\nA rough corollary one can draw is effective context windows are probably 50-60% or even lesser.\nDon't start a complicated task when you are half-way in the conversation. Do compaction or start a new one.\n\nEverything being done in prompts and code we have seen so far has been to -\n\nThe next few sections showcase features and implementation that are designed for\nbetter context management and agentic performance.\n\nI am personally not a fan of MCP servers but we gotta cover it. MCP servers are servers that can be hosted on your machine or remotely on the internet. These may expose filesystem, tools and integrations like CRM, Google Drive etc. They are essentially a way for models to connect to external tools and services.\n\nIn order to connect to MCP server, you need a host (Claude) which can house the MCP client. The MCP client\ncan invoke the protocol to connect. Once connected, the MCP client exposes tools, resources, prompts provided by server.\n\nThe tool definitions are loaded upfront into the context window of host bloating the context window.\n\nI like the idea of Code Execution with MCP even though it's propanda for more token consumption.\n\nQuoting Code execution with MCP:\n\nAs MCP usage scales, there are two common patterns that can increase agent cost and latency:\n\nMCP usage scale implies more MCP clients ~ more tool call definitions in context window.\n\nMCP Code exec suggests instead of direct tool calls, expose code APIs rather than tool call definitions and give Claude\na sandbox execution environment with a filesystem. Then let it write code to make the tool calls.\nIt is an elegant idea and is pretty similar to skills in the sense it's \"prompt on demand\"\n\nQuoting from Manus's Context Engineering Lesson blog:\n\nManipulate Attention Through Recitation\n\nIf you've worked with Manus, you've probably noticed something curious: when handling complex tasks, it tends to create a todo.md fileâ€”and update it step-by-step as the task progresses, checking off completed items.\n\nThat's not just cute behaviorâ€”it's a deliberate mechanism to manipulate attention.\n\nA typical task in Manus requires around 50 tool calls on average. That's a long loopâ€”and since Manus relies on LLMs for decision-making, it's vulnerable to drifting off-topic or forgetting earlier goals, especially in long contexts or complicated tasks.\n\nClaude Code has todo lists but they don't show them now. Now you know part of the logic for it.\n\nClaude Code also tries something similar via plugging reminder tags into user messages and tool results. Some of them are mentioned in tool descriptions, other reminders are added at runtime via code.\n\nI asked Claude about what system reminders are present in the system prompt.\n\nFor reference, an older version of CC 2.0.56 used to have this detailed reminder system-reminder-plan-mode-is-active.\n\nI think Armin talks about this in his post What Actually Is Claude Codeâ€™s Plan Mode? when he refers to recurring prompts to remind the agent.\n\nIf you look at the leaked prompts, you will notice there are like 2-3 prompts for plan mode and 2-3 tool schemas like ENTRY_PLAN_MODE_TOOL, EXIT_PLAN_MODE_TOOL. The latter would write down the output into a markdown file\nwhich you can access via /plan. Everything is a markdown.\n\nAnthropic introduced Agent Skills recently and these got recently adopted by Codex too. A skill\nis a folder containing a SKILL.md file, other referenceable files and code scripts that do some user-defined task.\n\nThe SKILL.md contains some meta-data via which LLM can know what skills are available (meta-data is added to system prompt)\nIf Claude feels the skill is relevant, it will perform a tool call to read the contents of skill and download the\ndomain expertise just like Neo in Matrix 1999. The code scripts may contain tools that Claude can use.\n\nNormally, to teach domain expertise, you would need to write all that info in system prompt and probably\neven tool call definitions. With skills, you don't have to do that as the model loads it on-demand.\nThis is especially useful when you are not sure if you require those instructions always.\n\nThe popular frontend-design plugin is actually a skill. You can check here\n\nHooks are available in Claude Code and Cursor. They allow you to observe when a certain stage in the agent loop\nlifecycle starts or ends and let you run bash scripts before or after to make changes to the agent loop.\n\nThere are hooks like Stop, UserPromptSubmit etc. For instance Stop hook runs after Claude finishes responding and the UserPromptSubmit hook runs when user submits a prompt before Claude processes it.\n\nThe first hook I created was to play an anime notification sound when Claude stopped responding. I was obviously inspired\n\nOne funny use case to run Claude for hours might be running a \"Do more\" prompt when Claude finishes current task\nvia the Stop hook.\n\nI came across this post during my research for this blog post. This person beautifully combined the concepts and features we discussed so far. They combine hooks to act as reminders for skills. If the utility/requirement arises, there's a lot of space for customization. You might not need such heavy customization but can at least take inspiration. (Speaking for myself lol)\n\nAnthropic recommends to keep skill.md under 500 lines so they divided it into separate files and combined with hooks and\nreduced the size of their CLAUDE.md.\n\nHopefully you learnt a bunch of things from this super long post and will apply the learnings not only in CC\nbut other tools as well. I feel a bit weird writing this but we are going through some transformative times.\nThere are already moments when I almost feel like a background agent and then other times when I feel smart when the models couldn't solve a particular bug.\n\nclaude and codex to me when i realise i am the background agent pic.twitter.com/wkihYFQmQM\n\nI no longer look forward to new releases because they just keep happening anyways (shoutout to OpenAI). Deepseek and Kimi K3 are in the queue.\n\nI am expecting improvements in RL training, long context effectiveness via maybe new attention architectures, higher throughput models, lesser hallucination models.\nThere might be a o1/o3 level reasoning breakthrough or maybe something in continual learning in 2026. I look forward to these but at the same time\nI find it scary because more significant capability unlock will make the world unpredictable haha.\n\nIf you found this useful, try one new feature from this post today. Happy building!\n\nThanks for reading. Please like/share/RT the post if you liked it.",
    "readingTime": 30,
    "keywords": [
      "claude code",
      "karpathy sensei",
      "stop hook",
      "mcp client",
      "anthropic doesn't",
      "mcp servers",
      "feedback loops",
      "spam ultrathink",
      "monitoring log",
      "domain expertise"
    ],
    "qualityScore": 1,
    "link": "https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/",
    "thumbnail_url": "https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/dario-2.webp",
    "created_at": "2025-12-28T01:03:19.149Z",
    "topic": "tech"
  },
  {
    "slug": "codenhack-a-free-gamified-inbrowser-coding-platform",
    "title": "Codenhack â€“ A free, gamified, in-browser coding platform",
    "description": "A coding practice website for all programming levels â€“ Join a community and learn from experienced developers.",
    "fullText": "Dive into the world of programming with our learning platform. Break through the matrix and emerge as a coding legend.\n\nBecause you learn faster when you build. With interactive courses, guided projects, and a vibrant community, Codenhack helps you go from beginner to builder, all inside your browser\n\nDive into structured learning paths with chapters and lessons designed to take you from beginner to expert.\n\nApply your knowledge by building production-ready projects. From web applications to Quantum Robot systems, we cover it all.\n\nShare your knowledge, insights, and experiences with our global community of developers. Create engaging blog posts, tutorials, and guides.\n\nShare your knowledge, insights, and experiences with our global community of developers. Create engaging blog posts, tutorials, and guides while learning from others in the field.\n\nMaster coding through interactive lessons. Read, practice, see instant results, and test your understandingâ€”all in one seamless learning experience.\n\nStart your learning journey with a concise introduction that sets the context and prepares you for hands-on practice.\n\nWatch your code come to life in real-time with our live preview feature. See instant visual feedback as you write and modify your code, making learning interactive and engaging.\n\nPractice coding directly in our interactive terminal. Get real-time feedback as you build your skills through hands-on experience with command-line tools.\n\nReinforce your learning through reflection and self-assessment. Test your understanding and confidently progress to the next challenge.\n\nMaster the most powerful programming languages and take your skills to the next level. Whether you're a beginner or an expert, there's always something new to learn. Start your journey today!\n\nExplore our cutting-edge curriculum designed to transform beginners into elite coders ready for the digital future.\n\nThe foundation of the digital grid â€“ structure beneath the neon skyline.\n\nDesign the web like a chrome-plated city. Style with flair.\n\nMake the neon signs blink, the systems dance â€“ control the DOM in real-time.\n\nHear from the cyberpunks who've leveled up their coding skills and transformed their careers.\n\n\"I was impressed by how Codenhack blends programming with a cyberpunk vibe â€” it makes learning way more exciting\"\n\n\"Codenhack makes it feel like you're not just learning â€” you're discovering tools to break through the system. Even as a beginner, I'm already building small hacks and projects that actually do stuff. That feeling? Wild.\"\n\n\"Codenhack helped me turn boring code into something that actually looks good. Playing with HTML and CSS here feels like crafting my own digital art â€” and I'm just getting started\"\n\n\"I love that Codenhack lets me preview my work instantly â€” it's super satisfying to see my code come alive right away.\"",
    "readingTime": 3,
    "keywords": [
      "developers create",
      "create engaging",
      "blog posts",
      "posts tutorials",
      "knowledge insights",
      "learning",
      "coding",
      "interactive",
      "beginner",
      "programming"
    ],
    "qualityScore": 1,
    "link": "https://codenhack.com/",
    "thumbnail_url": "https://pub-49e1acf3b61b485e8f14983f79b20721.r2.dev/app_images/helpcenter.png",
    "created_at": "2025-12-26T12:22:24.821Z",
    "topic": "tech"
  },
  {
    "slug": "apples-app-course-runs-20k-a-student-is-it-worth-it",
    "title": "Apple's App Course Runs $20k a Student. Is It Worth It?",
    "description": "Apple, Michigan taxpayers, and one of Detroitâ€™s wealthiest families spent roughly $30 million training hundreds of people to build iPhone apps. Not everyone lands coding jobs right away.",
    "fullText": "Lizmary Fernandez took a detour from studying to be an immigration attorney to join a free Apple course for making iPhone apps. The Apple Developer Academy in Detroit launched as part of the companyâ€™s $200 million response to the Black Lives Matter protests and aims to expand opportunities for people of color in the countryâ€™s poorest big city.\n\nBut Fernandez found the programâ€™s cost-of-living stipend lackingâ€”â€œA lot of us got on food stamps,â€ she saysâ€”and the coursework insufficient for landing a coding job. â€œI didnâ€™t have the experience or portfolio,â€ says the 25-year-old, who is now a flight attendant and preparing to apply to law school. â€œCoding is not something I got back to.â€\n\nSince 2021, the academy has welcomed over 1,700 students, a racially diverse mix with varying levels of tech literacy and financial flexibility. About 600 students, including Fernandez, have completed its 10-month course of half-days at Michigan State University, which cosponsors the Apple-branded and Apple-focused program.\n\nWIRED reviewed contracts and budgets and spoke with officials and graduates for the first in-depth examination of the nearly $30 million invested in the academy over the past four yearsâ€”almost 30 percent of which came from Michigan taxpayers and the universityâ€™s regular students. As tech giants begin pouring billions of dollars into AI-related job training courses across the country, the Apple academy offers lessons on the challenges of uplifting diverse communities.\n\nSeven graduates who spoke with WIRED said they had good experiences at the academy, citing benefits such as receiving mentorship from past students. Fernandez says she was impressed by a focus on developing inclusive apps and a series of speakers from Apple who were genuinely willing to help and share frank lessons. â€œTheir heart was in the right place,â€ she says.\n\nThe program does expose people of color to new possibilities. â€œIt changed my life,â€ says Min Thu Khine, whoâ€™s now mentoring coding students and working at an Apple Store Genius Bar. â€œMy dream is to be a software engineer at Apple.â€\n\nThe academy also draws positive grades from some researchers who study tech education, such as Quinn Burke. He says its fully subsidized in-person instruction surpasses the quality of many coding boot camps, which proliferated over the past decade and sometimes left students in debt and with narrow skills.\n\nBut the academy being open to all can complicate instruction and how to measure success. One entire family attended together, and at least two mothers have come with their daughters. Students on average are in their thirties, ranging from 18-year-olds to, for example, a grandfather in his seventies who wanted to develop a photo app for his grandchild, according to Sarah Gretter, the academy leader for Michigan State.",
    "readingTime": 3,
    "keywords": [
      "students",
      "coding",
      "tech",
      "academy",
      "course",
      "apps",
      "color",
      "diverse",
      "program",
      "wired"
    ],
    "qualityScore": 1,
    "link": "https://www.wired.com/story/apple-app-making-course-michigan-state-university/",
    "thumbnail_url": "https://media.wired.com/photos/69406bdd9f9b98727b285b83/191:100/w_1280,c_limit/Apples-App-Making%20Course-Costing-20k-A-Student-Business-2225891099.jpg",
    "created_at": "2025-12-26T06:19:00.674Z",
    "topic": "tech"
  },
  {
    "slug": "keystone-yc-s25-is-hiring-engineer-1-to-automate-coding",
    "title": "Keystone (YC S25) is hiring engineer #1 to automate coding",
    "description": "About Keystone\nWe're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.\nWe're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.\nWe're in-person in SoMa, San Francisco.",
    "fullText": "We're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.\n\nWe're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.\n\nWe're in-person in SoMa, San Francisco. We raised a $5.2M seed from True Ventures, Twenty Two Ventures, Pear VC, and Ritual Capital- plus the founders of YC, Dropbox, Supabase, Eight Sleep, Graphite, Resend, RocketMoney, and more. Early design partners include teams at Perplexity and Lovable.\n\nYou'd be the first engineering hire, working directly with me (the founder) to build the core product. You'll have more ownership and influence over the product, culture, and technical direction than you'd get almost anywhere else.\n\nYou might be a great fit if you:\n\nStack: TypeScript, React (Next.js), Python, Postgres, Redis, AWS\n\nComp & benefits: Top-of-market salary + significant equity, full health/dental/vision, all meals covered, equipment budget",
    "readingTime": 2,
    "keywords": [
      "we're",
      "product",
      "logs",
      "ventures",
      "you'd"
    ],
    "qualityScore": 0.85,
    "link": "https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/06e7837c1e5c8ce88da333ac2efcf401d8cbee53.png?1747973680",
    "created_at": "2025-12-25T00:56:12.872Z",
    "topic": "jobs"
  },
  {
    "slug": "the-guy-who-coined-vibe-coding-predicts-it-will-terraform-software-and-alter-job-descriptions",
    "title": "The guy who coined 'vibe coding' predicts it will 'terraform software and alter job descriptions'",
    "description": "Andrej Karpathy led AI at Tesla and cofounded OpenAI. He wrote that vibe coding has produced a new type of code that is \"free\" and \"discardable.\"",
    "fullText": "He coined \"vibe coding\" earlier this year. Now, he has something to say about it.\n\nAndrej Karpathy led AI at Tesla for five years, steering the company's Autopilot effort and briefly working on its humanoid robot Optimus. He sandwiched his Tesla job with two stints at OpenAI, making Karpathy a cofounder of the AI pioneer.\n\nAs 2025 comes to a close, Karpathy published his year-in-review for large language models on X. He reflected on the famous term he originated in February, a term that has since shaken up the software engineering industry.\n\n\"With vibe coding, programming is not strictly reserved for highly trained professionals,\" Karpathy wrote. He called it an example of how \"regular people benefit a lot more from LLMs compared to professionals, corporations and governments.\"\n\nVibe coding has likely benefited businesses, too. Tech companies have equipped their engineers with tools like Cursor, Claude Code, and OpenAI's Codex, aiming for productivity gains.\n\nKarpathy wrote that vibe coding \"empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written.\"\n\nIt may also change the makeup â€” or the use case â€”Â of the code itself. Karpathy threw out a slew of adjectives to describe this new body of code: It is \"free, ephemeral, malleable, discardable after single use.\"\n\n\"Vibe coding will terraform software and alter job descriptions,\" he wrote.\n\nHow does Karpathy feel about being the term's origin?\n\n\"Amusingly, I coined the term \"vibe coding\" in this shower of thoughts tweet totally oblivious to how far it would go,\" he wrote.\n\nThere's a new kind of coding I call \"vibe coding\", where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It's possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisperâ€¦\n\nIt's not yet clear how efficient vibe coding is making engineers. In a METR study published in July, AI coding assistants were found to decrease the productivity of participating experienced software developers by 19%. The developers in that study were also overconfident in the tools, its authors said, expecting a 20% productivity boost even after using them.\n\nWhat is clear, though, is that the practice is unlocking a whole new form of tech products. Twitter founder Jack Dorsey vibe-coded a new messaging app this year. Non-technical workers are easily building, shipping, and, in some cases, even selling apps they build in hours, if not minutes.\n\nKarpathy gave some other reflections. He praised Google Gemini's Nano Banana image model, and wrote that Claude Code was the \"first convincing demonstration of what an LLM Agent looks like.\"\n\nOverall, Karpathy wrote that 2025 was an \"exciting and mildly surprising year of LLMs.\"",
    "readingTime": 3,
    "keywords": [
      "trained professionals",
      "vibe coding",
      "software",
      "llms",
      "productivity",
      "karpathy",
      "coined",
      "tesla",
      "published",
      "tech"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andrej-karpathy-coined-vibecoding-ai-prediction-2025-12",
    "thumbnail_url": "https://i.insider.com/68f53bf05dbc4fd10dab1f5f?width=1200&format=jpeg",
    "created_at": "2025-12-23T18:17:54.745Z",
    "topic": "finance"
  },
  {
    "slug": "the-death-and-rebirth-of-programming",
    "title": "The Death and Rebirth of Programming",
    "description": "Programming didn't die all at once. There was no single moment, no dramatic obsolescence event. Instead, something quieter happened: the core constraint that shaped software for seventy years dissolved. Writing code stopped being the hard part.",
    "fullText": "For most of computing history, programming was bottlenecked by human cognition. Translating intent into working software required time, attention, and specialized skill. Even small changes were costly. This scarcity justified entire ecosystems: languages, frameworks, methodologies, reviews, team rituals that made sense when every line was expensive.\n\nGenerative AI removes that scarcity.\n\nToday, a single developer can generate thousands of lines of working code in minutes. Tomorrow, that number will be effectively infinite. The marginal cost of producing code is collapsing toward zero.\n\nWhat hasn't collapsed is the cost of knowing what the code does.\n\nUnderstanding, verifying, securing, and evolving software remain stubbornly expensive. In fact, they may be getting harder as volume explodes. This asymmetryâ€”the ease of creation versus the difficulty of comprehensionâ€”is the defining tension of modern software.\n\nProgramming hasn't disappeared. But its center of gravity has shifted.\n\nIn the old world, programmers owned code. You wrote it, you understood it, you maintained it. Your value was tied to mastery of specific implementations. Codebases accrued history, reputation, and power.\n\nIn the new world, ownership becomes a liability.\n\nWhen code can be regenerated faster than it can be understood, preserving it for sentimental or historical reasons no longer makes sense. What matters instead is stewardship: maintaining the system's behavior, boundaries, and intent over time, regardless of how many times its internals are replaced.\n\nThis reframing is subtle but profound:\n\nThe asset is no longer the codebase. The asset is the system's ability to keep working.\n\nThis is the thesis of everything that follows. Architecture, testing, interfaces, team structure: all of it flows from this inversion.\n\nMany of the \"modern\" software practices of the last decade were early adaptations to this shift, even if we didn't articulate them that way.\n\nImmutable infrastructure. Stateless services. Containers. Blue-green deployments. Infrastructure as code.\n\nThese ideas all share a common premise: never fix a running thing. Replace it.\n\nAI pushes this premise beyond infrastructure and into application code itself. When rewriting is cheap, editing in place becomes risky. Mutation accumulates entropy. Replacement resets it.\n\nDisposability stops being a hack. It becomes the default.\n\nThis transition isn't just technical. It's deeply psychological, and that psychology shapes architecture.\n\nMany developers identify as builders and craftspeople. We take pride in elegance, cleverness, and mastery of internals. We accumulate knowledge inside our heads and inside codebases. Longevity feels like validation.\n\nGenerative AI destabilizes this identity.\n\nWhen a machine can produce a competent version of \"your\" solution in seconds, craftsmanship no longer lies in the artifact. It lies in framing the problem, defining success, and deciding what to keep and what to discard.\n\nThe role shifts from maker to architect. From author to managing editor. From preserving code to designing for its replacement.\n\nThat shift is uncomfortable. And the discomfort isn't merely personal. It's what makes teams resist the very patterns that would help them. Developers cling to codebases because identity is at stake, not just technical judgment. Acknowledging this is the first step toward building systems that don't require heroics to change.\n\nResisting the shift doesn't stop it. It just makes systems more fragile.\n\nOne of the clearest signals of this new era is the rise of the n=1 developer.\n\nProjects that once required teams now fit inside a single person's cognitive boundaryâ€”with AI filling in the execution gaps. Entire products can be specified, generated, evaluated, and shipped by one human working with machines.\n\nThis isn't about productivity hacks. It's about a structural change in leverage.\n\nBut n=1 development only works if systems are designed for it. Large, tangled, historically accreted codebases collapse under their own weight when AI accelerates change. Small, modular, disposable systems thrive.\n\nThe n=1 developer is not a superhero. They are an indicator species. They are evidence that the environment has changed, and proof that the new patterns actually work.\n\nIt's tempting to frame this as the \"end of programming.\" That's misleading.\n\nWhat's dying is a specific form of programming: one that equates value with authored code, longevity of code with quality, and maintenance with virtue.\n\nWhat's being born is something closer to systems design as an ongoing process of regeneration:\n\nCode becomes an intermediate artifact, not the final product. Rewrites become routine, not traumatic. Tests and evaluations define truth, not files. Stability emerges from replacement, not preservation.\n\nThis is not nihilism. It's pragmatism under new constraints.\n\nThe rest of this publication builds on a single premise established here:\n\nWhen code is cheap and understanding is expensive, architecture must optimize for the impermanence of code.\n\nEverything else (pace layers, evaluations, clean interfaces, regeneration workflows) flows from that fact.\n\nWe are not entering a world with less software. We are entering a world with vastly more of it. The only way to survive that abundance is to stop treating code as precious.\n\nBut it has been reborn, and it expects us to change with it.",
    "readingTime": 5,
    "keywords": [
      "modern software",
      "generative ai",
      "code",
      "it's",
      "systems",
      "programming",
      "codebases",
      "expensive",
      "developer",
      "longer"
    ],
    "qualityScore": 1,
    "link": "https://aicoding.leaflet.pub/3malrv6poy22a",
    "thumbnail_url": "https://leaflet.pub/lish/did%253Aplc%253A4qsyxmnsblo4luuycm3572bq/3majnsnvafs2b/3malrv6poy22a/opengraph-image?6815eb61f733905a",
    "created_at": "2025-12-23T00:56:32.109Z",
    "topic": "tech"
  },
  {
    "slug": "browserforge-ai-browser-agents-1000-free-credits",
    "title": "BrowserForge â€“ AI browser agents (1000 free credits)",
    "description": "AI browser agents that automate web tasks 24/7. Extract data, fill forms, monitor prices, and handle any repetitive browser work. No coding required - just show your agent what to do.",
    "fullText": "Agents navigate websites like humansâ€”clicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.\n\nAgents navigate websites like humansâ€”clicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.\n\nAgents navigate websites like humansâ€”clicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.",
    "readingTime": 2,
    "keywords": [
      "sessions intelligent",
      "define connect",
      "connect browser",
      "via api",
      "api webhooks",
      "intelligent agents",
      "humansâ€”clicking buttons",
      "buttons filling",
      "maintaining authenticated",
      "understand web"
    ],
    "qualityScore": 0.85,
    "link": "https://www.browserforge.ai/",
    "thumbnail_url": "https://browserforge.ai/media/browserforge-hero-1.png",
    "created_at": "2025-12-22T18:17:58.401Z",
    "topic": "tech"
  },
  {
    "slug": "a-selfassessment-quiz-to-measure-software-development-seniority-level",
    "title": "A self-assessment quiz to measure software development seniority level",
    "description": "Take a free quiz based on real-world achievements and see your software developer level against cross-industry benchmarks.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://mylevel.dev/",
    "thumbnail_url": "https://storage.tally.so/53a7ed1d-311d-4027-be0d-d842b419a4a7/Level-measurement.jpeg",
    "created_at": "2025-12-21T01:00:00.485Z",
    "topic": "tech"
  },
  {
    "slug": "ai-tools-make-coders-more-important-not-less",
    "title": "AI Tools Make Coders More Important, Not Less",
    "description": "Many leaders are excited about the promise of AI coding tools that can make it easier for novices to write code and, seemingly, make experienced coders less essential. Yet these tools make experience moreâ€”not lessâ€”important, as AI is not a replacement for real engineers. Companies that want to use these tools should follow common rules. Make sure every change it makes is double-checkedâ€”with automatic checks, simple tests that confirm things still work, and at least one human review. Keep access limited: Let AI work only in a safe â€œpracticeâ€ environment, never give it the keys to live customer data, and routinely check for basic security mistakes like files or storage left open to the public.",
    "fullText": "AI Tools Make Coders More Important, Not Less by Michael LiDecember 19, 2025PostPostShareSavePrintSummary.Â Â Â Leer en espaÃ±olLer em portuguÃªsPostPostShareSavePrintOf all the possible applications of generative AI, the value proposition of using it to write code was perhaps the clearest. Coding can be slow and it requires expertise, both of which can be expensive. Moreover, the promise that anyone who could describe their idea in plain text could create apps, features, or other value-adding products meant that innovation would no longer be limited to those with the skills to execute, but could be done by anyone with an idea. The strength of this promise has created a $7.37 billion market for these tools.",
    "readingTime": 1,
    "keywords": [
      "tools",
      "promise",
      "anyone",
      "idea"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/ai-tools-make-coders-more-important-not-less",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_22t-kaiser-7uH3ndea63o-unsplash.jpg",
    "created_at": "2025-12-19T18:17:22.482Z",
    "topic": "business"
  },
  {
    "slug": "introduction-to-programming-the-commodore-pet",
    "title": "Introduction to Programming the Commodore PET",
    "description": "History of the Commodore PET and how to approach programming the classic system",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://retrogamecoders.com/introduction-to-programming-the-commodore-pet/",
    "thumbnail_url": "https://retrogamecoders.com/wp-content/uploads/2025/12/Programming-the-Commodore-PET.jpg",
    "created_at": "2025-12-19T12:22:25.882Z",
    "topic": "tech"
  },
  {
    "slug": "metas-28yearold-billionaire-prodigy-says-the-next-bill-gates-will-be-a-13yearold-who-is-vibe-coding-right-now",
    "title": "Metaâ€™s 28-year-old billionaire prodigy says the next Bill Gates will be a 13-year-old who is â€˜vibe codingâ€™ right now",
    "description": "Teenagers, Alexandr Wang argues, have a built-in edge.",
    "fullText": "Eva is a fellow on Fortune's news desk.\n\nAlexandr Wangâ€”who became the worldâ€™s youngest self-made billionaire at 24â€”is now, at 28, running one of the most ambitious AI efforts in Silicon Valley. In his first 60 days at Meta, he built a 100-person lab he described to TBPN hosts John Coogan and Jordi Hays as â€œsmaller and more talent dense than any of the other labs.â€\n\nHis goal: nothing less than superintelligence.\n\nWang, with his aerial view of the industry, has advice for kids, especially those in Gen Alpha now entering middle school: Forget gaming, sports, or traditional after-school hobbies.\n\nâ€œIf you are like 13 years old, you should spend all of your time vibe coding,â€ he said in his recent TBPN interview. â€œThatâ€™s how you should live your life.â€\n\nFor Wang, the reasoning is simple. Every engineer, himself included, is now writing code he believes will be obsolete within five years.\n\nâ€œLiterally all the code Iâ€™ve written in my life will be replaced by what will be produced by an AI model,â€ he said.\n\nThat realization has left him, in his words, â€œradicalized by AI coding.â€ What matters most now isnâ€™t syntax, or learning a particular language, but time spent experimenting with and steering AI tools.\n\nâ€œItâ€™s actually an incredible moment of discontinuity,â€ Wang said. â€œIf you just happen to spend 10,000 hours playing with the tools and figuring out how to use them better than other people, thatâ€™s a huge advantage.â€\n\nTeenagers have a clear advantage over adults: time and freedom to immerse themselves in new technology. And while in the past, entrepreneurial teenagers leveraged this time to be â€œsneaker flippersâ€ or run Minecraft servers, Wang says the focus should now be on the code.\n\nHe compares the moment to the dawn of the PC revolution. The Bill Gateses and Mark Zuckerbergs of the world had an â€œimmense advantageâ€ simply because they grew up tinkering with the earliest machines.\n\nâ€œThat moment is happening right now,â€ Wang said. â€œAnd the people who spend the most time with it will have the edge in the future economy.â€\n\nWang isnâ€™t coy about Metaâ€™s ambitions. He calls the companyâ€™s infrastructure, scale, and product distribution unmatched.\n\nâ€œWe have the business model to support building literally hundreds of billions of dollars of compute,â€ he said.\n\nHis team, just over 100 people, is deliberately designed to be â€œsmaller and more talent denseâ€ than rivals. â€œThe other labs are like 10 times bigger,â€ Wang said, but their lab had â€œcrackedâ€ coders.\n\nThe lab is split into three pillars: research, product, and infrastructure. Research builds the models Wang says will â€œultimately be superintelligent.â€ Product ensures they get distributed across billions of users through Metaâ€™s platforms. And infrastructure focuses on what he calls â€œliterally the largest data centers in the world.â€\n\nWang is particularly excited about hardware. Like many Meta executives now, he points to the companyâ€™s new smart glasses, which had a hilariously foppish demo, as the â€œnatural delivery mechanism for superintelligence.â€\n\nPlaced right next to the human senses, they will merge digital perception with cognition.\n\nâ€œIt will literally feel like cognitive enhancement,â€ Wang said. â€œYou will gain 100 IQ points by having your superintelligence right next to you.â€\n\nVibe coding is the shorthand for this shift: using natural language prompts to generate and iterate on code. Rather than writing complex syntax, users describe their intent, and AI produces functioning prototypes.\n\nThe concept is spreading across Silicon Valleyâ€™s C-suites. Klarna CEO Sebastian Siemiatkowski has said he can now test ideas in 20 minutes, instead of burning weeks of engineering cycles. Google CEO Sundar Pichai revealed that AI already generates more than 30% of new code at the company, calling it the biggest leap in software creation in 25 years.\n\nWang takes that further. For him, vibe coding isnâ€™t just a productivity hack, but a future cultural mandate. What matters isnâ€™t the code itself â€” itâ€™s the hours of intuition-building that come from pushing AI tools to their limits, which is why he urges Gen Alpha to start early.\n\nâ€œThe role of an engineer is just very different now than it was before,â€ he said.\n\nA version of this story was published onÂ Fortune.com on September 19, 2025.",
    "readingTime": 4,
    "keywords": [
      "talent dense",
      "vibe coding",
      "gen alpha",
      "code",
      "literally",
      "isnâ€™t",
      "wang",
      "superintelligence",
      "tools",
      "moment"
    ],
    "qualityScore": 1,
    "link": "https://fortune.com/article/what-is-vibe-coding-alexandr-wang-bill-gates-meta/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/09/GettyImages-1540568935-e1758305593707.jpg?resize=1200,600",
    "created_at": "2025-12-19T12:22:22.800Z",
    "topic": "business"
  },
  {
    "slug": "orbit-a-systems-level-programming-language-that-compiles-sh-to-llvm",
    "title": "Orbit a systems level programming language that compiles .sh to LLVM",
    "description": "A modern shell with functional programming synatx. - SIE-Libraries/orbit",
    "fullText": "SIE-Libraries\n\n /\n\n orbit\n\n Public\n\n A modern shell with functional programming synatx.\n\n License\n\n View license\n\n 5\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n SIE-Libraries/orbit",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/SIE-Libraries/orbit",
    "thumbnail_url": "https://opengraph.githubassets.com/dcaf4ed1c20da5475350ce0f3bf442eb03297772f6ad4097b4b2009e9ba5d922/SIE-Libraries/orbit",
    "created_at": "2025-12-19T09:39:44.047Z",
    "topic": "tech"
  },
  {
    "slug": "codingforpreschoolers-firm-files-bankruptcy-after-covid-boom",
    "title": "Coding-for-Preschoolers Firm Files Bankruptcy After Covid Boom",
    "description": "An education company that helps children as young as three learn to code filed for bankruptcy, blaming an expansion strategy that outpaced its ability to turn a profit.",
    "fullText": "WealthBy Steven ChurchSaveAn education company that helps children as young as three learn to code filed for bankruptcy, blaming an expansion strategy that outpaced its ability to turn a profit.Conscious Content Media Inc. would eliminate more than half of its $205.5 million in funded debt under a reorganization proposal backed by noteholders, according to court papers filed Wednesday in federal court in Wilmington, Delaware.",
    "readingTime": 1,
    "keywords": [
      "filed",
      "court"
    ],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/articles/2025-12-18/coding-for-preschoolers-firm-files-bankruptcy-after-covid-boom",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iCA4eahCxR3k/v1/1200x800.jpg",
    "created_at": "2025-12-18T18:18:26.956Z",
    "topic": "finance"
  },
  {
    "slug": "i-built-an-app-for-vibecoding-games",
    "title": "I built an app for vibe-coding games",
    "description": "Got a game idea? Just describe it and start playing in seconds.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://playmix.ai/",
    "thumbnail_url": "https://playmix.ai/assets/og-image.png",
    "created_at": "2025-12-18T12:23:04.291Z",
    "topic": "tech"
  },
  {
    "slug": "learning-the-oldest-programming-language-2024",
    "title": "Learning the oldest programming language (2024)",
    "description": "Who needs Rust when we have Fortran?",
    "fullText": "While I probably should be learning a language like C, Go, or whatever new trendy language the ThePrimeagen mentions on Twitter (OCaml?), I'm going to attempt to learn Fortran[1].\n\nFortran, which stands for FORmula TRANslator[2], was created at IBM by John Backus in 1957 for scientific applications and has apparently been popular for high-performance computing and benchmarking supercomputers in recent years. Fortran has had several subsequent releases since then; FORTRAN 77, Fortran 90, Fortran 95, Fortran 2003, Fortran 2008, and the latest Fortran 2018.\n\nTo understand what version of Fortran to learn/use, we first must understand the difference between fixed form and free form Fortran. The fixed form layout comes from the very beginning of Fortran, inherited from punch cards, and has odd restrictions about the column in which comments and statements are placed. The free form layout, first introduced in Fortran 90, removed special columns and added the ability to write comments wherever, and is what we'll be learning in this article. The compiler we'll be using is GNU Fortran, or gfortran. You can install it via Homebrew (macOS) with the gcc formula, or install it using a package manager for your OS. To tell gfortran that your code uses the free form layout, set the file extension to .f90 or newer. The following comment on the Fortran discussion board explains this well.\n\nThe .f90 suffix means that the source code is free format, not that\nthe code conforms to the Fortran 90 standard. Code that uses the .f90\nsuffix can use features from any Fortran standard. All Fortran\ncompilers recognize .f90 as a suffix indicating free source form, but\nsome may not recognize a suffix such as .f95, .f03, .f08, or .f18.\nSome users may have build tools that do not recognize suffixes other\nthan .f90. Most Fortran source code on GitHub that uses features from\na standard more recent than Fortran 90 still uses the .f90 suffix.\n\nComing from TypeScript, and before that, Python, I'm very used to (and comfortable with) modern â€” you might say \"aesthetic\" â€” syntax . Although I wouldn't say Fortran syntax is quite modern, it seems to avoid the syntactic sugar nightmares that plague beginners in other languages[3]. Take a look at this helloworld.f90 example below.\n\nOlder Fortran programs required the use of SCREAMING_CASE for all keywords, but in modern Fortran you can and it is recommended to use snake_case (you can still use SCREAMING_CASE or any other case you want though).\n\nJust from this small example we can gather that...\n\nThe syntax for printing is a little funky though. What is that asterisk doing there? The asterisk, aside from being used as a mathematical operator, indicates the \"default\". So for print, * means \"print to the default output channel\" (or \"print to the default output file unit\" to be precise), which is typically going to be STDOUT.\n\nI can't find exactly where this is documented but you don't actually need the start and end program <program-name>; you could write a hello world program like this, though as I just mentioned this doesn't seem to be a common practice and isn't really very useful in any practical scenario.\n\nHere's another, slightly more complicated example.\n\nStarting right at the top, we have something new: implicit none. Added in Fortran 90, implicit none disables implicit typing defaults and all variables must be explicitly declared. In Fortran, implicit typing is the practice of assigning default types to variables based on the character a variable name begins with. Variables starting with I through NÂ areÂ INTEGERs, everything else isÂ REAL. It is \"a legacy of the past\" and usage of an implicit noneÂ statement is \"strongly advised\" (implicit none - Fortran Wiki).\n\nA common Fortran joke goes along the lines of â€œGOD is REAL, unless declared INTEGER\"[4] because of implicit typing!\n\nMoving on, we declare our first variables in this program.\n\nHere we are declaring x, y, and answer with the REAL type, and choice with the CHARACTER type. The REAL type stores floating point numbers[5], and CHARACTER... stores characters.\n\nNext, we prompt the user for our x and y values.\n\nNotice how we can take input from the user with read and assign it to a value with the read *, <variable> syntax. The asterisk here means read from the default input channel/file unit, which would be STDIN.\n\nWe do the same for prompting the user to select an operation.\n\nFinally, we use a series of basic if-statements to calculate our answer and display it in the terminal.\n\nIf we run this, we- wait. Did I even tell you how to compile a Fortran program yet?\n\nFirst, compile our calculator program with gfortran -o calculator calculator.f90 . Then you can run it with ./calculator. If you only instruct gfortran of the input file (gfortran calculator.f90), the default output executable will be named a.out.\n\nOur calculator isn't perfect yet though. What if the user tries to divide by zero?\n\nProbably not the answer you expected. Let's try to fix that.\n\nHere we use the inequality operator, /=, to check if the y value is zero. Now, if the user tries to divide by zero, we'll print an error message and use the stop statement to end the program.\n\nGreat. We got rid of the zero division mess, but our code isn't pretty at all. Who wants a bunch of if statements? We can simplify this using the select case statement (also known as the case statement).\n\nThis also has the handy benefit of telling the user if they made an invalid choice while selecting the operation.\n\nThatâ€™s just a quick introduction to a few modern Fortran features: declaring variables, printing and reading to and from the terminal, if and select case, and stop. Next time, weâ€™ll talk more about where Fortran is actually used, cooler things you can build with it, and how the Fortran language & community are rapidly modernizing!\n\nIronically, in the ~3-ish months since I started writing this article, ThePrimagen has recently said he \"take[s] back everything i said about FORTRAN\" â€” apparently having some interest in the language! â†©ï¸Ž\n\nAccording to sources listed on Fortran's Wikipedia, the name might also have stood for Formula Translating System or just Formula Translation. â†©ï¸Ž\n\nSee The Rust programming language absolutely positively sucks : r/rust and Rust is a nightmare to learn coming from Java - community - The Rust Programming Language Forum. â†©ï¸Ž\n\nThe first letter of \"GOD\", a \"G\", is not within I through N and is therefore of the REAL type (\"GOD is REAL\"). â†©ï¸Ž\n\nYou can also use double precision for larger (more precise) floating point numbers. â†©ï¸Ž",
    "readingTime": 6,
    "keywords": [
      "rust programming",
      "default output",
      "programming language",
      "implicit none",
      "implicit typing",
      "fortran standard",
      "modern fortran",
      "code",
      "user",
      "free"
    ],
    "qualityScore": 1,
    "link": "https://uncenter.dev/posts/learning-fortran/",
    "thumbnail_url": "https://uncenter.dev/1024w.png?v=2316a73de1f9",
    "created_at": "2025-12-17T13:45:44.913Z",
    "topic": "tech"
  },
  {
    "slug": "scrappy-free-ai-code-assistant",
    "title": "Scrappy Free AI Code Assistant",
    "description": "A powerful, context-aware coding assistant for everyone. Students, learners, anyone who doesn't want to pay for subscriptions. - HakAl/scrappy",
    "fullText": "HakAl\n\n /\n\n scrappy\n\n Public\n\n A powerful, context-aware coding assistant for everyone. Students, learners, anyone who doesn't want to pay for subscriptions.\n\n pypi.org/project/scrappy-ai/\n\n License\n\n MIT license\n\n 6\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n HakAl/scrappy",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/HakAl/scrappy",
    "thumbnail_url": "https://opengraph.githubassets.com/f4b80c7981acbe65eb74d5f829f65f4c5ad79abda560cef1db5838b375628d52/HakAl/scrappy",
    "created_at": "2025-12-17T03:45:04.030Z",
    "topic": "tech"
  },
  {
    "slug": "adventures-in-the-land-of-language-servers",
    "title": "Adventures in the Land of Language Servers",
    "description": "Have you ever wondered how your editors and IDEs are able to support so many programming languages? Perhaps you've been thinking about designing your owâ€¦",
    "fullText": "Have you ever wondered how your editors and IDEs are able to support so many programming languages? Perhaps you've been thinking about designing your own language and wanted to know how you can give it editor support?\n\nThis talk is for you - I've spent over a year building a small language and integrating it with code editors, and I'd like to share some of the challenges I've faced, as well as lessons I've learned in that time.\n\nI'll also show how easy it is to build a new Language Server project in Scala 3 thanks to the Langoustine library.",
    "readingTime": 1,
    "keywords": [
      "i've",
      "editors",
      "language"
    ],
    "qualityScore": 0.45,
    "link": "https://speakerdeck.com/kubukoz/adventures-in-the-land-of-language-servers",
    "thumbnail_url": "https://files.speakerdeck.com/presentations/548a94549c554eaf8a5d70effbc439b1/slide_0.jpg?25884509",
    "created_at": "2025-12-17T03:45:03.996Z",
    "topic": "tech"
  },
  {
    "slug": "optimizing-claude-code",
    "title": "Optimizing Claude Code",
    "description": "Customize Claude Code with skills, plugins, commands, and configuration files that transform a capable coding assistant into one that matches your exact workflow.",
    "fullText": "Iâ€™ve been using Claude Code for months now, and for most of that time, I was doing it wrong. Not wrong in the sense of getting bad resultsâ€”the defaults are remarkably capable. Wrong in the sense that I was treating a customizable system like a fixed tool. I was adjusting my workflow to fit the AI instead of adjusting the AI to fit my workflow.\n\nThe difference between default Claude Code and a properly configured instance is the difference between hiring a talented generalist and hiring someone whoâ€™s worked at your company for years. Both can write code. Only one knows that your team prefers forâ€¦of over .forEach(), that you never use the I prefix on interfaces, and that when you say â€œanalyze this bug,â€ you mean a specific six-step process that includes hypothesis testing.\n\nHereâ€™s how I built that second version.\n\nClaude Codeâ€™s customization system has multiple layers, each serving a different purpose:\n\nWhatâ€™s less widely appreciated is how these layers interact. When Claude Code starts a session, it reads your settings, loads relevant skills based on context, and injects CLAUDE.md into its system prompt. When you invoke a command, it triggers a predefined workflow. When you mention a topic covered by a skill, Claude applies that expertise automatically.\n\nMy ~/.claude/settings.json is minimal but deliberate:\n\nalwaysThinkingEnabled: true â€” This enables extended thinking on every response. The tradeoff is latency for quality. For complex refactoring or architectural decisions, I want Claude to think deeply. For quick questions, itâ€™s overkill. I keep it on because my typical use case is substantial engineering work.\n\nToken limits â€” Increasing CLAUDE_CODE_MAX_OUTPUT_TOKENS to 64000 prevents truncation on large refactors. The MAX_THINKING_TOKENS setting controls how much â€œthinkingâ€ space Claude has before responding.\n\nincludeCoAuthoredBy: false â€” I donâ€™t need AI authorship attribution in every commit message. Personal preference.\n\nThe full settings file is available in my dotfiles repo.\n\nEvery project gets a CLAUDE.md at the root. This is where you encode project-specific knowledge: commands to build and test, directory structure, coding principles, workflow patterns.\n\nThe key insight: CLAUDE.md is a system prompt you control. Every instruction you put here shapes every response you get. You can define escalation patterns that tell Claude to stop thrashing and switch to a structured process after failed attemptsâ€”for example, my Bug Fix workflow triggers a 6-step root cause analysis after two failed fixes.\n\nFull template: CLAUDE.md in dotfiles\n\nSkills are markdown files that encode specialized knowledge. When Claude detects that a skill is relevant to your task, it applies that expertise automatically.\n\nThis skill encodes my teamâ€™s TypeScript conventionsâ€”things that arenâ€™t in style guides but matter for consistency:\n\nThe full skill covers interfaces vs types, enum conventions, null handling, type assertions, and module imports. Itâ€™s 700+ lines because TypeScript has a lot of conventions worth encoding.\n\nFor Lambda, DynamoDB, and SQS patterns:\n\nThis skill catches AI-generated code patterns that donâ€™t match human-written code:\n\nThis is something Iâ€™ve noticed consistently: AI models add defensive code and comments that human developers wouldnâ€™t. Having a skill that explicitly tells Claude to avoid these patterns makes the output feel more natural.\n\nSkills directory: skills in dotfiles\n\nSkills teach Claude how to code. Hooks enforce that it does. The difference matters.\n\nA skill might say â€œprefer forâ€¦of over .forEach()â€œâ€”but Claude can still forget. A hook catches it in real-time, warning or blocking before the code is written. Itâ€™s the difference between training and guardrails.\n\nI use the hookify plugin to create enforcement rules from simple markdown files. Here are my active hooks:\n\nHooks are markdown files with YAML frontmatter. Hereâ€™s an example that blocks as any casts:\n\nThe action field determines severity:\n\nThis is where customization compounds. My TypeScript patterns skill teaches Claude the conventions. My hooks enforce them. If Claude violates a conventionâ€”say, using as Type instead of <Type>â€”the hook catches it before the code is written.\n\nThe feedback loop is immediate: Claude sees the warning, adjusts its output, and continues. Since Claude Code is stateless between sessions, the hooks provide consistent enforcement every time. Skills inform, hooks enforce.\n\nHooks directory: hooks in dotfiles\n\nCommands are like shell aliases for Claude workflows. Instead of typing a detailed prompt, you invoke /analyze-bug or /simplify and get a consistent, structured response.\n\nCommands directory: commands in dotfiles\n\nAgent docs are markdown files in .claude/agent_docs/ that Claude reads when relevant. Unlike skills (which encode how to do things), agent docs provide reference material (what things are).\n\nCLAUDE.md tells Claude when to read each doc. More efficient than stuffing everything into contextâ€”Claude loads docs on demand.\n\nAgent docs: agent_docs in dotfiles\n\nPlugins add new tools and workflows to Claudeâ€™s toolkit. I use several, organized by purpose:\n\nast-grep â€” Structural code search using AST patterns. Better than regex for finding code patterns that span multiple lines or have variable formatting. When I need to find all functions that return a Promise but donâ€™t handle errors, ast-grep finds them regardless of formatting. Requires the CLI tool installed separately:\n\ndev-browser â€” Browser automation for testing web applications. When I say â€œgo to localhost:3000 and click the login button,â€ Claude can actually do that.\n\nfrontend-design â€” UI/UX design assistance for frontend work. Part of the official Claude Code plugins.\n\nhookify â€” Creates enforcement rules from markdown files (covered in the Hooks section above). The key plugin for active convention enforcement.\n\ncommit-commands â€” Three git workflow commands:\n\nfeature-dev â€” A 7-phase structured workflow for complex features:\n\nFor complex features that touch multiple files, /feature-dev ensures nothing is missed.\n\npr-review-toolkit â€” Six specialized review agents that run in parallel:\n\nWhen I say â€œreview my PR,â€ these agents analyze different dimensions simultaneously and return prioritized findings.\n\nPlugins are installed via the Claude Code plugin system. Official plugins require adding the Anthropic marketplace first:\n\nThe configuration in settings.json enables them:\n\nRun this to install my skills, commands, and hooks:\n\nThe script sets up ~/.claude/ and prints the plugin commands to run inside Claude Code.\n\nIf you prefer to set things up yourself:\n\nCreate ~/.claude/skills/typescript-patterns/SKILL.md with your TypeScript conventions. The filename must be SKILL.md and include frontmatter with name and description.\n\nCreate ~/.claude/commands/analyze-bug.md with your debugging workflow. Commands are invoked with /analyze-bug (the filename becomes the command name).\n\nAfter installing hookify, create enforcement rules:\n\nHooks take effect immediatelyâ€”no restart required.\n\nCreate CLAUDE.md at the root of each project with project-specific instructions.\n\nMy complete configuration: github.com/stevenmays/dotfiles/tree/master/ai/claude\n\nHereâ€™s what I didnâ€™t expect: these customizations compound.\n\nA skill that teaches TypeScript conventions means Claude knows my preferences. A hook that enforces those conventions means Claude canâ€™t forget them. A command that structures bug investigation means debugging follows a consistent process. A plugin that runs six review agents in parallel means PR reviews are thorough without being tedious.\n\nEach layer reinforces the others:\n\nThe time investmentâ€”maybe a few hours totalâ€”pays dividends on every subsequent session. Iâ€™m not constantly re-explaining preferences or correcting patterns. Claude already knows. And when it forgets, the hooks catch it.\n\nItâ€™s not that X is bad and Y is good, exactly; itâ€™s more that default Claude Code is a capable generalist, while optimized Claude Code is a specialist who happens to share your opinions about code style, your workflow preferences, and your debugging methodology.\n\nThe choice is simple: accept defaults, work around quirks, and occasionally complain about AI-generated code that doesnâ€™t match your styleâ€”or spend a few hours getting dialed in.",
    "readingTime": 7,
    "keywords": [
      "agent docs",
      "create enforcement",
      "typescript conventions",
      "expertise automatically",
      "claude code",
      "ai-generated code",
      "complex features",
      "hook catches",
      "review agents",
      "default claude"
    ],
    "qualityScore": 1,
    "link": "https://mays.co/optimizing-claude-code",
    "thumbnail_url": "https://mays.co/_astro/optimizing-claude-code.DOeMUOQN_Z2lns9R.jpg",
    "created_at": "2025-12-17T03:45:03.284Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-unveils-new-opensource-ai-models-amid-boom-in-chinese-offerings",
    "title": "Nvidia unveils new open-source AI models amid boom in Chinese offerings",
    "description": "Nvidia on Monday unveiled a new family of open-source artificial intelligence models that it says will be faster, cheaper and â€‹smarter than its previous offerings, as open-source offerings from Chinese AI labs proliferate.  Nvidia â€Œis primarily known for providing chips that firms such as OpenAI use to train their closed-source models and â€Œcharge money for them.  Nvidia â on Monday revealed the third â€Œgeneration of its \"Nemotron\" large-language models aimed at writing, coding and other tasks.",
    "fullText": "SAN FRANCISCO, Dec 15 (Reuters) - Nvidia (NVDA) on Monday unveiled a new family of open-source artificial intelligence models that it says will be faster, cheaper and â€‹smarter than its previous offerings, as open-source offerings from Chinese AI labs proliferate.\n\nNvidia â€Œis primarily known for providing chips that firms such as OpenAI use to train their closed-source models and â€Œcharge money for them. But it also offers a slew of its own models for everything from physics simulations to self-driving vehicles as open-source software that can be used by researchers or by other companies, with firms such as Palantir Technologies weaving Nvidia's model into their products.\n\nNvidia â on Monday revealed the third â€Œgeneration of its \"Nemotron\" large-language models aimed at writing, coding and other tasks. The smallest of the models, called Nemotron 3 Nano, was being released â€Monday, with two other, larger versions coming in the first half of 2026.\n\nNvidia, which has become the world's most valuable listed company, said that Nemotron 3 Nano was more efficient than its predecessor - â€‹meaning it would be cheaper to run - and would do better at long tasks â€Œwith multiple steps.\n\nNvidia is releasing the models as open-source offerings from Chinese tech firms such as DeepSeek, Moonshot AI and Alibaba Group Holdings are becoming widely used in the tech industry, with companies such as Airbnb disclosing use of Alibaba' s. (BABA) Qwen open-source model.\n\nAt the same time, CNBC and Bloomberg have reported that Meta Platforms is considering shifting toward closed-source â models, leaving Nvidia as one of the most prominent â€‹U.S. providers of open-source offerings.\n\nMany U.S. states and â€‹government entities have banned use of Chinese models over security concerns.\n\nKari Briski, vice president of generative AI software for enterprise at Nvidia, said the company aimed â€to provide a \"model that â people can depend on\", and was also openly releasing its training data and other tools so that government and business users could test it for security and â customize it.\n\n\"This is why we're treating it like a library,\" Briski told Reuters in an interview. \"This is â€Œwhy we're committed to it from a software engineering perspective.\"",
    "readingTime": 2,
    "keywords": [
      "open-source offerings",
      "closed-source models",
      "nemotron nano",
      "nvidia",
      "firms",
      "software",
      "reuters",
      "cheaper",
      "aimed",
      "tasks"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/nvidia-unveils-open-source-ai-140424565.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/31397226d241d376e5cffbf13490e071",
    "created_at": "2025-12-16T13:51:41.754Z",
    "topic": "finance"
  },
  {
    "slug": "claude-codes-creator-explains-the-limits-of-vibe-coding",
    "title": "Claude Code's creator explains the limits of vibe coding",
    "description": "The engineer behind Claude Code says vibe coding works for prototypes, but today's AI models still fall short for maintainable software.",
    "fullText": "The creator of one of the most popular AI coding tools says vibe coding can only go so far.\n\nBoris Cherny, the engineer behind Anthropic's Claude Code, said on an episode of \"The Peterman Podcast\" published Monday that while vibe coding has its place, it's far from a universal solution.\n\nIt works well for \"throwaway code and prototypes, code that's not in the critical path,\" he said.\n\n\"I do this all the time, but it's definitely not the thing you want to do all the time,\" Cherny said, referring to vibe coding.\n\n\"You want maintainable code sometimes. You want to be very thoughtful about every line sometimes,\" he added.\n\nClaude Code launched earlier this year as part of Anthropic's efforts to integrate AI more deeply into code development workflows.\n\nTop AI coding services like Cursor and Augment run on Anthropic's models, and even Meta uses Anthropic's models inside its coding assistant. Claude Code has also taken off with non-technical developers who want to build software with natural-language prompts.\n\nAnthropic's CEO, Dario Amodei, said in October that Claude was writing 90% of the code in the company.\n\nFor critical coding tasks, Cherny said he typically pairs with a model to write code.\n\nHe starts by asking an AI model to generate a plan, then iterates on the implementation in small steps. \"I might ask it to improve the code or clean it up or so on,\" he said.\n\nFor parts of the system where he has strong technical opinions, Cherny said he still writes the code by hand.\n\nCherny said the models are still \"not great at coding.\"\n\n\"There's still so much room to improve, and this is the worst it's ever going to be,\" he said.\n\nCherny said it's \"insane\" to compare current tools to where AI coding was just a year ago, when it amounted to little more than type-ahead autocomplete. Now, it's a \"completely different world,\" he said, adding that what excites him is how fast the models are improving.\n\nAI-assisted coding has been gaining momentum across the tech world.\n\nGoogle CEO Sundar Pichai said last month that vibe coding is \"making coding so much more enjoyable,\" adding that people with no technical background can now build simple apps and websites.\n\n\"Things are getting more approachable, it's getting exciting again, and the amazing thing is, it's only going to get better,\" he said in a podcast interview with Logan Kilpatrick, who leads Google's AI Studio.\n\nPichai said during Alphabet's April earnings call that AI is writing over 30% of the new code at Google, an increase from 25% in October 2024.\n\nIt's \"fantastic\" how quickly developers can write software with AI coding tools, sometimes while \"barely looking at the code,\" said Google Brain founder Andrew Ng in May.\n\nFor non-technical developers, vibe coding has enabled them to automate parts of their jobs, prototype ideas, or build a creative product on the side, Business Insider reported last month.\n\nStill, leaders caution that the technology has limits. AI-generated code could contain mistakes, be overly verbose, or lack the proper structure.\n\n\"I'm not working on large codebases where you really have to get it right, the security has to be there,\" Pichai said in November.",
    "readingTime": 3,
    "keywords": [
      "anthropic's models",
      "non-technical developers",
      "vibe coding",
      "coding tools",
      "claude code",
      "it's",
      "critical",
      "software",
      "improve",
      "parts"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/claude-code-creator-vibe-coding-limits-boris-cherny-anthropic-2025-12",
    "thumbnail_url": "https://i.insider.com/6940d32f04eda4732f2d9311?width=1200&format=jpeg",
    "created_at": "2025-12-16T06:59:53.631Z",
    "topic": "finance"
  },
  {
    "slug": "the-year-coding-changed-forever",
    "title": "The year coding changed forever",
    "description": "Optimism, laziness, and magical thinking: The year vibe coding took over tech.",
    "fullText": "Sriraam Raja, the founding engineer at the software company Decode, has been using generative AI to write code for two years. He says he can get projects done about twice as fast when he uses a chatbot to code with intention. Then one day, he fired off directions, and as he sat there while the bot's wheels turned, he realized he could have actively written what he was aimlessly waiting for the bot to do. \"I was giving away a bit of my agency, and so I made a decision to be very conscious,\" he tells me.\n\nRaja has become \"very specific about when I delegate, and also how much I delegate,\" he says. Waiting for the AI to spit out code can disrupt the flow of his work, and trusting too much work to it has led him to sometimes get bogged down in a lengthy review process. He's also anxious about the long-term effects AI can have on how we all think and problem solve. \"There's a side effect where everyone's confidence has increased, but so has their laziness, and their willingness to learn things from first principles has dropped,\" he says. \"I've definitely seen a drop in curiosity that I haven't seen before, and so that worries me.\"\n\nThe Collins dictionary made vibe coding its 2025 word of the year. Coined by OpenAI cofounder Andrej Karpathy in February, the term refers to using language and generative AI to speed up the coding process. Soon after, companies were adding it as a desired skill in job listings.\n\nVibe coding was the catalyst for the sort of vibe work era we've entered. It's a shift in how people think about their roles and relationships to work amid an AI boom, and software engineering, long considered a stable and lucrative career path, has perhaps been the career most scrutinized and pushed down a path toward automation. Product managers have suggested that AI will supercharge them, allowing them to take on some technical coding tasks and work without engineers.\n\nExecs have been all-in: Mark Zuckerberg said he expected AI to write half of Meta's code within a year; this spring, AI was already doing about a third of code at Google and on some Microsoft projects. Anthropic CEO Dario Amodei predicted in March that 90% of code would be generated by AI in three to six months. The bullish estimate hasn't materialized for most, but Amodei said in October the company's AI tool Claude was writing most of the code at Anthropic. Cognition, which built an AI-powered software engineer it named Devin, is now valued at $10 billion. Some without computer science backgrounds or any training in coding are vibe coding their own projects.\n\nVibe coding isn't yet the miracle that AI evangelists have professed. AI-generated code can have sneaky errors that pose security risks. As it takes on the work of junior developers, companies eager for gain could displace humans. Time banked with shortcuts now could disrupt training ground for learning basic coding skills, creating a tech worker career ladder collapse could ricochet through the industry. There is potential for developers to save time, to use AI to learn new languages and skills (something Raja tells me he's done), and to pare down their technical debt, or code that needs maintenance. But the impact of AI on the industry is more complicated than it is a silver bullet to efficiency.\n\nLast year, \"we were dealing with a lot of optimism and a lot of magical thinking\" around the capabilities of AI, says Tariq Shaukat, CEO of Sonar, a company that provides developers with tools to verify code. \"The vibe engineering tools are producing a lot of quantity. It's getting more functionally correct, but it's actually becoming more difficult to determine the quality and get the level of trust that you need to integrate that into your code base.\" The ranks of AI holdouts among developers are shrinking. A 2025 survey of professional developers from Stack Overflow found that only 19.3% don't use AI, and a commensurate 19.7% have an unfavorable opinion of AI. Yet less than 3% of respondents said they highly trust AI for accuracy.\n\nAnyone who has asked a chatbot a question knows that even a short inquiry often results in a verbose response. The same is true of code â€” when AI generates it, it's typically longer, making the possibility of errors hiding in the code more likely. Amy Carrillo Cotten, senior director of customer transformation at software development company Uplevel, told me in September: \"For a lot of engineers, the only thing that looks different is where they spend their time, not exactly how much time it took.\" Uplevel studied 800 software developers last year and compared the productivity levels of those who used GitHub's Copilot to those who did not. The developers who used Copilot weren't more efficient or less burnt out, and their code had bugs in it 41% more frequently. (GitHub's own research found that those who used Copilot wrote about 18 lines of clean code, compared to 16 lines for those who didn't.) For many, that shift from writing to reviewing code is \"not the job they signed up for,\" Shaukat says, which brings a big adjustment for many developers.\n\n\"The job looks completely different,\" says Frank Fusco, CEO of a software company called Silicon Society. His company works with clients on their software, but now they often get amateur, vibe coded versions of those ideas as the starting point. \"What I would normally do in code that would take me days, I now do in words and it takes me hours.\" But Fusco tells me he worries about a decline in critical thinking and basic coding skills. We're \"hardwired,\" he says, to find \"the shortest path to the solution.\" But that approach isn't the best for sharpening coding skills. \"It really is a muscle that you have to work all the time.\"\n\nIt's tricky to say AI is already killing developer jobs. Years of layoffs and \"right-sizing\" in the tech industry, paired with the economic precarity that has also defined 2025, could be shifting industry roles alongside AI. As of November, there were about 92,500 active job postings seeking software engineers, down from nearly 102,000 last November and 159,000 at the start of 2023, according to data from CompTIA, a nonprofit trade association for the US IT industry. The number of active tech job posts overall has fallen, from 621,000 in early 2023 to 433,500 last month. But the proportion of open jobs looking for AI skills has jumped by 53% this year.\n\nAfter two decades of being told to pursue computer science as a stable career and a proliferation of coding bootcamps, working as a developer may not be as cushy. College seniors studying computer science are more likely than any other discipline to say they're \"very pessimistic\" about their careers, according to a 2025 survey from early career website Handshake. They're the group most likely to say the advances of generative AI have made them regret their major choice. But young people are divided â€” 43% of computer science majors said they think AI will have a positive effect on their careers.\n\nAutomation is in some ways marking \"a correction\" on the developer labor market, says April Schuppel, developer relations manager at software company Apryse. Before AI, \"we needed as many people who were really pushing out the code to take the ideas of the visionaries and bring them to life.\" Now, \"the people who have always been able to make the most impact, they're still the ones that are the safest.\" Developers who looked at their jobs as clearing tickets might be more replaceable than those who were creative and cared about the project from start to finish. We're far from realizing the end game of vibe coding, but for creative, forward-thinking developers, there's optimism for now. \"The more well-rounded people are the ones that are going to have success,\" Schuppel says.\n\nAI could bring more opportunity for software testers, and also help companies pare down their technical debt. The developer job market might look messy right now, but there's still a heavy focus on the human aspect of the career than in the picture painted by some Big Tech execs. \"If there are opportunities for more fine-tuned models, more specialized models that only do certain types of code updates, and there is a way to use that more to augment human developers as opposed to replace, that seems like that's where this is going,\" says Tim Herbert, chief research officer at CompTIA.\n\nCodebases are valuable, and the security risks posed by goofs in AI code are serious threats. Traffic to vibe coding sites slumped in September after a summer of hype. Even Karpathy said his latest project is \"basically entirely hand-written (with tab autocomplete)\" in a post on X. \"I tried to use claude/codex agents a few times but they just didn't work well enough at all and net unhelpful.\" If 2025 was the year tech companies went all in on AI, 2026 might be the year when some of the craze around vibe coding subsides and reality sets in.\n\nAmanda Hoover is a senior correspondent at Business Insider covering the tech industry. She writes about the biggest tech companies and trends.",
    "readingTime": 8,
    "keywords": [
      "security risks",
      "technical debt",
      "computer science",
      "basic coding",
      "vibe coding",
      "tech industry",
      "coding skills",
      "developers",
      "software",
      "code"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/year-coding-changed-forever-silicon-valley-2025-12",
    "thumbnail_url": "https://i.insider.com/693c966a64858d02d216c23d?width=1200&format=jpeg",
    "created_at": "2025-12-15T13:53:47.187Z",
    "topic": "finance"
  },
  {
    "slug": "habits-that-make-a-great-programmer",
    "title": "Habits That Make a Great Programmer",
    "description": "8 rituals to level up your programming skills! Learn how to code better, think faster, and build complex systems with these actionable tips.",
    "fullText": "â€œHow to get better at programming?â€ is the question I had been asked quite a few times, and today I lay down the 8 rituals I have been following, and action items for each, to be good and get better at programming.\n\nDoing something repeatedly always helps and writing a lot of code will develop our ability to\n\nIf we donâ€™t do something repeatedly, it becomes extremely hard to get good at it. Writing code consistently helps us\n\nSolving programming questions is about developing logic but things become a little trickier when we build a complex system, as it requires us to take our programming skills to go up a notch. Some examples of complex systems are - a Library management system, a Twitter clone, an Instagram clone, etc. Building a complex system\n\nAfter we spend some time writing programs and solving problems, things become monotonous and do not seem to challenge us anymore, so to spice things up a bit we should model something from the real world, like\n\nThere are lots of libraries and framework like p5.js that makes visual programming simple.\n\nIt is not only writing code that improves our programming skills but it is reading some quality code written by expert programmers that make the difference. Reading code written by experts improve our programming vocabulary and by doing this we\n\nThe best way to start doing it is by picking up an open-source project and start skimming the code. It is okay to not understand it in the first go but it is important to skim it a few times and get acquainted. After a few skim, everything will fall in place, the code becomes familiar and we start to understand the flow and business logic.\n\nThere is always someone sitting on the other side of the globe, who knows a thing or two more than us. Look for them and collaborate on a project. The developer community is filled with super smart and super enthusiastic developers who love to share and collaborate. Use websites like Dev.to, Hashnode and Twitter to find and interact with like-minded people.\n\nA programming language is just a tool to express business logic. While learning a programming language we should try to understand the constructs and paradigms used - for example: Functional programming, Polymorphism, Event driven programming, Actor model, etc. It is important to do so because we could pick constructs from one language and use it in another to solve our problem. For example: picking Functional programming (Callbacks) from Javascript and using it in Python to create generic action functions.\n\nWriting code before putting in some thought is degraded the code more often than not. The code written like this lacks simplicity, reusability, and extensibility. Spending some time thinking about problem statement or task at hand and having a rough execution plan always helps.\n\nThese rituals have helped me get better at programming with time and in parallel, I pick at max 3 and act on the action items. Programming is simple but being better than most is difficult. Doing it consistently makes one get better by the day.",
    "readingTime": 3,
    "keywords": [
      "functional programming",
      "action items",
      "business logic",
      "complex system",
      "programming skills",
      "programming language",
      "code",
      "doing",
      "understand",
      "rituals"
    ],
    "qualityScore": 1,
    "link": "https://arpitbhayani.me/blogs/better-programmer/",
    "thumbnail_url": "https://edge.arpitbhayani.me/img/covers/general-cover.jpg",
    "created_at": "2025-12-15T03:59:06.895Z",
    "topic": "tech"
  },
  {
    "slug": "openais-head-of-codex-says-the-bottleneck-to-agi-is-humanitys-inability-to-type-fast-enough",
    "title": "OpenAI's head of Codex says the bottleneck to AGI is humanity's inability to type fast enough",
    "description": "OpenAI's Alexander Embiricos, who leads product development for its coding platform, said the need to review AI's work with prompts is limiting progress.",
    "fullText": "If you needed a sign for how determined AI-land is to achieve AGI quickly, it's that one of its leaders sees the speed of human typing as one of its biggest roadblocks.\n\nAlexander Embiricos, who leads product development for Codex, OpenAI's coding agent, said on \"Lenny's Podcast\" on Sunday that the \"current underappreciated limiting factor\" to AGI is \"human typing speed\" or \"human multi-tasking speed on writing prompts.\"\n\nAGI, or artificial general intelligence, is a still theoretical version of AI that reasons as well or better than humans. It's the thing all the big AI companies are competing to be the first to realize.\n\n\"You can have an agent watch all the work you're doing, but if you don't have the agent also validating its work, then you're still bottlenecked on, like, can you go review all that code?\" Embiricos said.\n\nEmbiricos' view is that we need to unburden humans from having to write prompts and validate AI's work, since we aren't fast enough.\n\n\"If we can rebuild systems to let the agent be default useful, we'll start unlocking hockey sticks,\" he said.\n\n\"Hockey stick growth\" is a term used to describe a growth curve that starts out flat and suddenly spikes, mirroring the shape of a hockey stick.\n\nEmbiricos said there's no simple path to a fully automated workflow â€” each use case will require its own approach â€” but he expects to see progress toward this level of growth soon.\n\n\"Starting next year, we're going to see early adopters starting to hockey stick their productivity, and then over the years that follow, we're going to see larger and larger companies hockey stick that productivity,\" he said.\n\nSomewhere in between the time early adopters start to see gains in productivity and when tech giants manage to fully automate processes with AI agents is when we'll see AGI, Embiricos said.\n\n\"That hockey-sticking will be flowing back into the AI labs, and that's when we'll basically be at the AGI,\" he said.",
    "readingTime": 2,
    "keywords": [
      "human typing",
      "hockey stick",
      "agent",
      "speed",
      "we'll",
      "growth",
      "productivity",
      "it's",
      "prompts",
      "humans"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/openai-artificial-general-intelligence-bottleneck-human-typing-speed-2025-12",
    "thumbnail_url": "https://i.insider.com/693f0599832e0ef1ead631ab?width=1200&format=jpeg",
    "created_at": "2025-12-15T03:59:01.869Z",
    "topic": "finance"
  },
  {
    "slug": "programming-languages-to-learn-first",
    "title": "Programming Languages to Learn First",
    "description": "Many IT professionals would recommend Python as the best programming language for beginners. Why? The syntax of the Python code is considered simple.",
    "fullText": "TL;DR: Python leads with 29.85% market share driven by AI/ML demand, while JavaScript remains essential for web development. But hereâ€™s what most hiring managers miss: the rise of AI-powered coding tools like GitHub Copilot has fundamentally altered what skills you should prioritize when building your engineering team.\n\nThe question isnâ€™t simply â€œwhich programming language should we hire for?â€ anymore. Companies are increasingly leveraging AI to automate routine coding tasks, reducing the need for large engineering teams and prioritizing professionals who can manage AI-driven workflows rather than simply write code.\n\nLetâ€™s cut through the noise and examine whatâ€™s actually happening in todayâ€™s tech hiring landscape.\n\nSoftware developer job listings are down 35% from their 2022 peak, but donâ€™t let that fool you into thinking demand has disappeared. Most technology positions tracked by the U.S. Bureau of Labor Statistics show unemployment rates well below the national averageâ€”software developers at 2.8%, systems analysts at 1.8%, and security analysts at 2.3%.\n\nWhatâ€™s changed is selectivity. Companies are becoming more selective with their technical hires while businesses struggle to ship quickly due to a shortage of qualified engineers. The old approach of scanning resumes for keyword matches no longer works when every engineer claims â€œfull-stackâ€ experience.\n\nPython dominates with 29.85% market share, and itâ€™s no surprise given AI and machine learningâ€™s explosive growth. But hereâ€™s what matters for your hiring strategy: the type of Python developer you need has evolved.\n\nTraditional Python roles focused on web development with Django or Flask. Modern Python roles require understanding of:\n\nWhen interviewing Python candidates, dig beyond syntax knowledge. Ask: â€œHow would you architect a system that processes real-time data for ML model inference?â€ The answer reveals whether they understand modern Pythonâ€™s role in AI-driven products.\n\nJavaScript maintains its position with 7.92% market share, remaining essential for front-end development. But traditional frontend development is seeing fewer job postings, suggesting a shift toward full-stack or specialized backend roles.\n\nThe modern JavaScript landscape demands expertise in:\n\nTypeScript continues gaining popularity for large-scale web development, with its static typing and enhanced tooling making it preferred for complex applications. If your product serves enterprise clients or handles complex state management, TypeScript experience isnâ€™t optional, itâ€™s essential.\n\nGoâ€™s popularity continues to grow as global demand for cloud computing rises, with its simple syntax, built-in concurrency support, and high performance making it well-suited for cloud-native applications.\n\nRust is emerging for system-level programming where memory safety and performance are critical. Rustâ€™s memory safety, high performance, and robust security properties make it particularly well-suited for performance- and safety-critical applications.\n\nIf your architecture includes real-time systems, embedded software, or blockchain applications, Rust expertise provides competitive advantages that Go simply cannot match.\n\nIn this article, you can find answers to these questions. Keep in mind that these are all useful languages that will bring you closer to your goal if youâ€™re committed.\n\nDespite competition from newer languages like Kotlin and Go, Java remains widely used in enterprise software, Android development, and backend systems. But the Java developer you need in 2025 looks different from five years ago.\n\nModern Java development requires:\n\nC# has been increasingly utilized in game development and enterprise software, with deep integration with the Unity game engine cementing C# as a top game developer language. For enterprise applications, .NETâ€™s cross-platform capabilities make C# developers valuable for modernizing legacy Windows-based systems.\n\nAccording to research for the Demand for Skilled Talent report, the most evident skills gap on technology teams is within AI, machine learning and data science. But letâ€™s be specific about what this means for different roles:\n\nPlatform-focused AI engineers build centralized tools and infrastructure to accelerate AI development, while product-focused AI engineers work inside product teams and ship AI features for users. Understanding this distinction helps you write better job descriptions and evaluate candidates correctly.\n\nDevelopers who can maintain and modernize legacy systems are highly valued, with work including ensuring security, improving performance, and integrating legacy systems with newer technologies like APIs or microservices. Many companies underestimate this need when planning their hiring strategy.\n\nCloud services like AWS, Google Cloud, and Microsoft Azure are at the core of modern software infrastructure, with over 90% of global enterprises expected to use cloud platforms by 2025.\n\nCritical cloud competencies include:\n\nWhen evaluating DevOps candidates, focus on their experience with incident response and disaster recovery. Anyone can deploy to the cloud; few can architect systems that gracefully handle failure at scale.\n\nEnterprise blockchain adoption is driving legitimate technical roles:\n\nMajor industries entering the space, including finance, healthcare and logistics, are expanding demand for blockchain engineers. When Deutsche Bank builds blockchain settlement systems or Nike creates digital collectibles, they need engineers who understand both traditional software architecture and decentralized protocols.\n\nEntry-level Solidity developers can write basic smart contracts and deploy them to testnets. Senior Solidity engineers architect systems that handle millions in value while remaining secure and gas-efficient.\n\nCore technical competencies for serious Solidity roles:\n\nFor Startups and Scale-ups: Python and JavaScript remain your best bets for rapid development and talent availability. The ecosystem maturity and hiring pool depth outweigh cutting-edge performance considerations.\n\nFor Enterprise and Financial Services: Java and C# provide the stability, security, and regulatory compliance frameworks that regulated industries require. Donâ€™t chase trends when handling mission-critical systems.\n\nFor Performance-Critical Applications: Go for backend services, Rust for system programming, and C++ for real-time applications. Latency requirements should drive language selection, not popularity metrics.\n\nFor AI/ML Products: Python dominates, but consider Julia for scientific computing or R for statistical analysis. Language choice depends on your specific AI use case and team expertise.\n\nGiven 95% of tech leaders face challenges finding skilled workers, your approach to technical hiring needs to evolve beyond traditional methods.\n\nFocus on fundamental problem-solving over specific syntax knowledge. A strong engineer can learn new languages; analytical thinking and system design skills transfer across technologies.\n\nPrioritize hands-on experience with real-world projects over certification collections. Ask candidates to walk through architecture decisions theyâ€™ve made and trade-offs theyâ€™ve considered.\n\nEvaluate AI collaboration skills. The shift toward engineers with expertise in AI augmentation, system architecture, and cross-functional problem-solving means traditional coding assessments miss crucial competencies.\n\nItâ€™s easy enough for software engineers to become AI engineers: just build applications on top of LLMs. This accessibility is reshaping what skills remain uniquely human and valuable.\n\nLanguages that enhance AI productivity:\n\nThe programming languages your team learns should align with how AI tools augment rather than replace human developers. Focus on languages that excel in areas where human judgment and creativity remain irreplaceable: system architecture, user experience design, and complex business logic implementation.\n\nBottom Line: The most important programming language for your 2025 hiring strategy isnâ€™t determined by popularity rankingsâ€”itâ€™s the one that best matches your technical architecture, team experience, and business requirements. Technology hiring trends in 2025 indicate that candidates place high value on exposure to AI and machine learning projects, as these skills significantly enhance their career trajectories.\n\nThe companies succeeding in todayâ€™s competitive hiring market understand that language proficiency is just the foundation. The real competitive advantage comes from engineers who can architect systems, collaborate with AI tools, and adapt to evolving technical requirements.\n\nReady to build a hiring strategy that actually reflects todayâ€™s market realities? Letâ€™s discuss how the current tech landscape impacts your specific technical requirements and talent acquisition approach.",
    "readingTime": 7,
    "keywords": [
      "python dominates",
      "applications rust",
      "shift toward",
      "memory safety",
      "syntax knowledge",
      "machine learning",
      "python roles",
      "web development",
      "hiring strategy",
      "technical requirements"
    ],
    "qualityScore": 1,
    "link": "https://www.omnesgroup.com/the-best-programming-languages-to-learn-first/",
    "thumbnail_url": "https://www.omnesgroup.com/wp-content/uploads/2018/08/download-69-1.png",
    "created_at": "2025-12-14T18:50:16.561Z",
    "topic": "tech"
  },
  {
    "slug": "terraform-sunsets-cdktf",
    "title": "Terraform Sunsets CDKTF",
    "description": "This decision forces Terraform's users to migrate to HCL, drawing criticism from those who point to the CDK's popularity as proof Terraform still needs advanced programming capabilities.",
    "fullText": "Going forward, when you run IBMâ€˜s Terraform Infrastructure as Code (IaC) software, you will have one language to write your configurations: the HashiCorp Configuration Language (HCL).\n\nOn Monday, HashiCorp, an IBM company, announced that it will no longer support the Terraform Cloud Development Kit (CDK or CDKTF). Although the existing code will remain available in a GitHub archive, HashiCorp will no longer maintain or update the code, leaving it all but unusable for enterprises.\n\nâ€œUnfortunately, Terraform CDK did not find product-market fit at scale. HashiCorp, an IBM Company, has chosen to focus its investments on Terraform core and its broader ecosystem,â€ a note on the site read.\n\nThe CDK itself is licensed under the Mozilla Public License (MPL), so users are free to fork the software itself, IBM suggested.\n\nThe company, however, is encouraging users to use HCL, which was developed by HashiCorp and licensed under the Mozilla Public License (MPL), originally designed for the software.\n\nOriginally released in 2014 by HashiCorp, Terraform is software that allows administrators to automate the deployment of IT infrastructure, either in the cloud or on premises, through the use of scripts and a set of Terraform commands such as terraform init, terraform plan and terraform apply. The output is rendered as JSON.\n\nOver time, Terraform has become the most popular software for automated IT deployment, especially in the cloud native community.\n\nIn 2023, HashiCorp switched the Terraform license from open source to a Business Source License, which spurred a user-based open source fork of the software, called OpenTofu, that was adopted by the Linux Foundation and, later, by the Cloud Native Computing Foundation (CNCF).\n\nIn 2024, IBM announced it was acquiring HashiCorp and finalized the purchase earlier this year.\n\nDespite a call to open source the CDK, IBM is encouraging current users to adopt the HCL if they are not already doing so.\n\nâ€œIf you are not using AWS CDK, we highly recommend migrating to standard Terraform and HCL for long-term support and ecosystem alignment,â€ the company asserted.\n\nTerraform users with .tf files created under the CDK can convert them to HCL with the following command:\n\nThose using CDTF on Amazon Web Services infrastructure can also use AWSâ€™ own CDK.\n\nOverall, the Infrastructure as Code user base appears to be chafing from the limits of IaC.\n\nAs a result, many alternative approaches to Terraform have popped up in the last few years, including Adam Jacobâ€™s System Initiative and Formae from Platform Engineering Labs.\n\nThey point to how HCL has its limits, especially for highly scalable environments. A declarative configuration language, HCL is limited in offering advanced programming constructs, and many resulting workarounds have resulted in obtuse code. Tooling is limited as well.\n\nThe advantage that the CDKTF brought to users was that it allowed them to detail deployment instructions through their own favorite programming language rather than HCL. CDKTF supported TypeScript, Python, C# and the Go programming language.\n\nThis is also the approach that Terraform competitor Pulumi has staked out, namely the ability to provision infrastructure in any one of a number of programming languages.\n\nYet, there has also been considerable debate around whether a general-purpose programming language is better than a domain-specific language. Terraformâ€™s users are administrators, not programmers, as critics have pointed out.\n\nNonetheless, many of those in the IaC community took the news hard. Kubernetes expert David Flanagan noted that the development kit has gotten over 140,000 downloads per week for TypeScript alone, with similar numbers in other language communities.\n\nSo clearly, the CDKTF is still highly used by the community, he argued.\n\nFuck you, Hashicorp â€¦ an IBM Company. pic.twitter.com/h1EicnT3pL\n\nâ€” David Flanagan (@rawkode), Dec. 11, 2025\n\nâ€œYou donâ€™t kill a project with [an estimated] million users every single month because nobody likes it or it doesnâ€™t have a â€˜market fit.â€™ You kill it because it is not increasing your profit margin, it is not selling enterprise licenses,â€ Flanagan said in a short video.\n\nTo be fair, IBM has a long history of buying open source-based companies, and keeping the open source licensing intact, including the Linux-based Red Hat, the Cassandra-focused Datastax and, most recently, the Kafka-based Confluent. (Thereâ€™s been no word, however, on whether IBM would revert the Terraform license back to open source.)\n\nFlanagan went on to note that people are probably using the CDKTF because they require the additional programming capabilities. â€œItâ€™s called Infrastructure as Code, not Infrastructure as JSON,â€ he quipped.\n\nSite reliability engineer Liz Fong-JonesÂ offered a more measured response.\n\nâ€œTo be more gentle about this, HashiCorp has decided to stop trying to compete with Pulumi with language-native APIs; theyâ€™re all in on HCL as the only way to work with Terraform,â€ Fong-Jones wrote on BlueSky.\n\nIn fact, others think this may not be a bad idea.\n\nPlatform Engineering Labsâ€™ Co-Founder and CEO Pavlo Baron thought the IBM move made sense.\n\nâ€œIBM is historically good at optimizing for the target buyer. This is rather a sign that nobody on the right side of the cycle wants to do full-blown programming. CDKs, and this includes the approach Pulumi takes, are exclusively for developers. Developers usually donâ€™t operate infrastructure,â€ he wrote by email.\n\nâ€œSerious operations happen on the right side of the cycle, though. Thus, the CDK is missing their target user and addresses the wrong one. So I understand and support the logic behind this move.â€",
    "readingTime": 5,
    "keywords": [
      "platform engineering",
      "engineering labs",
      "license mpl",
      "development kit",
      "cloud native",
      "language hcl",
      "configuration language",
      "programming language",
      "ibm company",
      "terraform license"
    ],
    "qualityScore": 1,
    "link": "https://thenewstack.io/ibm-hashicorp-sunsets-terraforms-external-language-support/",
    "thumbnail_url": "https://cdn.thenewstack.io/media/2025/12/65e7b1bd-ritu-dahiya-w2mlnx4yso-unsplash.jpg",
    "created_at": "2025-12-14T18:50:16.550Z",
    "topic": "tech"
  },
  {
    "slug": "component-party-compare-javascript-frameworks",
    "title": "Component Party â€“ Compare JavaScript Frameworks",
    "description": "Compare JavaScript frameworks side-by-side: React, Vue, Angular, Svelte, Solid.js, and more. See syntax differences, features, and code examples for web development frameworks.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://component-party.dev/?f=react-svelte5",
    "thumbnail_url": "https://component-party.dev/banner2.png",
    "created_at": "2025-12-14T03:53:12.102Z",
    "topic": "tech"
  },
  {
    "slug": "exmeta-staffer-nicknamed-coding-machine-says-the-best-engineers-arent-on-linkedin-but-theyre-special-cases",
    "title": "Ex-Meta staffer nicknamed 'coding machine' says the best engineers aren't on LinkedIn â€” but they're special cases",
    "description": "Michael Novati , a former Meta principal software engineer, said the names of the best of the best engineers are \"nowhere\" online.",
    "fullText": "LinkedIn is full of corporate braggarts. But don't expect the best engineers to flaunt their success on the platform â€” or even have an account, according one former Meta employee.\n\nMichael Novati spent almost eight years at Meta, back when it was still called Facebook and hadn't yet doubled down on AI. He reached the rank of principal software engineer and earned the nickname \"coding machine.\"\n\nOn the \"A Life Engineered\" podcast, host Steve Huynh asked Novati about his claim that the top five engineers aren't on LinkedIn. Novati stood by it.\n\n\"When I was at Facebook, the top engineers were like, 'If you had a LinkedIn account, people would be wondering if you're job hunting,'\" he said.\n\nNovati said these engineers don't need to publicly job hunt because of tech's extensive recruiting arm, which he called the \"secrets of the industry.\"\n\n\"There are very senior, very highly paid recruiters that work at the top companies who have very strong long-term social relationships with a lot of top engineers,\" he said.\n\nHow do these engineers and recruiters meet? Novati gave the example of an engineer who spends a week doing campus recruiting at Stanford, bonding with the company's recruiter in the process.\n\nHe referred to these as the \"secret backroom dealings of Silicon Valley.\"\n\n\"These engineers' names are nowhere, but they are the ones that are the most desirable by these recruiters,\" he said. \"The $100 million engineer is not on LinkedIn with a tagline that's like, #100millionengineer.\"\n\nTech recruiting has long been a large, lucrative industry. Big Tech companies both employ in-house recruiters and outside agencies to stay close to key talent.\n\nMeanwhile, talent is becoming increasingly competitive, particularly in the field of AI. Meta shelled out large contracts for its Superintelligence Labs, poaching engineers from its competitors.\n\nSometimes CEOs even get involved. Mark Zuckerberg reportedly made a list of the top AI talent to poach. OpenAI's chief research officer said that Zuckerberg hand-delivered soup to an employee he was trying to recruit.\n\nOne AI worker told Business Insider they got a personal call from OpenAI CEO Sam Altman, pitching them to join the company. They accepted.\n\nBeing offline may not be the golden key to tech recruiting, though. These top-tier engineers are a \"specific case,\" Novati said on the podcast.\n\n\"It doesn't mean that your strategy should be: delete LinkedIn and all the offers will come,\" he said.\n\nIt's a rarified class, Novati said, but one that stays away from all semblances of personal branding.\n\n\"I don't know any of those top engineers, who get special equity grants and special dinners with Bezos or whatever stuff like that, who have big personal brands,\" he said.",
    "readingTime": 3,
    "keywords": [
      "tech recruiting",
      "top engineers",
      "recruiters",
      "don't",
      "talent",
      "personal",
      "novati",
      "account",
      "employee",
      "facebook"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/best-engineers-not-on-linkedin-former-meta-employee-2025-12",
    "thumbnail_url": "https://i.insider.com/693ae21d832e0ef1ead60bb6?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.490Z",
    "topic": "finance"
  },
  {
    "slug": "a-new-series-on-cracking-faanglevel-code-challenges",
    "title": "A New Series on Cracking FAANG-Level Code Challenges",
    "description": "One of the most fundamental algorithms that appears in interviews at big tech companies is Binary Search. Of course, nobody will ask you to implement binary search directly. However, as Jon Bentley cited in his famous book Programming Pearls, only a small percentage of people he askedâ€”10% to be preciseâ€”were able to code this algorithm without any errors.\nHere, I will show you a correct implementation of binary search, its variants that appear in interviews, and LeetCode problems that you can solve using these techniques.",
    "fullText": "One of the most fundamental algorithms that appears in interviews at big tech companies is Binary Search. Of course, nobody will ask you to implement binary search directly. However, as Jon Bentley cited in his famous book Programming Pearls, only a small percentage of people he askedâ€”10% to be preciseâ€”were able to code this algorithm without any errors.\n\nHere, I will show you a correct implementation of binary search, its variants that appear in interviews, and LeetCode problems that you can solve using these techniques.\n\nGiven an array of items, we can find the position of a specific item linearly by iterating over the array, comparing each item with the desired item, and returning the position when the current item equals the desired item.\n\nWe must also consider the case where the desired item is not in the array; in this case, we can return any value. Since we are talking about positions in an array, we can return -1 if the item is not present. This is a very simple concept and implementation. However, if the array is sorted, we can do better.\n\nWe can find the position of an item in logarithmic time (O(log n)), where n is the number of items in the array, when the array is sorted.\n\nTo do this, we repeatedly compare the item we are looking for with the middle element of the array. If the middle element is the one we are looking for, we have our result. Otherwise, we need to update the range of the array we are considering accordingly.\n\nIf the element we are looking for is greater than the middle element, we need to search in the higher part of the array. Otherwise, we need to search in the lower part of the array.\n\nWhat we just described is the Binary Search algorithm. Below is the implementation of the binary search algorithm in C++:\n\nThis is less than 20 lines of code that you need to understand very well if you want to be successful in an interview. Note that I said â€œunderstand,â€ not â€œmemorize.â€\n\ncould be implemented in different ways, such as:\n\nCan you explain why the first implementation is better than the second?\n\nThe answer is integer overflow. When we add two integer numbers, we can exceed the maximum value allowed in the computerâ€™s representation of an int. Knowing these details and how to answer such questions puts you in a much better position compared to other candidates.\n\nAs you can see, even a small detail can demonstrate your expertise and experience. All these small details together help you get the position you want.\n\nDespite these details, as I said, nobody will ask you to implement binary search directly. However, there are some important variants of the binary search algorithm that appear as part of problem-solving. I will describe four of them in the next sections.\n\nLetâ€™s consider we have a sorted array with duplicate elements, such as [10, 20, 30, 30, 30, 40, 50]. Also, letâ€™s assume we are searching for the element 30 and we need to find the smallest position of this element in case of duplication.\n\nWith the binary search algorithm implementation shown above, we cannot guarantee we will always return the smallest position of an element in case of duplication. However, we can modify the original algorithm to answer this question correctly.\n\nAnd here is a very important point: You can only make this modification if you know the binary search algorithm and its implementation well.\n\nThinking about the problem, instead of returning the position when we find the element in the array, we need to update our result and continue the search in the lower part of the array.\n\nUpdating the result instead of returning immediately is easy to see. You cannot return immediately because there may be duplicate elements in the array. Since we want the smallest position, we cannot just return.\n\nSo, why go to the lower part of the array instead of the higher part? The answer is because of the problem definition: we want the smallest index. So, if we find the element, in case of duplication, we are interested in the presence of this element before the current position.\n\nThe implementation in C++ could be:\n\nThis problem is similar to the one above, but now we are interested in the higher part of the array in case of duplication. This is because we want the largest index instead of the smallest one.\n\nIn this case, the implementation in C++ could be:\n\nThis is a little different, but only slightly. Now, we are not interested in finding an element, but the largest value less than the given element. So, every time we find an element that is smaller than our desired element, we need to update our result. We also need to update the considered range of the array.\n\nIn this case, we are interested in the higher part of the array, since we are trying to find the largest value less than our element.\n\nThe implementation in C++ could be:\n\nSimilar to the problem above, but now we are interested in finding the smallest value greater than the desired value. So, we need to update our result when we find a larger element instead of a smaller one.\n\nThe implementation in C++ could be:\n\nHere are some interesting problems to solve on LeetCode using the techniques explained in this post:",
    "readingTime": 5,
    "keywords": [
      "directly however",
      "duplicate elements",
      "implement binary",
      "search directly",
      "desired item",
      "middle element",
      "search algorithm",
      "smallest position",
      "array",
      "implementation"
    ],
    "qualityScore": 1,
    "link": "https://johnjr.dev/posts/binary-search/",
    "thumbnail_url": "https://johnjr.dev/jj1.jpg",
    "created_at": "2025-12-11T18:58:27.000Z",
    "topic": "tech"
  },
  {
    "slug": "craft-software-that-makes-people-feel-something",
    "title": "Craft software that makes people feel something",
    "description": "Recently, people have been asking me why Iâ€™m pausing Boo to work on a programming language. I think it would actually be cool to write down how I feel.",
    "fullText": "So, I woke up today. Got my coffee, family went to sleep, and I have a free afternoon.\n\nI thought about writing something. I may delete this article, but if you are reading this, it means I went through with it.\n\nRecently, people have been asking me why Iâ€™m pausing Boo to work on a programming language. I think it would actually be cool to write down how I feel.\n\nBoo is a code editor I created solely for myself; I never had the intention of making it a mainstream editor. Of course, it would be fun if people used it, but that was never my goal. This year I got it working in a functional state, where I can actually use it for my daily work. It has innovative human-keyboard navigation and replaces the LSP system with something faster and less costly for the OS. So why on earth am I not open-sourcing it? Thatâ€™s what people keep asking me.\n\nMy mind isnâ€™t really moved by the idea that it would be a success or a failure â€” the end user of Boo is me. I donâ€™t feel itâ€™s there yet; in fact, I think software should inspire us. Working on Rio Terminal and Boo in my free time â€” both written in Rust and sharing many similarities â€” affects my joy, because it starts to become something automatic. Both have similar architecture, language, release process, and etcetera.\n\nSince I was a kid, I liked to build Lego blocks. Thatâ€™s probably what I did the most besides playing football or video games. The fun thing about Lego is that one day you can build a castle, and the next day you can build a ship. Not necessarily using the same pieces and colors â€” you can actually add a lot of stuff thatâ€™s external to what you have, like a wood stick.\n\nWhen programming becomes repetitive, the odds of you creating something that makes people go â€œwowâ€ are reduced quite a bit. It isnâ€™t a rule, of course. You need to be inspired to make inspiring software.\n\nI always use the example of The Legend of Zelda: Breath of the Wild. This game is so well crafted that I know people who donâ€™t even like video games but bought a console just to play it â€” and once they finished, they sold everything. This is what Iâ€™m talking about: taking time to build something so that once people try it, they remember it for as long as they live.\n\nBoo isnâ€™t a business. I donâ€™t need or want to make money out of it. I donâ€™t have a deadline, nor do I want to create another VS Code. I donâ€™t feel like forcing it to happen.\n\nIn that case, I donâ€™t necessarily need to stop building Lego blocks, right? Iâ€™ll just park it there, and when the inspiration comes back, Iâ€™ll pick it up where it was. That being said, I paused Boo, and I am working on my own programming language. Eventually, my idea is to rewrite Boo to use it.\n\nâ€œWow! Thatâ€™s a lot of work.â€ Indeed. But itâ€™s my hobby stuff. Iâ€™ve always loved programming languages, and I am having a blast learning more about binaries and compilers. So, I donâ€™t really feel I need to follow peopleâ€™s cake recipe for success. Thatâ€™s how my mind works, and I will stick with it.",
    "readingTime": 3,
    "keywords": [
      "lego blocks",
      "programming language",
      "donâ€™t",
      "isnâ€™t",
      "free",
      "course",
      "mind",
      "idea",
      "success",
      "itâ€™s"
    ],
    "qualityScore": 1,
    "link": "https://rapha.land/craft-software-that-makes-people-feel-something/",
    "thumbnail_url": "https://rapha.land/assets/images/banner.jpg",
    "created_at": "2025-12-11T13:53:41.026Z",
    "topic": "tech"
  },
  {
    "slug": "unreal-blueprintlike-mcp-server-builder-no-coding-knowledge-required",
    "title": "Unreal Blueprint-Like MCP Server Builder (No Coding Knowledge Required)",
    "description": "A Blueprint-style visual node editor for creating FastMCP servers. Build MCP tools, resources, and prompts by connecting nodes - no coding required. - PhialsBasement/GUI-MCP",
    "fullText": "PhialsBasement\n\n /\n\n GUI-MCP\n\n Public\n\n A Blueprint-style visual node editor for creating FastMCP servers. Build MCP tools, resources, and prompts by connecting nodes - no coding required.\n\n 3\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n PhialsBasement/GUI-MCP",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/PhialsBasement/GUI-MCP",
    "thumbnail_url": "https://opengraph.githubassets.com/619d24ecdcaf5477d9914c9ee0acb987700aa86035c0d50b25f6cd7d76ac6c38/PhialsBasement/GUI-MCP",
    "created_at": "2025-12-11T03:50:15.379Z",
    "topic": "tech"
  },
  {
    "slug": "young-people-are-growing-up-fluent-in-ai-and-thats-helping-them-stand-apart-from-their-older-peers-says-gen-z-founder",
    "title": "Young people are â€˜growing up fluent in AIâ€™ and thatâ€™s helping them stand apart from their older peers, says Gen Z founder Kiara Nirghin",
    "description": "Nirghin explained that young entrepreneurs see coding as something to be done alongside AI agents, rather than done alone and from scratch.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/gen-z-growing-up-fluent-ai-helping-stand-apart-from-older-peers/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974872644_4c9966d747_o.jpg?resize=1200,600",
    "created_at": "2025-12-10T18:55:46.731Z",
    "topic": "business"
  },
  {
    "slug": "the-boundary-of-copyrightability-in-aigenerated-code-under-j",
    "title": "The boundary of copyrightability in AI-generated code under Japan and US Law",
    "description": "When GitHub Copilot first appeared, many developers viewed it as an assistive tool for coding. The honest impression of most developers was likely that while it was useful, it was not a tool to whiâ€¦",
    "fullText": "A Curious Phenomenon with Gemma Model Outputs and LicenseÂ Propagation While examining the licensing details of Googleâ€™s Gemma model, I noticed a potentially puzzling phenomenon: you can freely assign a license to the modelâ€™s outputs, yet depending on how those outputs are used, the original Terms of Use might suddenly propagate to the resulting work. Outputs vs. Model Derivatives The Gemma Terms of Use distinguishâ€¦",
    "readingTime": 1,
    "keywords": [
      "gemma model",
      "outputs",
      "license",
      "phenomenon"
    ],
    "qualityScore": 0,
    "link": "https://shujisado.org/2025/12/10/the-boundary-of-copyrightability-in-ai-generated-code/",
    "thumbnail_url": "https://shujisado.org/wp-content/uploads/2025/12/chatgpt-image-2025e5b9b412e69c8810e697a5-21_53_59.png",
    "created_at": "2025-12-10T13:50:09.359Z",
    "topic": "tech"
  },
  {
    "slug": "databricks-ceo-ali-ghodsi-says-his-company-will-be-worth-1-t",
    "title": "Databricks CEO Ali Ghodsi says his company will be worth $1 trillion by doing these three things",
    "description": "Databricks CEO says AI-powered coding, enterprise agents, and rapid app development could propel it into the trillion-dollar club.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/databticks-ceo-1-trillion-valuation-agents-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974307746_cdbc8c031a_o.jpg?resize=1200,600",
    "created_at": "2025-12-10T03:48:33.338Z",
    "topic": "business"
  }
]
[
  {
    "slug": "why-reliability-demands-functional-programming",
    "title": "Why Reliability Demands Functional Programming",
    "description": "> In banking, telecom, and payments, reliability is not a nice to have. It is table stakes. The most reliable systems I have worked on reduce entire classes of bugs before the code even runs. Functional programming and Algebraic Data Types (ADTs) let you push correctness into the type system, so illegal states cannot be constructed in the first place. **What you will learn** - How invalid states show up in real systems and why they cause costly incidents - How ADTs encode business rules so the compiler enfo...",
    "fullText": "In banking, telecom, and payments, reliability is not a nice to have. It is table stakes. The most reliable systems I have worked on reduce entire classes of bugs before the code even runs. Functional programming and Algebraic Data Types (ADTs) let you push correctness into the type system, so illegal states cannot be constructed in the first place.\n\nMost production incidents are not due to complex algorithms. They are due to the code entering a state that should never have been possible. If you have been on call, you have seen variants of these:\n\nFunctional programming helps by modeling the domain with types that make invalid states unrepresentable. Pure functions and immutability keep behavior predictable and testable.\n\nProduct types combine fields, think \"and\". Sum types choose one of several cases, think \"or\". Together they model your domain rules.\n\nWith this shape, \"paypal\" cannot exist as a Payment. The compiler refuses the value.\n\nWhen you pattern match on a sum type, the compiler can force you to handle every variant. If you later add a new case, every non exhaustive match becomes a compilation error or warning. This is how refactors become safe by default.\n\nAdd a new Crypto method and both code bases will point out every place you must update.\n\nIncident story\n\nA payout worker retries on network timeouts and calls settle() twice. The table allows pending = false and settled = true twice with the same ledger id. Reconciliation finds duplicates and accounting needs a manual fix.\n\nWhy it happened\n\nState is spread across booleans and strings. The database does not express the lifecycle. The application code does, but only by convention and tests.\n\nTransitions become total functions. You can return a Result when a transition is not allowed.\n\nNow the illegal transitions are blocked by construction. Test coverage still matters, but the shape of the model prevents a class of bugs.\n\nRefactor safety\n\nWhen product adds Chargeback, the compiler highlights every match that ignores it. You cannot ship with a half handled lifecycle.\n\nEvery switch on TxnState now requires a chargeback branch. This is free guidance from the compiler.\n\nIncident story\n\nThe call detail record pipeline generates billing events whenever it sees a Connected event. Under jitter and retries, some sessions never receive Completed. The billing system charges based on the wrong boundary and customers complain.\n\nWhy it happened\n\nThe call lifecycle is implicit across many services. A connected session with no end was still billable because there was no type that separated non billable states from billable ones.\n\nNow a connected but never completed call cannot produce a billable duration. The shape forbids the bug.\n\nIncident story\n\nA cache TTL is stored in an environment variable. Someone sets CACHE_TTL_SECS=30s. In JavaScript, Number(\"30s\") yields NaN and your code treats it as zero, disabling caching in production.\n\nThe ambiguity disappears. The code must handle absence and parse errors explicitly.\n\nDo not use null to mean \"maybe\". Do not throw exceptions for expected errors.\n\nThese types make the happy path and the error path equally explicit.\n\nMutable shared state is a common source of heisenbugs under concurrency. Prefer immutable data and pure functions. When you need to update, create a new value.\n\nYour tests become simple. Given the same inputs, the function returns the same output.\n\nNumbers are not self describing. Create types that carry meaning.\n\nYou stop mixing milliseconds with seconds or dollars with cents by accident.\n\nKeep the domain logic pure and push IO to the edges. This makes unit tests cheap and fast.\n\nStart small and make continuous progress. Here is a practical order for a team new to these ideas.\n\nReplace pairs of booleans with a sum type\n\nReplace string enums with discriminated unions\n\nReplace nullable fields with Option\n\nReplace thrown control flow with Result\n\nIntroduce newtypes or branded types for units and ids\n\nPattern matching compiles to simple branches. Discriminated unions in TypeScript are just plain objects. The main cost you will feel is validation at the boundaries in smart constructors. This is a trade worth making. The compiler then protects the interior of the system.\n\nReliability is designed. With Algebraic Data Types, pattern matching, Option and Result, immutability, and smart constructors, you encode domain rules directly in your types. Illegal states cannot compile. This is why industries that cannot afford failure, such as banking and telecom, gravitate to functional ideas.\n\nIf you work on code that touches money, minutes, or public availability, adopt these patterns now.\n\nYour on call shifts will be quieter, and your users will notice the difference.",
    "readingTime": 4,
    "keywords": [
      "functional programming",
      "discriminated unions",
      "smart constructors",
      "pattern matching",
      "domain rules",
      "pure functions",
      "code",
      "cannot",
      "compiler",
      "billable"
    ],
    "qualityScore": 1,
    "link": "https://blog.rastrian.dev/post/why-reliability-demands-functional-programming-adts-safety-and-critical-infrastructure",
    "thumbnail_url": "https://rastrian.dev/assets/img/profile.png",
    "created_at": "2025-12-28T01:03:21.884Z",
    "topic": "tech"
  },
  {
    "slug": "a-guide-to-claude-code-20-and-getting-better-at-using-coding-agents",
    "title": "A Guide to Claude Code 2.0 and getting better at using coding agents",
    "description": "A deep dive into Claude Code 2.0 features, Opus 4.5 workflows, and context engineering. Learn sub-agents, MCP servers, hooks, skills, and practical tips to boost your AI-assisted coding productivity.",
    "fullText": "This post is a follow-up to my post from July'25 - My Experience With Claude Code After 2 Weeks of Adventures. If you are new to Claude Code or just want a quick refresh, I am once again asking you to go through it. It covers some lore, my workflow back then and then 80-90% of the Claude Code standard workflow. You may choose to skip the intro although I recommend you read it. Lore is important man.\n\nA short recap - we had covered CLAUDE.md, scratchpad, using task tool (now sub-agents), the general plan + execute workflow, tips for context window management, Sonnet 4 vs Opus 4 (not relevant now), using shortcuts like ! and using Shift + ? to show shortcuts, memory basics, /resume to restart conversation and short discussion on custom commands.\n\nI got a great response on my Opus 4.5 vibe-check tweets and still receieving good feedback on my July blog post (despite being somewhat poorly written). This shows there's clearly a demand for in-depth resources around Claude Code.\n\nI noticed that lots of people, both technical and many non-technical or less hands-on people i.e technically-lite people have started to try Claude Code (CC). CC is more of a general agent - you can use it for tasks other than coding as well - like making an excel invoice, data analysis, errands on your machine etc. And of course everything I talk about is by default meant for coding too.\n\nIf you can learn even 3-4 ideas that help you with using Claude Code (or other tools like Codex/Gemini CLI/OpenCode) or improve your understanding of LLMs, it would be a win for me.\n\nI don't want this post to be a prescription (map). My objective is to show you what is possible and the thought processes and simple things you can keep in mind to get the most out of these tools. I want to show you the map but also the territory.\n\nClaude Code dominated the CLI coding product experience this year and all the CLI products like Codex, OpenCode, Amp CLI, Vibe CLI and even Cursor have heavily taken inspiration from it. This means learning how things work in Claude Code directly transfers to other tools both in terms of personal usage and production grade engineering.\n\nKarpathy sensei posted this which caused the Twitter timeline. This led to a lot of discussion and there were some really good takes - some which I have written about too.\n\nIt's a reasonable crashout - the technology is evolving at a mindblowing pace and it's difficult to keep up for most of us and especially for senior folks and people with high quality standards. Nevertheless, I think if you are reading this post, it's scary but also exciting time to build stuff at speeds never possible before.\n\nInstead of thinking in terms of \"keeping up\", a better framing is how can I improve myself with help of these tools i.e augment.\n\nIn my opinion, there are 3 components to augment yourself:\n\nStay updated with tooling - What Karpathy sensei mentioned. Use these tools regularly and keep up with releases. I have been doing this regularly; it can be draining but I enjoy the process and I have the incentive that it helps me at my job. For the technically lite, even weekly/monthly updates would help.\n\nUpskill in your domain - It's a great time to spread both vertically (domain depth) and horizontally (adjacent areas). The more you know, the better you can prompt - converting unknown unknowns to known unknowns. Experience builds judgement and taste - that's what differentiates professional devs from vibe-coders. Since implementation is much faster now, you can spend more time on taste refinement.\n\nFor software engineering folks, this might mean getting better at good practices, system design, planning - where more thinking is involved. Ask more questions, run more experiments (since you can iterate fast), spend more time on understanding requirements. Using good software engineering practices to create better feedback loops for LLMs (good naming, refactoring, docs, tests, typed annotations, observability etc.). Review code. Please don't forget to come back to my post lol but I liked Addy Osmani's take on this.\n\nThe idea is to let the LLM perform things with input, get output and see errors.\n\nAs an aside, getting better at articulating thoughts via writing helps. One may also try touch typing/writing using speech-to-text tools to operate faster.\n\nThis post will act as a guide for things Karpathy said but you'll need to play around, build intuition and achieve outcomes with help of these tools yourself. The good news is it's fun.\n\nI am having a great time with Claude Code 2.0 since the launch of Opus 4.5 and it's been my daily driver since then. Before we go all lovey-dovey about Claude, I wanted to quickly go through the timeline and lore. I love yapping in my blog and I feel it's important to set the context here.\n\n2025 saw release of many frontier models by OpenAI and Anthropic. Also, it's super under-talked but OpenAI actually caught up to Anthropic in code-generation capability - intelligence wise, context window effectiveness, instruction following and intent detection.\n\nIt's been a wild year and honestly speaking I got tired of trying out new releases by OpenAI every 2 weeks.\n\n>no swe-bench-verified comparison\n>no comparison against opus 4.5\n>\"we are topping in cybersecurity\"\n>mfw i realise i am the fucking eval https://t.co/4oDG3yj6CP pic.twitter.com/aUfJfwROCf\n\nThere have been several Open Source competitors like GLM-4.7, Kimi-K2, Minimax-2.1. The space is very competitive and there is definitely an audience that uses the cheaper priced but high performant Chinese models for low-medium difficulty tasks.\n\nThat said, I still think Anthropic/OpenAI lead over Chinese Frontier models. The latter have contributed \n\n(Note: I am talking with respect to personal coding usage, not production API usage for applications).\n\nI was using Claude Code as my main driver from late June to early September. I cancelled my Claude Max (100 USD/month) sub in early September and switched to using OpenAI Codex as my main driver. Switch was driven by two factors -\n\nclaude code is more enjoyable as a product and has more features. i have always felt to try out more things related to automation in cc as compared to codex. once they drop a new iteration i would consider getting a max sub again if its better than gpt-5-codex\n\nAnthropic also had tonne of API outages and at one point of time they had degradation due to inference bugs. This also was a major driver for several people to move to the next best alternative i.e Codex or GPT-5.1 on Cursor.\n\nI was using Codex (main driver) and Cursor (never cancelled) until late October. Claude Sonnet 4.5 had released on 29th September along with Claude Code 2.0.. and I did take a 20 USD sub from another email account of mine to try it out (I had lots of prompting work and Claude models are my preferred choice) but GPT-5/GPT-5-codex were overall better despite being slow.\n\nSonnet 4.5's problem was fast and good but it would make many haphazard changes which would lead to bugs for me. In other words, I felt it to be producing a lot of slop in comparison to GPT-5.1/GPT-5.1-codex later.\n\nAround October 30, Anthropic sent an email saying we are offering the 200 USD max plan to users who cancelled the subscription and obviously I took it.\n\nchat please remind me to cancel after 28 daysüòÇ pic.twitter.com/TSGidVJ2xo\n\nMy Claude Code usage was still minimal but on 24th November, they launched Opus 4.5 and I had 5 days to try out Opus 4.5. I used the hell out of it for my work and also wrote this highly technical blog with the help of it discovering several of its capabilities.\n\nI had done a similar tweet when I had switched to GPT-5.1 which had gotten half the response of this one. This indicated to me that more people resonated with Opus 4.5 (at least on Twitter) back then. Also, many people were just not able to realise GPT-5.1's capabilities tbh.\n\nOther than the above State of the Art at the coding benchmarks like SWE-bench-verified (code-generation), Tau Bench (agentic stuff), Opus 4.5 was faster, at-par in coding, super collaborative and good at communication. These factors led to my conversion. It had good vibes. More comparison points later in the post.\n\nAs I described in the screenshot, Opus 4.5 was roughly at same code-gen capability with GPT-5.1-Codex-Max.\n\nToday, in my experience I think GPT-5.2-Codex exceeds Opus 4.5 in raw capability by a small margin. Still, Opus 4.5 has been my main driver since release.\n\nI think first reason is it's faster and can do similar difficulty tasks in much lesser time than Codex. Also, it's overall\na much better communicator and pair-programmer than Codex which can even ignore your instructions at times (and go and make changes). Opus has better intent-detection as well.\n\nOne nice-use case shown here by Thariq on creating a background async agent to explain changes to a non-technical person leveraging Claude's explanation abilities.\n\nTo further demonstrate the difference, here's a CC vs Codex comparison\n\nFor the same prompt, see the outputs. Codex tends towards super concise while Claude matches my expectation.\nYou can modify the verbosity in Claude's case but Codex won't budge. Another thing I want to highlight is\nthe UI itself - Claude has more saturated white color on black whereas Codex's text is thinner/less readable\nand the thinking traces are shown in even lighter shade which I don't like.\n\nBecause of being faster not only in terms of lesser thinking to perform task but throughput wise also, it unlocks\nmuch faster feedback loops for your tasks. This makes progress feel more visceral even though capability wise, GPT-5.1/Codex were at par even in November.\nThe only downside with faster loop is if you are cautious, you end up micro-managing for long hours.\n\nOpus 4.5 is a great writer and comes closest to humans so I have always preferred Claude models for customizing prompts.\n\nBesides the model, obviously the Claude Code Product goes a long way to make things magical.\n\nAs a product it's a mile ahead of Codex in QoL features. The harness, prompts and the model make for a magical experience. The model is amazing but there is a massive amount of tasteful engineering that has gone into UX/UI and just the code/prompts to let Claude feel comfortable in the harness and make function calling accurate. We will explore this \n\nBefore we move ahead - my previous post somehow reached Hackernews #5 and I was facing allegations that my post was sponsored by Anthropic. I was like bro are you serious? Anthropic doesn't sponsor random users like me. Anthropic doesn't even think about me (meme.jpeg) besides from a user point of view.\n\nBesides praise, I have been snarky, made fun of outages, made a lot of fun of Sonnet 4.5 slop. I have expressed what I have felt over time and it's led to good discourse on the timeline as well.\n\nAll this said, Claude Code has been one of the most enjoyable product experiences I have ever had. I am grateful and highly respect the engineering and research team behind it.\n\nThat's enough yapping. In the next few sections, I will talk about useful features that I didn't talk about in my previous blog and notable features introduced in the iterations from Claude 2.0 - 2.074.\n\ncurrently using Claude Code for the first time, I can officially put \"Technical-lite\" on my resume now\n\nI am assuming several technical-lite people are gonna read this. Few concepts to help comprehension later in the blog -\n\nMore specifically, context is the input tokens. The context window refers to the maximum amount of tokens that an LLM can see and process at once during a conversation. It's like the model's working memory. Opus 4.5 has a 200K context window which is approximately 150,000 words.\n\nTool calling - Learn about tool calling. Here's a good resource. You know that LLMs can generate text but what if you want the LLM to perform an action - say draft an email or lookup the weather on the internet or just do google search. That's where tools come in. Tools are functions (in code or skills) defined by the engineer that do these exact things. We define tools and we let the LLM know about it in the system prompt and it can decide which tool to call when you are chatting with it! Once the tool call i.e the action is performed, the results are relayed back to the LLM.\n\nAgent - The simplest definition is an LLM that can pro-actively run tools to achieve a goal. For a more sophisticated definition, I like the one by Anthropic\n\n\"Agents, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.\" from Building Effective Agents.\n\n\"Agentic\" - refers to the tool calling capabilities of the model - how pro-active, how accurate the tool calling is (detecting user's intent to perform the action, choosing the correct tool, knowing when to stop)\n\nHarness/scaffolding - Sonnet 4.5/Opus 4.5 are the models. They need to be provided with lots of \"scaffolding\" / layers of code, prompts, tool calls and software packaging/environment to make them work in a semi-autonomous fashion. Note that Claude Code is not a harness, it's a product (think the TUI, integrations etc.). Claude Code has a harness.\n\nClaude Code has had lots of AI features and quality of life improvements since July. Let's look at the ones that I found to be useful. You can see all changes in the Changelog.\n\nAsk mode options - Another thing I like is Option 3 when it asks questions in the syntax highlighting image above - \"Type here to tell Claude what to do differently\". Fun fact: All these are really prompts for the model whose output is parsed by another tool call and shown in this way.\n\nUltrathink - I like to spam ultrathink for hard tasks or when I want Opus 4.5 to be more rigorous e.g. explaining me something, self-reviewing its changes\n\nThinking toggle - Tab to toggle thinking on/off was a good feature. They changed it to Alt/Option + Tab recently but there's a bug and it does not work on Mac. Anyways CC defaults to thinking always true if you check in your settings.json\n\nPrompt history search - Search through prompts using Ctrl + R (similar to terminal backsearch). I have it in 2.0.74. It can search across project wide conversations. Repeatedly do Ctrl + R to cycle through results.\n\nCursor cycling - When you reach beginning/end of prompt, press down/up to cycle around\n\nMessage queue navigation - It's possible to navigate through queued messages and image attachments (2.0.73) now (idk if it's possible to display image attachment as well).\n\nFuzzy file search - File suggestion is 3x faster and supports fuzzy search (2.0.72)\n\nLSP support was added recently. Access via plugins.\n\nThere have been new integrations too like Slack Integration, Claude Web (beta), Claude Chrome extension. These are pretty obvious and I won't cover these. I think Claude Web would be interesting for many particularly (since you can launch tasks from iOS/Android too).\n\nNext few sub-sections are all about most used features.\n\nI didn't cover commands properly in my previous blog post. You can use / to access the built-in slash commands. These are pre-defined prompts that perform a specific task.\n\nIf these don't cover a specific task you want, then you can create a custom command. When you enter a command, that prompt gets appended to the current conversation/context and the main agent begins to perform the task.\n\nCommands can be made on a project level or global level. Project level resides at .claude/commands/ and global one at ~/.claude/commands.\n\nOften when the context window starts getting full or I feel the model is struggling with a complex task, I want to start a new conversation using /clear. Claude provides /compact which also runs faster in CC 2.0 but sometimes I prefer to make Claude write what happened in current session (with some specific stuff) before I kill it and start a new one. I made a /handoff command for this.\n\nIf you find yourself writing a prompt for something repetitively and instructions can be static/precise, it's a good idea to make a custom command. You can tell Claude to make custom commands. It knows how (or it will search the web and figure it out via claude-code-guide.md) and then it will make it for you.\n\nYou can find a bunch of commands, hooks, skills at awesome-claude-code though I recommend to build your own or search for one only when it's really required.\n\nI have a command called bootstrap-repo that searches the repo with 10 parallel sub-agents to create a comprehensive doc. I rarely use it these days and so many parallel sub-agents lead to the Claude Code flickering bug lol.\n\nAnyways, notice the \"Explore\" sub-agent and \"running in background\".\n\nSub-agents were introduced shortly after I published my last blogpost. Sub-agents are separate Claude instances that are spawned if the main agent wishes so or you explicitly tell it to do so. These powers are defined already in system prompt and sometimes you just have to remind... Understanding these features will help you micro-manage Claude haha.\n\nYou can also define your custom sub-agents. To create one:\n\nOr just use /agents to manage and create sub-agents automatically - recommended approach.\n\nThe \"Explore\" thing in above pic is a sub-agent. You can tell Claude \"Launch explore agent with Sonnet 4.5\" if you want it to use Sonnet instead of Haiku (I found this by just trying things out but we will see how this happens)\n\nThe Explore agent is a read-only file search specialist. It can use Glob, Grep, Read, and limited Bash commands to navigate codebases but is strictly prohibited from creating or modifying files.\n\nYou will notice how thorough the prompt is in terms of specifying when to use what tool call. Well, most people underestimate how hard it's to make tool calling work accurately.\n\nThis is the Explore agent prompt from 2.0.56 and it should be similar now too. Reference. These are captured by intercepting requests. Reference video.\n\nIn case of Explore sub-agent, it starts with a fresh slate which makes sense. It does not inherit any context from main agent. Many tasks involve searching through large amounts of digital media or code to filter for something relevant. Often the individual parts are independent of each other when you want to filter for something so launching parallel agents makes sense.\n\nIf I am trying to understand a feature or just looking up simple things in the codebase, I let Claude do the Explore agent searches. Explore agent passes a summary back to the main agent and then Opus 4.5 will publish the results or may choose to go through each file itself. If it does not, I explicitly tell it to.\n\nIt's important that the model goes through each of the relevant files itself so that all that ingested context can attend to each other. That's the high level idea of attention. Make context cross with previous context. This way model can extract more pair-wise relationships and therefore better reasoning and prediction. Explore agent returns summaries which can be lossy compression. When Opus 4.5 reads all relevant context itself, it knows what details are relevant to what context. This insight goes a long way even in production applications (but you only get it if someone tells you or you have read about self-attention mechanism).\n\nCodex does not have a concept of sub-agents and it's probably a conscious decision by the devs. GPT-5.2 has a 400K context window\nand according to benchmarks, it's long context retrieval capabilities are a massive improvement. Although people have tried\nmaking Codex use headless claude as sub-agents haha. You can just do things.\n\nThe general-purpose and plan sub-agent (separate from plan mode) inherit the context. With respect to user defined sub-agents, I am not sure but I think they start with clean slate.\n\nFrom the reverse engineered resources/leaked system prompt, it's possible to see that the sub-agents are spawned via the Task tool.\n\nTurns out you can ask Claude too. (I think the developers are allowing this now?). It's not a hallucination. The prompt pertaining to pre-defined tools are there in the system prompt and Claude code dynamically injects reminders/tools often to the ongoing context.\n\nTry these set of prompts with Opus 4.5\n\nYou will get the output something like below (click) but to summarise -\nIt defines 5 agent types: general-purpose (full tool access, inherits context), Explore (fast read-only codebase search), Plan (software architect for implementation planning), claude-code-guide (documentation lookup), and statusline-setup. Notice how each sub-agent is defined with its specific use case and available tools. Also notice the \"When NOT to use\" section - this kind of negative guidance helps the model avoid unnecessary sub-agent spawning for simple tasks.\n\nI want you to focus on the tool schema. The Task tool prompt above is detailed guidance on how to use the tool that resides in the system prompt. The tool schema defines the tool or the function.\n\nThe main agent calls the Task tool to spawn a sub-agent, using its reasoning to decide the parameters. Notice the model parameter - when I say \"Use Explore with Sonnet\", the model makes the tool call with model: \"sonnet\".\n\nTill August'25 or so, Claude Code used to show the Task tool performing actions in the TUI but now TUI shows the sub-agent name instead.\n\nNotice the run_in_background parameter. It decides whether to send a sub-agent to run in the background. I like the background process feature - it is super helpful for debugging or just monitoring log outputs from process. Sometimes you have a long running python script that you wanna monitor etc.\n\nModel usually automatically decides to put a process in background but you can explicitly tell it to do so. Note that \"Background Tasks\" is different. Using an & sends a task to Claude Web (should have named it Claude Cloud haha). I am yet to get this to work properly.\n\nI have a pretty simplish/task based workflow: CC as the main driver, Codex for review and difficult tasks, and Cursor for reading code and manual edits. I rarely use Plan Mode. Instead, once requirements are clear enough, I explore the codebase to find the relevant files myself.\n\nOpus 4.5 is amazing at explaining stuff and makes stellar ASCII diagrams. The 2025 Aug knowledge cutoff helps here too. So my exploration involves asking lots of questions‚Äîclarifying requirements, understanding where/how/why to make changes. It might be less efficient than Plan Mode, but I like this approach.\n\nOnce I have enough context, I spam /ultrathink and ask it what changes are required and then if things look ok, I start the execution closely monitoring the changes - basically micro-managing it. I sometimes ask Codex's second opinion here lol.\n\nFor difficult new features, I sometimes use a \"throw-away first draft\" approach. Once I understand what changes are needed, I create a new branch and let Claude write the feature end-to-end while I observe. I then compare its output against my mental model as to how close did it get to my requirements? Where did it diverge? This process reveals Claude's errors and the decisions/biases it made based on the context it had. With the benefit of this hindsight, I run another iteration, this time with sharper prompts informed by what I learned from the first pass. Kinda like Tenet.\n\nFor backend-heavy or just complex features specifically, I'll sometimes ask Codex xhigh to generate the plan instead.\n\nI maintain a few custom commands, use CLAUDE.md and scratchpad extensively. No custom sub-agents. I use MCP sometimes if need shall arise (e.g for docs. I have tried Playwright and Figma MCP so far) but in general not a fan. I have used hooks for simple stuff in the past and need-basis. skills/plugins are something that I am yet to use more regularly. I often use background agents for\nobservability (monitoring log / error) purposes. I rarely use git worktrees.\n\nIt's worth noting that the harness is so heavily engineered that Claude knows which sub-agent to spawn, what command/tool call/skill to run, what to run in async manner. It's able to heavy carry the agent loop that your task is mainly to use your judgement and prompt it in right direction. The next generation of models will get better and the relevant scaffolding will reduce for existing feature and increase for newer features. (Re: contrasting to Karpathy sensei's latest tweet shown at beginning)\n\nIt's not at all required to know the features in depth to be honest. However knowing how things work can make you a better micro-manager if the need arises like telling the Explore agent to use Sonnet.\n\ngetting claude opus 4.5 changes reviewed by gpt-5.1-codex-max high pic.twitter.com/A4tYN3W3Q6\n\nFor reviewing code and finding bugs, I find GPT-5.2-Codex is superior. Just use /review. Better than code review products too.\n\nIt's able to find bugs and mention severity like P1, P2. It's less likely to report false-positives and more trustable when it comes to confusing changes as compared to Claude. This Claude for execution and GPT/o-series model for review/bugs dynamic has been pretty constant for me for probably a year.\n\nNow is a good time to take a breath and refresh your context window. Before we get to the next set of features, it's worth\ngoing through context management fundamentals. Things might get a bit difficult for the technically-lite folks.\nDon't give up. Read through the post. Even ask Claude to explain stuff you don't understand.\n\nAn agent in a harness can pro-actively do a lot of tool calls to read your codebase and other inputs, edit stuff, make writes etc. In this process, they can produce a lot of data which gets added to the running conversation i.e the context window. Anthropic refers to this art and science of curating what will go into the limited context window from this information as context engineering.\n\nYou may ask how are tool calls adding tokens to the context window? The flow works like this:\n\nThe key thing to note here is that both the tool call and the tool call outputs are added to the context so that the LLM can know the results. This is because LLMs are stateless. They don't have memory outside the context window. Let's say you have n messages in a conversation. When you send the next message, the request will again process n + 1 messages in the LLM ~ single context window.\n\nIf you don't add information about the chosen tool call was, LLM won't know and if you don't plug the output, then it won't know\nthe outcome. The tool call results can quickly fill your context and this is why agents can get super expensive too.\n\nI quote directly from effective-context-engineering-for-ai-agents\n\nContext refers to the set of tokens included when sampling from a large-language model (LLM). The engineering problem at hand is optimizing the utility of those tokens against the inherent constraints of LLMs in order to consistently achieve a desired outcome. Effectively wrangling LLMs often requires thinking in context ‚Äî in other words: considering the holistic state available to the LLM at any given time and what potential behaviors that state might yield.\n\nContext engineering is about answering \"what configuration of context is most likely to generate our model's desired behavior?\"\n\nEverything we have discussed so far comes under context engineering. Sub-agents, using a scratch, compaction are obvious examples\nof context management methods used in Claude Code. Some notes around why context engineering is needed -\n\nLimited context window - The context retrieval performance of LLMs degrades as every new token is introduced. To paraphrase the above blog - think of context as a limited \"attention budget\". This is a consequence of the attention mechanism itself as it gets harder to model the pairwise relationships - think of it like getting harder to focus on things far apart.\n\nGPT-5.2 has a context window of 400K input tokens. Opus 4.5 has 200K. Gemini 3 Pro has a 1M context window length. Now the effectiveness of these context windows can vary too, just the length doesn't matter. That said if you want to ask something\nfrom a 900K long input, you would be able to most reliably do that only with Gemini 3 Pro.\n\nContext rot article goes deep into some experiments which showed performance\ndrops with length and not task difficulty.\n\nA rough corollary one can draw is effective context windows are probably 50-60% or even lesser.\nDon't start a complicated task when you are half-way in the conversation. Do compaction or start a new one.\n\nEverything being done in prompts and code we have seen so far has been to -\n\nThe next few sections showcase features and implementation that are designed for\nbetter context management and agentic performance.\n\nI am personally not a fan of MCP servers but we gotta cover it. MCP servers are servers that can be hosted on your machine or remotely on the internet. These may expose filesystem, tools and integrations like CRM, Google Drive etc. They are essentially a way for models to connect to external tools and services.\n\nIn order to connect to MCP server, you need a host (Claude) which can house the MCP client. The MCP client\ncan invoke the protocol to connect. Once connected, the MCP client exposes tools, resources, prompts provided by server.\n\nThe tool definitions are loaded upfront into the context window of host bloating the context window.\n\nI like the idea of Code Execution with MCP even though it's propanda for more token consumption.\n\nQuoting Code execution with MCP:\n\nAs MCP usage scales, there are two common patterns that can increase agent cost and latency:\n\nMCP usage scale implies more MCP clients ~ more tool call definitions in context window.\n\nMCP Code exec suggests instead of direct tool calls, expose code APIs rather than tool call definitions and give Claude\na sandbox execution environment with a filesystem. Then let it write code to make the tool calls.\nIt is an elegant idea and is pretty similar to skills in the sense it's \"prompt on demand\"\n\nQuoting from Manus's Context Engineering Lesson blog:\n\nManipulate Attention Through Recitation\n\nIf you've worked with Manus, you've probably noticed something curious: when handling complex tasks, it tends to create a todo.md file‚Äîand update it step-by-step as the task progresses, checking off completed items.\n\nThat's not just cute behavior‚Äîit's a deliberate mechanism to manipulate attention.\n\nA typical task in Manus requires around 50 tool calls on average. That's a long loop‚Äîand since Manus relies on LLMs for decision-making, it's vulnerable to drifting off-topic or forgetting earlier goals, especially in long contexts or complicated tasks.\n\nClaude Code has todo lists but they don't show them now. Now you know part of the logic for it.\n\nClaude Code also tries something similar via plugging reminder tags into user messages and tool results. Some of them are mentioned in tool descriptions, other reminders are added at runtime via code.\n\nI asked Claude about what system reminders are present in the system prompt.\n\nFor reference, an older version of CC 2.0.56 used to have this detailed reminder system-reminder-plan-mode-is-active.\n\nI think Armin talks about this in his post What Actually Is Claude Code‚Äôs Plan Mode? when he refers to recurring prompts to remind the agent.\n\nIf you look at the leaked prompts, you will notice there are like 2-3 prompts for plan mode and 2-3 tool schemas like ENTRY_PLAN_MODE_TOOL, EXIT_PLAN_MODE_TOOL. The latter would write down the output into a markdown file\nwhich you can access via /plan. Everything is a markdown.\n\nAnthropic introduced Agent Skills recently and these got recently adopted by Codex too. A skill\nis a folder containing a SKILL.md file, other referenceable files and code scripts that do some user-defined task.\n\nThe SKILL.md contains some meta-data via which LLM can know what skills are available (meta-data is added to system prompt)\nIf Claude feels the skill is relevant, it will perform a tool call to read the contents of skill and download the\ndomain expertise just like Neo in Matrix 1999. The code scripts may contain tools that Claude can use.\n\nNormally, to teach domain expertise, you would need to write all that info in system prompt and probably\neven tool call definitions. With skills, you don't have to do that as the model loads it on-demand.\nThis is especially useful when you are not sure if you require those instructions always.\n\nThe popular frontend-design plugin is actually a skill. You can check here\n\nHooks are available in Claude Code and Cursor. They allow you to observe when a certain stage in the agent loop\nlifecycle starts or ends and let you run bash scripts before or after to make changes to the agent loop.\n\nThere are hooks like Stop, UserPromptSubmit etc. For instance Stop hook runs after Claude finishes responding and the UserPromptSubmit hook runs when user submits a prompt before Claude processes it.\n\nThe first hook I created was to play an anime notification sound when Claude stopped responding. I was obviously inspired\n\nOne funny use case to run Claude for hours might be running a \"Do more\" prompt when Claude finishes current task\nvia the Stop hook.\n\nI came across this post during my research for this blog post. This person beautifully combined the concepts and features we discussed so far. They combine hooks to act as reminders for skills. If the utility/requirement arises, there's a lot of space for customization. You might not need such heavy customization but can at least take inspiration. (Speaking for myself lol)\n\nAnthropic recommends to keep skill.md under 500 lines so they divided it into separate files and combined with hooks and\nreduced the size of their CLAUDE.md.\n\nHopefully you learnt a bunch of things from this super long post and will apply the learnings not only in CC\nbut other tools as well. I feel a bit weird writing this but we are going through some transformative times.\nThere are already moments when I almost feel like a background agent and then other times when I feel smart when the models couldn't solve a particular bug.\n\nclaude and codex to me when i realise i am the background agent pic.twitter.com/wkihYFQmQM\n\nI no longer look forward to new releases because they just keep happening anyways (shoutout to OpenAI). Deepseek and Kimi K3 are in the queue.\n\nI am expecting improvements in RL training, long context effectiveness via maybe new attention architectures, higher throughput models, lesser hallucination models.\nThere might be a o1/o3 level reasoning breakthrough or maybe something in continual learning in 2026. I look forward to these but at the same time\nI find it scary because more significant capability unlock will make the world unpredictable haha.\n\nIf you found this useful, try one new feature from this post today. Happy building!\n\nThanks for reading. Please like/share/RT the post if you liked it.",
    "readingTime": 30,
    "keywords": [
      "claude code",
      "karpathy sensei",
      "stop hook",
      "mcp client",
      "anthropic doesn't",
      "mcp servers",
      "feedback loops",
      "spam ultrathink",
      "monitoring log",
      "domain expertise"
    ],
    "qualityScore": 1,
    "link": "https://sankalp.bearblog.dev/my-experience-with-claude-code-20-and-how-to-get-better-at-using-coding-agents/",
    "thumbnail_url": "https://bear-images.sfo2.cdn.digitaloceanspaces.com/sankalp/dario-2.webp",
    "created_at": "2025-12-28T01:03:19.149Z",
    "topic": "tech"
  },
  {
    "slug": "codenhack-a-free-gamified-inbrowser-coding-platform",
    "title": "Codenhack ‚Äì A free, gamified, in-browser coding platform",
    "description": "A coding practice website for all programming levels ‚Äì Join a community and learn from experienced developers.",
    "fullText": "Dive into the world of programming with our learning platform. Break through the matrix and emerge as a coding legend.\n\nBecause you learn faster when you build. With interactive courses, guided projects, and a vibrant community, Codenhack helps you go from beginner to builder, all inside your browser\n\nDive into structured learning paths with chapters and lessons designed to take you from beginner to expert.\n\nApply your knowledge by building production-ready projects. From web applications to Quantum Robot systems, we cover it all.\n\nShare your knowledge, insights, and experiences with our global community of developers. Create engaging blog posts, tutorials, and guides.\n\nShare your knowledge, insights, and experiences with our global community of developers. Create engaging blog posts, tutorials, and guides while learning from others in the field.\n\nMaster coding through interactive lessons. Read, practice, see instant results, and test your understanding‚Äîall in one seamless learning experience.\n\nStart your learning journey with a concise introduction that sets the context and prepares you for hands-on practice.\n\nWatch your code come to life in real-time with our live preview feature. See instant visual feedback as you write and modify your code, making learning interactive and engaging.\n\nPractice coding directly in our interactive terminal. Get real-time feedback as you build your skills through hands-on experience with command-line tools.\n\nReinforce your learning through reflection and self-assessment. Test your understanding and confidently progress to the next challenge.\n\nMaster the most powerful programming languages and take your skills to the next level. Whether you're a beginner or an expert, there's always something new to learn. Start your journey today!\n\nExplore our cutting-edge curriculum designed to transform beginners into elite coders ready for the digital future.\n\nThe foundation of the digital grid ‚Äì structure beneath the neon skyline.\n\nDesign the web like a chrome-plated city. Style with flair.\n\nMake the neon signs blink, the systems dance ‚Äì control the DOM in real-time.\n\nHear from the cyberpunks who've leveled up their coding skills and transformed their careers.\n\n\"I was impressed by how Codenhack blends programming with a cyberpunk vibe ‚Äî it makes learning way more exciting\"\n\n\"Codenhack makes it feel like you're not just learning ‚Äî you're discovering tools to break through the system. Even as a beginner, I'm already building small hacks and projects that actually do stuff. That feeling? Wild.\"\n\n\"Codenhack helped me turn boring code into something that actually looks good. Playing with HTML and CSS here feels like crafting my own digital art ‚Äî and I'm just getting started\"\n\n\"I love that Codenhack lets me preview my work instantly ‚Äî it's super satisfying to see my code come alive right away.\"",
    "readingTime": 3,
    "keywords": [
      "developers create",
      "create engaging",
      "blog posts",
      "posts tutorials",
      "knowledge insights",
      "learning",
      "coding",
      "interactive",
      "beginner",
      "programming"
    ],
    "qualityScore": 1,
    "link": "https://codenhack.com/",
    "thumbnail_url": "https://pub-49e1acf3b61b485e8f14983f79b20721.r2.dev/app_images/helpcenter.png",
    "created_at": "2025-12-26T12:22:24.821Z",
    "topic": "tech"
  },
  {
    "slug": "apples-app-course-runs-20k-a-student-is-it-worth-it",
    "title": "Apple's App Course Runs $20k a Student. Is It Worth It?",
    "description": "Apple, Michigan taxpayers, and one of Detroit‚Äôs wealthiest families spent roughly $30 million training hundreds of people to build iPhone apps. Not everyone lands coding jobs right away.",
    "fullText": "Lizmary Fernandez took a detour from studying to be an immigration attorney to join a free Apple course for making iPhone apps. The Apple Developer Academy in Detroit launched as part of the company‚Äôs $200 million response to the Black Lives Matter protests and aims to expand opportunities for people of color in the country‚Äôs poorest big city.\n\nBut Fernandez found the program‚Äôs cost-of-living stipend lacking‚Äî‚ÄúA lot of us got on food stamps,‚Äù she says‚Äîand the coursework insufficient for landing a coding job. ‚ÄúI didn‚Äôt have the experience or portfolio,‚Äù says the 25-year-old, who is now a flight attendant and preparing to apply to law school. ‚ÄúCoding is not something I got back to.‚Äù\n\nSince 2021, the academy has welcomed over 1,700 students, a racially diverse mix with varying levels of tech literacy and financial flexibility. About 600 students, including Fernandez, have completed its 10-month course of half-days at Michigan State University, which cosponsors the Apple-branded and Apple-focused program.\n\nWIRED reviewed contracts and budgets and spoke with officials and graduates for the first in-depth examination of the nearly $30 million invested in the academy over the past four years‚Äîalmost 30 percent of which came from Michigan taxpayers and the university‚Äôs regular students. As tech giants begin pouring billions of dollars into AI-related job training courses across the country, the Apple academy offers lessons on the challenges of uplifting diverse communities.\n\nSeven graduates who spoke with WIRED said they had good experiences at the academy, citing benefits such as receiving mentorship from past students. Fernandez says she was impressed by a focus on developing inclusive apps and a series of speakers from Apple who were genuinely willing to help and share frank lessons. ‚ÄúTheir heart was in the right place,‚Äù she says.\n\nThe program does expose people of color to new possibilities. ‚ÄúIt changed my life,‚Äù says Min Thu Khine, who‚Äôs now mentoring coding students and working at an Apple Store Genius Bar. ‚ÄúMy dream is to be a software engineer at Apple.‚Äù\n\nThe academy also draws positive grades from some researchers who study tech education, such as Quinn Burke. He says its fully subsidized in-person instruction surpasses the quality of many coding boot camps, which proliferated over the past decade and sometimes left students in debt and with narrow skills.\n\nBut the academy being open to all can complicate instruction and how to measure success. One entire family attended together, and at least two mothers have come with their daughters. Students on average are in their thirties, ranging from 18-year-olds to, for example, a grandfather in his seventies who wanted to develop a photo app for his grandchild, according to Sarah Gretter, the academy leader for Michigan State.",
    "readingTime": 3,
    "keywords": [
      "students",
      "coding",
      "tech",
      "academy",
      "course",
      "apps",
      "color",
      "diverse",
      "program",
      "wired"
    ],
    "qualityScore": 1,
    "link": "https://www.wired.com/story/apple-app-making-course-michigan-state-university/",
    "thumbnail_url": "https://media.wired.com/photos/69406bdd9f9b98727b285b83/191:100/w_1280,c_limit/Apples-App-Making%20Course-Costing-20k-A-Student-Business-2225891099.jpg",
    "created_at": "2025-12-26T06:19:00.674Z",
    "topic": "tech"
  },
  {
    "slug": "keystone-yc-s25-is-hiring-engineer-1-to-automate-coding",
    "title": "Keystone (YC S25) is hiring engineer #1 to automate coding",
    "description": "About Keystone\nWe're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.\nWe're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.\nWe're in-person in SoMa, San Francisco.",
    "fullText": "We're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.\n\nWe're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.\n\nWe're in-person in SoMa, San Francisco. We raised a $5.2M seed from True Ventures, Twenty Two Ventures, Pear VC, and Ritual Capital- plus the founders of YC, Dropbox, Supabase, Eight Sleep, Graphite, Resend, RocketMoney, and more. Early design partners include teams at Perplexity and Lovable.\n\nYou'd be the first engineering hire, working directly with me (the founder) to build the core product. You'll have more ownership and influence over the product, culture, and technical direction than you'd get almost anywhere else.\n\nYou might be a great fit if you:\n\nStack: TypeScript, React (Next.js), Python, Postgres, Redis, AWS\n\nComp & benefits: Top-of-market salary + significant equity, full health/dental/vision, all meals covered, equipment budget",
    "readingTime": 2,
    "keywords": [
      "we're",
      "product",
      "logs",
      "ventures",
      "you'd"
    ],
    "qualityScore": 0.85,
    "link": "https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer",
    "thumbnail_url": "https://bookface-images.s3.amazonaws.com/logos/06e7837c1e5c8ce88da333ac2efcf401d8cbee53.png?1747973680",
    "created_at": "2025-12-25T00:56:12.872Z",
    "topic": "jobs"
  },
  {
    "slug": "the-guy-who-coined-vibe-coding-predicts-it-will-terraform-software-and-alter-job-descriptions",
    "title": "The guy who coined 'vibe coding' predicts it will 'terraform software and alter job descriptions'",
    "description": "Andrej Karpathy led AI at Tesla and cofounded OpenAI. He wrote that vibe coding has produced a new type of code that is \"free\" and \"discardable.\"",
    "fullText": "He coined \"vibe coding\" earlier this year. Now, he has something to say about it.\n\nAndrej Karpathy led AI at Tesla for five years, steering the company's Autopilot effort and briefly working on its humanoid robot Optimus. He sandwiched his Tesla job with two stints at OpenAI, making Karpathy a cofounder of the AI pioneer.\n\nAs 2025 comes to a close, Karpathy published his year-in-review for large language models on X. He reflected on the famous term he originated in February, a term that has since shaken up the software engineering industry.\n\n\"With vibe coding, programming is not strictly reserved for highly trained professionals,\" Karpathy wrote. He called it an example of how \"regular people benefit a lot more from LLMs compared to professionals, corporations and governments.\"\n\nVibe coding has likely benefited businesses, too. Tech companies have equipped their engineers with tools like Cursor, Claude Code, and OpenAI's Codex, aiming for productivity gains.\n\nKarpathy wrote that vibe coding \"empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written.\"\n\nIt may also change the makeup ‚Äî or the use case ‚Äî¬†of the code itself. Karpathy threw out a slew of adjectives to describe this new body of code: It is \"free, ephemeral, malleable, discardable after single use.\"\n\n\"Vibe coding will terraform software and alter job descriptions,\" he wrote.\n\nHow does Karpathy feel about being the term's origin?\n\n\"Amusingly, I coined the term \"vibe coding\" in this shower of thoughts tweet totally oblivious to how far it would go,\" he wrote.\n\nThere's a new kind of coding I call \"vibe coding\", where you fully give in to the vibes, embrace exponentials, and forget that the code even exists. It's possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisper‚Ä¶\n\nIt's not yet clear how efficient vibe coding is making engineers. In a METR study published in July, AI coding assistants were found to decrease the productivity of participating experienced software developers by 19%. The developers in that study were also overconfident in the tools, its authors said, expecting a 20% productivity boost even after using them.\n\nWhat is clear, though, is that the practice is unlocking a whole new form of tech products. Twitter founder Jack Dorsey vibe-coded a new messaging app this year. Non-technical workers are easily building, shipping, and, in some cases, even selling apps they build in hours, if not minutes.\n\nKarpathy gave some other reflections. He praised Google Gemini's Nano Banana image model, and wrote that Claude Code was the \"first convincing demonstration of what an LLM Agent looks like.\"\n\nOverall, Karpathy wrote that 2025 was an \"exciting and mildly surprising year of LLMs.\"",
    "readingTime": 3,
    "keywords": [
      "trained professionals",
      "vibe coding",
      "software",
      "llms",
      "productivity",
      "karpathy",
      "coined",
      "tesla",
      "published",
      "tech"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/andrej-karpathy-coined-vibecoding-ai-prediction-2025-12",
    "thumbnail_url": "https://i.insider.com/68f53bf05dbc4fd10dab1f5f?width=1200&format=jpeg",
    "created_at": "2025-12-23T18:17:54.745Z",
    "topic": "finance"
  },
  {
    "slug": "the-death-and-rebirth-of-programming",
    "title": "The Death and Rebirth of Programming",
    "description": "Programming didn't die all at once. There was no single moment, no dramatic obsolescence event. Instead, something quieter happened: the core constraint that shaped software for seventy years dissolved. Writing code stopped being the hard part.",
    "fullText": "For most of computing history, programming was bottlenecked by human cognition. Translating intent into working software required time, attention, and specialized skill. Even small changes were costly. This scarcity justified entire ecosystems: languages, frameworks, methodologies, reviews, team rituals that made sense when every line was expensive.\n\nGenerative AI removes that scarcity.\n\nToday, a single developer can generate thousands of lines of working code in minutes. Tomorrow, that number will be effectively infinite. The marginal cost of producing code is collapsing toward zero.\n\nWhat hasn't collapsed is the cost of knowing what the code does.\n\nUnderstanding, verifying, securing, and evolving software remain stubbornly expensive. In fact, they may be getting harder as volume explodes. This asymmetry‚Äîthe ease of creation versus the difficulty of comprehension‚Äîis the defining tension of modern software.\n\nProgramming hasn't disappeared. But its center of gravity has shifted.\n\nIn the old world, programmers owned code. You wrote it, you understood it, you maintained it. Your value was tied to mastery of specific implementations. Codebases accrued history, reputation, and power.\n\nIn the new world, ownership becomes a liability.\n\nWhen code can be regenerated faster than it can be understood, preserving it for sentimental or historical reasons no longer makes sense. What matters instead is stewardship: maintaining the system's behavior, boundaries, and intent over time, regardless of how many times its internals are replaced.\n\nThis reframing is subtle but profound:\n\nThe asset is no longer the codebase. The asset is the system's ability to keep working.\n\nThis is the thesis of everything that follows. Architecture, testing, interfaces, team structure: all of it flows from this inversion.\n\nMany of the \"modern\" software practices of the last decade were early adaptations to this shift, even if we didn't articulate them that way.\n\nImmutable infrastructure. Stateless services. Containers. Blue-green deployments. Infrastructure as code.\n\nThese ideas all share a common premise: never fix a running thing. Replace it.\n\nAI pushes this premise beyond infrastructure and into application code itself. When rewriting is cheap, editing in place becomes risky. Mutation accumulates entropy. Replacement resets it.\n\nDisposability stops being a hack. It becomes the default.\n\nThis transition isn't just technical. It's deeply psychological, and that psychology shapes architecture.\n\nMany developers identify as builders and craftspeople. We take pride in elegance, cleverness, and mastery of internals. We accumulate knowledge inside our heads and inside codebases. Longevity feels like validation.\n\nGenerative AI destabilizes this identity.\n\nWhen a machine can produce a competent version of \"your\" solution in seconds, craftsmanship no longer lies in the artifact. It lies in framing the problem, defining success, and deciding what to keep and what to discard.\n\nThe role shifts from maker to architect. From author to managing editor. From preserving code to designing for its replacement.\n\nThat shift is uncomfortable. And the discomfort isn't merely personal. It's what makes teams resist the very patterns that would help them. Developers cling to codebases because identity is at stake, not just technical judgment. Acknowledging this is the first step toward building systems that don't require heroics to change.\n\nResisting the shift doesn't stop it. It just makes systems more fragile.\n\nOne of the clearest signals of this new era is the rise of the n=1 developer.\n\nProjects that once required teams now fit inside a single person's cognitive boundary‚Äîwith AI filling in the execution gaps. Entire products can be specified, generated, evaluated, and shipped by one human working with machines.\n\nThis isn't about productivity hacks. It's about a structural change in leverage.\n\nBut n=1 development only works if systems are designed for it. Large, tangled, historically accreted codebases collapse under their own weight when AI accelerates change. Small, modular, disposable systems thrive.\n\nThe n=1 developer is not a superhero. They are an indicator species. They are evidence that the environment has changed, and proof that the new patterns actually work.\n\nIt's tempting to frame this as the \"end of programming.\" That's misleading.\n\nWhat's dying is a specific form of programming: one that equates value with authored code, longevity of code with quality, and maintenance with virtue.\n\nWhat's being born is something closer to systems design as an ongoing process of regeneration:\n\nCode becomes an intermediate artifact, not the final product. Rewrites become routine, not traumatic. Tests and evaluations define truth, not files. Stability emerges from replacement, not preservation.\n\nThis is not nihilism. It's pragmatism under new constraints.\n\nThe rest of this publication builds on a single premise established here:\n\nWhen code is cheap and understanding is expensive, architecture must optimize for the impermanence of code.\n\nEverything else (pace layers, evaluations, clean interfaces, regeneration workflows) flows from that fact.\n\nWe are not entering a world with less software. We are entering a world with vastly more of it. The only way to survive that abundance is to stop treating code as precious.\n\nBut it has been reborn, and it expects us to change with it.",
    "readingTime": 5,
    "keywords": [
      "modern software",
      "generative ai",
      "code",
      "it's",
      "systems",
      "programming",
      "codebases",
      "expensive",
      "developer",
      "longer"
    ],
    "qualityScore": 1,
    "link": "https://aicoding.leaflet.pub/3malrv6poy22a",
    "thumbnail_url": "https://leaflet.pub/lish/did%253Aplc%253A4qsyxmnsblo4luuycm3572bq/3majnsnvafs2b/3malrv6poy22a/opengraph-image?6815eb61f733905a",
    "created_at": "2025-12-23T00:56:32.109Z",
    "topic": "tech"
  },
  {
    "slug": "browserforge-ai-browser-agents-1000-free-credits",
    "title": "BrowserForge ‚Äì AI browser agents (1000 free credits)",
    "description": "AI browser agents that automate web tasks 24/7. Extract data, fill forms, monitor prices, and handle any repetitive browser work. No coding required - just show your agent what to do.",
    "fullText": "Agents navigate websites like humans‚Äîclicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.\n\nAgents navigate websites like humans‚Äîclicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.\n\nAgents navigate websites like humans‚Äîclicking buttons, filling forms, extracting data, and monitoring changes while maintaining authenticated sessions.\n\nIntelligent agents that understand web interfaces, adapt to layout changes, and handle complex multi-step workflows across any website.\n\nSet agents to continuously monitor websites for price changes, new listings, content updates, or any custom conditions you define.\n\nConnect browser agents to your existing tools via API, webhooks, or custom integrations to create seamless automated workflows.",
    "readingTime": 2,
    "keywords": [
      "sessions intelligent",
      "define connect",
      "connect browser",
      "via api",
      "api webhooks",
      "intelligent agents",
      "humans‚Äîclicking buttons",
      "buttons filling",
      "maintaining authenticated",
      "understand web"
    ],
    "qualityScore": 0.85,
    "link": "https://www.browserforge.ai/",
    "thumbnail_url": "https://browserforge.ai/media/browserforge-hero-1.png",
    "created_at": "2025-12-22T18:17:58.401Z",
    "topic": "tech"
  },
  {
    "slug": "a-selfassessment-quiz-to-measure-software-development-seniority-level",
    "title": "A self-assessment quiz to measure software development seniority level",
    "description": "Take a free quiz based on real-world achievements and see your software developer level against cross-industry benchmarks.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://mylevel.dev/",
    "thumbnail_url": "https://storage.tally.so/53a7ed1d-311d-4027-be0d-d842b419a4a7/Level-measurement.jpeg",
    "created_at": "2025-12-21T01:00:00.485Z",
    "topic": "tech"
  },
  {
    "slug": "ai-tools-make-coders-more-important-not-less",
    "title": "AI Tools Make Coders More Important, Not Less",
    "description": "Many leaders are excited about the promise of AI coding tools that can make it easier for novices to write code and, seemingly, make experienced coders less essential. Yet these tools make experience more‚Äînot less‚Äîimportant, as AI is not a replacement for real engineers. Companies that want to use these tools should follow common rules. Make sure every change it makes is double-checked‚Äîwith automatic checks, simple tests that confirm things still work, and at least one human review. Keep access limited: Let AI work only in a safe ‚Äúpractice‚Äù environment, never give it the keys to live customer data, and routinely check for basic security mistakes like files or storage left open to the public.",
    "fullText": "AI Tools Make Coders More Important, Not Less by Michael LiDecember 19, 2025PostPostShareSavePrintSummary.¬†¬†¬†Leer en espa√±olLer em portugu√™sPostPostShareSavePrintOf all the possible applications of generative AI, the value proposition of using it to write code was perhaps the clearest. Coding can be slow and it requires expertise, both of which can be expensive. Moreover, the promise that anyone who could describe their idea in plain text could create apps, features, or other value-adding products meant that innovation would no longer be limited to those with the skills to execute, but could be done by anyone with an idea. The strength of this promise has created a $7.37 billion market for these tools.",
    "readingTime": 1,
    "keywords": [
      "tools",
      "promise",
      "anyone",
      "idea"
    ],
    "qualityScore": 0.45,
    "link": "https://hbr.org/2025/12/ai-tools-make-coders-more-important-not-less",
    "thumbnail_url": "/resources/images/article_assets/2025/12/Dec25_22t-kaiser-7uH3ndea63o-unsplash.jpg",
    "created_at": "2025-12-19T18:17:22.482Z",
    "topic": "business"
  },
  {
    "slug": "introduction-to-programming-the-commodore-pet",
    "title": "Introduction to Programming the Commodore PET",
    "description": "History of the Commodore PET and how to approach programming the classic system",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://retrogamecoders.com/introduction-to-programming-the-commodore-pet/",
    "thumbnail_url": "https://retrogamecoders.com/wp-content/uploads/2025/12/Programming-the-Commodore-PET.jpg",
    "created_at": "2025-12-19T12:22:25.882Z",
    "topic": "tech"
  },
  {
    "slug": "metas-28yearold-billionaire-prodigy-says-the-next-bill-gates-will-be-a-13yearold-who-is-vibe-coding-right-now",
    "title": "Meta‚Äôs 28-year-old billionaire prodigy says the next Bill Gates will be a 13-year-old who is ‚Äòvibe coding‚Äô right now",
    "description": "Teenagers, Alexandr Wang argues, have a built-in edge.",
    "fullText": "Eva is a fellow on Fortune's news desk.\n\nAlexandr Wang‚Äîwho became the world‚Äôs youngest self-made billionaire at 24‚Äîis now, at 28, running one of the most ambitious AI efforts in Silicon Valley. In his first 60 days at Meta, he built a 100-person lab he described to TBPN hosts John Coogan and Jordi Hays as ‚Äúsmaller and more talent dense than any of the other labs.‚Äù\n\nHis goal: nothing less than superintelligence.\n\nWang, with his aerial view of the industry, has advice for kids, especially those in Gen Alpha now entering middle school: Forget gaming, sports, or traditional after-school hobbies.\n\n‚ÄúIf you are like 13 years old, you should spend all of your time vibe coding,‚Äù he said in his recent TBPN interview. ‚ÄúThat‚Äôs how you should live your life.‚Äù\n\nFor Wang, the reasoning is simple. Every engineer, himself included, is now writing code he believes will be obsolete within five years.\n\n‚ÄúLiterally all the code I‚Äôve written in my life will be replaced by what will be produced by an AI model,‚Äù he said.\n\nThat realization has left him, in his words, ‚Äúradicalized by AI coding.‚Äù What matters most now isn‚Äôt syntax, or learning a particular language, but time spent experimenting with and steering AI tools.\n\n‚ÄúIt‚Äôs actually an incredible moment of discontinuity,‚Äù Wang said. ‚ÄúIf you just happen to spend 10,000 hours playing with the tools and figuring out how to use them better than other people, that‚Äôs a huge advantage.‚Äù\n\nTeenagers have a clear advantage over adults: time and freedom to immerse themselves in new technology. And while in the past, entrepreneurial teenagers leveraged this time to be ‚Äúsneaker flippers‚Äù or run Minecraft servers, Wang says the focus should now be on the code.\n\nHe compares the moment to the dawn of the PC revolution. The Bill Gateses and Mark Zuckerbergs of the world had an ‚Äúimmense advantage‚Äù simply because they grew up tinkering with the earliest machines.\n\n‚ÄúThat moment is happening right now,‚Äù Wang said. ‚ÄúAnd the people who spend the most time with it will have the edge in the future economy.‚Äù\n\nWang isn‚Äôt coy about Meta‚Äôs ambitions. He calls the company‚Äôs infrastructure, scale, and product distribution unmatched.\n\n‚ÄúWe have the business model to support building literally hundreds of billions of dollars of compute,‚Äù he said.\n\nHis team, just over 100 people, is deliberately designed to be ‚Äúsmaller and more talent dense‚Äù than rivals. ‚ÄúThe other labs are like 10 times bigger,‚Äù Wang said, but their lab had ‚Äúcracked‚Äù coders.\n\nThe lab is split into three pillars: research, product, and infrastructure. Research builds the models Wang says will ‚Äúultimately be superintelligent.‚Äù Product ensures they get distributed across billions of users through Meta‚Äôs platforms. And infrastructure focuses on what he calls ‚Äúliterally the largest data centers in the world.‚Äù\n\nWang is particularly excited about hardware. Like many Meta executives now, he points to the company‚Äôs new smart glasses, which had a hilariously foppish demo, as the ‚Äúnatural delivery mechanism for superintelligence.‚Äù\n\nPlaced right next to the human senses, they will merge digital perception with cognition.\n\n‚ÄúIt will literally feel like cognitive enhancement,‚Äù Wang said. ‚ÄúYou will gain 100 IQ points by having your superintelligence right next to you.‚Äù\n\nVibe coding is the shorthand for this shift: using natural language prompts to generate and iterate on code. Rather than writing complex syntax, users describe their intent, and AI produces functioning prototypes.\n\nThe concept is spreading across Silicon Valley‚Äôs C-suites. Klarna CEO Sebastian Siemiatkowski has said he can now test ideas in 20 minutes, instead of burning weeks of engineering cycles. Google CEO Sundar Pichai revealed that AI already generates more than 30% of new code at the company, calling it the biggest leap in software creation in 25 years.\n\nWang takes that further. For him, vibe coding isn‚Äôt just a productivity hack, but a future cultural mandate. What matters isn‚Äôt the code itself ‚Äî it‚Äôs the hours of intuition-building that come from pushing AI tools to their limits, which is why he urges Gen Alpha to start early.\n\n‚ÄúThe role of an engineer is just very different now than it was before,‚Äù he said.\n\nA version of this story was published on¬†Fortune.com on September 19, 2025.",
    "readingTime": 4,
    "keywords": [
      "talent dense",
      "vibe coding",
      "gen alpha",
      "code",
      "literally",
      "isn‚Äôt",
      "wang",
      "superintelligence",
      "tools",
      "moment"
    ],
    "qualityScore": 1,
    "link": "https://fortune.com/article/what-is-vibe-coding-alexandr-wang-bill-gates-meta/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/09/GettyImages-1540568935-e1758305593707.jpg?resize=1200,600",
    "created_at": "2025-12-19T12:22:22.800Z",
    "topic": "business"
  },
  {
    "slug": "orbit-a-systems-level-programming-language-that-compiles-sh-to-llvm",
    "title": "Orbit a systems level programming language that compiles .sh to LLVM",
    "description": "A modern shell with functional programming synatx. - SIE-Libraries/orbit",
    "fullText": "SIE-Libraries\n\n /\n\n orbit\n\n Public\n\n A modern shell with functional programming synatx.\n\n License\n\n View license\n\n 5\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n SIE-Libraries/orbit",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.2,
    "link": "https://github.com/SIE-Libraries/orbit",
    "thumbnail_url": "https://opengraph.githubassets.com/dcaf4ed1c20da5475350ce0f3bf442eb03297772f6ad4097b4b2009e9ba5d922/SIE-Libraries/orbit",
    "created_at": "2025-12-19T09:39:44.047Z",
    "topic": "tech"
  },
  {
    "slug": "codingforpreschoolers-firm-files-bankruptcy-after-covid-boom",
    "title": "Coding-for-Preschoolers Firm Files Bankruptcy After Covid Boom",
    "description": "An education company that helps children as young as three learn to code filed for bankruptcy, blaming an expansion strategy that outpaced its ability to turn a profit.",
    "fullText": "WealthBy Steven ChurchSaveAn education company that helps children as young as three learn to code filed for bankruptcy, blaming an expansion strategy that outpaced its ability to turn a profit.Conscious Content Media Inc. would eliminate more than half of its $205.5 million in funded debt under a reorganization proposal backed by noteholders, according to court papers filed Wednesday in federal court in Wilmington, Delaware.",
    "readingTime": 1,
    "keywords": [
      "filed",
      "court"
    ],
    "qualityScore": 0.2,
    "link": "https://www.bloomberg.com/news/articles/2025-12-18/coding-for-preschoolers-firm-files-bankruptcy-after-covid-boom",
    "thumbnail_url": "https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iCA4eahCxR3k/v1/1200x800.jpg",
    "created_at": "2025-12-18T18:18:26.956Z",
    "topic": "finance"
  },
  {
    "slug": "i-built-an-app-for-vibecoding-games",
    "title": "I built an app for vibe-coding games",
    "description": "Got a game idea? Just describe it and start playing in seconds.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://playmix.ai/",
    "thumbnail_url": "https://playmix.ai/assets/og-image.png",
    "created_at": "2025-12-18T12:23:04.291Z",
    "topic": "tech"
  },
  {
    "slug": "learning-the-oldest-programming-language-2024",
    "title": "Learning the oldest programming language (2024)",
    "description": "Who needs Rust when we have Fortran?",
    "fullText": "While I probably should be learning a language like C, Go, or whatever new trendy language the ThePrimeagen mentions on Twitter (OCaml?), I'm going to attempt to learn Fortran[1].\n\nFortran, which stands for FORmula TRANslator[2], was created at IBM by John Backus in 1957 for scientific applications and has apparently been popular for high-performance computing and benchmarking supercomputers in recent years. Fortran has had several subsequent releases since then; FORTRAN 77, Fortran 90, Fortran 95, Fortran 2003, Fortran 2008, and the latest Fortran 2018.\n\nTo understand what version of Fortran to learn/use, we first must understand the difference between fixed form and free form Fortran. The fixed form layout comes from the very beginning of Fortran, inherited from punch cards, and has odd restrictions about the column in which comments and statements are placed. The free form layout, first introduced in Fortran 90, removed special columns and added the ability to write comments wherever, and is what we'll be learning in this article. The compiler we'll be using is GNU Fortran, or gfortran. You can install it via Homebrew (macOS) with the gcc formula, or install it using a package manager for your OS. To tell gfortran that your code uses the free form layout, set the file extension to .f90 or newer. The following comment on the Fortran discussion board explains this well.\n\nThe .f90 suffix means that the source code is free format, not that\nthe code conforms to the Fortran 90 standard. Code that uses the .f90\nsuffix can use features from any Fortran standard. All Fortran\ncompilers recognize .f90 as a suffix indicating free source form, but\nsome may not recognize a suffix such as .f95, .f03, .f08, or .f18.\nSome users may have build tools that do not recognize suffixes other\nthan .f90. Most Fortran source code on GitHub that uses features from\na standard more recent than Fortran 90 still uses the .f90 suffix.\n\nComing from TypeScript, and before that, Python, I'm very used to (and comfortable with) modern ‚Äî you might say \"aesthetic\" ‚Äî syntax . Although I wouldn't say Fortran syntax is quite modern, it seems to avoid the syntactic sugar nightmares that plague beginners in other languages[3]. Take a look at this helloworld.f90 example below.\n\nOlder Fortran programs required the use of SCREAMING_CASE for all keywords, but in modern Fortran you can and it is recommended to use snake_case (you can still use SCREAMING_CASE or any other case you want though).\n\nJust from this small example we can gather that...\n\nThe syntax for printing is a little funky though. What is that asterisk doing there? The asterisk, aside from being used as a mathematical operator, indicates the \"default\". So for print, * means \"print to the default output channel\" (or \"print to the default output file unit\" to be precise), which is typically going to be STDOUT.\n\nI can't find exactly where this is documented but you don't actually need the start and end program <program-name>; you could write a hello world program like this, though as I just mentioned this doesn't seem to be a common practice and isn't really very useful in any practical scenario.\n\nHere's another, slightly more complicated example.\n\nStarting right at the top, we have something new: implicit none. Added in Fortran 90, implicit none disables implicit typing defaults and all variables must be explicitly declared. In Fortran, implicit typing is the practice of assigning default types to variables based on the character a variable name begins with. Variables starting with I through N¬†are¬†INTEGERs, everything else is¬†REAL. It is \"a legacy of the past\" and usage of an implicit none¬†statement is \"strongly advised\" (implicit none - Fortran Wiki).\n\nA common Fortran joke goes along the lines of ‚ÄúGOD is REAL, unless declared INTEGER\"[4] because of implicit typing!\n\nMoving on, we declare our first variables in this program.\n\nHere we are declaring x, y, and answer with the REAL type, and choice with the CHARACTER type. The REAL type stores floating point numbers[5], and CHARACTER... stores characters.\n\nNext, we prompt the user for our x and y values.\n\nNotice how we can take input from the user with read and assign it to a value with the read *, <variable> syntax. The asterisk here means read from the default input channel/file unit, which would be STDIN.\n\nWe do the same for prompting the user to select an operation.\n\nFinally, we use a series of basic if-statements to calculate our answer and display it in the terminal.\n\nIf we run this, we- wait. Did I even tell you how to compile a Fortran program yet?\n\nFirst, compile our calculator program with gfortran -o calculator calculator.f90 . Then you can run it with ./calculator. If you only instruct gfortran of the input file (gfortran calculator.f90), the default output executable will be named a.out.\n\nOur calculator isn't perfect yet though. What if the user tries to divide by zero?\n\nProbably not the answer you expected. Let's try to fix that.\n\nHere we use the inequality operator, /=, to check if the y value is zero. Now, if the user tries to divide by zero, we'll print an error message and use the stop statement to end the program.\n\nGreat. We got rid of the zero division mess, but our code isn't pretty at all. Who wants a bunch of if statements? We can simplify this using the select case statement (also known as the case statement).\n\nThis also has the handy benefit of telling the user if they made an invalid choice while selecting the operation.\n\nThat‚Äôs just a quick introduction to a few modern Fortran features: declaring variables, printing and reading to and from the terminal, if and select case, and stop. Next time, we‚Äôll talk more about where Fortran is actually used, cooler things you can build with it, and how the Fortran language & community are rapidly modernizing!\n\nIronically, in the ~3-ish months since I started writing this article, ThePrimagen has recently said he \"take[s] back everything i said about FORTRAN\" ‚Äî apparently having some interest in the language! ‚Ü©Ô∏é\n\nAccording to sources listed on Fortran's Wikipedia, the name might also have stood for Formula Translating System or just Formula Translation. ‚Ü©Ô∏é\n\nSee The Rust programming language absolutely positively sucks : r/rust and Rust is a nightmare to learn coming from Java - community - The Rust Programming Language Forum. ‚Ü©Ô∏é\n\nThe first letter of \"GOD\", a \"G\", is not within I through N and is therefore of the REAL type (\"GOD is REAL\"). ‚Ü©Ô∏é\n\nYou can also use double precision for larger (more precise) floating point numbers. ‚Ü©Ô∏é",
    "readingTime": 6,
    "keywords": [
      "rust programming",
      "default output",
      "programming language",
      "implicit none",
      "implicit typing",
      "fortran standard",
      "modern fortran",
      "code",
      "user",
      "free"
    ],
    "qualityScore": 1,
    "link": "https://uncenter.dev/posts/learning-fortran/",
    "thumbnail_url": "https://uncenter.dev/1024w.png?v=2316a73de1f9",
    "created_at": "2025-12-17T13:45:44.913Z",
    "topic": "tech"
  },
  {
    "slug": "scrappy-free-ai-code-assistant",
    "title": "Scrappy Free AI Code Assistant",
    "description": "A powerful, context-aware coding assistant for everyone. Students, learners, anyone who doesn't want to pay for subscriptions. - HakAl/scrappy",
    "fullText": "HakAl\n\n /\n\n scrappy\n\n Public\n\n A powerful, context-aware coding assistant for everyone. Students, learners, anyone who doesn't want to pay for subscriptions.\n\n pypi.org/project/scrappy-ai/\n\n License\n\n MIT license\n\n 6\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n HakAl/scrappy",
    "readingTime": 1,
    "keywords": [
      "license"
    ],
    "qualityScore": 0.4,
    "link": "https://github.com/HakAl/scrappy",
    "thumbnail_url": "https://opengraph.githubassets.com/f4b80c7981acbe65eb74d5f829f65f4c5ad79abda560cef1db5838b375628d52/HakAl/scrappy",
    "created_at": "2025-12-17T03:45:04.030Z",
    "topic": "tech"
  },
  {
    "slug": "adventures-in-the-land-of-language-servers",
    "title": "Adventures in the Land of Language Servers",
    "description": "Have you ever wondered how your editors and IDEs are able to support so many programming languages? Perhaps you've been thinking about designing your ow‚Ä¶",
    "fullText": "Have you ever wondered how your editors and IDEs are able to support so many programming languages? Perhaps you've been thinking about designing your own language and wanted to know how you can give it editor support?\n\nThis talk is for you - I've spent over a year building a small language and integrating it with code editors, and I'd like to share some of the challenges I've faced, as well as lessons I've learned in that time.\n\nI'll also show how easy it is to build a new Language Server project in Scala 3 thanks to the Langoustine library.",
    "readingTime": 1,
    "keywords": [
      "i've",
      "editors",
      "language"
    ],
    "qualityScore": 0.45,
    "link": "https://speakerdeck.com/kubukoz/adventures-in-the-land-of-language-servers",
    "thumbnail_url": "https://files.speakerdeck.com/presentations/548a94549c554eaf8a5d70effbc439b1/slide_0.jpg?25884509",
    "created_at": "2025-12-17T03:45:03.996Z",
    "topic": "tech"
  },
  {
    "slug": "optimizing-claude-code",
    "title": "Optimizing Claude Code",
    "description": "Customize Claude Code with skills, plugins, commands, and configuration files that transform a capable coding assistant into one that matches your exact workflow.",
    "fullText": "I‚Äôve been using Claude Code for months now, and for most of that time, I was doing it wrong. Not wrong in the sense of getting bad results‚Äîthe defaults are remarkably capable. Wrong in the sense that I was treating a customizable system like a fixed tool. I was adjusting my workflow to fit the AI instead of adjusting the AI to fit my workflow.\n\nThe difference between default Claude Code and a properly configured instance is the difference between hiring a talented generalist and hiring someone who‚Äôs worked at your company for years. Both can write code. Only one knows that your team prefers for‚Ä¶of over .forEach(), that you never use the I prefix on interfaces, and that when you say ‚Äúanalyze this bug,‚Äù you mean a specific six-step process that includes hypothesis testing.\n\nHere‚Äôs how I built that second version.\n\nClaude Code‚Äôs customization system has multiple layers, each serving a different purpose:\n\nWhat‚Äôs less widely appreciated is how these layers interact. When Claude Code starts a session, it reads your settings, loads relevant skills based on context, and injects CLAUDE.md into its system prompt. When you invoke a command, it triggers a predefined workflow. When you mention a topic covered by a skill, Claude applies that expertise automatically.\n\nMy ~/.claude/settings.json is minimal but deliberate:\n\nalwaysThinkingEnabled: true ‚Äî This enables extended thinking on every response. The tradeoff is latency for quality. For complex refactoring or architectural decisions, I want Claude to think deeply. For quick questions, it‚Äôs overkill. I keep it on because my typical use case is substantial engineering work.\n\nToken limits ‚Äî Increasing CLAUDE_CODE_MAX_OUTPUT_TOKENS to 64000 prevents truncation on large refactors. The MAX_THINKING_TOKENS setting controls how much ‚Äúthinking‚Äù space Claude has before responding.\n\nincludeCoAuthoredBy: false ‚Äî I don‚Äôt need AI authorship attribution in every commit message. Personal preference.\n\nThe full settings file is available in my dotfiles repo.\n\nEvery project gets a CLAUDE.md at the root. This is where you encode project-specific knowledge: commands to build and test, directory structure, coding principles, workflow patterns.\n\nThe key insight: CLAUDE.md is a system prompt you control. Every instruction you put here shapes every response you get. You can define escalation patterns that tell Claude to stop thrashing and switch to a structured process after failed attempts‚Äîfor example, my Bug Fix workflow triggers a 6-step root cause analysis after two failed fixes.\n\nFull template: CLAUDE.md in dotfiles\n\nSkills are markdown files that encode specialized knowledge. When Claude detects that a skill is relevant to your task, it applies that expertise automatically.\n\nThis skill encodes my team‚Äôs TypeScript conventions‚Äîthings that aren‚Äôt in style guides but matter for consistency:\n\nThe full skill covers interfaces vs types, enum conventions, null handling, type assertions, and module imports. It‚Äôs 700+ lines because TypeScript has a lot of conventions worth encoding.\n\nFor Lambda, DynamoDB, and SQS patterns:\n\nThis skill catches AI-generated code patterns that don‚Äôt match human-written code:\n\nThis is something I‚Äôve noticed consistently: AI models add defensive code and comments that human developers wouldn‚Äôt. Having a skill that explicitly tells Claude to avoid these patterns makes the output feel more natural.\n\nSkills directory: skills in dotfiles\n\nSkills teach Claude how to code. Hooks enforce that it does. The difference matters.\n\nA skill might say ‚Äúprefer for‚Ä¶of over .forEach()‚Äú‚Äîbut Claude can still forget. A hook catches it in real-time, warning or blocking before the code is written. It‚Äôs the difference between training and guardrails.\n\nI use the hookify plugin to create enforcement rules from simple markdown files. Here are my active hooks:\n\nHooks are markdown files with YAML frontmatter. Here‚Äôs an example that blocks as any casts:\n\nThe action field determines severity:\n\nThis is where customization compounds. My TypeScript patterns skill teaches Claude the conventions. My hooks enforce them. If Claude violates a convention‚Äîsay, using as Type instead of <Type>‚Äîthe hook catches it before the code is written.\n\nThe feedback loop is immediate: Claude sees the warning, adjusts its output, and continues. Since Claude Code is stateless between sessions, the hooks provide consistent enforcement every time. Skills inform, hooks enforce.\n\nHooks directory: hooks in dotfiles\n\nCommands are like shell aliases for Claude workflows. Instead of typing a detailed prompt, you invoke /analyze-bug or /simplify and get a consistent, structured response.\n\nCommands directory: commands in dotfiles\n\nAgent docs are markdown files in .claude/agent_docs/ that Claude reads when relevant. Unlike skills (which encode how to do things), agent docs provide reference material (what things are).\n\nCLAUDE.md tells Claude when to read each doc. More efficient than stuffing everything into context‚ÄîClaude loads docs on demand.\n\nAgent docs: agent_docs in dotfiles\n\nPlugins add new tools and workflows to Claude‚Äôs toolkit. I use several, organized by purpose:\n\nast-grep ‚Äî Structural code search using AST patterns. Better than regex for finding code patterns that span multiple lines or have variable formatting. When I need to find all functions that return a Promise but don‚Äôt handle errors, ast-grep finds them regardless of formatting. Requires the CLI tool installed separately:\n\ndev-browser ‚Äî Browser automation for testing web applications. When I say ‚Äúgo to localhost:3000 and click the login button,‚Äù Claude can actually do that.\n\nfrontend-design ‚Äî UI/UX design assistance for frontend work. Part of the official Claude Code plugins.\n\nhookify ‚Äî Creates enforcement rules from markdown files (covered in the Hooks section above). The key plugin for active convention enforcement.\n\ncommit-commands ‚Äî Three git workflow commands:\n\nfeature-dev ‚Äî A 7-phase structured workflow for complex features:\n\nFor complex features that touch multiple files, /feature-dev ensures nothing is missed.\n\npr-review-toolkit ‚Äî Six specialized review agents that run in parallel:\n\nWhen I say ‚Äúreview my PR,‚Äù these agents analyze different dimensions simultaneously and return prioritized findings.\n\nPlugins are installed via the Claude Code plugin system. Official plugins require adding the Anthropic marketplace first:\n\nThe configuration in settings.json enables them:\n\nRun this to install my skills, commands, and hooks:\n\nThe script sets up ~/.claude/ and prints the plugin commands to run inside Claude Code.\n\nIf you prefer to set things up yourself:\n\nCreate ~/.claude/skills/typescript-patterns/SKILL.md with your TypeScript conventions. The filename must be SKILL.md and include frontmatter with name and description.\n\nCreate ~/.claude/commands/analyze-bug.md with your debugging workflow. Commands are invoked with /analyze-bug (the filename becomes the command name).\n\nAfter installing hookify, create enforcement rules:\n\nHooks take effect immediately‚Äîno restart required.\n\nCreate CLAUDE.md at the root of each project with project-specific instructions.\n\nMy complete configuration: github.com/stevenmays/dotfiles/tree/master/ai/claude\n\nHere‚Äôs what I didn‚Äôt expect: these customizations compound.\n\nA skill that teaches TypeScript conventions means Claude knows my preferences. A hook that enforces those conventions means Claude can‚Äôt forget them. A command that structures bug investigation means debugging follows a consistent process. A plugin that runs six review agents in parallel means PR reviews are thorough without being tedious.\n\nEach layer reinforces the others:\n\nThe time investment‚Äîmaybe a few hours total‚Äîpays dividends on every subsequent session. I‚Äôm not constantly re-explaining preferences or correcting patterns. Claude already knows. And when it forgets, the hooks catch it.\n\nIt‚Äôs not that X is bad and Y is good, exactly; it‚Äôs more that default Claude Code is a capable generalist, while optimized Claude Code is a specialist who happens to share your opinions about code style, your workflow preferences, and your debugging methodology.\n\nThe choice is simple: accept defaults, work around quirks, and occasionally complain about AI-generated code that doesn‚Äôt match your style‚Äîor spend a few hours getting dialed in.",
    "readingTime": 7,
    "keywords": [
      "agent docs",
      "create enforcement",
      "typescript conventions",
      "expertise automatically",
      "claude code",
      "ai-generated code",
      "complex features",
      "hook catches",
      "review agents",
      "default claude"
    ],
    "qualityScore": 1,
    "link": "https://mays.co/optimizing-claude-code",
    "thumbnail_url": "https://mays.co/_astro/optimizing-claude-code.DOeMUOQN_Z2lns9R.jpg",
    "created_at": "2025-12-17T03:45:03.284Z",
    "topic": "tech"
  },
  {
    "slug": "nvidia-unveils-new-opensource-ai-models-amid-boom-in-chinese-offerings",
    "title": "Nvidia unveils new open-source AI models amid boom in Chinese offerings",
    "description": "Nvidia on Monday unveiled a new family of open-source artificial intelligence models that it says will be faster, cheaper and ‚Äãsmarter than its previous offerings, as open-source offerings from Chinese AI labs proliferate.  Nvidia ‚Äåis primarily known for providing chips that firms such as OpenAI use to train their closed-source models and ‚Äåcharge money for them.  Nvidia ‚Å†on Monday revealed the third ‚Äågeneration of its \"Nemotron\" large-language models aimed at writing, coding and other tasks.",
    "fullText": "SAN FRANCISCO, Dec 15 (Reuters) - Nvidia (NVDA) on Monday unveiled a new family of open-source artificial intelligence models that it says will be faster, cheaper and ‚Äãsmarter than its previous offerings, as open-source offerings from Chinese AI labs proliferate.\n\nNvidia ‚Äåis primarily known for providing chips that firms such as OpenAI use to train their closed-source models and ‚Äåcharge money for them. But it also offers a slew of its own models for everything from physics simulations to self-driving vehicles as open-source software that can be used by researchers or by other companies, with firms such as Palantir Technologies weaving Nvidia's model into their products.\n\nNvidia ‚Å†on Monday revealed the third ‚Äågeneration of its \"Nemotron\" large-language models aimed at writing, coding and other tasks. The smallest of the models, called Nemotron 3 Nano, was being released ‚ÄçMonday, with two other, larger versions coming in the first half of 2026.\n\nNvidia, which has become the world's most valuable listed company, said that Nemotron 3 Nano was more efficient than its predecessor - ‚Äãmeaning it would be cheaper to run - and would do better at long tasks ‚Äåwith multiple steps.\n\nNvidia is releasing the models as open-source offerings from Chinese tech firms such as DeepSeek, Moonshot AI and Alibaba Group Holdings are becoming widely used in the tech industry, with companies such as Airbnb disclosing use of Alibaba' s. (BABA) Qwen open-source model.\n\nAt the same time, CNBC and Bloomberg have reported that Meta Platforms is considering shifting toward closed-source ‚Å†models, leaving Nvidia as one of the most prominent ‚ÄãU.S. providers of open-source offerings.\n\nMany U.S. states and ‚Äãgovernment entities have banned use of Chinese models over security concerns.\n\nKari Briski, vice president of generative AI software for enterprise at Nvidia, said the company aimed ‚Äçto provide a \"model that ‚Å†people can depend on\", and was also openly releasing its training data and other tools so that government and business users could test it for security and ‚Å†customize it.\n\n\"This is why we're treating it like a library,\" Briski told Reuters in an interview. \"This is ‚Äåwhy we're committed to it from a software engineering perspective.\"",
    "readingTime": 2,
    "keywords": [
      "open-source offerings",
      "closed-source models",
      "nemotron nano",
      "nvidia",
      "firms",
      "software",
      "reuters",
      "cheaper",
      "aimed",
      "tasks"
    ],
    "qualityScore": 0.9,
    "link": "https://finance.yahoo.com/news/nvidia-unveils-open-source-ai-140424565.html",
    "thumbnail_url": "https://media.zenfs.com/en/reuters-finance.com/31397226d241d376e5cffbf13490e071",
    "created_at": "2025-12-16T13:51:41.754Z",
    "topic": "finance"
  },
  {
    "slug": "claude-codes-creator-explains-the-limits-of-vibe-coding",
    "title": "Claude Code's creator explains the limits of vibe coding",
    "description": "The engineer behind Claude Code says vibe coding works for prototypes, but today's AI models still fall short for maintainable software.",
    "fullText": "The creator of one of the most popular AI coding tools says vibe coding can only go so far.\n\nBoris Cherny, the engineer behind Anthropic's Claude Code, said on an episode of \"The Peterman Podcast\" published Monday that while vibe coding has its place, it's far from a universal solution.\n\nIt works well for \"throwaway code and prototypes, code that's not in the critical path,\" he said.\n\n\"I do this all the time, but it's definitely not the thing you want to do all the time,\" Cherny said, referring to vibe coding.\n\n\"You want maintainable code sometimes. You want to be very thoughtful about every line sometimes,\" he added.\n\nClaude Code launched earlier this year as part of Anthropic's efforts to integrate AI more deeply into code development workflows.\n\nTop AI coding services like Cursor and Augment run on Anthropic's models, and even Meta uses Anthropic's models inside its coding assistant. Claude Code has also taken off with non-technical developers who want to build software with natural-language prompts.\n\nAnthropic's CEO, Dario Amodei, said in October that Claude was writing 90% of the code in the company.\n\nFor critical coding tasks, Cherny said he typically pairs with a model to write code.\n\nHe starts by asking an AI model to generate a plan, then iterates on the implementation in small steps. \"I might ask it to improve the code or clean it up or so on,\" he said.\n\nFor parts of the system where he has strong technical opinions, Cherny said he still writes the code by hand.\n\nCherny said the models are still \"not great at coding.\"\n\n\"There's still so much room to improve, and this is the worst it's ever going to be,\" he said.\n\nCherny said it's \"insane\" to compare current tools to where AI coding was just a year ago, when it amounted to little more than type-ahead autocomplete. Now, it's a \"completely different world,\" he said, adding that what excites him is how fast the models are improving.\n\nAI-assisted coding has been gaining momentum across the tech world.\n\nGoogle CEO Sundar Pichai said last month that vibe coding is \"making coding so much more enjoyable,\" adding that people with no technical background can now build simple apps and websites.\n\n\"Things are getting more approachable, it's getting exciting again, and the amazing thing is, it's only going to get better,\" he said in a podcast interview with Logan Kilpatrick, who leads Google's AI Studio.\n\nPichai said during Alphabet's April earnings call that AI is writing over 30% of the new code at Google, an increase from 25% in October 2024.\n\nIt's \"fantastic\" how quickly developers can write software with AI coding tools, sometimes while \"barely looking at the code,\" said Google Brain founder Andrew Ng in May.\n\nFor non-technical developers, vibe coding has enabled them to automate parts of their jobs, prototype ideas, or build a creative product on the side, Business Insider reported last month.\n\nStill, leaders caution that the technology has limits. AI-generated code could contain mistakes, be overly verbose, or lack the proper structure.\n\n\"I'm not working on large codebases where you really have to get it right, the security has to be there,\" Pichai said in November.",
    "readingTime": 3,
    "keywords": [
      "anthropic's models",
      "non-technical developers",
      "vibe coding",
      "coding tools",
      "claude code",
      "it's",
      "critical",
      "software",
      "improve",
      "parts"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/claude-code-creator-vibe-coding-limits-boris-cherny-anthropic-2025-12",
    "thumbnail_url": "https://i.insider.com/6940d32f04eda4732f2d9311?width=1200&format=jpeg",
    "created_at": "2025-12-16T06:59:53.631Z",
    "topic": "finance"
  },
  {
    "slug": "the-year-coding-changed-forever",
    "title": "The year coding changed forever",
    "description": "Optimism, laziness, and magical thinking: The year vibe coding took over tech.",
    "fullText": "Sriraam Raja, the founding engineer at the software company Decode, has been using generative AI to write code for two years. He says he can get projects done about twice as fast when he uses a chatbot to code with intention. Then one day, he fired off directions, and as he sat there while the bot's wheels turned, he realized he could have actively written what he was aimlessly waiting for the bot to do. \"I was giving away a bit of my agency, and so I made a decision to be very conscious,\" he tells me.\n\nRaja has become \"very specific about when I delegate, and also how much I delegate,\" he says. Waiting for the AI to spit out code can disrupt the flow of his work, and trusting too much work to it has led him to sometimes get bogged down in a lengthy review process. He's also anxious about the long-term effects AI can have on how we all think and problem solve. \"There's a side effect where everyone's confidence has increased, but so has their laziness, and their willingness to learn things from first principles has dropped,\" he says. \"I've definitely seen a drop in curiosity that I haven't seen before, and so that worries me.\"\n\nThe Collins dictionary made vibe coding its 2025 word of the year. Coined by OpenAI cofounder Andrej Karpathy in February, the term refers to using language and generative AI to speed up the coding process. Soon after, companies were adding it as a desired skill in job listings.\n\nVibe coding was the catalyst for the sort of vibe work era we've entered. It's a shift in how people think about their roles and relationships to work amid an AI boom, and software engineering, long considered a stable and lucrative career path, has perhaps been the career most scrutinized and pushed down a path toward automation. Product managers have suggested that AI will supercharge them, allowing them to take on some technical coding tasks and work without engineers.\n\nExecs have been all-in: Mark Zuckerberg said he expected AI to write half of Meta's code within a year; this spring, AI was already doing about a third of code at Google and on some Microsoft projects. Anthropic CEO Dario Amodei predicted in March that 90% of code would be generated by AI in three to six months. The bullish estimate hasn't materialized for most, but Amodei said in October the company's AI tool Claude was writing most of the code at Anthropic. Cognition, which built an AI-powered software engineer it named Devin, is now valued at $10 billion. Some without computer science backgrounds or any training in coding are vibe coding their own projects.\n\nVibe coding isn't yet the miracle that AI evangelists have professed. AI-generated code can have sneaky errors that pose security risks. As it takes on the work of junior developers, companies eager for gain could displace humans. Time banked with shortcuts now could disrupt training ground for learning basic coding skills, creating a tech worker career ladder collapse could ricochet through the industry. There is potential for developers to save time, to use AI to learn new languages and skills (something Raja tells me he's done), and to pare down their technical debt, or code that needs maintenance. But the impact of AI on the industry is more complicated than it is a silver bullet to efficiency.\n\nLast year, \"we were dealing with a lot of optimism and a lot of magical thinking\" around the capabilities of AI, says Tariq Shaukat, CEO of Sonar, a company that provides developers with tools to verify code. \"The vibe engineering tools are producing a lot of quantity. It's getting more functionally correct, but it's actually becoming more difficult to determine the quality and get the level of trust that you need to integrate that into your code base.\" The ranks of AI holdouts among developers are shrinking. A 2025 survey of professional developers from Stack Overflow found that only 19.3% don't use AI, and a commensurate 19.7% have an unfavorable opinion of AI. Yet less than 3% of respondents said they highly trust AI for accuracy.\n\nAnyone who has asked a chatbot a question knows that even a short inquiry often results in a verbose response. The same is true of code ‚Äî when AI generates it, it's typically longer, making the possibility of errors hiding in the code more likely. Amy Carrillo Cotten, senior director of customer transformation at software development company Uplevel, told me in September: \"For a lot of engineers, the only thing that looks different is where they spend their time, not exactly how much time it took.\" Uplevel studied 800 software developers last year and compared the productivity levels of those who used GitHub's Copilot to those who did not. The developers who used Copilot weren't more efficient or less burnt out, and their code had bugs in it 41% more frequently. (GitHub's own research found that those who used Copilot wrote about 18 lines of clean code, compared to 16 lines for those who didn't.) For many, that shift from writing to reviewing code is \"not the job they signed up for,\" Shaukat says, which brings a big adjustment for many developers.\n\n\"The job looks completely different,\" says Frank Fusco, CEO of a software company called Silicon Society. His company works with clients on their software, but now they often get amateur, vibe coded versions of those ideas as the starting point. \"What I would normally do in code that would take me days, I now do in words and it takes me hours.\" But Fusco tells me he worries about a decline in critical thinking and basic coding skills. We're \"hardwired,\" he says, to find \"the shortest path to the solution.\" But that approach isn't the best for sharpening coding skills. \"It really is a muscle that you have to work all the time.\"\n\nIt's tricky to say AI is already killing developer jobs. Years of layoffs and \"right-sizing\" in the tech industry, paired with the economic precarity that has also defined 2025, could be shifting industry roles alongside AI. As of November, there were about 92,500 active job postings seeking software engineers, down from nearly 102,000 last November and 159,000 at the start of 2023, according to data from CompTIA, a nonprofit trade association for the US IT industry. The number of active tech job posts overall has fallen, from 621,000 in early 2023 to 433,500 last month. But the proportion of open jobs looking for AI skills has jumped by 53% this year.\n\nAfter two decades of being told to pursue computer science as a stable career and a proliferation of coding bootcamps, working as a developer may not be as cushy. College seniors studying computer science are more likely than any other discipline to say they're \"very pessimistic\" about their careers, according to a 2025 survey from early career website Handshake. They're the group most likely to say the advances of generative AI have made them regret their major choice. But young people are divided ‚Äî 43% of computer science majors said they think AI will have a positive effect on their careers.\n\nAutomation is in some ways marking \"a correction\" on the developer labor market, says April Schuppel, developer relations manager at software company Apryse. Before AI, \"we needed as many people who were really pushing out the code to take the ideas of the visionaries and bring them to life.\" Now, \"the people who have always been able to make the most impact, they're still the ones that are the safest.\" Developers who looked at their jobs as clearing tickets might be more replaceable than those who were creative and cared about the project from start to finish. We're far from realizing the end game of vibe coding, but for creative, forward-thinking developers, there's optimism for now. \"The more well-rounded people are the ones that are going to have success,\" Schuppel says.\n\nAI could bring more opportunity for software testers, and also help companies pare down their technical debt. The developer job market might look messy right now, but there's still a heavy focus on the human aspect of the career than in the picture painted by some Big Tech execs. \"If there are opportunities for more fine-tuned models, more specialized models that only do certain types of code updates, and there is a way to use that more to augment human developers as opposed to replace, that seems like that's where this is going,\" says Tim Herbert, chief research officer at CompTIA.\n\nCodebases are valuable, and the security risks posed by goofs in AI code are serious threats. Traffic to vibe coding sites slumped in September after a summer of hype. Even Karpathy said his latest project is \"basically entirely hand-written (with tab autocomplete)\" in a post on X. \"I tried to use claude/codex agents a few times but they just didn't work well enough at all and net unhelpful.\" If 2025 was the year tech companies went all in on AI, 2026 might be the year when some of the craze around vibe coding subsides and reality sets in.\n\nAmanda Hoover is a senior correspondent at Business Insider covering the tech industry. She writes about the biggest tech companies and trends.",
    "readingTime": 8,
    "keywords": [
      "security risks",
      "technical debt",
      "computer science",
      "basic coding",
      "vibe coding",
      "tech industry",
      "coding skills",
      "developers",
      "software",
      "code"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/year-coding-changed-forever-silicon-valley-2025-12",
    "thumbnail_url": "https://i.insider.com/693c966a64858d02d216c23d?width=1200&format=jpeg",
    "created_at": "2025-12-15T13:53:47.187Z",
    "topic": "finance"
  },
  {
    "slug": "habits-that-make-a-great-programmer",
    "title": "Habits That Make a Great Programmer",
    "description": "8 rituals to level up your programming skills! Learn how to code better, think faster, and build complex systems with these actionable tips.",
    "fullText": "‚ÄúHow to get better at programming?‚Äù is the question I had been asked quite a few times, and today I lay down the 8 rituals I have been following, and action items for each, to be good and get better at programming.\n\nDoing something repeatedly always helps and writing a lot of code will develop our ability to\n\nIf we don‚Äôt do something repeatedly, it becomes extremely hard to get good at it. Writing code consistently helps us\n\nSolving programming questions is about developing logic but things become a little trickier when we build a complex system, as it requires us to take our programming skills to go up a notch. Some examples of complex systems are - a Library management system, a Twitter clone, an Instagram clone, etc. Building a complex system\n\nAfter we spend some time writing programs and solving problems, things become monotonous and do not seem to challenge us anymore, so to spice things up a bit we should model something from the real world, like\n\nThere are lots of libraries and framework like p5.js that makes visual programming simple.\n\nIt is not only writing code that improves our programming skills but it is reading some quality code written by expert programmers that make the difference. Reading code written by experts improve our programming vocabulary and by doing this we\n\nThe best way to start doing it is by picking up an open-source project and start skimming the code. It is okay to not understand it in the first go but it is important to skim it a few times and get acquainted. After a few skim, everything will fall in place, the code becomes familiar and we start to understand the flow and business logic.\n\nThere is always someone sitting on the other side of the globe, who knows a thing or two more than us. Look for them and collaborate on a project. The developer community is filled with super smart and super enthusiastic developers who love to share and collaborate. Use websites like Dev.to, Hashnode and Twitter to find and interact with like-minded people.\n\nA programming language is just a tool to express business logic. While learning a programming language we should try to understand the constructs and paradigms used - for example: Functional programming, Polymorphism, Event driven programming, Actor model, etc. It is important to do so because we could pick constructs from one language and use it in another to solve our problem. For example: picking Functional programming (Callbacks) from Javascript and using it in Python to create generic action functions.\n\nWriting code before putting in some thought is degraded the code more often than not. The code written like this lacks simplicity, reusability, and extensibility. Spending some time thinking about problem statement or task at hand and having a rough execution plan always helps.\n\nThese rituals have helped me get better at programming with time and in parallel, I pick at max 3 and act on the action items. Programming is simple but being better than most is difficult. Doing it consistently makes one get better by the day.",
    "readingTime": 3,
    "keywords": [
      "functional programming",
      "action items",
      "business logic",
      "complex system",
      "programming skills",
      "programming language",
      "code",
      "doing",
      "understand",
      "rituals"
    ],
    "qualityScore": 1,
    "link": "https://arpitbhayani.me/blogs/better-programmer/",
    "thumbnail_url": "https://edge.arpitbhayani.me/img/covers/general-cover.jpg",
    "created_at": "2025-12-15T03:59:06.895Z",
    "topic": "tech"
  },
  {
    "slug": "openais-head-of-codex-says-the-bottleneck-to-agi-is-humanitys-inability-to-type-fast-enough",
    "title": "OpenAI's head of Codex says the bottleneck to AGI is humanity's inability to type fast enough",
    "description": "OpenAI's Alexander Embiricos, who leads product development for its coding platform, said the need to review AI's work with prompts is limiting progress.",
    "fullText": "If you needed a sign for how determined AI-land is to achieve AGI quickly, it's that one of its leaders sees the speed of human typing as one of its biggest roadblocks.\n\nAlexander Embiricos, who leads product development for Codex, OpenAI's coding agent, said on \"Lenny's Podcast\" on Sunday that the \"current underappreciated limiting factor\" to AGI is \"human typing speed\" or \"human multi-tasking speed on writing prompts.\"\n\nAGI, or artificial general intelligence, is a still theoretical version of AI that reasons as well or better than humans. It's the thing all the big AI companies are competing to be the first to realize.\n\n\"You can have an agent watch all the work you're doing, but if you don't have the agent also validating its work, then you're still bottlenecked on, like, can you go review all that code?\" Embiricos said.\n\nEmbiricos' view is that we need to unburden humans from having to write prompts and validate AI's work, since we aren't fast enough.\n\n\"If we can rebuild systems to let the agent be default useful, we'll start unlocking hockey sticks,\" he said.\n\n\"Hockey stick growth\" is a term used to describe a growth curve that starts out flat and suddenly spikes, mirroring the shape of a hockey stick.\n\nEmbiricos said there's no simple path to a fully automated workflow ‚Äî each use case will require its own approach ‚Äî but he expects to see progress toward this level of growth soon.\n\n\"Starting next year, we're going to see early adopters starting to hockey stick their productivity, and then over the years that follow, we're going to see larger and larger companies hockey stick that productivity,\" he said.\n\nSomewhere in between the time early adopters start to see gains in productivity and when tech giants manage to fully automate processes with AI agents is when we'll see AGI, Embiricos said.\n\n\"That hockey-sticking will be flowing back into the AI labs, and that's when we'll basically be at the AGI,\" he said.",
    "readingTime": 2,
    "keywords": [
      "human typing",
      "hockey stick",
      "agent",
      "speed",
      "we'll",
      "growth",
      "productivity",
      "it's",
      "prompts",
      "humans"
    ],
    "qualityScore": 0.85,
    "link": "https://www.businessinsider.com/openai-artificial-general-intelligence-bottleneck-human-typing-speed-2025-12",
    "thumbnail_url": "https://i.insider.com/693f0599832e0ef1ead631ab?width=1200&format=jpeg",
    "created_at": "2025-12-15T03:59:01.869Z",
    "topic": "finance"
  },
  {
    "slug": "programming-languages-to-learn-first",
    "title": "Programming Languages to Learn First",
    "description": "Many IT professionals would recommend Python as the best programming language for beginners. Why? The syntax of the Python code is considered simple.",
    "fullText": "TL;DR: Python leads with 29.85% market share driven by AI/ML demand, while JavaScript remains essential for web development. But here‚Äôs what most hiring managers miss: the rise of AI-powered coding tools like GitHub Copilot has fundamentally altered what skills you should prioritize when building your engineering team.\n\nThe question isn‚Äôt simply ‚Äúwhich programming language should we hire for?‚Äù anymore. Companies are increasingly leveraging AI to automate routine coding tasks, reducing the need for large engineering teams and prioritizing professionals who can manage AI-driven workflows rather than simply write code.\n\nLet‚Äôs cut through the noise and examine what‚Äôs actually happening in today‚Äôs tech hiring landscape.\n\nSoftware developer job listings are down 35% from their 2022 peak, but don‚Äôt let that fool you into thinking demand has disappeared. Most technology positions tracked by the U.S. Bureau of Labor Statistics show unemployment rates well below the national average‚Äîsoftware developers at 2.8%, systems analysts at 1.8%, and security analysts at 2.3%.\n\nWhat‚Äôs changed is selectivity. Companies are becoming more selective with their technical hires while businesses struggle to ship quickly due to a shortage of qualified engineers. The old approach of scanning resumes for keyword matches no longer works when every engineer claims ‚Äúfull-stack‚Äù experience.\n\nPython dominates with 29.85% market share, and it‚Äôs no surprise given AI and machine learning‚Äôs explosive growth. But here‚Äôs what matters for your hiring strategy: the type of Python developer you need has evolved.\n\nTraditional Python roles focused on web development with Django or Flask. Modern Python roles require understanding of:\n\nWhen interviewing Python candidates, dig beyond syntax knowledge. Ask: ‚ÄúHow would you architect a system that processes real-time data for ML model inference?‚Äù The answer reveals whether they understand modern Python‚Äôs role in AI-driven products.\n\nJavaScript maintains its position with 7.92% market share, remaining essential for front-end development. But traditional frontend development is seeing fewer job postings, suggesting a shift toward full-stack or specialized backend roles.\n\nThe modern JavaScript landscape demands expertise in:\n\nTypeScript continues gaining popularity for large-scale web development, with its static typing and enhanced tooling making it preferred for complex applications. If your product serves enterprise clients or handles complex state management, TypeScript experience isn‚Äôt optional, it‚Äôs essential.\n\nGo‚Äôs popularity continues to grow as global demand for cloud computing rises, with its simple syntax, built-in concurrency support, and high performance making it well-suited for cloud-native applications.\n\nRust is emerging for system-level programming where memory safety and performance are critical. Rust‚Äôs memory safety, high performance, and robust security properties make it particularly well-suited for performance- and safety-critical applications.\n\nIf your architecture includes real-time systems, embedded software, or blockchain applications, Rust expertise provides competitive advantages that Go simply cannot match.\n\nIn this article, you can find answers to these questions. Keep in mind that these are all useful languages that will bring you closer to your goal if you‚Äôre committed.\n\nDespite competition from newer languages like Kotlin and Go, Java remains widely used in enterprise software, Android development, and backend systems. But the Java developer you need in 2025 looks different from five years ago.\n\nModern Java development requires:\n\nC# has been increasingly utilized in game development and enterprise software, with deep integration with the Unity game engine cementing C# as a top game developer language. For enterprise applications, .NET‚Äôs cross-platform capabilities make C# developers valuable for modernizing legacy Windows-based systems.\n\nAccording to research for the Demand for Skilled Talent report, the most evident skills gap on technology teams is within AI, machine learning and data science. But let‚Äôs be specific about what this means for different roles:\n\nPlatform-focused AI engineers build centralized tools and infrastructure to accelerate AI development, while product-focused AI engineers work inside product teams and ship AI features for users. Understanding this distinction helps you write better job descriptions and evaluate candidates correctly.\n\nDevelopers who can maintain and modernize legacy systems are highly valued, with work including ensuring security, improving performance, and integrating legacy systems with newer technologies like APIs or microservices. Many companies underestimate this need when planning their hiring strategy.\n\nCloud services like AWS, Google Cloud, and Microsoft Azure are at the core of modern software infrastructure, with over 90% of global enterprises expected to use cloud platforms by 2025.\n\nCritical cloud competencies include:\n\nWhen evaluating DevOps candidates, focus on their experience with incident response and disaster recovery. Anyone can deploy to the cloud; few can architect systems that gracefully handle failure at scale.\n\nEnterprise blockchain adoption is driving legitimate technical roles:\n\nMajor industries entering the space, including finance, healthcare and logistics, are expanding demand for blockchain engineers. When Deutsche Bank builds blockchain settlement systems or Nike creates digital collectibles, they need engineers who understand both traditional software architecture and decentralized protocols.\n\nEntry-level Solidity developers can write basic smart contracts and deploy them to testnets. Senior Solidity engineers architect systems that handle millions in value while remaining secure and gas-efficient.\n\nCore technical competencies for serious Solidity roles:\n\nFor Startups and Scale-ups: Python and JavaScript remain your best bets for rapid development and talent availability. The ecosystem maturity and hiring pool depth outweigh cutting-edge performance considerations.\n\nFor Enterprise and Financial Services: Java and C# provide the stability, security, and regulatory compliance frameworks that regulated industries require. Don‚Äôt chase trends when handling mission-critical systems.\n\nFor Performance-Critical Applications: Go for backend services, Rust for system programming, and C++ for real-time applications. Latency requirements should drive language selection, not popularity metrics.\n\nFor AI/ML Products: Python dominates, but consider Julia for scientific computing or R for statistical analysis. Language choice depends on your specific AI use case and team expertise.\n\nGiven 95% of tech leaders face challenges finding skilled workers, your approach to technical hiring needs to evolve beyond traditional methods.\n\nFocus on fundamental problem-solving over specific syntax knowledge. A strong engineer can learn new languages; analytical thinking and system design skills transfer across technologies.\n\nPrioritize hands-on experience with real-world projects over certification collections. Ask candidates to walk through architecture decisions they‚Äôve made and trade-offs they‚Äôve considered.\n\nEvaluate AI collaboration skills. The shift toward engineers with expertise in AI augmentation, system architecture, and cross-functional problem-solving means traditional coding assessments miss crucial competencies.\n\nIt‚Äôs easy enough for software engineers to become AI engineers: just build applications on top of LLMs. This accessibility is reshaping what skills remain uniquely human and valuable.\n\nLanguages that enhance AI productivity:\n\nThe programming languages your team learns should align with how AI tools augment rather than replace human developers. Focus on languages that excel in areas where human judgment and creativity remain irreplaceable: system architecture, user experience design, and complex business logic implementation.\n\nBottom Line: The most important programming language for your 2025 hiring strategy isn‚Äôt determined by popularity rankings‚Äîit‚Äôs the one that best matches your technical architecture, team experience, and business requirements. Technology hiring trends in 2025 indicate that candidates place high value on exposure to AI and machine learning projects, as these skills significantly enhance their career trajectories.\n\nThe companies succeeding in today‚Äôs competitive hiring market understand that language proficiency is just the foundation. The real competitive advantage comes from engineers who can architect systems, collaborate with AI tools, and adapt to evolving technical requirements.\n\nReady to build a hiring strategy that actually reflects today‚Äôs market realities? Let‚Äôs discuss how the current tech landscape impacts your specific technical requirements and talent acquisition approach.",
    "readingTime": 7,
    "keywords": [
      "python dominates",
      "applications rust",
      "shift toward",
      "memory safety",
      "syntax knowledge",
      "machine learning",
      "python roles",
      "web development",
      "hiring strategy",
      "technical requirements"
    ],
    "qualityScore": 1,
    "link": "https://www.omnesgroup.com/the-best-programming-languages-to-learn-first/",
    "thumbnail_url": "https://www.omnesgroup.com/wp-content/uploads/2018/08/download-69-1.png",
    "created_at": "2025-12-14T18:50:16.561Z",
    "topic": "tech"
  },
  {
    "slug": "terraform-sunsets-cdktf",
    "title": "Terraform Sunsets CDKTF",
    "description": "This decision forces Terraform's users to migrate to HCL, drawing criticism from those who point to the CDK's popularity as proof Terraform still needs advanced programming capabilities.",
    "fullText": "Going forward, when you run IBM‚Äòs Terraform Infrastructure as Code (IaC) software, you will have one language to write your configurations: the HashiCorp Configuration Language (HCL).\n\nOn Monday, HashiCorp, an IBM company, announced that it will no longer support the Terraform Cloud Development Kit (CDK or CDKTF). Although the existing code will remain available in a GitHub archive, HashiCorp will no longer maintain or update the code, leaving it all but unusable for enterprises.\n\n‚ÄúUnfortunately, Terraform CDK did not find product-market fit at scale. HashiCorp, an IBM Company, has chosen to focus its investments on Terraform core and its broader ecosystem,‚Äù a note on the site read.\n\nThe CDK itself is licensed under the Mozilla Public License (MPL), so users are free to fork the software itself, IBM suggested.\n\nThe company, however, is encouraging users to use HCL, which was developed by HashiCorp and licensed under the Mozilla Public License (MPL), originally designed for the software.\n\nOriginally released in 2014 by HashiCorp, Terraform is software that allows administrators to automate the deployment of IT infrastructure, either in the cloud or on premises, through the use of scripts and a set of Terraform commands such as terraform init, terraform plan and terraform apply. The output is rendered as JSON.\n\nOver time, Terraform has become the most popular software for automated IT deployment, especially in the cloud native community.\n\nIn 2023, HashiCorp switched the Terraform license from open source to a Business Source License, which spurred a user-based open source fork of the software, called OpenTofu, that was adopted by the Linux Foundation and, later, by the Cloud Native Computing Foundation (CNCF).\n\nIn 2024, IBM announced it was acquiring HashiCorp and finalized the purchase earlier this year.\n\nDespite a call to open source the CDK, IBM is encouraging current users to adopt the HCL if they are not already doing so.\n\n‚ÄúIf you are not using AWS CDK, we highly recommend migrating to standard Terraform and HCL for long-term support and ecosystem alignment,‚Äù the company asserted.\n\nTerraform users with .tf files created under the CDK can convert them to HCL with the following command:\n\nThose using CDTF on Amazon Web Services infrastructure can also use AWS‚Äô own CDK.\n\nOverall, the Infrastructure as Code user base appears to be chafing from the limits of IaC.\n\nAs a result, many alternative approaches to Terraform have popped up in the last few years, including Adam Jacob‚Äôs System Initiative and Formae from Platform Engineering Labs.\n\nThey point to how HCL has its limits, especially for highly scalable environments. A declarative configuration language, HCL is limited in offering advanced programming constructs, and many resulting workarounds have resulted in obtuse code. Tooling is limited as well.\n\nThe advantage that the CDKTF brought to users was that it allowed them to detail deployment instructions through their own favorite programming language rather than HCL. CDKTF supported TypeScript, Python, C# and the Go programming language.\n\nThis is also the approach that Terraform competitor Pulumi has staked out, namely the ability to provision infrastructure in any one of a number of programming languages.\n\nYet, there has also been considerable debate around whether a general-purpose programming language is better than a domain-specific language. Terraform‚Äôs users are administrators, not programmers, as critics have pointed out.\n\nNonetheless, many of those in the IaC community took the news hard. Kubernetes expert David Flanagan noted that the development kit has gotten over 140,000 downloads per week for TypeScript alone, with similar numbers in other language communities.\n\nSo clearly, the CDKTF is still highly used by the community, he argued.\n\nFuck you, Hashicorp ‚Ä¶ an IBM Company. pic.twitter.com/h1EicnT3pL\n\n‚Äî David Flanagan (@rawkode), Dec. 11, 2025\n\n‚ÄúYou don‚Äôt kill a project with [an estimated] million users every single month because nobody likes it or it doesn‚Äôt have a ‚Äòmarket fit.‚Äô You kill it because it is not increasing your profit margin, it is not selling enterprise licenses,‚Äù Flanagan said in a short video.\n\nTo be fair, IBM has a long history of buying open source-based companies, and keeping the open source licensing intact, including the Linux-based Red Hat, the Cassandra-focused Datastax and, most recently, the Kafka-based Confluent. (There‚Äôs been no word, however, on whether IBM would revert the Terraform license back to open source.)\n\nFlanagan went on to note that people are probably using the CDKTF because they require the additional programming capabilities. ‚ÄúIt‚Äôs called Infrastructure as Code, not Infrastructure as JSON,‚Äù he quipped.\n\nSite reliability engineer Liz Fong-Jones¬†offered a more measured response.\n\n‚ÄúTo be more gentle about this, HashiCorp has decided to stop trying to compete with Pulumi with language-native APIs; they‚Äôre all in on HCL as the only way to work with Terraform,‚Äù Fong-Jones wrote on BlueSky.\n\nIn fact, others think this may not be a bad idea.\n\nPlatform Engineering Labs‚Äô Co-Founder and CEO Pavlo Baron thought the IBM move made sense.\n\n‚ÄúIBM is historically good at optimizing for the target buyer. This is rather a sign that nobody on the right side of the cycle wants to do full-blown programming. CDKs, and this includes the approach Pulumi takes, are exclusively for developers. Developers usually don‚Äôt operate infrastructure,‚Äù he wrote by email.\n\n‚ÄúSerious operations happen on the right side of the cycle, though. Thus, the CDK is missing their target user and addresses the wrong one. So I understand and support the logic behind this move.‚Äù",
    "readingTime": 5,
    "keywords": [
      "platform engineering",
      "engineering labs",
      "license mpl",
      "development kit",
      "cloud native",
      "language hcl",
      "configuration language",
      "programming language",
      "ibm company",
      "terraform license"
    ],
    "qualityScore": 1,
    "link": "https://thenewstack.io/ibm-hashicorp-sunsets-terraforms-external-language-support/",
    "thumbnail_url": "https://cdn.thenewstack.io/media/2025/12/65e7b1bd-ritu-dahiya-w2mlnx4yso-unsplash.jpg",
    "created_at": "2025-12-14T18:50:16.550Z",
    "topic": "tech"
  },
  {
    "slug": "component-party-compare-javascript-frameworks",
    "title": "Component Party ‚Äì Compare JavaScript Frameworks",
    "description": "Compare JavaScript frameworks side-by-side: React, Vue, Angular, Svelte, Solid.js, and more. See syntax differences, features, and code examples for web development frameworks.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://component-party.dev/?f=react-svelte5",
    "thumbnail_url": "https://component-party.dev/banner2.png",
    "created_at": "2025-12-14T03:53:12.102Z",
    "topic": "tech"
  },
  {
    "slug": "exmeta-staffer-nicknamed-coding-machine-says-the-best-engineers-arent-on-linkedin-but-theyre-special-cases",
    "title": "Ex-Meta staffer nicknamed 'coding machine' says the best engineers aren't on LinkedIn ‚Äî but they're special cases",
    "description": "Michael Novati , a former Meta principal software engineer, said the names of the best of the best engineers are \"nowhere\" online.",
    "fullText": "LinkedIn is full of corporate braggarts. But don't expect the best engineers to flaunt their success on the platform ‚Äî or even have an account, according one former Meta employee.\n\nMichael Novati spent almost eight years at Meta, back when it was still called Facebook and hadn't yet doubled down on AI. He reached the rank of principal software engineer and earned the nickname \"coding machine.\"\n\nOn the \"A Life Engineered\" podcast, host Steve Huynh asked Novati about his claim that the top five engineers aren't on LinkedIn. Novati stood by it.\n\n\"When I was at Facebook, the top engineers were like, 'If you had a LinkedIn account, people would be wondering if you're job hunting,'\" he said.\n\nNovati said these engineers don't need to publicly job hunt because of tech's extensive recruiting arm, which he called the \"secrets of the industry.\"\n\n\"There are very senior, very highly paid recruiters that work at the top companies who have very strong long-term social relationships with a lot of top engineers,\" he said.\n\nHow do these engineers and recruiters meet? Novati gave the example of an engineer who spends a week doing campus recruiting at Stanford, bonding with the company's recruiter in the process.\n\nHe referred to these as the \"secret backroom dealings of Silicon Valley.\"\n\n\"These engineers' names are nowhere, but they are the ones that are the most desirable by these recruiters,\" he said. \"The $100 million engineer is not on LinkedIn with a tagline that's like, #100millionengineer.\"\n\nTech recruiting has long been a large, lucrative industry. Big Tech companies both employ in-house recruiters and outside agencies to stay close to key talent.\n\nMeanwhile, talent is becoming increasingly competitive, particularly in the field of AI. Meta shelled out large contracts for its Superintelligence Labs, poaching engineers from its competitors.\n\nSometimes CEOs even get involved. Mark Zuckerberg reportedly made a list of the top AI talent to poach. OpenAI's chief research officer said that Zuckerberg hand-delivered soup to an employee he was trying to recruit.\n\nOne AI worker told Business Insider they got a personal call from OpenAI CEO Sam Altman, pitching them to join the company. They accepted.\n\nBeing offline may not be the golden key to tech recruiting, though. These top-tier engineers are a \"specific case,\" Novati said on the podcast.\n\n\"It doesn't mean that your strategy should be: delete LinkedIn and all the offers will come,\" he said.\n\nIt's a rarified class, Novati said, but one that stays away from all semblances of personal branding.\n\n\"I don't know any of those top engineers, who get special equity grants and special dinners with Bezos or whatever stuff like that, who have big personal brands,\" he said.",
    "readingTime": 3,
    "keywords": [
      "tech recruiting",
      "top engineers",
      "recruiters",
      "don't",
      "talent",
      "personal",
      "novati",
      "account",
      "employee",
      "facebook"
    ],
    "qualityScore": 1,
    "link": "https://www.businessinsider.com/best-engineers-not-on-linkedin-former-meta-employee-2025-12",
    "thumbnail_url": "https://i.insider.com/693ae21d832e0ef1ead60bb6?width=1200&format=jpeg",
    "created_at": "2025-12-12T13:47:21.490Z",
    "topic": "finance"
  },
  {
    "slug": "a-new-series-on-cracking-faanglevel-code-challenges",
    "title": "A New Series on Cracking FAANG-Level Code Challenges",
    "description": "One of the most fundamental algorithms that appears in interviews at big tech companies is Binary Search. Of course, nobody will ask you to implement binary search directly. However, as Jon Bentley cited in his famous book Programming Pearls, only a small percentage of people he asked‚Äî10% to be precise‚Äîwere able to code this algorithm without any errors.\nHere, I will show you a correct implementation of binary search, its variants that appear in interviews, and LeetCode problems that you can solve using these techniques.",
    "fullText": "One of the most fundamental algorithms that appears in interviews at big tech companies is Binary Search. Of course, nobody will ask you to implement binary search directly. However, as Jon Bentley cited in his famous book Programming Pearls, only a small percentage of people he asked‚Äî10% to be precise‚Äîwere able to code this algorithm without any errors.\n\nHere, I will show you a correct implementation of binary search, its variants that appear in interviews, and LeetCode problems that you can solve using these techniques.\n\nGiven an array of items, we can find the position of a specific item linearly by iterating over the array, comparing each item with the desired item, and returning the position when the current item equals the desired item.\n\nWe must also consider the case where the desired item is not in the array; in this case, we can return any value. Since we are talking about positions in an array, we can return -1 if the item is not present. This is a very simple concept and implementation. However, if the array is sorted, we can do better.\n\nWe can find the position of an item in logarithmic time (O(log n)), where n is the number of items in the array, when the array is sorted.\n\nTo do this, we repeatedly compare the item we are looking for with the middle element of the array. If the middle element is the one we are looking for, we have our result. Otherwise, we need to update the range of the array we are considering accordingly.\n\nIf the element we are looking for is greater than the middle element, we need to search in the higher part of the array. Otherwise, we need to search in the lower part of the array.\n\nWhat we just described is the Binary Search algorithm. Below is the implementation of the binary search algorithm in C++:\n\nThis is less than 20 lines of code that you need to understand very well if you want to be successful in an interview. Note that I said ‚Äúunderstand,‚Äù not ‚Äúmemorize.‚Äù\n\ncould be implemented in different ways, such as:\n\nCan you explain why the first implementation is better than the second?\n\nThe answer is integer overflow. When we add two integer numbers, we can exceed the maximum value allowed in the computer‚Äôs representation of an int. Knowing these details and how to answer such questions puts you in a much better position compared to other candidates.\n\nAs you can see, even a small detail can demonstrate your expertise and experience. All these small details together help you get the position you want.\n\nDespite these details, as I said, nobody will ask you to implement binary search directly. However, there are some important variants of the binary search algorithm that appear as part of problem-solving. I will describe four of them in the next sections.\n\nLet‚Äôs consider we have a sorted array with duplicate elements, such as [10, 20, 30, 30, 30, 40, 50]. Also, let‚Äôs assume we are searching for the element 30 and we need to find the smallest position of this element in case of duplication.\n\nWith the binary search algorithm implementation shown above, we cannot guarantee we will always return the smallest position of an element in case of duplication. However, we can modify the original algorithm to answer this question correctly.\n\nAnd here is a very important point: You can only make this modification if you know the binary search algorithm and its implementation well.\n\nThinking about the problem, instead of returning the position when we find the element in the array, we need to update our result and continue the search in the lower part of the array.\n\nUpdating the result instead of returning immediately is easy to see. You cannot return immediately because there may be duplicate elements in the array. Since we want the smallest position, we cannot just return.\n\nSo, why go to the lower part of the array instead of the higher part? The answer is because of the problem definition: we want the smallest index. So, if we find the element, in case of duplication, we are interested in the presence of this element before the current position.\n\nThe implementation in C++ could be:\n\nThis problem is similar to the one above, but now we are interested in the higher part of the array in case of duplication. This is because we want the largest index instead of the smallest one.\n\nIn this case, the implementation in C++ could be:\n\nThis is a little different, but only slightly. Now, we are not interested in finding an element, but the largest value less than the given element. So, every time we find an element that is smaller than our desired element, we need to update our result. We also need to update the considered range of the array.\n\nIn this case, we are interested in the higher part of the array, since we are trying to find the largest value less than our element.\n\nThe implementation in C++ could be:\n\nSimilar to the problem above, but now we are interested in finding the smallest value greater than the desired value. So, we need to update our result when we find a larger element instead of a smaller one.\n\nThe implementation in C++ could be:\n\nHere are some interesting problems to solve on LeetCode using the techniques explained in this post:",
    "readingTime": 5,
    "keywords": [
      "directly however",
      "duplicate elements",
      "implement binary",
      "search directly",
      "desired item",
      "middle element",
      "search algorithm",
      "smallest position",
      "array",
      "implementation"
    ],
    "qualityScore": 1,
    "link": "https://johnjr.dev/posts/binary-search/",
    "thumbnail_url": "https://johnjr.dev/jj1.jpg",
    "created_at": "2025-12-11T18:58:27.000Z",
    "topic": "tech"
  },
  {
    "slug": "craft-software-that-makes-people-feel-something",
    "title": "Craft software that makes people feel something",
    "description": "Recently, people have been asking me why I‚Äôm pausing Boo to work on a programming language. I think it would actually be cool to write down how I feel.",
    "fullText": "So, I woke up today. Got my coffee, family went to sleep, and I have a free afternoon.\n\nI thought about writing something. I may delete this article, but if you are reading this, it means I went through with it.\n\nRecently, people have been asking me why I‚Äôm pausing Boo to work on a programming language. I think it would actually be cool to write down how I feel.\n\nBoo is a code editor I created solely for myself; I never had the intention of making it a mainstream editor. Of course, it would be fun if people used it, but that was never my goal. This year I got it working in a functional state, where I can actually use it for my daily work. It has innovative human-keyboard navigation and replaces the LSP system with something faster and less costly for the OS. So why on earth am I not open-sourcing it? That‚Äôs what people keep asking me.\n\nMy mind isn‚Äôt really moved by the idea that it would be a success or a failure ‚Äî the end user of Boo is me. I don‚Äôt feel it‚Äôs there yet; in fact, I think software should inspire us. Working on Rio Terminal and Boo in my free time ‚Äî both written in Rust and sharing many similarities ‚Äî affects my joy, because it starts to become something automatic. Both have similar architecture, language, release process, and etcetera.\n\nSince I was a kid, I liked to build Lego blocks. That‚Äôs probably what I did the most besides playing football or video games. The fun thing about Lego is that one day you can build a castle, and the next day you can build a ship. Not necessarily using the same pieces and colors ‚Äî you can actually add a lot of stuff that‚Äôs external to what you have, like a wood stick.\n\nWhen programming becomes repetitive, the odds of you creating something that makes people go ‚Äúwow‚Äù are reduced quite a bit. It isn‚Äôt a rule, of course. You need to be inspired to make inspiring software.\n\nI always use the example of The Legend of Zelda: Breath of the Wild. This game is so well crafted that I know people who don‚Äôt even like video games but bought a console just to play it ‚Äî and once they finished, they sold everything. This is what I‚Äôm talking about: taking time to build something so that once people try it, they remember it for as long as they live.\n\nBoo isn‚Äôt a business. I don‚Äôt need or want to make money out of it. I don‚Äôt have a deadline, nor do I want to create another VS Code. I don‚Äôt feel like forcing it to happen.\n\nIn that case, I don‚Äôt necessarily need to stop building Lego blocks, right? I‚Äôll just park it there, and when the inspiration comes back, I‚Äôll pick it up where it was. That being said, I paused Boo, and I am working on my own programming language. Eventually, my idea is to rewrite Boo to use it.\n\n‚ÄúWow! That‚Äôs a lot of work.‚Äù Indeed. But it‚Äôs my hobby stuff. I‚Äôve always loved programming languages, and I am having a blast learning more about binaries and compilers. So, I don‚Äôt really feel I need to follow people‚Äôs cake recipe for success. That‚Äôs how my mind works, and I will stick with it.",
    "readingTime": 3,
    "keywords": [
      "lego blocks",
      "programming language",
      "don‚Äôt",
      "isn‚Äôt",
      "free",
      "course",
      "mind",
      "idea",
      "success",
      "it‚Äôs"
    ],
    "qualityScore": 1,
    "link": "https://rapha.land/craft-software-that-makes-people-feel-something/",
    "thumbnail_url": "https://rapha.land/assets/images/banner.jpg",
    "created_at": "2025-12-11T13:53:41.026Z",
    "topic": "tech"
  },
  {
    "slug": "unreal-blueprintlike-mcp-server-builder-no-coding-knowledge-required",
    "title": "Unreal Blueprint-Like MCP Server Builder (No Coding Knowledge Required)",
    "description": "A Blueprint-style visual node editor for creating FastMCP servers. Build MCP tools, resources, and prompts by connecting nodes - no coding required. - PhialsBasement/GUI-MCP",
    "fullText": "PhialsBasement\n\n /\n\n GUI-MCP\n\n Public\n\n A Blueprint-style visual node editor for creating FastMCP servers. Build MCP tools, resources, and prompts by connecting nodes - no coding required.\n\n 3\n stars\n\n 0\n forks\n\n Branches\n\n Tags\n\n Activity\n\n Star\n\n Notifications\n You must be signed in to change notification settings\n\n PhialsBasement/GUI-MCP",
    "readingTime": 1,
    "keywords": [],
    "qualityScore": 0.4,
    "link": "https://github.com/PhialsBasement/GUI-MCP",
    "thumbnail_url": "https://opengraph.githubassets.com/619d24ecdcaf5477d9914c9ee0acb987700aa86035c0d50b25f6cd7d76ac6c38/PhialsBasement/GUI-MCP",
    "created_at": "2025-12-11T03:50:15.379Z",
    "topic": "tech"
  },
  {
    "slug": "young-people-are-growing-up-fluent-in-ai-and-thats-helping-them-stand-apart-from-their-older-peers-says-gen-z-founder",
    "title": "Young people are ‚Äògrowing up fluent in AI‚Äô and that‚Äôs helping them stand apart from their older peers, says Gen Z founder Kiara Nirghin",
    "description": "Nirghin explained that young entrepreneurs see coding as something to be done alongside AI agents, rather than done alone and from scratch.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/10/gen-z-growing-up-fluent-ai-helping-stand-apart-from-older-peers/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974872644_4c9966d747_o.jpg?resize=1200,600",
    "created_at": "2025-12-10T18:55:46.731Z",
    "topic": "business"
  },
  {
    "slug": "the-boundary-of-copyrightability-in-aigenerated-code-under-j",
    "title": "The boundary of copyrightability in AI-generated code under Japan and US Law",
    "description": "When GitHub Copilot first appeared, many developers viewed it as an assistive tool for coding. The honest impression of most developers was likely that while it was useful, it was not a tool to whi‚Ä¶",
    "fullText": "A Curious Phenomenon with Gemma Model Outputs and License¬†Propagation While examining the licensing details of Google‚Äôs Gemma model, I noticed a potentially puzzling phenomenon: you can freely assign a license to the model‚Äôs outputs, yet depending on how those outputs are used, the original Terms of Use might suddenly propagate to the resulting work. Outputs vs. Model Derivatives The Gemma Terms of Use distinguish‚Ä¶",
    "readingTime": 1,
    "keywords": [
      "gemma model",
      "outputs",
      "license",
      "phenomenon"
    ],
    "qualityScore": 0,
    "link": "https://shujisado.org/2025/12/10/the-boundary-of-copyrightability-in-ai-generated-code/",
    "thumbnail_url": "https://shujisado.org/wp-content/uploads/2025/12/chatgpt-image-2025e5b9b412e69c8810e697a5-21_53_59.png",
    "created_at": "2025-12-10T13:50:09.359Z",
    "topic": "tech"
  },
  {
    "slug": "databricks-ceo-ali-ghodsi-says-his-company-will-be-worth-1-t",
    "title": "Databricks CEO Ali Ghodsi says his company will be worth $1 trillion by doing these three things",
    "description": "Databricks CEO says AI-powered coding, enterprise agents, and rapid app development could propel it into the trillion-dollar club.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/databticks-ceo-1-trillion-valuation-agents-brainstorm-ai/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/54974307746_cdbc8c031a_o.jpg?resize=1200,600",
    "created_at": "2025-12-10T03:48:33.338Z",
    "topic": "business"
  }
]
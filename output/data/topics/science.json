[
  {
    "slug": "why-ai-reading-science-fiction-could-be-a-problem",
    "title": "Why AI reading science fiction could be a problem",
    "description": "The theory that we’re accidentally teaching AI to turn against us",
    "fullText": "Discussion about this postRestacksPeter Bowden 26mOur team's work with LLM metognition shows some promise in addressing this. Enabling a more dynamic cognitive process allows models to reason beyond the stochastic patterns. The challenge is that it makes for a more aware system. As the technology progresses, I expect humanity will have to choose between the benefits of a more conscious process and having AI that are just tools. Expand full commentReplyShareNo postsReady for more?",
    "readingTime": 1,
    "keywords": [
      "process"
    ],
    "qualityScore": 0.3,
    "link": "https://www.transformernews.ai/p/why-ai-reading-science-fiction-could",
    "thumbnail_url": "https://substackcdn.com/image/fetch/$s_!-mwr!,w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4c1abe9-26dd-44d0-a196-d5321951f56f_3000x2286.jpeg",
    "created_at": "2025-12-09T18:53:30.938Z",
    "topic": "tech"
  },
  {
    "slug": "the-clara7b-models-unify-rag-and-provide-builtin-semantic-do",
    "title": "The CLaRa-7B models unify RAG and provide built-in semantic doc compression",
    "description": "We’re on a journey to advance and democratize artificial intelligence through open source and open science.",
    "fullText": "The CLaRa-7B-Base model is our foundational unified RAG model with built-in semantic document compression (16× and 128x).\nIt provides a base compressor + generator capable of producing answers directly from compressed document representations.\n\nTraining recipe: Trained using QA-guided semantic compression and paraphrase consistency objectives.\nBenchmarks: Strong baseline performance across multi-hop QA tasks under a 16× compression ratio.\n\nPaper: CLaRa: Bridging Retrieval and Generation with Continuous Latent Reasoning\nGitHub: https://github.com/apple/ml-clara",
    "readingTime": 1,
    "keywords": [
      "compression",
      "model",
      "semantic",
      "document"
    ],
    "qualityScore": 0.55,
    "link": "https://huggingface.co/apple/CLaRa-7B-Base",
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/models/apple/CLaRa-7B-Base.png",
    "created_at": "2025-12-09T18:53:30.905Z",
    "topic": "tech"
  },
  {
    "slug": "ceo-says-hes-started-giving-job-candidates-live-feedback-in",
    "title": "CEO says he’s started giving job candidates live feedback in the interview—and if they ‘freeze up’ or ‘get offended’ they’re not fit for the role",
    "description": "Forget waiting days for feedback—one CEO delivers it live, sometimes in front of a full panel, to test candidates’ reactions. Experts call it “an insensitive science experiment” but warn the practice is on the rise.",
    "fullText": null,
    "readingTime": 0,
    "keywords": [],
    "qualityScore": 0,
    "link": "https://fortune.com/2025/12/09/ceo-gives-job-candidates-live-feedback-in-the-interview-if-they-freeze-up-or-get-offended-theyre-not-fit-for-the-role-red-flag-test-hiring/",
    "thumbnail_url": "https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2247099195-e1765279772451.jpg?resize=1200,600",
    "created_at": "2025-12-09T13:48:21.830Z",
    "topic": "business"
  }
]